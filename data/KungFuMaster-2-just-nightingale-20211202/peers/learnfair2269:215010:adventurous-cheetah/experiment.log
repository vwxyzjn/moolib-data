[INFO:learnfair2269:215010:adventurous-cheetah experiment:228 2021-12-02 11:15:42,355] flags:
{'actor_batch_size': 128,
 'baseline_cost': 0.5,
 'batch_size': 32,
 'checkpoint_history_interval': 3600,
 'checkpoint_interval': 600,
 'connect': '100.97.72.44:4431',
 'device': 'cuda:0',
 'discounting': 0.99,
 'entity': None,
 'entropy_cost': 0.0006,
 'env': {'name': 'ALE/KungFuMaster-v5', 'repeat_action_probability': 0.0, 'num_action_repeats': 4, 'noop_max': 30},
 'exp_set': 'vtrace-run-13',
 'fixup_init': True,
 'grad_norm_clipping': 40,
 'group': 'KungFuMaster-2-just-nightingale-20211202',
 'local_name': 'learnfair2269:215010:adventurous-cheetah',
 'localdir': '/checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/peers/learnfair2269:215010:adventurous-cheetah',
 'log_fmt': '[%(levelname)s:learnfair2269:215010:adventurous-cheetah '
            '%(module)s:%(lineno)d %(asctime)s] %(message)s',
 'log_interval': 10,
 'num_actor_batches': 2,
 'num_actor_cpus': 10,
 'optimizer': {'learning_rate': 0.0006, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-08},
 'project': 'moolib-atari',
 'reward_clip': 1.0,
 'savedir': '/checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202',
 'state_counter': 'none',
 'total_steps': 50000000.0,
 'unroll_length': 20,
 'use_lstm': False,
 'virtual_batch_size': 32,
 'wandb': True,
 'warmup': 0}

[INFO:learnfair2269:215010:adventurous-cheetah experiment:233 2021-12-02 11:15:42,358] savedir: /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202 (symlinked as 'latest')
[INFO:learnfair2269:215010:adventurous-cheetah experiment:243 2021-12-02 11:15:42,358] train_id: hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202
[INFO:learnfair2269:215010:adventurous-cheetah experiment:260 2021-12-02 11:15:45,326] Number of model parameters: 1094476
[INFO:learnfair2269:215010:adventurous-cheetah experiment:350 2021-12-02 11:15:51,071] Optimising CuDNN kernels
[INFO:learnfair2269:215010:adventurous-cheetah experiment:387 2021-12-02 11:15:51,072] Your training will commence shortly.
[INFO:learnfair2269:215010:adventurous-cheetah experiment:387 2021-12-02 11:15:52,073] Your training will commence shortly.
[INFO:learnfair2269:215010:adventurous-cheetah experiment:394 2021-12-02 11:15:53,091] Training started. Leader is me!, 1 members, model version is 0
[INFO:learnfair2269:215010:adventurous-cheetah experiment:444 2021-12-02 11:15:53,096] Created symlink /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/leader-000 -> /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/peers/learnfair2269:215010:adventurous-cheetah
[INFO:learnfair2269:215010:adventurous-cheetah experiment:449 2021-12-02 11:15:53,096] Training a new model from scratch.
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:04,627] calculate_sps 0 steps in 13.5527
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:04,642] calculate_sps 0 steps in 13.5527
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:04,642] {'local/mean_episode_return': None, 'local/mean_episode_step': None, 'local/SPS': 0.0, 'local/env_act_steps': 256, 'local/env_train_steps': 0, 'local/optimizer_steps': 0, 'local/running_reward': 0.0, 'local/running_step': 1.0, 'local/steps_done': 256, 'local/episodes_done': 0, 'local/unclipped_grad_norm': None, 'local/model_version': 0, 'local/virtual_batch_size': None, 'local/num_gradients': None}
[INFO:learnfair2269:215010:adventurous-cheetah record:22 2021-12-02 11:16:04,645] Writing logs to logs.tsv
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:04,646] {'global/mean_episode_return': None, 'global/mean_episode_step': None, 'global/SPS': 0.0, 'global/env_act_steps': 256, 'global/env_train_steps': 0, 'global/optimizer_steps': 0, 'global/running_reward': 0.0, 'global/running_step': 1.0, 'global/steps_done': 256, 'global/episodes_done': 0, 'global/unclipped_grad_norm': None, 'global/model_version': 0, 'global/virtual_batch_size': None, 'global/num_gradients': None}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:14,631] calculate_sps 30720 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:14,632] calculate_sps 24960 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:14,632] {'local/mean_episode_return': None, 'local/mean_episode_step': None, 'local/SPS': 3070.1635252789088, 'local/env_act_steps': 33280, 'local/env_train_steps': 30720, 'local/optimizer_steps': 48, 'local/running_reward': 0.0, 'local/running_step': 66.0, 'local/steps_done': 33280, 'local/episodes_done': 0, 'local/unclipped_grad_norm': 0.15116682377023002, 'local/model_version': 48, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:14,634] {'global/mean_episode_return': None, 'global/mean_episode_step': None, 'global/SPS': 2494.5078642891135, 'global/env_act_steps': 26624, 'global/env_train_steps': 24960, 'global/optimizer_steps': 38, 'global/running_reward': 0.0, 'global/running_step': 53.0, 'global/steps_done': 26624, 'global/episodes_done': 0, 'global/unclipped_grad_norm': 0.1600719335194873, 'global/model_version': 38, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:24,661] calculate_sps 31360 steps in 10.0295
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:24,661] calculate_sps 31360 steps in 10.0295
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:24,661] {'local/mean_episode_return': None, 'local/mean_episode_step': None, 'local/SPS': 3126.7734812098643, 'local/env_act_steps': 66688, 'local/env_train_steps': 62080, 'local/optimizer_steps': 96, 'local/running_reward': 103.0411877394636, 'local/running_step': 195.75095785440612, 'local/steps_done': 66688, 'local/episodes_done': 0, 'local/unclipped_grad_norm': 0.2733585158518205, 'local/model_version': 96, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:24,662] {'global/mean_episode_return': None, 'global/mean_episode_step': None, 'global/SPS': 3126.7734812098643, 'global/env_act_steps': 60672, 'global/env_train_steps': 56320, 'global/optimizer_steps': 88, 'global/running_reward': 69.95124530075188, 'global/running_step': 171.0, 'global/steps_done': 60672, 'global/episodes_done': 0, 'global/unclipped_grad_norm': 0.23563506284728647, 'global/model_version': 88, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:34,688] calculate_sps 35200 steps in 10.0267
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:34,688] calculate_sps 35840 steps in 10.0267
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:34,689] {'local/mean_episode_return': None, 'local/mean_episode_step': None, 'local/SPS': 3510.626870391826, 'local/env_act_steps': 99200, 'local/env_train_steps': 97280, 'local/optimizer_steps': 152, 'local/running_reward': 387.5553641732283, 'local/running_step': 324.5, 'local/steps_done': 99200, 'local/episodes_done': 0, 'local/unclipped_grad_norm': 0.32925794792494606, 'local/model_version': 152, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:34,690] {'global/mean_episode_return': None, 'global/mean_episode_step': None, 'global/SPS': 3574.4564498534955, 'global/env_act_steps': 93184, 'global/env_train_steps': 92160, 'global/optimizer_steps': 143, 'global/running_reward': 323.8035187007874, 'global/running_step': 301.0, 'global/steps_done': 93184, 'global/episodes_done': 0, 'global/unclipped_grad_norm': 0.32763251249085773, 'global/model_version': 143, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:44,702] calculate_sps 30720 steps in 10.0142
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:44,702] calculate_sps 30720 steps in 10.0142
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:44,703] {'local/mean_episode_return': None, 'local/mean_episode_step': None, 'local/SPS': 3067.6332180757895, 'local/env_act_steps': 132992, 'local/env_train_steps': 128000, 'local/optimizer_steps': 200, 'local/running_reward': 729.78515625, 'local/running_step': 454.0, 'local/steps_done': 132992, 'local/episodes_done': 0, 'local/unclipped_grad_norm': 0.41484527437326807, 'local/model_version': 200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:44,704] {'global/mean_episode_return': None, 'global/mean_episode_step': None, 'global/SPS': 3067.6332180757895, 'global/env_act_steps': 127360, 'global/env_train_steps': 122880, 'global/optimizer_steps': 192, 'global/running_reward': 666.6081460674158, 'global/running_step': 431.250936329588, 'global/steps_done': 127360, 'global/episodes_done': 0, 'global/unclipped_grad_norm': 0.37364924623041734, 'global/model_version': 192, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:54,706] calculate_sps 35200 steps in 10.0038
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:16:54,706] calculate_sps 35840 steps in 10.0038
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:54,707] {'local/mean_episode_return': None, 'local/mean_episode_step': None, 'local/SPS': 3518.6776133723356, 'local/env_act_steps': 164864, 'local/env_train_steps': 163200, 'local/optimizer_steps': 255, 'local/running_reward': 1005.5817018072289, 'local/running_step': 582.2489959839357, 'local/steps_done': 164864, 'local/episodes_done': 0, 'local/unclipped_grad_norm': 0.31013972542502666, 'local/model_version': 255, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:16:54,708] {'global/mean_episode_return': None, 'global/mean_episode_step': None, 'global/SPS': 3582.6535699791057, 'global/env_act_steps': 159744, 'global/env_train_steps': 158720, 'global/optimizer_steps': 247, 'global/running_reward': 971.7514822134387, 'global/running_step': 561.2490118577075, 'global/steps_done': 159744, 'global/episodes_done': 0, 'global/unclipped_grad_norm': 0.33228629346598276, 'global/model_version': 247, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:04,714] calculate_sps 31360 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:04,715] calculate_sps 30720 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:04,715] {'local/mean_episode_return': 500.0, 'local/mean_episode_step': 753.0, 'local/SPS': 3133.285579090075, 'local/env_act_steps': 198016, 'local/env_train_steps': 194560, 'local/optimizer_steps': 304, 'local/running_reward': 1265.1182432432433, 'local/running_step': 708.3444437741313, 'local/steps_done': 198016, 'local/episodes_done': 2, 'local/unclipped_grad_norm': 0.33260270071272946, 'local/model_version': 304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:04,727] {'global/mean_episode_return': 600.0, 'global/mean_episode_step': 733.0, 'global/SPS': 3069.3409754351756, 'global/env_act_steps': 193024, 'global/env_train_steps': 189440, 'global/optimizer_steps': 296, 'global/running_reward': 1215.9525240384614, 'global/running_step': 689.0374699519231, 'global/steps_done': 193024, 'global/episodes_done': 1, 'global/unclipped_grad_norm': 0.347786938201408, 'global/model_version': 296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:14,762] calculate_sps 32640 steps in 10.048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:14,762] calculate_sps 33280 steps in 10.048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:14,762] {'local/mean_episode_return': 1230.7692307692307, 'local/mean_episode_step': 849.3846153846154, 'local/SPS': 3248.3987479072584, 'local/env_act_steps': 230784, 'local/env_train_steps': 227200, 'local/optimizer_steps': 354, 'local/running_reward': 1598.931884765625, 'local/running_step': 815.0704650878906, 'local/steps_done': 230784, 'local/episodes_done': 15, 'local/unclipped_grad_norm': 0.35500511780381205, 'local/model_version': 354, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:14,763] {'global/mean_episode_return': 1030.0, 'global/mean_episode_step': 825.9, 'global/SPS': 3312.0928410034794, 'global/env_act_steps': 225792, 'global/env_train_steps': 222720, 'global/optimizer_steps': 347, 'global/running_reward': 1554.0557861328125, 'global/running_step': 801.8168640136719, 'global/steps_done': 225792, 'global/episodes_done': 11, 'global/unclipped_grad_norm': 0.36139079300211924, 'global/model_version': 347, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:24,764] calculate_sps 33920 steps in 10.0017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:24,765] calculate_sps 33280 steps in 10.0017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:24,765] {'local/mean_episode_return': 1450.0, 'local/mean_episode_step': 960.55, 'local/SPS': 3391.4229985590523, 'local/env_act_steps': 263168, 'local/env_train_steps': 261120, 'local/optimizer_steps': 408, 'local/running_reward': 1869.4756669960475, 'local/running_step': 877.1555397727273, 'local/steps_done': 263168, 'local/episodes_done': 35, 'local/unclipped_grad_norm': 0.3493363791041904, 'local/model_version': 408, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:24,766] {'global/mean_episode_return': 1439.1304347826087, 'global/mean_episode_step': 945.1739130434783, 'global/SPS': 3327.433885378693, 'global/env_act_steps': 258944, 'global/env_train_steps': 256000, 'global/optimizer_steps': 400, 'global/running_reward': 1829.615106177606, 'global/running_step': 869.8689370173745, 'global/steps_done': 258944, 'global/episodes_done': 34, 'global/unclipped_grad_norm': 0.32957474057966807, 'global/model_version': 400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:34,771] calculate_sps 30720 steps in 10.0071
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:34,771] calculate_sps 32000 steps in 10.0071
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:34,772] {'local/mean_episode_return': 2012.5, 'local/mean_episode_step': 1085.1666666666667, 'local/SPS': 3069.8130813867606, 'local/env_act_steps': 296576, 'local/env_train_steps': 291840, 'local/optimizer_steps': 456, 'local/running_reward': 2113.2932231800764, 'local/running_step': 913.4163074712644, 'local/steps_done': 296576, 'local/episodes_done': 59, 'local/unclipped_grad_norm': 0.3694648921179275, 'local/model_version': 456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:34,773] {'global/mean_episode_return': 1987.5, 'global/mean_episode_step': 1080.0416666666667, 'global/SPS': 3197.721959777876, 'global/env_act_steps': 292224, 'global/env_train_steps': 288000, 'global/optimizer_steps': 449, 'global/running_reward': 2087.9146634615386, 'global/running_step': 909.9245492788461, 'global/steps_done': 292224, 'global/episodes_done': 58, 'global/unclipped_grad_norm': 0.3709098552258647, 'global/model_version': 449, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:44,779] calculate_sps 35200 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:44,780] calculate_sps 34560 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:44,780] {'local/mean_episode_return': 2508.3333333333335, 'local/mean_episode_step': 1217.875, 'local/SPS': 3517.1807571159784, 'local/env_act_steps': 328704, 'local/env_train_steps': 327040, 'local/optimizer_steps': 511, 'local/running_reward': 2282.610184262948, 'local/running_step': 936.707015687251, 'local/steps_done': 328704, 'local/episodes_done': 83, 'local/unclipped_grad_norm': 0.37855094359679653, 'local/model_version': 511, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:44,781] {'global/mean_episode_return': 2473.913043478261, 'global/mean_episode_step': 1210.1304347826087, 'global/SPS': 3453.2320160775057, 'global/env_act_steps': 324736, 'global/env_train_steps': 322560, 'global/optimizer_steps': 504, 'global/running_reward': 2265.95718503937, 'global/running_step': 935.1262610728346, 'global/steps_done': 324736, 'global/episodes_done': 81, 'global/unclipped_grad_norm': 0.39391043375838886, 'global/model_version': 504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:54,784] calculate_sps 31360 steps in 10.0043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:17:54,784] calculate_sps 30720 steps in 10.0043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:54,784] {'local/mean_episode_return': 2730.769230769231, 'local/mean_episode_step': 1348.7692307692307, 'local/SPS': 3134.6580390989766, 'local/env_act_steps': 362112, 'local/env_train_steps': 358400, 'local/optimizer_steps': 560, 'local/running_reward': 2445.48910440613, 'local/running_step': 975.6056034482758, 'local/steps_done': 362112, 'local/episodes_done': 96, 'local/unclipped_grad_norm': 0.32297199455146886, 'local/model_version': 560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:17:54,786] {'global/mean_episode_return': 2760.0, 'global/mean_episode_step': 1338.7333333333333, 'global/SPS': 3070.6854260561404, 'global/env_act_steps': 358400, 'global/env_train_steps': 353280, 'global/optimizer_steps': 552, 'global/running_reward': 2420.9006653992396, 'global/running_step': 968.677845769962, 'global/steps_done': 358400, 'global/episodes_done': 96, 'global/unclipped_grad_norm': 0.32193722754406434, 'global/model_version': 552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:04,826] calculate_sps 33280 steps in 10.0427
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:04,826] calculate_sps 35840 steps in 10.0427
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:04,826] {'local/mean_episode_return': 3555.0, 'local/mean_episode_step': 1485.4, 'local/SPS': 3313.85204667696, 'local/env_act_steps': 394752, 'local/env_train_steps': 391680, 'local/optimizer_steps': 611, 'local/running_reward': 2626.9607843137255, 'local/running_step': 1019.5108455882353, 'local/steps_done': 394752, 'local/episodes_done': 116, 'local/unclipped_grad_norm': 0.35823379427778956, 'local/model_version': 611, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:04,827] {'global/mean_episode_return': 3712.5, 'global/mean_episode_step': 1474.3125, 'global/SPS': 3568.7637425751877, 'global/env_act_steps': 390656, 'global/env_train_steps': 389120, 'global/optimizer_steps': 608, 'global/running_reward': 2611.7404513888887, 'global/running_step': 1017.7304997519841, 'global/steps_done': 390656, 'global/episodes_done': 112, 'global/unclipped_grad_norm': 0.3512758093753031, 'global/model_version': 608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:14,851] calculate_sps 33280 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:14,851] calculate_sps 30720 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:14,852] {'local/mean_episode_return': 4028.2608695652175, 'local/mean_episode_step': 1597.7391304347825, 'local/SPS': 3319.7263756459856, 'local/env_act_steps': 427648, 'local/env_train_steps': 424960, 'local/optimizer_steps': 664, 'local/running_reward': 2641.2329766536964, 'local/running_step': 996.6444248540856, 'local/steps_done': 427648, 'local/episodes_done': 140, 'local/unclipped_grad_norm': 0.3642651759228616, 'local/model_version': 664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:14,853] {'global/mean_episode_return': 3767.3076923076924, 'global/mean_episode_step': 1584.5, 'global/SPS': 3064.362808288602, 'global/env_act_steps': 424448, 'global/env_train_steps': 419840, 'global/optimizer_steps': 656, 'global/running_reward': 2641.4328835227275, 'global/running_step': 998.8277994791666, 'global/steps_done': 424448, 'global/episodes_done': 139, 'global/unclipped_grad_norm': 0.36244669525573653, 'global/model_version': 656, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:24,894] calculate_sps 31360 steps in 10.0437
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:24,895] calculate_sps 35200 steps in 10.0437
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:24,895] {'local/mean_episode_return': 4064.285714285714, 'local/mean_episode_step': 1733.0714285714287, 'local/SPS': 3122.370211552782, 'local/env_act_steps': 460928, 'local/env_train_steps': 456320, 'local/optimizer_steps': 712, 'local/running_reward': 2761.5474759615386, 'local/running_step': 1012.859765625, 'local/steps_done': 460928, 'local/episodes_done': 154, 'local/unclipped_grad_norm': 0.4148857429002722, 'local/model_version': 712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:24,896] {'global/mean_episode_return': 4220.0, 'global/mean_episode_step': 1728.8666666666666, 'global/SPS': 3504.7012578653676, 'global/env_act_steps': 456704, 'global/env_train_steps': 455040, 'global/optimizer_steps': 711, 'global/running_reward': 2739.152405753968, 'global/running_step': 1009.8352864583334, 'global/steps_done': 456704, 'global/episodes_done': 154, 'global/unclipped_grad_norm': 0.40780936154452235, 'global/model_version': 711, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:34,915] calculate_sps 35200 steps in 10.0202
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:34,915] calculate_sps 31360 steps in 10.0202
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:34,916] {'local/mean_episode_return': 4666.666666666667, 'local/mean_episode_step': 1871.888888888889, 'local/SPS': 3512.9047649582994, 'local/env_act_steps': 493312, 'local/env_train_steps': 491520, 'local/optimizer_steps': 768, 'local/running_reward': 3031.367341897233, 'local/running_step': 1066.940340909091, 'local/steps_done': 493312, 'local/episodes_done': 163, 'local/unclipped_grad_norm': 0.3906494223379663, 'local/model_version': 768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:34,917] {'global/mean_episode_return': 4762.5, 'global/mean_episode_step': 1866.125, 'global/SPS': 3129.6787905992123, 'global/env_act_steps': 490368, 'global/env_train_steps': 486400, 'global/optimizer_steps': 760, 'global/running_reward': 3001.2773288973385, 'global/running_step': 1059.7088284220533, 'global/steps_done': 490368, 'global/episodes_done': 162, 'global/unclipped_grad_norm': 0.39683197195432623, 'global/model_version': 760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:44,939] calculate_sps 30720 steps in 10.0242
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:44,939] calculate_sps 34560 steps in 10.0242
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:44,940] {'local/mean_episode_return': 5415.625, 'local/mean_episode_step': 1991.6875, 'local/SPS': 3064.586853086298, 'local/env_act_steps': 526848, 'local/env_train_steps': 522240, 'local/optimizer_steps': 816, 'local/running_reward': 3196.040076335878, 'local/running_step': 1093.6753936068703, 'local/steps_done': 526848, 'local/episodes_done': 180, 'local/unclipped_grad_norm': 0.3662452350060145, 'local/model_version': 816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:44,951] {'global/mean_episode_return': 5190.625, 'global/mean_episode_step': 1983.0625, 'global/SPS': 3447.6602097220853, 'global/env_act_steps': 523008, 'global/env_train_steps': 520960, 'global/optimizer_steps': 813, 'global/running_reward': 3187.1783088235293, 'global/running_step': 1093.5720894607844, 'global/steps_done': 523008, 'global/episodes_done': 179, 'global/unclipped_grad_norm': 0.3606271002933664, 'global/model_version': 813, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:54,942] calculate_sps 34560 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:18:54,942] calculate_sps 32000 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:54,942] {'local/mean_episode_return': 5972.727272727273, 'local/mean_episode_step': 2113.7272727272725, 'local/SPS': 3455.072041832179, 'local/env_act_steps': 558976, 'local/env_train_steps': 556800, 'local/optimizer_steps': 870, 'local/running_reward': 3278.212151394422, 'local/running_step': 1100.757470119522, 'local/steps_done': 558976, 'local/episodes_done': 192, 'local/unclipped_grad_norm': 0.42774144063393277, 'local/model_version': 870, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:18:54,944] {'global/mean_episode_return': 6100.0, 'global/mean_episode_step': 2108.9166666666665, 'global/SPS': 3199.14077947424, 'global/env_act_steps': 556288, 'global/env_train_steps': 552960, 'global/optimizer_steps': 864, 'global/running_reward': 3266.649639423077, 'global/running_step': 1098.6167067307692, 'global/steps_done': 556288, 'global/episodes_done': 192, 'global/unclipped_grad_norm': 0.43079252219667624, 'global/model_version': 864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:04,961] calculate_sps 32000 steps in 10.019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:04,961] calculate_sps 32640 steps in 10.019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:04,961] {'local/mean_episode_return': 5962.5, 'local/mean_episode_step': 1990.5, 'local/SPS': 3193.925204677507, 'local/env_act_steps': 591872, 'local/env_train_steps': 588800, 'local/optimizer_steps': 920, 'local/running_reward': 3495.7563229571983, 'local/running_step': 1145.3080009727626, 'local/steps_done': 591872, 'local/episodes_done': 200, 'local/unclipped_grad_norm': 0.35551109120249746, 'local/model_version': 920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:04,963] {'global/mean_episode_return': 6442.857142857143, 'global/mean_episode_step': 2058.285714285714, 'global/SPS': 3257.803708771057, 'global/env_act_steps': 589184, 'global/env_train_steps': 585600, 'global/optimizer_steps': 914, 'global/running_reward': 3470.1969844357977, 'global/running_step': 1139.8493129863814, 'global/steps_done': 589184, 'global/episodes_done': 199, 'global/unclipped_grad_norm': 0.358217376023531, 'global/model_version': 914, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:14,991] calculate_sps 32000 steps in 10.0309
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:14,992] calculate_sps 33920 steps in 10.0309
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:14,992] {'local/mean_episode_return': 7400.0, 'local/mean_episode_step': 2385.1, 'local/SPS': 3190.139881278772, 'local/env_act_steps': 624896, 'local/env_train_steps': 620800, 'local/optimizer_steps': 969, 'local/running_reward': 3803.1431686046512, 'local/running_step': 1208.3932594476744, 'local/steps_done': 624896, 'local/episodes_done': 210, 'local/unclipped_grad_norm': 0.4042233879468879, 'local/model_version': 969, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:14,993] {'global/mean_episode_return': 6963.636363636364, 'global/mean_episode_step': 2306.090909090909, 'global/SPS': 3381.5482741554983, 'global/env_act_steps': 622208, 'global/env_train_steps': 619520, 'global/optimizer_steps': 968, 'global/running_reward': 3785.2864583333335, 'global/running_step': 1205.5419391957364, 'global/steps_done': 622208, 'global/episodes_done': 210, 'global/unclipped_grad_norm': 0.40409488258538423, 'global/model_version': 968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:25,008] calculate_sps 34560 steps in 10.0161
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:25,008] calculate_sps 31360 steps in 10.0161
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:25,009] {'local/mean_episode_return': 7320.0, 'local/mean_episode_step': 2326.2, 'local/SPS': 3450.4473541959246, 'local/env_act_steps': 657152, 'local/env_train_steps': 655360, 'local/optimizer_steps': 1024, 'local/running_reward': 3883.1101190476193, 'local/running_step': 1230.536892361111, 'local/steps_done': 657152, 'local/episodes_done': 220, 'local/unclipped_grad_norm': 0.34867986460978334, 'local/model_version': 1024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:25,010] {'global/mean_episode_return': 7320.0, 'global/mean_episode_step': 2326.2, 'global/SPS': 3130.9614880666722, 'global/env_act_steps': 655488, 'global/env_train_steps': 650880, 'global/optimizer_steps': 1016, 'global/running_reward': 3879.7806490384614, 'global/running_step': 1228.117157451923, 'global/steps_done': 655488, 'global/episodes_done': 220, 'global/unclipped_grad_norm': 0.3404747729655355, 'global/model_version': 1016, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:35,026] calculate_sps 30720 steps in 10.0184
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:35,027] calculate_sps 35200 steps in 10.0184
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:35,027] {'local/mean_episode_return': 7375.0, 'local/mean_episode_step': 2493.625, 'local/SPS': 3066.3703940909722, 'local/env_act_steps': 690944, 'local/env_train_steps': 686080, 'local/optimizer_steps': 1072, 'local/running_reward': 4072.1413352272725, 'local/running_step': 1277.232362689394, 'local/steps_done': 690944, 'local/episodes_done': 228, 'local/unclipped_grad_norm': 0.478004387114197, 'local/model_version': 1072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:35,039] {'global/mean_episode_return': 7375.0, 'global/mean_episode_step': 2493.625, 'global/SPS': 3513.5494098959057, 'global/env_act_steps': 688384, 'global/env_train_steps': 686080, 'global/optimizer_steps': 1072, 'global/running_reward': 4053.635700389105, 'global/running_step': 1273.9565904669262, 'global/steps_done': 688384, 'global/episodes_done': 228, 'global/unclipped_grad_norm': 0.46471172225262436, 'global/model_version': 1072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:45,027] calculate_sps 35840 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:45,027] calculate_sps 31360 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:45,028] {'local/mean_episode_return': 6722.222222222223, 'local/mean_episode_step': 2249.8888888888887, 'local/SPS': 3583.7289755747192, 'local/env_act_steps': 723072, 'local/env_train_steps': 721920, 'local/optimizer_steps': 1128, 'local/running_reward': 4429.06499003984, 'local/running_step': 1337.9436628486055, 'local/steps_done': 723072, 'local/episodes_done': 237, 'local/unclipped_grad_norm': 0.5392628716903606, 'local/model_version': 1128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:45,029] {'global/mean_episode_return': 7300.0, 'global/mean_episode_step': 2458.714285714286, 'global/SPS': 3135.7628536278794, 'global/env_act_steps': 722048, 'global/env_train_steps': 717440, 'global/optimizer_steps': 1120, 'global/running_reward': 4409.5443203422055, 'global/running_step': 1334.586383079848, 'global/steps_done': 722048, 'global/episodes_done': 235, 'global/unclipped_grad_norm': 0.5993202661629766, 'global/model_version': 1120, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:55,040] calculate_sps 30720 steps in 10.013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:19:55,040] calculate_sps 35200 steps in 10.013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:55,041] {'local/mean_episode_return': 7788.461538461538, 'local/mean_episode_step': 2573.923076923077, 'local/SPS': 3068.0177178241306, 'local/env_act_steps': 756352, 'local/env_train_steps': 752640, 'local/optimizer_steps': 1176, 'local/running_reward': 4410.099158653846, 'local/running_step': 1332.0676382211539, 'local/steps_done': 756352, 'local/episodes_done': 251, 'local/unclipped_grad_norm': 0.3068692988405625, 'local/model_version': 1176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:19:55,042] {'global/mean_episode_return': 7376.666666666667, 'global/mean_episode_step': 2433.266666666667, 'global/SPS': 3515.4369683401496, 'global/env_act_steps': 754560, 'global/env_train_steps': 752640, 'global/optimizer_steps': 1176, 'global/running_reward': 4412.939837598426, 'global/running_step': 1332.6140501968505, 'global/steps_done': 754560, 'global/episodes_done': 251, 'global/unclipped_grad_norm': 0.2885906139854342, 'global/model_version': 1176, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:05,046] calculate_sps 32640 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:05,047] calculate_sps 30720 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:05,047] {'local/mean_episode_return': 7816.666666666667, 'local/mean_episode_step': 2444.9166666666665, 'local/SPS': 3261.8269283804957, 'local/env_act_steps': 788864, 'local/env_train_steps': 785280, 'local/optimizer_steps': 1226, 'local/running_reward': 4306.994340551181, 'local/running_step': 1314.4251660925197, 'local/steps_done': 788864, 'local/episodes_done': 270, 'local/unclipped_grad_norm': 0.3430411846935749, 'local/model_version': 1226, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:05,048] {'global/mean_episode_return': 7816.666666666667, 'global/mean_episode_step': 2444.9166666666665, 'global/SPS': 3069.9547561228196, 'global/env_act_steps': 788096, 'global/env_train_steps': 783360, 'global/optimizer_steps': 1224, 'global/running_reward': 4315.616054389313, 'global/running_step': 1316.3316734255725, 'global/steps_done': 788096, 'global/episodes_done': 270, 'global/unclipped_grad_norm': 0.2991828181159993, 'global/model_version': 1224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:15,073] calculate_sps 33920 steps in 10.026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:15,073] calculate_sps 35840 steps in 10.026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:15,073] {'local/mean_episode_return': 7300.0, 'local/mean_episode_step': 2265.5, 'local/SPS': 3383.1880549846924, 'local/env_act_steps': 822016, 'local/env_train_steps': 819200, 'local/optimizer_steps': 1280, 'local/running_reward': 4398.289695945946, 'local/running_step': 1326.8071307915059, 'local/steps_done': 822016, 'local/episodes_done': 278, 'local/unclipped_grad_norm': 0.42641677124494753, 'local/model_version': 1280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:15,074] {'global/mean_episode_return': 7300.0, 'global/mean_episode_step': 2265.5, 'global/SPS': 3574.689265644203, 'global/env_act_steps': 820864, 'global/env_train_steps': 819200, 'global/optimizer_steps': 1280, 'global/running_reward': 4389.39208984375, 'global/running_step': 1325.2037658691406, 'global/steps_done': 820864, 'global/episodes_done': 278, 'global/unclipped_grad_norm': 0.46103195736317765, 'global/model_version': 1280, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:25,100] calculate_sps 30720 steps in 10.0277
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:25,101] calculate_sps 30720 steps in 10.0277
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:25,101] {'local/mean_episode_return': 8150.0, 'local/mean_episode_step': 2288.25, 'local/SPS': 3063.5133537388415, 'local/env_act_steps': 855168, 'local/env_train_steps': 849920, 'local/optimizer_steps': 1328, 'local/running_reward': 4790.93569015444, 'local/running_step': 1388.8686655405406, 'local/steps_done': 855168, 'local/episodes_done': 282, 'local/unclipped_grad_norm': 0.547155181877315, 'local/model_version': 1328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:25,102] {'global/mean_episode_return': 8150.0, 'global/mean_episode_step': 2288.25, 'global/SPS': 3063.5133537388415, 'global/env_act_steps': 854144, 'global/env_train_steps': 849920, 'global/optimizer_steps': 1328, 'global/running_reward': 4772.139423076923, 'global/running_step': 1385.86328125, 'global/steps_done': 854144, 'global/episodes_done': 282, 'global/unclipped_grad_norm': 0.547155181877315, 'global/model_version': 1328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:35,117] calculate_sps 35840 steps in 10.0169
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:35,117] calculate_sps 35200 steps in 10.0169
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:35,118] {'local/mean_episode_return': 8890.90909090909, 'local/mean_episode_step': 2583.7272727272725, 'local/SPS': 3577.9604753567032, 'local/env_act_steps': 887424, 'local/env_train_steps': 885760, 'local/optimizer_steps': 1384, 'local/running_reward': 5257.536582341269, 'local/running_step': 1447.4747953869048, 'local/steps_done': 887424, 'local/episodes_done': 293, 'local/unclipped_grad_norm': 0.5263815769659621, 'local/model_version': 1384, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:35,119] {'global/mean_episode_return': 9160.0, 'global/mean_episode_step': 2633.4, 'global/SPS': 3514.068324011048, 'global/env_act_steps': 886656, 'global/env_train_steps': 885120, 'global/optimizer_steps': 1382, 'global/running_reward': 5248.84657972441, 'global/running_step': 1446.9972933070867, 'global/steps_done': 886656, 'global/episodes_done': 292, 'global/unclipped_grad_norm': 0.5276623779424915, 'global/model_version': 1382, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:45,152] calculate_sps 30720 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:45,152] calculate_sps 31360 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:45,162] {'local/mean_episode_return': 8525.0, 'local/mean_episode_step': 2534.25, 'local/SPS': 3061.4207623786942, 'local/env_act_steps': 920960, 'local/env_train_steps': 916480, 'local/optimizer_steps': 1432, 'local/running_reward': 5747.990219465649, 'local/running_step': 1498.0763060591603, 'local/steps_done': 920960, 'local/episodes_done': 297, 'local/unclipped_grad_norm': 0.5727640204131603, 'local/model_version': 1432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:45,164] {'global/mean_episode_return': 8060.0, 'global/mean_episode_step': 2444.8, 'global/SPS': 3125.200361594917, 'global/env_act_steps': 920320, 'global/env_train_steps': 916480, 'global/optimizer_steps': 1432, 'global/running_reward': 5734.27697243346, 'global/running_step': 1496.1468928231939, 'global/steps_done': 920320, 'global/episodes_done': 297, 'global/unclipped_grad_norm': 0.5695254576206207, 'global/model_version': 1432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:55,174] calculate_sps 33280 steps in 10.0222
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:20:55,174] calculate_sps 32000 steps in 10.0222
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:55,174] {'local/mean_episode_return': 10057.142857142857, 'local/mean_episode_step': 2717.1428571428573, 'local/SPS': 3320.623035102182, 'local/env_act_steps': 952832, 'local/env_train_steps': 949760, 'local/optimizer_steps': 1483, 'local/running_reward': 6284.9554467871485, 'local/running_step': 1575.656438253012, 'local/steps_done': 952832, 'local/episodes_done': 304, 'local/unclipped_grad_norm': 0.5985540236328163, 'local/model_version': 1483, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:20:55,175] {'global/mean_episode_return': 10057.142857142857, 'global/mean_episode_step': 2717.1428571428573, 'global/SPS': 3192.9067645213286, 'global/env_act_steps': 952704, 'global/env_train_steps': 948480, 'global/optimizer_steps': 1482, 'global/running_reward': 6280.542860671937, 'global/running_step': 1575.1205842391305, 'global/steps_done': 952704, 'global/episodes_done': 304, 'global/unclipped_grad_norm': 0.5861161890625953, 'global/model_version': 1482, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:05,196] calculate_sps 33280 steps in 10.0219
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:05,196] calculate_sps 34560 steps in 10.0219
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:05,196] {'local/mean_episode_return': 9800.0, 'local/mean_episode_step': 2617.804347826087, 'local/SPS': 3320.7130910828073, 'local/env_act_steps': 985344, 'local/env_train_steps': 983040, 'local/optimizer_steps': 1536, 'local/running_reward': 6232.566437007874, 'local/running_step': 1553.7177657480315, 'local/steps_done': 985344, 'local/episodes_done': 328, 'local/unclipped_grad_norm': 0.5272130942815598, 'local/model_version': 1536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:05,198] {'global/mean_episode_return': 9800.0, 'global/mean_episode_step': 2617.804347826087, 'global/SPS': 3448.432825355223, 'global/env_act_steps': 984960, 'global/env_train_steps': 983040, 'global/optimizer_steps': 1536, 'global/running_reward': 6238.743179563492, 'global/running_step': 1554.783420138889, 'global/steps_done': 984960, 'global/episodes_done': 328, 'global/unclipped_grad_norm': 0.5400507360938247, 'global/model_version': 1536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:15,202] calculate_sps 30720 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:15,214] calculate_sps 30720 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:15,214] {'local/mean_episode_return': 9258.333333333334, 'local/mean_episode_step': 2553.625, 'local/SPS': 3070.2137833418583, 'local/env_act_steps': 1018752, 'local/env_train_steps': 1013760, 'local/optimizer_steps': 1584, 'local/running_reward': 5717.953783524904, 'local/running_step': 1469.2835548371647, 'local/steps_done': 1018752, 'local/episodes_done': 341, 'local/unclipped_grad_norm': 0.33035412275542814, 'local/model_version': 1584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:15,216] {'global/mean_episode_return': 9258.333333333334, 'global/mean_episode_step': 2553.625, 'global/SPS': 3070.2137833418583, 'global/env_act_steps': 1018624, 'global/env_train_steps': 1013760, 'global/optimizer_steps': 1584, 'global/running_reward': 5719.0411121673005, 'global/running_step': 1469.4552043726235, 'global/steps_done': 1018624, 'global/episodes_done': 341, 'global/unclipped_grad_norm': 0.33035412275542814, 'global/model_version': 1584, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:25,223] calculate_sps 35840 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:25,223] calculate_sps 26880 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:25,224] {'local/mean_episode_return': 7537.5, 'local/mean_episode_step': 2269.0, 'local/SPS': 3576.3724931478014, 'local/env_act_steps': 1051008, 'local/env_train_steps': 1049600, 'local/optimizer_steps': 1640, 'local/running_reward': 5875.9765625, 'local/running_step': 1525.862320188492, 'local/steps_done': 1051008, 'local/episodes_done': 349, 'local/unclipped_grad_norm': 0.3950954909835543, 'local/model_version': 1640, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:25,225] {'global/mean_episode_return': 7340.0, 'global/mean_episode_step': 2314.8, 'global/SPS': 2682.279369860851, 'global/env_act_steps': 1044864, 'global/env_train_steps': 1040640, 'global/optimizer_steps': 1626, 'global/running_reward': 5864.012957317073, 'global/running_step': 1522.3358231707316, 'global/steps_done': 1044864, 'global/episodes_done': 346, 'global/unclipped_grad_norm': 0.38744668822203365, 'global/model_version': 1626, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:35,228] calculate_sps 30720 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:35,229] calculate_sps 34560 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:35,229] {'local/mean_episode_return': 10410.0, 'local/mean_episode_step': 2678.8, 'local/SPS': 3070.3959551770727, 'local/env_act_steps': 1084416, 'local/env_train_steps': 1080320, 'local/optimizer_steps': 1688, 'local/running_reward': 5965.619013409962, 'local/running_step': 1542.8356082375478, 'local/steps_done': 1084416, 'local/episodes_done': 359, 'local/unclipped_grad_norm': 0.3735733865760267, 'local/model_version': 1688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:35,230] {'global/mean_episode_return': 9772.727272727272, 'global/mean_episode_step': 2555.5454545454545, 'global/SPS': 3454.1954495742066, 'global/env_act_steps': 1077760, 'global/env_train_steps': 1075200, 'global/optimizer_steps': 1680, 'global/running_reward': 5934.940418287938, 'global/running_step': 1538.8525656614786, 'global/steps_done': 1077760, 'global/episodes_done': 357, 'global/unclipped_grad_norm': 0.3772055459795175, 'global/model_version': 1680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:45,228] calculate_sps 33920 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:45,229] calculate_sps 32000 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:45,229] {'local/mean_episode_return': 10137.5, 'local/mean_episode_step': 2731.0, 'local/SPS': 3391.9129844100185, 'local/env_act_steps': 1116800, 'local/env_train_steps': 1114240, 'local/optimizer_steps': 1740, 'local/running_reward': 6234.325592885375, 'local/running_step': 1588.420238389328, 'local/steps_done': 1116800, 'local/episodes_done': 367, 'local/unclipped_grad_norm': 0.4764603370657334, 'local/model_version': 1740, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:45,230] {'global/mean_episode_return': 10762.5, 'global/mean_episode_step': 2823.0, 'global/SPS': 3199.917909820772, 'global/env_act_steps': 1111296, 'global/env_train_steps': 1107200, 'global/optimizer_steps': 1729, 'global/running_reward': 6184.440601145038, 'global/running_step': 1580.7692927003816, 'global/steps_done': 1111296, 'global/episodes_done': 365, 'global/unclipped_grad_norm': 0.4477536815161608, 'global/model_version': 1729, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:55,257] calculate_sps 32640 steps in 10.0283
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:21:55,258] calculate_sps 34560 steps in 10.0283
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:55,258] {'local/mean_episode_return': 10460.0, 'local/mean_episode_step': 2786.5333333333333, 'local/SPS': 3254.7825868024115, 'local/env_act_steps': 1149312, 'local/env_train_steps': 1146880, 'local/optimizer_steps': 1792, 'local/running_reward': 6421.4197834645665, 'local/running_step': 1597.8016117125985, 'local/steps_done': 1149312, 'local/episodes_done': 382, 'local/unclipped_grad_norm': 0.5200202404879607, 'local/model_version': 1792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:21:55,259] {'global/mean_episode_return': 9992.307692307691, 'global/mean_episode_step': 2656.769230769231, 'global/SPS': 3446.240386026083, 'global/env_act_steps': 1143808, 'global/env_train_steps': 1141760, 'global/optimizer_steps': 1784, 'global/running_reward': 6402.7989665354335, 'global/running_step': 1598.9381459153544, 'global/steps_done': 1143808, 'global/episodes_done': 378, 'global/unclipped_grad_norm': 0.5368180327794768, 'global/model_version': 1784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:05,278] calculate_sps 30720 steps in 10.0209
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:05,278] calculate_sps 30720 steps in 10.0209
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:05,278] {'local/mean_episode_return': 10310.526315789473, 'local/mean_episode_step': 2782.157894736842, 'local/SPS': 3065.602608082765, 'local/env_act_steps': 1182208, 'local/env_train_steps': 1177600, 'local/optimizer_steps': 1840, 'local/running_reward': 6422.8568822957195, 'local/running_step': 1555.4136673151752, 'local/steps_done': 1182208, 'local/episodes_done': 401, 'local/unclipped_grad_norm': 0.5734521597623825, 'local/model_version': 1840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:05,280] {'global/mean_episode_return': 10500.0, 'global/mean_episode_step': 2832.6666666666665, 'global/SPS': 3065.602608082765, 'global/env_act_steps': 1176960, 'global/env_train_steps': 1172480, 'global/optimizer_steps': 1832, 'global/running_reward': 6442.431829150579, 'global/running_step': 1567.9003076737451, 'global/steps_done': 1176960, 'global/episodes_done': 396, 'global/unclipped_grad_norm': 0.5441040072279671, 'global/model_version': 1832, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:15,306] calculate_sps 35200 steps in 10.0283
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:15,306] calculate_sps 35200 steps in 10.0283
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:15,306] {'local/mean_episode_return': 12500.0, 'local/mean_episode_step': 3008.5384615384614, 'local/SPS': 3510.0811826702684, 'local/env_act_steps': 1214336, 'local/env_train_steps': 1212800, 'local/optimizer_steps': 1894, 'local/running_reward': 6254.304656374502, 'local/running_step': 1474.2101282370518, 'local/steps_done': 1214336, 'local/episodes_done': 414, 'local/unclipped_grad_norm': 0.7622817448443837, 'local/model_version': 1894, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:15,307] {'global/mean_episode_return': 11987.5, 'global/mean_episode_step': 2997.875, 'global/SPS': 3510.0811826702684, 'global/env_act_steps': 1209216, 'global/env_train_steps': 1207680, 'global/optimizer_steps': 1886, 'global/running_reward': 6277.458457341269, 'global/running_step': 1483.5845114087301, 'global/steps_done': 1209216, 'global/episodes_done': 412, 'global/unclipped_grad_norm': 0.7875210576587253, 'global/model_version': 1886, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:25,331] calculate_sps 31360 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:25,331] calculate_sps 31360 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:25,332] {'local/mean_episode_return': 12300.0, 'local/mean_episode_step': 2936.03125, 'local/SPS': 3128.2701378563065, 'local/env_act_steps': 1247104, 'local/env_train_steps': 1244160, 'local/optimizer_steps': 1944, 'local/running_reward': 6118.90869140625, 'local/running_step': 1442.4090881347656, 'local/steps_done': 1247104, 'local/episodes_done': 431, 'local/unclipped_grad_norm': 0.5453221900761127, 'local/model_version': 1944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:25,333] {'global/mean_episode_return': 11647.058823529413, 'global/mean_episode_step': 2832.205882352941, 'global/SPS': 3128.2701378563065, 'global/env_act_steps': 1242624, 'global/env_train_steps': 1239040, 'global/optimizer_steps': 1936, 'global/running_reward': 6163.894875478927, 'global/running_step': 1450.3499161877394, 'global/steps_done': 1242624, 'global/episodes_done': 430, 'global/unclipped_grad_norm': 0.5873643888533115, 'global/model_version': 1936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:35,352] calculate_sps 32000 steps in 10.0218
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:35,352] calculate_sps 33920 steps in 10.0218
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:35,353] {'local/mean_episode_return': 10931.818181818182, 'local/mean_episode_step': 2756.1363636363635, 'local/SPS': 3193.0535943919685, 'local/env_act_steps': 1280256, 'local/env_train_steps': 1276160, 'local/optimizer_steps': 1993, 'local/running_reward': 5987.050555019305, 'local/running_step': 1425.3425132722007, 'local/steps_done': 1280256, 'local/episodes_done': 443, 'local/unclipped_grad_norm': 1.0343696744922473, 'local/model_version': 1993, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:35,354] {'global/mean_episode_return': 12700.0, 'global/mean_episode_step': 3017.6666666666665, 'global/SPS': 3384.6368100554864, 'global/env_act_steps': 1275520, 'global/env_train_steps': 1272960, 'global/optimizer_steps': 1988, 'global/running_reward': 5979.158560311284, 'global/running_step': 1422.9073443579766, 'global/steps_done': 1275520, 'global/episodes_done': 436, 'global/unclipped_grad_norm': 0.9874318416875142, 'global/model_version': 1988, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:45,380] calculate_sps 34560 steps in 10.028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:45,381] calculate_sps 32640 steps in 10.028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:45,381] {'local/mean_episode_return': 10891.666666666666, 'local/mean_episode_step': 2795.9166666666665, 'local/SPS': 3446.3647644193147, 'local/env_act_steps': 1313152, 'local/env_train_steps': 1310720, 'local/optimizer_steps': 2048, 'local/running_reward': 5598.635092412452, 'local/running_step': 1370.5105787937744, 'local/steps_done': 1313152, 'local/episodes_done': 455, 'local/unclipped_grad_norm': 0.2473442179574208, 'local/model_version': 2048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:45,382] {'global/mean_episode_return': 11173.529411764706, 'global/mean_episode_step': 2823.676470588235, 'global/SPS': 3254.9000552849084, 'global/env_act_steps': 1308928, 'global/env_train_steps': 1305600, 'global/optimizer_steps': 2040, 'global/running_reward': 5647.404813218391, 'global/running_step': 1375.7109674329502, 'global/steps_done': 1308928, 'global/episodes_done': 454, 'global/unclipped_grad_norm': 0.23273465220028391, 'global/model_version': 2040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:55,387] calculate_sps 30720 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:22:55,387] calculate_sps 32640 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:55,387] {'local/mean_episode_return': 12163.636363636364, 'local/mean_episode_step': 2930.7272727272725, 'local/SPS': 3070.0095424771757, 'local/env_act_steps': 1346176, 'local/env_train_steps': 1341440, 'local/optimizer_steps': 2096, 'local/running_reward': 5526.350532945737, 'local/running_step': 1391.7711361434108, 'local/steps_done': 1346176, 'local/episodes_done': 466, 'local/unclipped_grad_norm': 0.45261141339627403, 'local/model_version': 2096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:22:55,403] {'global/mean_episode_return': 11218.181818181818, 'global/mean_episode_step': 2767.2727272727275, 'global/SPS': 3261.885138881999, 'global/env_act_steps': 1341952, 'global/env_train_steps': 1338240, 'global/optimizer_steps': 2090, 'global/running_reward': 5542.662911821705, 'global/running_step': 1391.1033490794573, 'global/steps_done': 1341952, 'global/episodes_done': 465, 'global/unclipped_grad_norm': 0.43905431367456915, 'global/model_version': 2090, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:05,434] calculate_sps 35200 steps in 10.0477
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:05,435] calculate_sps 33920 steps in 10.0477
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:05,435] {'local/mean_episode_return': 11188.888888888889, 'local/mean_episode_step': 2787.777777777778, 'local/SPS': 3503.2900000237287, 'local/env_act_steps': 1378176, 'local/env_train_steps': 1376640, 'local/optimizer_steps': 2150, 'local/running_reward': 5517.6375, 'local/running_step': 1417.8861875, 'local/steps_done': 1378176, 'local/episodes_done': 475, 'local/unclipped_grad_norm': 0.45256554176685987, 'local/model_version': 2150, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:05,436] {'global/mean_episode_return': 12342.857142857143, 'global/mean_episode_step': 3028.285714285714, 'global/SPS': 3375.897636386502, 'global/env_act_steps': 1374848, 'global/env_train_steps': 1372160, 'global/optimizer_steps': 2144, 'global/running_reward': 5509.064931906615, 'global/running_step': 1412.8357247081713, 'global/steps_done': 1374848, 'global/episodes_done': 472, 'global/unclipped_grad_norm': 0.45811388420837895, 'global/model_version': 2144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:15,452] calculate_sps 31360 steps in 10.0177
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:15,453] calculate_sps 31360 steps in 10.0177
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:15,453] {'local/mean_episode_return': 10612.5, 'local/mean_episode_step': 2613.5, 'local/SPS': 3130.469978520429, 'local/env_act_steps': 1411456, 'local/env_train_steps': 1408000, 'local/optimizer_steps': 2200, 'local/running_reward': 5505.982572115385, 'local/running_step': 1438.9728365384615, 'local/steps_done': 1411456, 'local/episodes_done': 488, 'local/unclipped_grad_norm': 0.4124978885054588, 'local/model_version': 2200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:15,454] {'global/mean_episode_return': 9568.181818181818, 'global/mean_episode_step': 2414.909090909091, 'global/SPS': 3130.469978520429, 'global/env_act_steps': 1408256, 'global/env_train_steps': 1403520, 'global/optimizer_steps': 2192, 'global/running_reward': 5510.072437739464, 'global/running_step': 1438.289212164751, 'global/steps_done': 1408256, 'global/episodes_done': 484, 'global/unclipped_grad_norm': 0.4000821035200109, 'global/model_version': 2192, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:25,474] calculate_sps 32000 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:25,474] calculate_sps 35200 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:25,478] {'local/mean_episode_return': 9129.166666666666, 'local/mean_episode_step': 2368.4166666666665, 'local/SPS': 3193.1828887798097, 'local/env_act_steps': 1444224, 'local/env_train_steps': 1440000, 'local/optimizer_steps': 2250, 'local/running_reward': 5419.189453125, 'local/running_step': 1421.506591796875, 'local/steps_done': 1444224, 'local/episodes_done': 501, 'local/unclipped_grad_norm': 0.57750163346529, 'local/model_version': 2250, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:25,480] {'global/mean_episode_return': 9984.375, 'global/mean_episode_step': 2518.4375, 'global/SPS': 3512.5011776577903, 'global/env_act_steps': 1440512, 'global/env_train_steps': 1438720, 'global/optimizer_steps': 2248, 'global/running_reward': 5426.112971230159, 'global/running_step': 1424.1392299107142, 'global/steps_done': 1440512, 'global/episodes_done': 501, 'global/unclipped_grad_norm': 0.5561330291841712, 'global/model_version': 2248, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:35,477] calculate_sps 34560 steps in 10.0038
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:35,478] calculate_sps 30720 steps in 10.0038
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:35,478] {'local/mean_episode_return': 10918.181818181818, 'local/mean_episode_step': 2775.7272727272725, 'local/SPS': 3454.6737452353054, 'local/env_act_steps': 1476480, 'local/env_train_steps': 1474560, 'local/optimizer_steps': 2304, 'local/running_reward': 5543.126860119048, 'local/running_step': 1429.575427827381, 'local/steps_done': 1476480, 'local/episodes_done': 512, 'local/unclipped_grad_norm': 0.4373849507559229, 'local/model_version': 2304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:35,479] {'global/mean_episode_return': 11210.0, 'global/mean_episode_step': 2855.6, 'global/SPS': 3070.821106875827, 'global/env_act_steps': 1473792, 'global/env_train_steps': 1469440, 'global/optimizer_steps': 2296, 'global/running_reward': 5524.275841346154, 'global/running_step': 1427.9987079326922, 'global/steps_done': 1473792, 'global/episodes_done': 511, 'global/unclipped_grad_norm': 0.4597473619505763, 'global/model_version': 2296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:45,489] calculate_sps 30720 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:45,489] calculate_sps 35840 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:45,498] {'local/mean_episode_return': 9433.333333333334, 'local/mean_episode_step': 2295.0, 'local/SPS': 3068.596913684844, 'local/env_act_steps': 1509888, 'local/env_train_steps': 1505280, 'local/optimizer_steps': 2352, 'local/running_reward': 5952.146192528736, 'local/running_step': 1484.7087823275863, 'local/steps_done': 1509888, 'local/episodes_done': 515, 'local/unclipped_grad_norm': 0.7991201387097439, 'local/model_version': 2352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:45,500] {'global/mean_episode_return': 9366.666666666666, 'global/mean_episode_step': 2257.0, 'global/SPS': 3580.0297326323175, 'global/env_act_steps': 1506304, 'global/env_train_steps': 1505280, 'global/optimizer_steps': 2351, 'global/running_reward': 5888.668799212598, 'global/running_step': 1474.5961183562993, 'global/steps_done': 1506304, 'global/episodes_done': 514, 'global/unclipped_grad_norm': 0.7310571465979923, 'global/model_version': 2351, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:55,536] calculate_sps 35840 steps in 10.0483
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:23:55,537] calculate_sps 30720 steps in 10.0483
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:55,537] {'local/mean_episode_return': 9120.0, 'local/mean_episode_step': 2453.8, 'local/SPS': 3566.76850140152, 'local/env_act_steps': 1542144, 'local/env_train_steps': 1541120, 'local/optimizer_steps': 2407, 'local/running_reward': 6637.574404761905, 'local/running_step': 1589.9989459325398, 'local/steps_done': 1542144, 'local/episodes_done': 520, 'local/unclipped_grad_norm': 0.7644166141748429, 'local/model_version': 2407, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:23:55,538] {'global/mean_episode_return': 7500.0, 'global/mean_episode_step': 2058.0, 'global/SPS': 3057.2301440584456, 'global/env_act_steps': 1540352, 'global/env_train_steps': 1536000, 'global/optimizer_steps': 2400, 'global/running_reward': 6584.004934210527, 'global/running_step': 1582.2574894266918, 'global/steps_done': 1540352, 'global/episodes_done': 518, 'global/unclipped_grad_norm': 0.7933054703230761, 'global/model_version': 2400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:05,555] calculate_sps 30720 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:05,555] calculate_sps 35840 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:05,555] {'local/mean_episode_return': 7233.333333333333, 'local/mean_episode_step': 2257.0, 'local/SPS': 3066.4919006037812, 'local/env_act_steps': 1576192, 'local/env_train_steps': 1571840, 'local/optimizer_steps': 2456, 'local/running_reward': 7222.550516917293, 'local/running_step': 1661.159568843985, 'local/steps_done': 1576192, 'local/episodes_done': 523, 'local/unclipped_grad_norm': 0.5480037836395965, 'local/model_version': 2456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:05,557] {'global/mean_episode_return': 9100.0, 'global/mean_episode_step': 2579.8, 'global/SPS': 3577.5738840377444, 'global/env_act_steps': 1573504, 'global/env_train_steps': 1571840, 'global/optimizer_steps': 2456, 'global/running_reward': 7175.93207046332, 'global/running_step': 1654.585304054054, 'global/steps_done': 1573504, 'global/episodes_done': 523, 'global/unclipped_grad_norm': 0.551775360746043, 'global/model_version': 2456, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:15,556] calculate_sps 33920 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:15,556] calculate_sps 30720 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:15,556] {'local/mean_episode_return': 16400.0, 'local/mean_episode_step': 3594.0, 'local/SPS': 3391.6535006701856, 'local/env_act_steps': 1608448, 'local/env_train_steps': 1605760, 'local/optimizer_steps': 2509, 'local/running_reward': 7867.553323412699, 'local/running_step': 1756.2218191964287, 'local/steps_done': 1608448, 'local/episodes_done': 528, 'local/unclipped_grad_norm': 0.4572606241365649, 'local/model_version': 2509, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:15,557] {'global/mean_episode_return': 16400.0, 'global/mean_episode_step': 3594.0, 'global/SPS': 3071.686189286206, 'global/env_act_steps': 1607168, 'global/env_train_steps': 1602560, 'global/optimizer_steps': 2504, 'global/running_reward': 7838.1951045627375, 'global/running_step': 1752.448223621673, 'global/steps_done': 1607168, 'global/episodes_done': 528, 'global/unclipped_grad_norm': 0.4626583366965254, 'global/model_version': 2504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:25,587] calculate_sps 32640 steps in 10.0316
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:25,588] calculate_sps 34560 steps in 10.0316
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:25,588] {'local/mean_episode_return': 14000.0, 'local/mean_episode_step': 3039.5, 'local/SPS': 3253.725519890608, 'local/env_act_steps': 1641216, 'local/env_train_steps': 1638400, 'local/optimizer_steps': 2560, 'local/running_reward': 8394.7021484375, 'local/running_step': 1826.9514770507812, 'local/steps_done': 1641216, 'local/episodes_done': 530, 'local/unclipped_grad_norm': 0.6007083845781345, 'local/model_version': 2560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:25,589] {'global/mean_episode_return': 14000.0, 'global/mean_episode_step': 3039.5, 'global/SPS': 3445.121138707703, 'global/env_act_steps': 1639168, 'global/env_train_steps': 1637120, 'global/optimizer_steps': 2557, 'global/running_reward': 8361.740625, 'global/running_step': 1821.67953125, 'global/steps_done': 1639168, 'global/episodes_done': 530, 'global/unclipped_grad_norm': 0.5880202413448747, 'global/model_version': 2557, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:35,589] calculate_sps 30720 steps in 10.0015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:35,589] calculate_sps 32000 steps in 10.0015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:35,589] {'local/mean_episode_return': 11900.0, 'local/mean_episode_step': 2842.8, 'local/SPS': 3071.537179113102, 'local/env_act_steps': 1674368, 'local/env_train_steps': 1669120, 'local/optimizer_steps': 2608, 'local/running_reward': 8938.284266409266, 'local/running_step': 1902.0215673262549, 'local/steps_done': 1674368, 'local/episodes_done': 535, 'local/unclipped_grad_norm': 0.5424367419133583, 'local/model_version': 2608, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:35,591] {'global/mean_episode_return': 11900.0, 'global/mean_episode_step': 2842.8, 'global/SPS': 3199.517894909481, 'global/env_act_steps': 1672448, 'global/env_train_steps': 1669120, 'global/optimizer_steps': 2608, 'global/running_reward': 8904.146634615385, 'global/running_step': 1897.684795673077, 'global/steps_done': 1672448, 'global/episodes_done': 535, 'global/unclipped_grad_norm': 0.5399064970951454, 'global/model_version': 2608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:45,605] calculate_sps 35840 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:45,605] calculate_sps 33280 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:45,606] {'local/mean_episode_return': 11800.0, 'local/mean_episode_step': 2869.0, 'local/SPS': 3578.2123155614777, 'local/env_act_steps': 1706624, 'local/env_train_steps': 1704960, 'local/optimizer_steps': 2664, 'local/running_reward': 9475.424727182539, 'local/running_step': 1966.0879526289682, 'local/steps_done': 1706624, 'local/episodes_done': 542, 'local/unclipped_grad_norm': 0.4992048131035907, 'local/model_version': 2664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:45,615] {'global/mean_episode_return': 11800.0, 'global/mean_episode_step': 2869.0, 'global/SPS': 3322.625721592801, 'global/env_act_steps': 1705472, 'global/env_train_steps': 1702400, 'global/optimizer_steps': 2659, 'global/running_reward': 9454.53609496124, 'global/running_step': 1964.0268289728683, 'global/steps_done': 1705472, 'global/episodes_done': 542, 'global/unclipped_grad_norm': 0.5228835990031561, 'global/model_version': 2659, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:55,612] calculate_sps 30720 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:24:55,612] calculate_sps 33280 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:55,612] {'local/mean_episode_return': 19833.333333333332, 'local/mean_episode_step': 3896.5, 'local/SPS': 3070.0509444106156, 'local/env_act_steps': 1739904, 'local/env_train_steps': 1735680, 'local/optimizer_steps': 2712, 'local/running_reward': 9985.655048076924, 'local/running_step': 2030.968359375, 'local/steps_done': 1739904, 'local/episodes_done': 548, 'local/unclipped_grad_norm': 0.5266715561350187, 'local/model_version': 2712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:24:55,614] {'global/mean_episode_return': 19200.0, 'global/mean_episode_step': 3858.6, 'global/SPS': 3325.8885231115005, 'global/env_act_steps': 1738624, 'global/env_train_steps': 1735680, 'global/optimizer_steps': 2712, 'global/running_reward': 9969.440757722008, 'global/running_step': 2028.911468388031, 'global/steps_done': 1738624, 'global/episodes_done': 547, 'global/unclipped_grad_norm': 0.5012951071532268, 'global/model_version': 2712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:05,613] calculate_sps 33920 steps in 10.0015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:05,626] calculate_sps 31360 steps in 10.0015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:05,626] {'local/mean_episode_return': 15757.142857142857, 'local/mean_episode_step': 3408.5714285714284, 'local/SPS': 3391.484360319, 'local/env_act_steps': 1772288, 'local/env_train_steps': 1769600, 'local/optimizer_steps': 2765, 'local/running_reward': 10297.122035573122, 'local/running_step': 2060.71121541502, 'local/steps_done': 1772288, 'local/episodes_done': 555, 'local/unclipped_grad_norm': 0.4603501629998099, 'local/model_version': 2765, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:05,628] {'global/mean_episode_return': 16900.0, 'global/mean_episode_step': 3542.714285714286, 'global/SPS': 3135.52327652134, 'global/env_act_steps': 1771776, 'global/env_train_steps': 1767040, 'global/optimizer_steps': 2760, 'global/running_reward': 10289.303812741313, 'global/running_step': 2060.052364864865, 'global/steps_done': 1771776, 'global/episodes_done': 554, 'global/unclipped_grad_norm': 0.47227776624883216, 'global/model_version': 2760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:15,631] calculate_sps 32640 steps in 10.0182
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:15,631] calculate_sps 35200 steps in 10.0182
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:15,632] {'local/mean_episode_return': 17010.0, 'local/mean_episode_step': 3472.2, 'local/SPS': 3258.066926197458, 'local/env_act_steps': 1805056, 'local/env_train_steps': 1802240, 'local/optimizer_steps': 2816, 'local/running_reward': 10512.643432617188, 'local/running_step': 2079.9791564941406, 'local/steps_done': 1805056, 'local/episodes_done': 565, 'local/unclipped_grad_norm': 0.4169955072449703, 'local/model_version': 2816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:15,633] {'global/mean_episode_return': 16450.0, 'global/mean_episode_step': 3364.2, 'global/SPS': 3513.60158707569, 'global/env_act_steps': 1804160, 'global/env_train_steps': 1802240, 'global/optimizer_steps': 2816, 'global/running_reward': 10512.311635375494, 'global/running_step': 2080.2588932806325, 'global/steps_done': 1804160, 'global/episodes_done': 564, 'global/unclipped_grad_norm': 0.41064279872391907, 'global/model_version': 2816, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:25,641] calculate_sps 31360 steps in 10.0106
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:25,642] calculate_sps 30720 steps in 10.0106
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:25,642] {'local/mean_episode_return': 22800.0, 'local/mean_episode_step': 4116.25, 'local/SPS': 3132.6647082516747, 'local/env_act_steps': 1838208, 'local/env_train_steps': 1833600, 'local/optimizer_steps': 2864, 'local/running_reward': 10661.522683397683, 'local/running_step': 2090.10382480695, 'local/steps_done': 1838208, 'local/episodes_done': 569, 'local/unclipped_grad_norm': 0.552018842039009, 'local/model_version': 2864, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:25,643] {'global/mean_episode_return': 22360.0, 'global/mean_episode_step': 4138.4, 'global/SPS': 3068.732775430212, 'global/env_act_steps': 1837824, 'global/env_train_steps': 1832960, 'global/optimizer_steps': 2864, 'global/running_reward': 10653.915161596959, 'global/running_step': 2089.033567015209, 'global/steps_done': 1837824, 'global/episodes_done': 569, 'global/unclipped_grad_norm': 0.552018842039009, 'global/model_version': 2864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:35,666] calculate_sps 35200 steps in 10.0237
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:35,666] calculate_sps 35840 steps in 10.0237
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:35,678] {'local/mean_episode_return': 17400.0, 'local/mean_episode_step': 3584.8, 'local/SPS': 3511.6728982183695, 'local/env_act_steps': 1870592, 'local/env_train_steps': 1868800, 'local/optimizer_steps': 2920, 'local/running_reward': 11210.813982213438, 'local/running_step': 2169.890192687747, 'local/steps_done': 1870592, 'local/episodes_done': 574, 'local/unclipped_grad_norm': 0.5016085625227008, 'local/model_version': 2920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:35,680] {'global/mean_episode_return': 17400.0, 'global/mean_episode_step': 3584.8, 'global/SPS': 3575.5214963677945, 'global/env_act_steps': 1870336, 'global/env_train_steps': 1868800, 'global/optimizer_steps': 2920, 'global/running_reward': 11206.822096456694, 'global/running_step': 2169.434116633858, 'global/steps_done': 1870336, 'global/episodes_done': 574, 'global/unclipped_grad_norm': 0.5016085625227008, 'global/model_version': 2920, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:45,676] calculate_sps 30720 steps in 10.0101
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:45,676] calculate_sps 25600 steps in 10.0101
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:45,677] {'local/mean_episode_return': 19214.285714285714, 'local/mean_episode_step': 3741.1428571428573, 'local/SPS': 3068.908777760438, 'local/env_act_steps': 1904384, 'local/env_train_steps': 1899520, 'local/optimizer_steps': 2968, 'local/running_reward': 11539.624763257576, 'local/running_step': 2208.788204308712, 'local/steps_done': 1904384, 'local/episodes_done': 581, 'local/unclipped_grad_norm': 0.5494850669056177, 'local/model_version': 2968, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:45,678] {'global/mean_episode_return': 20240.0, 'global/mean_episode_step': 4005.4, 'global/SPS': 2557.423981467032, 'global/env_act_steps': 1897600, 'global/env_train_steps': 1894400, 'global/optimizer_steps': 2960, 'global/running_reward': 11524.471830985916, 'global/running_step': 2207.7717136150236, 'global/steps_done': 1897600, 'global/episodes_done': 579, 'global/unclipped_grad_norm': 0.5792585998773575, 'global/model_version': 2960, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 11:25:52,108] saving global stats {'mean_episode_return': 21175.0, 'mean_episode_step': 3995.25, 'SPS': None, 'env_act_steps': 1917312, 'env_train_steps': 1914880, 'optimizer_steps': 2992, 'running_reward': 11682.325487012988, 'running_step': 2228.015523538961, 'steps_done': 1917312, 'episodes_done': 583, 'unclipped_grad_norm': 0.5211280167568475, 'model_version': 2992, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 11:25:52,187] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:55,709] calculate_sps 35200 steps in 10.0338
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:25:55,709] calculate_sps 32000 steps in 10.0338
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:55,709] {'local/mean_episode_return': 22375.0, 'local/mean_episode_step': 4148.5, 'local/SPS': 3508.152271051539, 'local/env_act_steps': 1936256, 'local/env_train_steps': 1934720, 'local/optimizer_steps': 3022, 'local/running_reward': 11822.273468875503, 'local/running_step': 2247.7391440763054, 'local/steps_done': 1936256, 'local/episodes_done': 585, 'local/unclipped_grad_norm': 0.56121825206059, 'local/model_version': 3022, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:25:55,710] {'global/mean_episode_return': 20600.0, 'global/mean_episode_step': 3941.8, 'global/SPS': 3189.229337319581, 'global/env_act_steps': 1930624, 'global/env_train_steps': 1926400, 'global/optimizer_steps': 3009, 'global/running_reward': 11752.89183624031, 'global/running_step': 2237.319949127907, 'global/steps_done': 1930624, 'global/episodes_done': 584, 'global/unclipped_grad_norm': 0.5638950572026019, 'global/model_version': 3009, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:05,712] calculate_sps 31360 steps in 10.0029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:05,722] calculate_sps 34560 steps in 10.0029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:05,722] {'local/mean_episode_return': 17257.14285714286, 'local/mean_episode_step': 3545.6428571428573, 'local/SPS': 3135.089888227485, 'local/env_act_steps': 1969024, 'local/env_train_steps': 1966080, 'local/optimizer_steps': 3072, 'local/running_reward': 12206.94580078125, 'local/running_step': 2300.9781494140625, 'local/steps_done': 1969024, 'local/episodes_done': 593, 'local/unclipped_grad_norm': 0.4287550015747547, 'local/model_version': 3072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:05,724] {'global/mean_episode_return': 17400.0, 'global/mean_episode_step': 3323.5833333333335, 'global/SPS': 3454.997019679269, 'global/env_act_steps': 1962624, 'global/env_train_steps': 1960960, 'global/optimizer_steps': 3064, 'global/running_reward': 12167.021875, 'global/running_step': 2297.81540625, 'global/steps_done': 1962624, 'global/episodes_done': 591, 'global/unclipped_grad_norm': 0.42938480350104247, 'global/model_version': 3064, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:15,730] calculate_sps 32640 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:15,730] calculate_sps 30720 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:15,730] {'local/mean_episode_return': 17114.285714285714, 'local/mean_episode_step': 3558.4285714285716, 'local/SPS': 3258.1783509217944, 'local/env_act_steps': 2002304, 'local/env_train_steps': 1998720, 'local/optimizer_steps': 3122, 'local/running_reward': 12470.766225961539, 'local/running_step': 2321.2220853365384, 'local/steps_done': 2002304, 'local/episodes_done': 600, 'local/unclipped_grad_norm': 0.7062916105985642, 'local/model_version': 3122, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:15,731] {'global/mean_episode_return': 17214.285714285714, 'global/mean_episode_step': 3675.1428571428573, 'global/SPS': 3066.5208008675713, 'global/env_act_steps': 1996672, 'global/env_train_steps': 1991680, 'global/optimizer_steps': 3112, 'global/running_reward': 12406.285244360903, 'global/running_step': 2314.5574483082705, 'global/steps_done': 1996672, 'global/episodes_done': 598, 'global/unclipped_grad_norm': 0.6903482703492045, 'global/model_version': 3112, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:25,746] calculate_sps 33920 steps in 10.0161
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:25,747] calculate_sps 35840 steps in 10.0161
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:25,747] {'local/mean_episode_return': 20512.5, 'local/mean_episode_step': 4197.5, 'local/SPS': 3386.5580809569738, 'local/env_act_steps': 2034688, 'local/env_train_steps': 2032640, 'local/optimizer_steps': 3176, 'local/running_reward': 12703.189846837944, 'local/running_step': 2335.8959980237155, 'local/steps_done': 2034688, 'local/episodes_done': 608, 'local/unclipped_grad_norm': 0.558245600649604, 'local/model_version': 3176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:25,748] {'global/mean_episode_return': 18925.0, 'global/mean_episode_step': 3865.375, 'global/SPS': 3578.2500478035945, 'global/env_act_steps': 2029056, 'global/env_train_steps': 2027520, 'global/optimizer_steps': 3168, 'global/running_reward': 12669.222455533596, 'global/running_step': 2334.683887104743, 'global/steps_done': 2029056, 'global/episodes_done': 606, 'global/unclipped_grad_norm': 0.5878201145678759, 'global/model_version': 3168, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:35,768] calculate_sps 30720 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:35,768] calculate_sps 30720 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:35,778] {'local/mean_episode_return': 24733.333333333332, 'local/mean_episode_step': 4434.666666666667, 'local/SPS': 3065.479275810515, 'local/env_act_steps': 2068096, 'local/env_train_steps': 2063360, 'local/optimizer_steps': 3224, 'local/running_reward': 13037.497006704982, 'local/running_step': 2365.294210967433, 'local/steps_done': 2068096, 'local/episodes_done': 611, 'local/unclipped_grad_norm': 0.6245736613248786, 'local/model_version': 3224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:35,780] {'global/mean_episode_return': 24480.0, 'global/mean_episode_step': 4613.6, 'global/SPS': 3065.479275810515, 'global/env_act_steps': 2062720, 'global/env_train_steps': 2058240, 'global/optimizer_steps': 3216, 'global/running_reward': 12953.930014258554, 'global/running_step': 2355.0466373574145, 'global/steps_done': 2062720, 'global/episodes_done': 611, 'global/unclipped_grad_norm': 0.5655185068026185, 'global/model_version': 3216, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:45,814] calculate_sps 35840 steps in 10.0468
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:45,814] calculate_sps 35840 steps in 10.0468
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:45,814] {'local/mean_episode_return': 22300.0, 'local/mean_episode_step': 4364.4, 'local/SPS': 3567.3086888744447, 'local/env_act_steps': 2100224, 'local/env_train_steps': 2099200, 'local/optimizer_steps': 3279, 'local/running_reward': 13532.880976095617, 'local/running_step': 2426.886983316733, 'local/steps_done': 2100224, 'local/episodes_done': 616, 'local/unclipped_grad_norm': 0.5237310466441241, 'local/model_version': 3279, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:45,815] {'global/mean_episode_return': 22975.0, 'global/mean_episode_step': 4324.5, 'global/SPS': 3567.3086888744447, 'global/env_act_steps': 2095104, 'global/env_train_steps': 2094080, 'global/optimizer_steps': 3271, 'global/running_reward': 13455.348320158102, 'global/running_step': 2417.5026865118575, 'global/steps_done': 2095104, 'global/episodes_done': 615, 'global/unclipped_grad_norm': 0.5608189204877073, 'global/model_version': 3271, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:55,815] calculate_sps 30720 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:26:55,816] calculate_sps 30720 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:55,816] {'local/mean_episode_return': 21800.0, 'local/mean_episode_step': 4123.333333333333, 'local/SPS': 3071.632441443834, 'local/env_act_steps': 2133632, 'local/env_train_steps': 2129920, 'local/optimizer_steps': 3328, 'local/running_reward': 14047.536518199233, 'local/running_step': 2493.149066091954, 'local/steps_done': 2133632, 'local/episodes_done': 619, 'local/unclipped_grad_norm': 0.6836521312290308, 'local/model_version': 3328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:26:55,818] {'global/mean_episode_return': 22100.0, 'global/mean_episode_step': 4650.0, 'global/SPS': 3071.632441443834, 'global/env_act_steps': 2128768, 'global/env_train_steps': 2124800, 'global/optimizer_steps': 3320, 'global/running_reward': 13959.333412547528, 'global/running_step': 2480.4300142585553, 'global/steps_done': 2128768, 'global/episodes_done': 617, 'global/unclipped_grad_norm': 0.6452202165917474, 'global/model_version': 3320, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:05,861] calculate_sps 33280 steps in 10.0459
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:05,861] calculate_sps 33920 steps in 10.0459
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:05,861] {'local/mean_episode_return': 20485.714285714286, 'local/mean_episode_step': 3720.8571428571427, 'local/SPS': 3312.7844900484943, 'local/env_act_steps': 2166272, 'local/env_train_steps': 2163200, 'local/optimizer_steps': 3379, 'local/running_reward': 14358.422181372549, 'local/running_step': 2527.161856617647, 'local/steps_done': 2166272, 'local/episodes_done': 626, 'local/unclipped_grad_norm': 0.6960303463480052, 'local/model_version': 3379, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:05,862] {'global/mean_episode_return': 20466.666666666668, 'global/mean_episode_step': 3737.777777777778, 'global/SPS': 3376.491884087888, 'global/env_act_steps': 2161408, 'global/env_train_steps': 2158720, 'global/optimizer_steps': 3373, 'global/running_reward': 14331.473651960785, 'global/running_step': 2526.2701899509802, 'global/steps_done': 2161408, 'global/episodes_done': 626, 'global/unclipped_grad_norm': 0.7429995730800448, 'global/model_version': 3373, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:15,870] calculate_sps 33280 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:15,871] calculate_sps 32640 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:15,871] {'local/mean_episode_return': 21243.75, 'local/mean_episode_step': 4133.1875, 'local/SPS': 3324.996067143148, 'local/env_act_steps': 2199168, 'local/env_train_steps': 2196480, 'local/optimizer_steps': 3432, 'local/running_reward': 14507.599708171207, 'local/running_step': 2532.370044990272, 'local/steps_done': 2199168, 'local/episodes_done': 635, 'local/unclipped_grad_norm': 0.5942698562482618, 'local/model_version': 3432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:15,872] {'global/mean_episode_return': 21433.333333333332, 'global/mean_episode_step': 4184.5, 'global/SPS': 3261.053835082703, 'global/env_act_steps': 2194560, 'global/env_train_steps': 2191360, 'global/optimizer_steps': 3424, 'global/running_reward': 14506.129343629344, 'global/running_step': 2533.8024855212357, 'global/steps_done': 2194560, 'global/episodes_done': 632, 'global/unclipped_grad_norm': 0.5331064250831511, 'global/model_version': 3424, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:25,907] calculate_sps 31360 steps in 10.0365
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:25,908] calculate_sps 33280 steps in 10.0365
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:25,908] {'local/mean_episode_return': 22580.0, 'local/mean_episode_step': 4142.8, 'local/SPS': 3124.6026570865397, 'local/env_act_steps': 2232448, 'local/env_train_steps': 2227840, 'local/optimizer_steps': 3480, 'local/running_reward': 14740.44170673077, 'local/running_step': 2562.029747596154, 'local/steps_done': 2232448, 'local/episodes_done': 640, 'local/unclipped_grad_norm': 0.44344805522511405, 'local/model_version': 3480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:25,910] {'global/mean_episode_return': 20958.333333333332, 'global/mean_episode_step': 4005.4166666666665, 'global/SPS': 3315.904860581634, 'global/env_act_steps': 2227712, 'global/env_train_steps': 2224640, 'global/optimizer_steps': 3475, 'global/running_reward': 14686.175796332047, 'global/running_step': 2554.3369932432433, 'global/steps_done': 2227712, 'global/episodes_done': 639, 'global/unclipped_grad_norm': 0.5060415823085636, 'global/model_version': 3475, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:35,919] calculate_sps 35200 steps in 10.0122
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:35,919] calculate_sps 33280 steps in 10.0122
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:35,920] {'local/mean_episode_return': 23366.666666666668, 'local/mean_episode_step': 4289.0, 'local/SPS': 3515.7082800948824, 'local/env_act_steps': 2264704, 'local/env_train_steps': 2263040, 'local/optimizer_steps': 3536, 'local/running_reward': 14820.628720238095, 'local/running_step': 2567.0231274801586, 'local/steps_done': 2264704, 'local/episodes_done': 649, 'local/unclipped_grad_norm': 0.6134655558105025, 'local/model_version': 3536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:35,921] {'global/mean_episode_return': 23880.0, 'global/mean_episode_step': 4324.1, 'global/SPS': 3323.942373907889, 'global/env_act_steps': 2261120, 'global/env_train_steps': 2257920, 'global/optimizer_steps': 3528, 'global/running_reward': 14836.557112068966, 'global/running_step': 2571.244222940613, 'global/steps_done': 2261120, 'global/episodes_done': 649, 'global/unclipped_grad_norm': 0.6004383977291718, 'global/model_version': 3528, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:45,956] calculate_sps 30720 steps in 10.0371
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:45,957] calculate_sps 32640 steps in 10.0371
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:45,957] {'local/mean_episode_return': 23620.0, 'local/mean_episode_step': 4493.4, 'local/SPS': 3060.642439084319, 'local/env_act_steps': 2298240, 'local/env_train_steps': 2293760, 'local/optimizer_steps': 3584, 'local/running_reward': 14969.271827290077, 'local/running_step': 2579.5773795324426, 'local/steps_done': 2298240, 'local/episodes_done': 654, 'local/unclipped_grad_norm': 0.40831035453205305, 'local/model_version': 3584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:45,958] {'global/mean_episode_return': 25625.0, 'global/mean_episode_step': 4767.5, 'global/SPS': 3251.9325915270892, 'global/env_act_steps': 2294144, 'global/env_train_steps': 2290560, 'global/optimizer_steps': 3578, 'global/running_reward': 14925.832727713178, 'global/running_step': 2573.7520288275196, 'global/steps_done': 2294144, 'global/episodes_done': 653, 'global/unclipped_grad_norm': 0.4325214309990406, 'global/model_version': 3578, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:55,974] calculate_sps 35840 steps in 10.0177
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:27:55,974] calculate_sps 33920 steps in 10.0177
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:55,974] {'local/mean_episode_return': 27800.0, 'local/mean_episode_step': 5338.0, 'local/SPS': 3577.6643934134204, 'local/env_act_steps': 2330624, 'local/env_train_steps': 2329600, 'local/optimizer_steps': 3639, 'local/running_reward': 15513.16699604743, 'local/running_step': 2654.8608880928855, 'local/steps_done': 2330624, 'local/episodes_done': 655, 'local/unclipped_grad_norm': 0.4574647383256392, 'local/model_version': 3639, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:27:55,975] {'global/mean_episode_return': 21700.0, 'global/mean_episode_step': 4367.5, 'global/SPS': 3386.00380090913, 'global/env_act_steps': 2327552, 'global/env_train_steps': 2324480, 'global/optimizer_steps': 3632, 'global/running_reward': 15436.673850574713, 'global/running_step': 2644.0919839559388, 'global/steps_done': 2327552, 'global/episodes_done': 655, 'global/unclipped_grad_norm': 0.4429649409872514, 'global/model_version': 3632, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:05,986] calculate_sps 30720 steps in 10.012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:05,986] calculate_sps 32000 steps in 10.012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:05,987] {'local/mean_episode_return': 27171.428571428572, 'local/mean_episode_step': 4997.714285714285, 'local/SPS': 3068.3217190657533, 'local/env_act_steps': 2363776, 'local/env_train_steps': 2360320, 'local/optimizer_steps': 3688, 'local/running_reward': 16076.239744208495, 'local/running_step': 2733.290661196911, 'local/steps_done': 2363776, 'local/episodes_done': 662, 'local/unclipped_grad_norm': 0.5152353790341592, 'local/model_version': 3688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:05,988] {'global/mean_episode_return': 26540.0, 'global/mean_episode_step': 4955.4, 'global/SPS': 3196.1684573601597, 'global/env_act_steps': 2360576, 'global/env_train_steps': 2356480, 'global/optimizer_steps': 3681, 'global/running_reward': 16050.566254844962, 'global/running_step': 2730.5890564437987, 'global/steps_done': 2360576, 'global/episodes_done': 660, 'global/unclipped_grad_norm': 0.5116727093652803, 'global/model_version': 3681, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:15,989] calculate_sps 32000 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:15,995] calculate_sps 34560 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:15,995] {'local/mean_episode_return': 26450.0, 'local/mean_episode_step': 4817.0, 'local/SPS': 3199.6192622247277, 'local/env_act_steps': 2396544, 'local/env_train_steps': 2392320, 'local/optimizer_steps': 3737, 'local/running_reward': 15964.75830078125, 'local/running_step': 2697.399932861328, 'local/steps_done': 2396544, 'local/episodes_done': 671, 'local/unclipped_grad_norm': 0.4643908863773151, 'local/model_version': 3737, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:15,996] {'global/mean_episode_return': 27300.0, 'global/mean_episode_step': 4915.777777777777, 'global/SPS': 3455.5888032027055, 'global/env_act_steps': 2393216, 'global/env_train_steps': 2391040, 'global/optimizer_steps': 3736, 'global/running_reward': 15996.979166666666, 'global/running_step': 2704.688756127451, 'global/steps_done': 2393216, 'global/episodes_done': 670, 'global/unclipped_grad_norm': 0.4630867944522338, 'global/model_version': 3736, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:26,016] calculate_sps 34560 steps in 10.0283
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:26,016] calculate_sps 30720 steps in 10.0283
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:26,016] {'local/mean_episode_return': 28771.428571428572, 'local/mean_episode_step': 5009.142857142857, 'local/SPS': 3446.260295797747, 'local/env_act_steps': 2428672, 'local/env_train_steps': 2426880, 'local/optimizer_steps': 3792, 'local/running_reward': 16028.607445219124, 'local/running_step': 2686.925143177291, 'local/steps_done': 2428672, 'local/episodes_done': 678, 'local/unclipped_grad_norm': 0.601262927326289, 'local/model_version': 3792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:26,017] {'global/mean_episode_return': 26866.666666666668, 'global/mean_episode_step': 4879.166666666667, 'global/SPS': 3063.342485153553, 'global/env_act_steps': 2426496, 'global/env_train_steps': 2421760, 'global/optimizer_steps': 3784, 'global/running_reward': 16004.741586538461, 'global/running_step': 2684.5415564903847, 'global/steps_done': 2426496, 'global/episodes_done': 676, 'global/unclipped_grad_norm': 0.6276740664616227, 'global/model_version': 3784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:36,042] calculate_sps 30720 steps in 10.0268
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:36,043] calculate_sps 35840 steps in 10.0268
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:36,043] {'local/mean_episode_return': 28425.0, 'local/mean_episode_step': 4861.5, 'local/SPS': 3063.7825869107933, 'local/env_act_steps': 2462464, 'local/env_train_steps': 2457600, 'local/optimizer_steps': 3840, 'local/running_reward': 16061.215672348484, 'local/running_step': 2676.950964725379, 'local/steps_done': 2462464, 'local/episodes_done': 682, 'local/unclipped_grad_norm': 0.572183029105266, 'local/model_version': 3840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:36,044] {'global/mean_episode_return': 29550.0, 'global/mean_episode_step': 4956.0, 'global/SPS': 3574.413018062592, 'global/env_act_steps': 2459392, 'global/env_train_steps': 2457600, 'global/optimizer_steps': 3840, 'global/running_reward': 16044.275899805447, 'global/running_step': 2675.1570403696496, 'global/steps_done': 2459392, 'global/episodes_done': 682, 'global/unclipped_grad_norm': 0.5589003334087985, 'global/model_version': 3840, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:46,046] calculate_sps 35840 steps in 10.0035
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:46,062] calculate_sps 30720 steps in 10.0035
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:46,062] {'local/mean_episode_return': 27900.0, 'local/mean_episode_step': 5227.0, 'local/SPS': 3582.7398963224755, 'local/env_act_steps': 2494720, 'local/env_train_steps': 2493440, 'local/optimizer_steps': 3896, 'local/running_reward': 16409.883432539682, 'local/running_step': 2719.0997333829364, 'local/steps_done': 2494720, 'local/episodes_done': 685, 'local/unclipped_grad_norm': 0.5418139142649514, 'local/model_version': 3896, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:46,064] {'global/mean_episode_return': 27900.0, 'global/mean_episode_step': 5227.0, 'global/SPS': 3070.9199111335506, 'global/env_act_steps': 2493312, 'global/env_train_steps': 2488320, 'global/optimizer_steps': 3888, 'global/running_reward': 16378.181014150943, 'global/running_step': 2714.797553066038, 'global/steps_done': 2493312, 'global/episodes_done': 685, 'global/unclipped_grad_norm': 0.5339741439869007, 'global/model_version': 3888, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:56,054] calculate_sps 30720 steps in 10.0082
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:28:56,054] calculate_sps 35840 steps in 10.0082
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:56,055] {'local/mean_episode_return': 30760.0, 'local/mean_episode_step': 5170.2, 'local/SPS': 3069.4727351323354, 'local/env_act_steps': 2527872, 'local/env_train_steps': 2524160, 'local/optimizer_steps': 3944, 'local/running_reward': 16891.689792471043, 'local/running_step': 2787.343930984556, 'local/steps_done': 2527872, 'local/episodes_done': 690, 'local/unclipped_grad_norm': 0.48921770974993706, 'local/model_version': 3944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:28:56,056] {'global/mean_episode_return': 30760.0, 'global/mean_episode_step': 5170.2, 'global/SPS': 3581.0515243210575, 'global/env_act_steps': 2525568, 'global/env_train_steps': 2524160, 'global/optimizer_steps': 3944, 'global/running_reward': 16882.049851190477, 'global/running_step': 2786.4694010416665, 'global/steps_done': 2525568, 'global/episodes_done': 690, 'global/unclipped_grad_norm': 0.503451256347554, 'global/model_version': 3944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:06,058] calculate_sps 32640 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:06,058] calculate_sps 30720 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:06,059] {'local/mean_episode_return': 27800.0, 'local/mean_episode_step': 4941.333333333333, 'local/SPS': 3262.5367097715325, 'local/env_act_steps': 2560384, 'local/env_train_steps': 2556800, 'local/optimizer_steps': 3994, 'local/running_reward': 16829.152312992126, 'local/running_step': 2761.4799151082675, 'local/steps_done': 2560384, 'local/episodes_done': 702, 'local/unclipped_grad_norm': 0.5866179913282394, 'local/model_version': 3994, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:06,060] {'global/mean_episode_return': 27581.81818181818, 'global/mean_episode_step': 4937.545454545455, 'global/SPS': 3070.6227856673245, 'global/env_act_steps': 2559232, 'global/env_train_steps': 2554880, 'global/optimizer_steps': 3992, 'global/running_reward': 16849.474215779468, 'global/running_step': 2765.735444391635, 'global/steps_done': 2559232, 'global/episodes_done': 701, 'global/unclipped_grad_norm': 0.5715339127928019, 'global/model_version': 3992, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:16,061] calculate_sps 33920 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:16,061] calculate_sps 35840 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:16,061] {'local/mean_episode_return': 30680.0, 'local/mean_episode_step': 5270.8, 'local/SPS': 3391.279021381529, 'local/env_act_steps': 2593024, 'local/env_train_steps': 2590720, 'local/optimizer_steps': 4048, 'local/running_reward': 16406.05698529412, 'local/running_step': 2688.2685355392155, 'local/steps_done': 2593024, 'local/episodes_done': 707, 'local/unclipped_grad_norm': 0.4939702485722524, 'local/model_version': 4048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:16,071] {'global/mean_episode_return': 30600.0, 'global/mean_episode_step': 5222.833333333333, 'global/SPS': 3583.2382112710497, 'global/env_act_steps': 2591744, 'global/env_train_steps': 2590720, 'global/optimizer_steps': 4047, 'global/running_reward': 16402.140748031496, 'global/running_step': 2687.6026082677167, 'global/steps_done': 2591744, 'global/episodes_done': 707, 'global/unclipped_grad_norm': 0.5108985636721958, 'global/model_version': 4047, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:26,079] calculate_sps 30720 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:26,079] calculate_sps 30720 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:26,080] {'local/mean_episode_return': 30485.714285714286, 'local/mean_episode_step': 5199.571428571428, 'local/SPS': 3066.382799719961, 'local/env_act_steps': 2626176, 'local/env_train_steps': 2621440, 'local/optimizer_steps': 4096, 'local/running_reward': 16618.535834942086, 'local/running_step': 2717.772110279923, 'local/steps_done': 2626176, 'local/episodes_done': 714, 'local/unclipped_grad_norm': 0.6030436437577009, 'local/model_version': 4096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:26,081] {'global/mean_episode_return': 30485.714285714286, 'global/mean_episode_step': 5199.571428571428, 'global/SPS': 3066.382799719961, 'global/env_act_steps': 2625152, 'global/env_train_steps': 2621440, 'global/optimizer_steps': 4096, 'global/running_reward': 16619.010416666668, 'global/running_step': 2718.114343869732, 'global/steps_done': 2625152, 'global/episodes_done': 714, 'global/unclipped_grad_norm': 0.6003742668093467, 'global/model_version': 4096, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:36,097] calculate_sps 35840 steps in 10.0187
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:36,097] calculate_sps 34560 steps in 10.0187
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:36,098] {'local/mean_episode_return': 32300.0, 'local/mean_episode_step': 5397.5, 'local/SPS': 3577.3065547678084, 'local/env_act_steps': 2658304, 'local/env_train_steps': 2657280, 'local/optimizer_steps': 4151, 'local/running_reward': 16866.92293326693, 'local/running_step': 2754.37546688247, 'local/steps_done': 2658304, 'local/episodes_done': 716, 'local/unclipped_grad_norm': 0.6558731374415484, 'local/model_version': 4151, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:36,098] {'global/mean_episode_return': 32300.0, 'global/mean_episode_step': 5397.5, 'global/SPS': 3449.545606383244, 'global/env_act_steps': 2658048, 'global/env_train_steps': 2656000, 'global/optimizer_steps': 4149, 'global/running_reward': 16854.678380350193, 'global/running_step': 2752.4821254863814, 'global/steps_done': 2658048, 'global/episodes_done': 716, 'global/unclipped_grad_norm': 0.662715383576897, 'global/model_version': 4149, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:46,112] calculate_sps 30720 steps in 10.0147
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:46,113] calculate_sps 32000 steps in 10.0147
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:46,113] {'local/mean_episode_return': 32320.0, 'local/mean_episode_step': 5358.3, 'local/SPS': 3067.4805843784275, 'local/env_act_steps': 2691584, 'local/env_train_steps': 2688000, 'local/optimizer_steps': 4200, 'local/running_reward': 16608.47355769231, 'local/running_step': 2703.3956730769232, 'local/steps_done': 2691584, 'local/episodes_done': 726, 'local/unclipped_grad_norm': 0.5627718320002362, 'local/model_version': 4200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:46,115] {'global/mean_episode_return': 32320.0, 'global/mean_episode_step': 5358.3, 'global/SPS': 3195.2922753941953, 'global/env_act_steps': 2691072, 'global/env_train_steps': 2688000, 'global/optimizer_steps': 4200, 'global/running_reward': 16611.967054263565, 'global/running_step': 2703.9896741763564, 'global/steps_done': 2691072, 'global/episodes_done': 726, 'global/unclipped_grad_norm': 0.5593122940729646, 'global/model_version': 4200, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:56,140] calculate_sps 32640 steps in 10.0269
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:29:56,140] calculate_sps 32000 steps in 10.0269
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:56,140] {'local/mean_episode_return': 31080.0, 'local/mean_episode_step': 5135.9, 'local/SPS': 3255.248718856791, 'local/env_act_steps': 2724224, 'local/env_train_steps': 2720640, 'local/optimizer_steps': 4250, 'local/running_reward': 16422.720588235294, 'local/running_step': 2677.8407475490194, 'local/steps_done': 2724224, 'local/episodes_done': 736, 'local/unclipped_grad_norm': 0.5257890623807907, 'local/model_version': 4250, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:29:56,142] {'global/mean_episode_return': 31080.0, 'global/mean_episode_step': 5135.9, 'global/SPS': 3191.4203126046973, 'global/env_act_steps': 2724096, 'global/env_train_steps': 2720000, 'global/optimizer_steps': 4249, 'global/running_reward': 16430.208333333332, 'global/running_step': 2678.9487039728683, 'global/steps_done': 2724096, 'global/episodes_done': 736, 'global/unclipped_grad_norm': 0.5261141201671289, 'global/model_version': 4249, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:06,152] calculate_sps 33920 steps in 10.0132
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:06,153] calculate_sps 34560 steps in 10.0132
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:06,153] {'local/mean_episode_return': 32580.0, 'local/mean_episode_step': 5214.7, 'local/SPS': 3387.5376424245455, 'local/env_act_steps': 2756992, 'local/env_train_steps': 2754560, 'local/optimizer_steps': 4304, 'local/running_reward': 15999.444580078125, 'local/running_step': 2618.436737060547, 'local/steps_done': 2756992, 'local/episodes_done': 746, 'local/unclipped_grad_norm': 0.5737344801977828, 'local/model_version': 4304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:06,154] {'global/mean_episode_return': 32488.88888888889, 'global/mean_episode_step': 5194.888888888889, 'global/SPS': 3451.4534469985933, 'global/env_act_steps': 2756864, 'global/env_train_steps': 2754560, 'global/optimizer_steps': 4304, 'global/running_reward': 15999.822998046875, 'global/running_step': 2618.4177856445312, 'global/steps_done': 2756864, 'global/episodes_done': 745, 'global/unclipped_grad_norm': 0.5725731483914636, 'global/model_version': 4304, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:16,165] calculate_sps 30720 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:16,165] calculate_sps 25600 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:16,165] {'local/mean_episode_return': 32833.333333333336, 'local/mean_episode_step': 5375.166666666667, 'local/SPS': 3068.2162140923992, 'local/env_act_steps': 2790144, 'local/env_train_steps': 2785280, 'local/optimizer_steps': 4352, 'local/running_reward': 15512.125965250965, 'local/running_step': 2550.265625, 'local/steps_done': 2790144, 'local/episodes_done': 752, 'local/unclipped_grad_norm': 0.6449283305555582, 'local/model_version': 4352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:16,167] {'global/mean_episode_return': 32466.666666666668, 'global/mean_episode_step': 5375.0, 'global/SPS': 2556.8468450769997, 'global/env_act_steps': 2783360, 'global/env_train_steps': 2780160, 'global/optimizer_steps': 4344, 'global/running_reward': 15479.234601449276, 'global/running_step': 2545.079294987923, 'global/steps_done': 2783360, 'global/episodes_done': 751, 'global/unclipped_grad_norm': 0.6094185456633567, 'global/model_version': 4344, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:26,212] calculate_sps 35200 steps in 10.0477
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:26,212] calculate_sps 31360 steps in 10.0477
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:26,213] {'local/mean_episode_return': 32585.714285714286, 'local/mean_episode_step': 5328.0, 'local/SPS': 3503.2817703278765, 'local/env_act_steps': 2822016, 'local/env_train_steps': 2820480, 'local/optimizer_steps': 4406, 'local/running_reward': 15207.542670682731, 'local/running_step': 2498.7048506526103, 'local/steps_done': 2822016, 'local/episodes_done': 766, 'local/unclipped_grad_norm': 0.6814294095944475, 'local/model_version': 4406, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:26,214] {'global/mean_episode_return': 32692.30769230769, 'global/mean_episode_step': 5322.538461538462, 'global/SPS': 3121.105577201199, 'global/env_act_steps': 2816256, 'global/env_train_steps': 2811520, 'global/optimizer_steps': 4393, 'global/running_reward': 15408.426556420234, 'global/running_step': 2531.4595087548637, 'global/steps_done': 2816256, 'global/episodes_done': 764, 'global/unclipped_grad_norm': 0.7292364844862296, 'global/model_version': 4393, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:36,221] calculate_sps 31360 steps in 10.0083
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:36,221] calculate_sps 35200 steps in 10.0083
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:36,221] {'local/mean_episode_return': 33844.444444444445, 'local/mean_episode_step': 5300.666666666667, 'local/SPS': 3133.4043337446224, 'local/env_act_steps': 2855296, 'local/env_train_steps': 2851840, 'local/optimizer_steps': 4456, 'local/running_reward': 14418.185096153846, 'local/running_step': 2374.1513521634615, 'local/steps_done': 2855296, 'local/episodes_done': 775, 'local/unclipped_grad_norm': 0.5166416142880916, 'local/model_version': 4456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:36,231] {'global/mean_episode_return': 33400.0, 'global/mean_episode_step': 5288.75, 'global/SPS': 3517.08649706029, 'global/env_act_steps': 2848896, 'global/env_train_steps': 2846720, 'global/optimizer_steps': 4448, 'global/running_reward': 14484.859068627451, 'global/running_step': 2385.079381127451, 'global/steps_done': 2848896, 'global/episodes_done': 772, 'global/unclipped_grad_norm': 0.5342299829829823, 'global/model_version': 4448, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:46,265] calculate_sps 33280 steps in 10.0443
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:46,265] calculate_sps 30720 steps in 10.0443
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:46,265] {'local/mean_episode_return': 29650.0, 'local/mean_episode_step': 5035.25, 'local/SPS': 3313.326990876357, 'local/env_act_steps': 2888192, 'local/env_train_steps': 2885120, 'local/optimizer_steps': 4507, 'local/running_reward': 14328.459387159533, 'local/running_step': 2353.058943336576, 'local/steps_done': 2888192, 'local/episodes_done': 779, 'local/unclipped_grad_norm': 0.6828100121780938, 'local/model_version': 4507, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:46,266] {'global/mean_episode_return': 31828.571428571428, 'global/mean_episode_step': 5190.0, 'global/SPS': 3058.4556838858675, 'global/env_act_steps': 2882560, 'global/env_train_steps': 2877440, 'global/optimizer_steps': 4496, 'global/running_reward': 14277.317015209126, 'global/running_step': 2345.9518773764257, 'global/steps_done': 2882560, 'global/episodes_done': 779, 'global/unclipped_grad_norm': 0.6535407227153579, 'global/model_version': 4496, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:56,288] calculate_sps 33280 steps in 10.0232
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:30:56,289] calculate_sps 35840 steps in 10.0232
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:56,289] {'local/mean_episode_return': 31640.0, 'local/mean_episode_step': 5150.8, 'local/SPS': 3320.2898704406903, 'local/env_act_steps': 2920960, 'local/env_train_steps': 2918400, 'local/optimizer_steps': 4560, 'local/running_reward': 14787.298583984375, 'local/running_step': 2421.9489135742188, 'local/steps_done': 2920960, 'local/episodes_done': 784, 'local/unclipped_grad_norm': 0.46797616582996443, 'local/model_version': 4560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:30:56,290] {'global/mean_episode_return': 31466.666666666668, 'global/mean_episode_step': 5137.0, 'global/SPS': 3575.6967835515125, 'global/env_act_steps': 2914816, 'global/env_train_steps': 2913280, 'global/optimizer_steps': 4552, 'global/running_reward': 14729.061259920634, 'global/running_step': 2413.2580295138887, 'global/steps_done': 2914816, 'global/episodes_done': 782, 'global/unclipped_grad_norm': 0.5000658402485507, 'global/model_version': 4552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:06,309] calculate_sps 30720 steps in 10.0206
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:06,309] calculate_sps 30720 steps in 10.0206
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:06,318] {'local/mean_episode_return': 33150.0, 'local/mean_episode_step': 5328.5, 'local/SPS': 3065.686050800982, 'local/env_act_steps': 2954112, 'local/env_train_steps': 2949120, 'local/optimizer_steps': 4608, 'local/running_reward': 14855.170125482626, 'local/running_step': 2425.972158542471, 'local/steps_done': 2954112, 'local/episodes_done': 788, 'local/unclipped_grad_norm': 0.5017627254128456, 'local/model_version': 4608, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:06,319] {'global/mean_episode_return': 32733.333333333332, 'global/mean_episode_step': 5276.166666666667, 'global/SPS': 3065.686050800982, 'global/env_act_steps': 2948352, 'global/env_train_steps': 2944000, 'global/optimizer_steps': 4600, 'global/running_reward': 14820.234971374046, 'global/running_step': 2422.023556774809, 'global/steps_done': 2948352, 'global/episodes_done': 788, 'global/unclipped_grad_norm': 0.46360466225693625, 'global/model_version': 4600, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:16,335] calculate_sps 35840 steps in 10.0264
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:16,336] calculate_sps 35200 steps in 10.0264
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:16,336] {'local/mean_episode_return': 32100.0, 'local/mean_episode_step': 5365.0, 'local/SPS': 3574.562016454025, 'local/env_act_steps': 2986368, 'local/env_train_steps': 2984960, 'local/optimizer_steps': 4664, 'local/running_reward': 15367.652529761905, 'local/running_step': 2502.1711309523807, 'local/steps_done': 2986368, 'local/episodes_done': 790, 'local/unclipped_grad_norm': 0.5355467253497669, 'local/model_version': 4664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:16,337] {'global/mean_episode_return': 31400.0, 'global/mean_episode_step': 5332.0, 'global/SPS': 3510.730551874489, 'global/env_act_steps': 2980864, 'global/env_train_steps': 2979200, 'global/optimizer_steps': 4655, 'global/running_reward': 15270.269438976378, 'global/running_step': 2486.787524606299, 'global/steps_done': 2980864, 'global/episodes_done': 789, 'global/unclipped_grad_norm': 0.5618425111879002, 'global/model_version': 4655, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:26,360] calculate_sps 30720 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:26,360] calculate_sps 31360 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:26,361] {'local/mean_episode_return': 32200.0, 'local/mean_episode_step': 5394.0, 'local/SPS': 3064.4338664450333, 'local/env_act_steps': 3019776, 'local/env_train_steps': 3015680, 'local/optimizer_steps': 4712, 'local/running_reward': 15974.0780651341, 'local/running_step': 2601.533644636015, 'local/steps_done': 3019776, 'local/episodes_done': 791, 'local/unclipped_grad_norm': 0.5142543842084706, 'local/model_version': 4712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:26,368] {'global/mean_episode_return': 32500.0, 'global/mean_episode_step': 5396.0, 'global/SPS': 3128.276238662638, 'global/env_act_steps': 3014528, 'global/env_train_steps': 3010560, 'global/optimizer_steps': 4704, 'global/running_reward': 15867.53208174905, 'global/running_step': 2584.267169676806, 'global/steps_done': 3014528, 'global/episodes_done': 791, 'global/unclipped_grad_norm': 0.5296441917212642, 'global/model_version': 4704, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:36,392] calculate_sps 34560 steps in 10.0323
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:36,392] calculate_sps 34560 steps in 10.0323
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:36,392] {'local/mean_episode_return': 32550.0, 'local/mean_episode_step': 5287.0, 'local/SPS': 3444.8834588225322, 'local/env_act_steps': 3052288, 'local/env_train_steps': 3050240, 'local/optimizer_steps': 4765, 'local/running_reward': 16308.71062992126, 'local/running_step': 2656.9568467027557, 'local/steps_done': 3052288, 'local/episodes_done': 795, 'local/unclipped_grad_norm': 0.5525589127023265, 'local/model_version': 4765, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:36,394] {'global/mean_episode_return': 32550.0, 'global/mean_episode_step': 5287.0, 'global/SPS': 3444.8834588225322, 'global/env_act_steps': 3047168, 'global/env_train_steps': 3045120, 'global/optimizer_steps': 4757, 'global/running_reward': 16268.192401960785, 'global/running_step': 2650.0089767156865, 'global/steps_done': 3047168, 'global/episodes_done': 795, 'global/unclipped_grad_norm': 0.5483111446758486, 'global/model_version': 4757, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:46,409] calculate_sps 32000 steps in 10.0166
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:46,409] calculate_sps 32000 steps in 10.0166
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:46,409] {'local/mean_episode_return': 34600.0, 'local/mean_episode_step': 5259.4, 'local/SPS': 3194.6864956706886, 'local/env_act_steps': 3084928, 'local/env_train_steps': 3082240, 'local/optimizer_steps': 4816, 'local/running_reward': 16533.553921568626, 'local/running_step': 2697.3872549019607, 'local/steps_done': 3084928, 'local/episodes_done': 800, 'local/unclipped_grad_norm': 0.49789156793963674, 'local/model_version': 4816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:46,411] {'global/mean_episode_return': 34600.0, 'global/mean_episode_step': 5259.4, 'global/SPS': 3194.6864956706886, 'global/env_act_steps': 3080192, 'global/env_train_steps': 3077120, 'global/optimizer_steps': 4808, 'global/running_reward': 16511.6824127907, 'global/running_step': 2693.5146257267443, 'global/steps_done': 3080192, 'global/episodes_done': 800, 'global/unclipped_grad_norm': 0.5374300625978732, 'global/model_version': 4808, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:56,428] calculate_sps 30720 steps in 10.0195
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:31:56,429] calculate_sps 31360 steps in 10.0195
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:56,429] {'local/mean_episode_return': 34057.142857142855, 'local/mean_episode_step': 5269.142857142857, 'local/SPS': 3066.034385676844, 'local/env_act_steps': 3117952, 'local/env_train_steps': 3112960, 'local/optimizer_steps': 4864, 'local/running_reward': 16693.192829457363, 'local/running_step': 2725.3348171027133, 'local/steps_done': 3117952, 'local/episodes_done': 807, 'local/unclipped_grad_norm': 0.58706482903411, 'local/model_version': 4864, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:31:56,439] {'global/mean_episode_return': 33560.0, 'global/mean_episode_step': 5217.6, 'global/SPS': 3129.9101020451117, 'global/env_act_steps': 3113088, 'global/env_train_steps': 3108480, 'global/optimizer_steps': 4856, 'global/running_reward': 16677.176556420232, 'global/running_step': 2722.025747811284, 'global/steps_done': 3113088, 'global/episodes_done': 805, 'global/unclipped_grad_norm': 0.538710151022921, 'global/model_version': 4856, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:06,476] calculate_sps 35840 steps in 10.0478
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:06,476] calculate_sps 35200 steps in 10.0478
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:06,476] {'local/mean_episode_return': 30733.333333333332, 'local/mean_episode_step': 5159.166666666667, 'local/SPS': 3566.9511412835673, 'local/env_act_steps': 3149824, 'local/env_train_steps': 3148800, 'local/optimizer_steps': 4919, 'local/running_reward': 16359.789156626506, 'local/running_step': 2676.5503576807228, 'local/steps_done': 3149824, 'local/episodes_done': 813, 'local/unclipped_grad_norm': 0.6172925055027008, 'local/model_version': 4919, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:06,477] {'global/mean_episode_return': 31875.0, 'global/mean_episode_step': 5218.875, 'global/SPS': 3503.255585189218, 'global/env_act_steps': 3145472, 'global/env_train_steps': 3143680, 'global/optimizer_steps': 4912, 'global/running_reward': 16398.165760869564, 'global/running_step': 2682.149209486166, 'global/steps_done': 3145472, 'global/episodes_done': 813, 'global/unclipped_grad_norm': 0.6354192019041095, 'global/model_version': 4912, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:16,499] calculate_sps 30720 steps in 10.0228
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:16,499] calculate_sps 30720 steps in 10.0228
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:16,499] {'local/mean_episode_return': 34890.90909090909, 'local/mean_episode_step': 5396.0, 'local/SPS': 3065.019292403568, 'local/env_act_steps': 3183616, 'local/env_train_steps': 3179520, 'local/optimizer_steps': 4968, 'local/running_reward': 16254.290956439394, 'local/running_step': 2662.183445785985, 'local/steps_done': 3183616, 'local/episodes_done': 824, 'local/unclipped_grad_norm': 0.5042074860966935, 'local/model_version': 4968, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:16,501] {'global/mean_episode_return': 35355.555555555555, 'global/mean_episode_step': 5396.0, 'global/SPS': 3065.019292403568, 'global/env_act_steps': 3179392, 'global/env_train_steps': 3174400, 'global/optimizer_steps': 4960, 'global/running_reward': 16322.16391509434, 'global/running_step': 2672.3267688679243, 'global/steps_done': 3179392, 'global/episodes_done': 822, 'global/unclipped_grad_norm': 0.502706757436196, 'global/model_version': 4960, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:26,506] calculate_sps 33920 steps in 10.0069
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:26,506] calculate_sps 35840 steps in 10.0069
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:26,507] {'local/mean_episode_return': 31600.0, 'local/mean_episode_step': 5238.5, 'local/SPS': 3389.657152155852, 'local/env_act_steps': 3216128, 'local/env_train_steps': 3213440, 'local/optimizer_steps': 5021, 'local/running_reward': 15953.635580708662, 'local/running_step': 2614.600024606299, 'local/steps_done': 3216128, 'local/episodes_done': 830, 'local/unclipped_grad_norm': 0.526766117451326, 'local/model_version': 5021, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:26,508] {'global/mean_episode_return': 33171.42857142857, 'global/mean_episode_step': 5398.285714285715, 'global/SPS': 3581.5245381269383, 'global/env_act_steps': 3211392, 'global/env_train_steps': 3210240, 'global/optimizer_steps': 5016, 'global/running_reward': 15949.625, 'global/running_step': 2614.79190625, 'global/steps_done': 3211392, 'global/episodes_done': 829, 'global/unclipped_grad_norm': 0.5227573527289289, 'global/model_version': 5016, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:36,534] calculate_sps 32640 steps in 10.0285
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:36,535] calculate_sps 30720 steps in 10.0285
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:36,535] {'local/mean_episode_return': 29800.0, 'local/mean_episode_step': 5058.0, 'local/SPS': 3254.724087875072, 'local/env_act_steps': 3249152, 'local/env_train_steps': 3246080, 'local/optimizer_steps': 5072, 'local/running_reward': 16258.733042635658, 'local/running_step': 2649.0823340600773, 'local/steps_done': 3249152, 'local/episodes_done': 833, 'local/unclipped_grad_norm': 0.45840189854304, 'local/model_version': 5072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:36,536] {'global/mean_episode_return': 27000.0, 'global/mean_episode_step': 4738.333333333333, 'global/SPS': 3063.269729764774, 'global/env_act_steps': 3245184, 'global/env_train_steps': 3240960, 'global/optimizer_steps': 5064, 'global/running_reward': 16200.698390151516, 'global/running_step': 2641.941347064394, 'global/steps_done': 3245184, 'global/episodes_done': 832, 'global/unclipped_grad_norm': 0.47636424160252017, 'global/model_version': 5064, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:46,551] calculate_sps 32000 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:46,551] calculate_sps 35840 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:46,552] {'local/mean_episode_return': 31545.454545454544, 'local/mean_episode_step': 5189.545454545455, 'local/SPS': 3194.510546978153, 'local/env_act_steps': 3282176, 'local/env_train_steps': 3278080, 'local/optimizer_steps': 5121, 'local/running_reward': 16485.101744186046, 'local/running_step': 2680.6935562015506, 'local/steps_done': 3282176, 'local/episodes_done': 844, 'local/unclipped_grad_norm': 0.5500718260906181, 'local/model_version': 5121, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:46,552] {'global/mean_episode_return': 31571.428571428572, 'global/mean_episode_step': 5322.714285714285, 'global/SPS': 3577.8518126155313, 'global/env_act_steps': 3277824, 'global/env_train_steps': 3276800, 'global/optimizer_steps': 5119, 'global/running_reward': 16520.208333333332, 'global/running_step': 2686.5390625, 'global/steps_done': 3277824, 'global/episodes_done': 839, 'global/unclipped_grad_norm': 0.5102810721505772, 'global/model_version': 5119, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:56,555] calculate_sps 34560 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:32:56,556] calculate_sps 30720 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:56,556] {'local/mean_episode_return': 36200.0, 'local/mean_episode_step': 5397.0, 'local/SPS': 3454.618664512097, 'local/env_act_steps': 3314816, 'local/env_train_steps': 3312640, 'local/optimizer_steps': 5176, 'local/running_reward': 16134.04411764706, 'local/running_step': 2629.2726409313727, 'local/steps_done': 3314816, 'local/episodes_done': 848, 'local/unclipped_grad_norm': 0.5222090837630359, 'local/model_version': 5176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:32:56,557] {'global/mean_episode_return': 33577.77777777778, 'global/mean_episode_step': 5200.888888888889, 'global/SPS': 3070.772146232975, 'global/env_act_steps': 3311616, 'global/env_train_steps': 3307520, 'global/optimizer_steps': 5168, 'global/running_reward': 16141.96259469697, 'global/running_step': 2629.516808712121, 'global/steps_done': 3311616, 'global/episodes_done': 848, 'global/unclipped_grad_norm': 0.5418984257445043, 'global/model_version': 5168, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:06,580] calculate_sps 30720 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:06,580] calculate_sps 35200 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:06,581] {'local/mean_episode_return': 33542.857142857145, 'local/mean_episode_step': 5380.857142857143, 'local/SPS': 3064.463165229026, 'local/env_act_steps': 3348352, 'local/env_train_steps': 3343360, 'local/optimizer_steps': 5224, 'local/running_reward': 16244.280772900764, 'local/running_step': 2647.9945729961833, 'local/steps_done': 3348352, 'local/episodes_done': 855, 'local/unclipped_grad_norm': 0.45558982621878386, 'local/model_version': 5224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:06,582] {'global/mean_episode_return': 33333.333333333336, 'global/mean_episode_step': 5378.5, 'global/SPS': 3511.364043491592, 'global/env_act_steps': 3344256, 'global/env_train_steps': 3342720, 'global/optimizer_steps': 5222, 'global/running_reward': 16260.863970588236, 'global/running_step': 2650.874080882353, 'global/steps_done': 3344256, 'global/episodes_done': 854, 'global/unclipped_grad_norm': 0.45830876021473493, 'global/model_version': 5222, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:16,583] calculate_sps 35840 steps in 10.0029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:16,583] calculate_sps 31360 steps in 10.0029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:16,584] {'local/mean_episode_return': 34428.57142857143, 'local/mean_episode_step': 5380.571428571428, 'local/SPS': 3582.9519301121104, 'local/env_act_steps': 3380480, 'local/env_train_steps': 3379200, 'local/optimizer_steps': 5280, 'local/running_reward': 16071.227589641434, 'local/running_step': 2620.086124252988, 'local/steps_done': 3380480, 'local/episodes_done': 862, 'local/unclipped_grad_norm': 0.4549116670553173, 'local/model_version': 5280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:16,585] {'global/mean_episode_return': 34475.0, 'global/mean_episode_step': 5382.375, 'global/SPS': 3135.0829388480965, 'global/env_act_steps': 3377920, 'global/env_train_steps': 3374080, 'global/optimizer_steps': 5272, 'global/running_reward': 16082.052043726235, 'global/running_step': 2621.332283745247, 'global/steps_done': 3377920, 'global/episodes_done': 862, 'global/unclipped_grad_norm': 0.46770312666893005, 'global/model_version': 5272, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:26,591] calculate_sps 30720 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:26,591] calculate_sps 32640 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:26,591] {'local/mean_episode_return': 32342.85714285714, 'local/mean_episode_step': 5216.571428571428, 'local/SPS': 3069.5747433324027, 'local/env_act_steps': 3413120, 'local/env_train_steps': 3409920, 'local/optimizer_steps': 5328, 'local/running_reward': 15988.921568627451, 'local/running_step': 2610.641544117647, 'local/steps_done': 3413120, 'local/episodes_done': 869, 'local/unclipped_grad_norm': 0.4921600439896186, 'local/model_version': 5328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:26,593] {'global/mean_episode_return': 31900.0, 'global/mean_episode_step': 5186.333333333333, 'global/SPS': 3261.423164790678, 'global/env_act_steps': 3410432, 'global/env_train_steps': 3406720, 'global/optimizer_steps': 5323, 'global/running_reward': 15987.598425196851, 'global/running_step': 2610.5907664862207, 'global/steps_done': 3410432, 'global/episodes_done': 868, 'global/unclipped_grad_norm': 0.448589827207958, 'global/model_version': 5323, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:36,626] calculate_sps 32640 steps in 10.0353
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:36,626] calculate_sps 33920 steps in 10.0353
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:36,626] {'local/mean_episode_return': 33150.0, 'local/mean_episode_step': 5394.5, 'local/SPS': 3252.503381221619, 'local/env_act_steps': 3446144, 'local/env_train_steps': 3442560, 'local/optimizer_steps': 5378, 'local/running_reward': 15947.916666666666, 'local/running_step': 2605.4467357073645, 'local/steps_done': 3446144, 'local/episodes_done': 873, 'local/unclipped_grad_norm': 0.5283479343354702, 'local/model_version': 5378, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:36,627] {'global/mean_episode_return': 33520.0, 'global/mean_episode_step': 5395.2, 'global/SPS': 3380.052533426388, 'global/env_act_steps': 3443328, 'global/env_train_steps': 3440640, 'global/optimizer_steps': 5376, 'global/running_reward': 15931.420233463035, 'global/running_step': 2603.116001945525, 'global/steps_done': 3443328, 'global/episodes_done': 873, 'global/unclipped_grad_norm': 0.5318434366358901, 'global/model_version': 5376, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:46,639] calculate_sps 33920 steps in 10.013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:46,640] calculate_sps 32000 steps in 10.013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:46,640] {'local/mean_episode_return': 34000.0, 'local/mean_episode_step': 5397.0, 'local/SPS': 3387.5904748543467, 'local/env_act_steps': 3478784, 'local/env_train_steps': 3476480, 'local/optimizer_steps': 5432, 'local/running_reward': 16494.05024509804, 'local/running_step': 2683.385324754902, 'local/steps_done': 3478784, 'local/episodes_done': 875, 'local/unclipped_grad_norm': 0.6435151508560887, 'local/model_version': 5432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:46,641] {'global/mean_episode_return': 34000.0, 'global/mean_episode_step': 5397.0, 'global/SPS': 3195.840070617308, 'global/env_act_steps': 3476736, 'global/env_train_steps': 3472640, 'global/optimizer_steps': 5425, 'global/running_reward': 16449.46120689655, 'global/running_step': 2676.6805256226053, 'global/steps_done': 3476736, 'global/episodes_done': 875, 'global/unclipped_grad_norm': 0.6506093308633688, 'global/model_version': 5425, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:56,662] calculate_sps 30720 steps in 10.0225
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:33:56,662] calculate_sps 34560 steps in 10.0225
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:56,667] {'local/mean_episode_return': 35000.0, 'local/mean_episode_step': 5394.0, 'local/SPS': 3065.1095572699205, 'local/env_act_steps': 3512320, 'local/env_train_steps': 3507200, 'local/optimizer_steps': 5480, 'local/running_reward': 17053.470896946565, 'local/running_step': 2767.2401598282445, 'local/steps_done': 3512320, 'local/episodes_done': 876, 'local/unclipped_grad_norm': 0.5095198548709353, 'local/model_version': 5480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:33:56,669] {'global/mean_episode_return': 35000.0, 'global/mean_episode_step': 5394.0, 'global/SPS': 3448.248251928661, 'global/env_act_steps': 3509888, 'global/env_train_steps': 3507200, 'global/optimizer_steps': 5480, 'global/running_reward': 17007.7763030888, 'global/running_step': 2760.1951013513512, 'global/steps_done': 3509888, 'global/episodes_done': 876, 'global/unclipped_grad_norm': 0.5308691336350008, 'global/model_version': 5480, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:06,667] calculate_sps 35200 steps in 10.0057
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:06,667] calculate_sps 30720 steps in 10.0057
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:06,667] {'local/mean_episode_return': 32925.0, 'local/mean_episode_step': 5272.25, 'local/SPS': 3518.0111341473366, 'local/env_act_steps': 3543936, 'local/env_train_steps': 3542400, 'local/optimizer_steps': 5534, 'local/running_reward': 17175.92990890688, 'local/running_step': 2780.276189271255, 'local/steps_done': 3543936, 'local/episodes_done': 885, 'local/unclipped_grad_norm': 0.5246379118826654, 'local/model_version': 5534, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:06,669] {'global/mean_episode_return': 32925.0, 'global/mean_episode_step': 5272.25, 'global/SPS': 3070.2642625285844, 'global/env_act_steps': 3543040, 'global/env_train_steps': 3537920, 'global/optimizer_steps': 5528, 'global/running_reward': 17188.531611969112, 'global/running_step': 2782.8680320945946, 'global/steps_done': 3543040, 'global/episodes_done': 885, 'global/unclipped_grad_norm': 0.5301111492638787, 'global/model_version': 5528, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:16,703] calculate_sps 31360 steps in 10.0358
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:16,704] calculate_sps 35840 steps in 10.0358
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:16,704] {'local/mean_episode_return': 32920.0, 'local/mean_episode_step': 5268.7, 'local/SPS': 3124.8068650196215, 'local/env_act_steps': 3576960, 'local/env_train_steps': 3573760, 'local/optimizer_steps': 5584, 'local/running_reward': 16822.20203488372, 'local/running_step': 2723.3197977228683, 'local/steps_done': 3576960, 'local/episodes_done': 895, 'local/unclipped_grad_norm': 0.4525772187113762, 'local/model_version': 5584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:16,705] {'global/mean_episode_return': 32375.0, 'global/mean_episode_step': 5237.0, 'global/SPS': 3571.20784573671, 'global/env_act_steps': 3575168, 'global/env_train_steps': 3573760, 'global/optimizer_steps': 5584, 'global/running_reward': 16839.404880478087, 'global/running_step': 2725.8238296812747, 'global/steps_done': 3575168, 'global/episodes_done': 893, 'global/unclipped_grad_norm': 0.4556066609386887, 'global/model_version': 5584, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:26,737] calculate_sps 32640 steps in 10.0341
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:26,737] calculate_sps 30720 steps in 10.0341
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:26,737] {'local/mean_episode_return': 34350.0, 'local/mean_episode_step': 5397.25, 'local/SPS': 3252.922948219173, 'local/env_act_steps': 3609984, 'local/env_train_steps': 3606400, 'local/optimizer_steps': 5634, 'local/running_reward': 16658.660368217053, 'local/running_step': 2698.8291242732557, 'local/steps_done': 3609984, 'local/episodes_done': 899, 'local/unclipped_grad_norm': 0.5059812426567077, 'local/model_version': 5634, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:26,738] {'global/mean_episode_return': 34600.0, 'global/mean_episode_step': 5396.666666666667, 'global/SPS': 3061.5745395003983, 'global/env_act_steps': 3608960, 'global/env_train_steps': 3604480, 'global/optimizer_steps': 5632, 'global/running_reward': 16653.551136363636, 'global/running_step': 2698.239080255682, 'global/steps_done': 3608960, 'global/episodes_done': 899, 'global/unclipped_grad_norm': 0.5065579563379288, 'global/model_version': 5632, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:36,754] calculate_sps 33920 steps in 10.0167
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:36,754] calculate_sps 35840 steps in 10.0167
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:36,754] {'local/mean_episode_return': 33666.666666666664, 'local/mean_episode_step': 5377.555555555556, 'local/SPS': 3386.3575294337384, 'local/env_act_steps': 3642880, 'local/env_train_steps': 3640320, 'local/optimizer_steps': 5688, 'local/running_reward': 16747.720087548638, 'local/running_step': 2704.7888193093386, 'local/steps_done': 3642880, 'local/episodes_done': 908, 'local/unclipped_grad_norm': 0.5656865550963966, 'local/model_version': 5688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:36,756] {'global/mean_episode_return': 33825.0, 'global/mean_episode_step': 5374.875, 'global/SPS': 3578.038144307346, 'global/env_act_steps': 3641472, 'global/env_train_steps': 3640320, 'global/optimizer_steps': 5687, 'global/running_reward': 16761.42347440945, 'global/running_step': 2706.9574926181103, 'global/steps_done': 3641472, 'global/episodes_done': 907, 'global/unclipped_grad_norm': 0.5685198179700158, 'global/model_version': 5687, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:46,762] calculate_sps 30720 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:46,762] calculate_sps 30720 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:46,762] {'local/mean_episode_return': 32050.0, 'local/mean_episode_step': 5120.5, 'local/SPS': 3069.5511967517255, 'local/env_act_steps': 3676032, 'local/env_train_steps': 3671040, 'local/optimizer_steps': 5736, 'local/running_reward': 16706.726592664094, 'local/running_step': 2695.8718327702704, 'local/steps_done': 3676032, 'local/episodes_done': 912, 'local/unclipped_grad_norm': 0.6349538161108891, 'local/model_version': 5736, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:46,764] {'global/mean_episode_return': 32120.0, 'global/mean_episode_step': 5176.2, 'global/SPS': 3069.5511967517255, 'global/env_act_steps': 3674880, 'global/env_train_steps': 3671040, 'global/optimizer_steps': 5736, 'global/running_reward': 16692.199473180077, 'global/running_step': 2693.945162835249, 'global/steps_done': 3674880, 'global/episodes_done': 912, 'global/unclipped_grad_norm': 0.6273581099753477, 'global/model_version': 5736, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:56,778] calculate_sps 35840 steps in 10.0166
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:34:56,778] calculate_sps 33920 steps in 10.0166
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:56,779] {'local/mean_episode_return': 33866.666666666664, 'local/mean_episode_step': 5231.666666666667, 'local/SPS': 3578.0669303669906, 'local/env_act_steps': 3707904, 'local/env_train_steps': 3706880, 'local/optimizer_steps': 5791, 'local/running_reward': 17011.60266064257, 'local/running_step': 2741.5408822791164, 'local/steps_done': 3707904, 'local/episodes_done': 915, 'local/unclipped_grad_norm': 0.5307822123169899, 'local/model_version': 5791, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:34:56,780] {'global/mean_episode_return': 33866.666666666664, 'global/mean_episode_step': 5231.666666666667, 'global/SPS': 3386.384773383045, 'global/env_act_steps': 3707520, 'global/env_train_steps': 3704960, 'global/optimizer_steps': 5788, 'global/running_reward': 17004.883578431374, 'global/running_step': 2740.388174019608, 'global/steps_done': 3707520, 'global/episodes_done': 915, 'global/unclipped_grad_norm': 0.531405003168262, 'global/model_version': 5788, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:06,786] calculate_sps 30720 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:06,787] calculate_sps 32640 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:06,787] {'local/mean_episode_return': 32800.0, 'local/mean_episode_step': 5314.166666666667, 'local/SPS': 3069.5437379723176, 'local/env_act_steps': 3741568, 'local/env_train_steps': 3737600, 'local/optimizer_steps': 5840, 'local/running_reward': 17484.81463878327, 'local/running_step': 2813.7867157794676, 'local/steps_done': 3741568, 'local/episodes_done': 921, 'local/unclipped_grad_norm': 0.6423600221775017, 'local/model_version': 5840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:06,799] {'global/mean_episode_return': 32800.0, 'global/mean_episode_step': 5314.166666666667, 'global/SPS': 3261.3902215955873, 'global/env_act_steps': 3740800, 'global/env_train_steps': 3737600, 'global/optimizer_steps': 5840, 'global/running_reward': 17485.673076923078, 'global/running_step': 2814.0407752403844, 'global/steps_done': 3740800, 'global/episodes_done': 921, 'global/unclipped_grad_norm': 0.6353000499881231, 'global/model_version': 5840, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:16,825] calculate_sps 33280 steps in 10.0385
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:16,825] calculate_sps 32640 steps in 10.0385
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:16,825] {'local/mean_episode_return': 33240.0, 'local/mean_episode_step': 5327.2, 'local/SPS': 3315.2288366672196, 'local/env_act_steps': 3773952, 'local/env_train_steps': 3770880, 'local/optimizer_steps': 5891, 'local/running_reward': 17168.675889328064, 'local/running_step': 2759.536839179842, 'local/steps_done': 3773952, 'local/episodes_done': 931, 'local/unclipped_grad_norm': 0.5089416581333852, 'local/model_version': 5891, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:16,826] {'global/mean_episode_return': 33240.0, 'global/mean_episode_step': 5327.2, 'global/SPS': 3251.474435962081, 'global/env_act_steps': 3773824, 'global/env_train_steps': 3770240, 'global/optimizer_steps': 5890, 'global/running_reward': 17173.13468992248, 'global/running_step': 2760.2496669089146, 'global/steps_done': 3773824, 'global/episodes_done': 931, 'global/unclipped_grad_norm': 0.5139607973396778, 'global/model_version': 5890, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:26,843] calculate_sps 33280 steps in 10.0167
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:26,843] calculate_sps 33920 steps in 10.0167
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:26,843] {'local/mean_episode_return': 35760.0, 'local/mean_episode_step': 5396.8, 'local/SPS': 3322.4365499341948, 'local/env_act_steps': 3806976, 'local/env_train_steps': 3804160, 'local/optimizer_steps': 5944, 'local/running_reward': 16823.800872093023, 'local/running_step': 2709.8522286821703, 'local/steps_done': 3806976, 'local/episodes_done': 936, 'local/unclipped_grad_norm': 0.5813949200904595, 'local/model_version': 5944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:26,844] {'global/mean_episode_return': 35760.0, 'global/mean_episode_step': 5396.8, 'global/SPS': 3386.3295605098524, 'global/env_act_steps': 3806976, 'global/env_train_steps': 3804160, 'global/optimizer_steps': 5944, 'global/running_reward': 16825.162886100385, 'global/running_step': 2710.062680984556, 'global/steps_done': 3806976, 'global/episodes_done': 936, 'global/unclipped_grad_norm': 0.5754058419002427, 'global/model_version': 5944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:36,844] calculate_sps 31360 steps in 10.0029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:36,844] calculate_sps 25600 steps in 10.0029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:36,845] {'local/mean_episode_return': 33685.71428571428, 'local/mean_episode_step': 5318.714285714285, 'local/SPS': 3135.100947518426, 'local/env_act_steps': 3840128, 'local/env_train_steps': 3835520, 'local/optimizer_steps': 5992, 'local/running_reward': 16884.97828185328, 'local/running_step': 2721.5117941602316, 'local/steps_done': 3840128, 'local/episodes_done': 943, 'local/unclipped_grad_norm': 0.480514803280433, 'local/model_version': 5992, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:36,846] {'global/mean_episode_return': 34066.666666666664, 'global/mean_episode_step': 5306.333333333333, 'global/SPS': 2559.2660796068785, 'global/env_act_steps': 3833728, 'global/env_train_steps': 3829760, 'global/optimizer_steps': 5984, 'global/running_reward': 16898.12350478469, 'global/running_step': 2723.9991776315787, 'global/steps_done': 3833728, 'global/episodes_done': 942, 'global/unclipped_grad_norm': 0.48620571196079254, 'global/model_version': 5984, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:46,857] calculate_sps 35200 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:46,866] calculate_sps 34560 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:46,866] {'local/mean_episode_return': 29600.0, 'local/mean_episode_step': 4852.0, 'local/SPS': 3515.6790624697132, 'local/env_act_steps': 3872640, 'local/env_train_steps': 3870720, 'local/optimizer_steps': 6048, 'local/running_reward': 16962.08784448819, 'local/running_step': 2728.9944943405512, 'local/steps_done': 3872640, 'local/episodes_done': 947, 'local/unclipped_grad_norm': 0.5020938640726464, 'local/model_version': 6048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:46,868] {'global/mean_episode_return': 29960.0, 'global/mean_episode_step': 4960.2, 'global/SPS': 3451.757624970264, 'global/env_act_steps': 3866496, 'global/env_train_steps': 3864320, 'global/optimizer_steps': 6037, 'global/running_reward': 16898.3642578125, 'global/running_step': 2720.1113891601562, 'global/steps_done': 3866496, 'global/episodes_done': 947, 'global/unclipped_grad_norm': 0.482495109146496, 'global/model_version': 6037, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 11:35:52,111] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 3880320, 'env_train_steps': 3875840, 'optimizer_steps': 6056, 'running_reward': 17263.78761574074, 'running_step': 2772.74609375, 'steps_done': 3880320, 'episodes_done': 947, 'unclipped_grad_norm': 0.5493419687998923, 'model_version': 6056, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 11:35:52,213] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:56,887] calculate_sps 30720 steps in 10.0299
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:35:56,887] calculate_sps 32000 steps in 10.0299
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:56,888] {'local/mean_episode_return': 31900.0, 'local/mean_episode_step': 5396.5, 'local/SPS': 3062.8299209360744, 'local/env_act_steps': 3905792, 'local/env_train_steps': 3901440, 'local/optimizer_steps': 6096, 'local/running_reward': 17465.932673745174, 'local/running_step': 2800.078758445946, 'local/steps_done': 3905792, 'local/episodes_done': 951, 'local/unclipped_grad_norm': 0.5019276908909281, 'local/model_version': 6096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:35:56,889] {'global/mean_episode_return': 31866.666666666668, 'global/mean_episode_step': 5396.0, 'global/SPS': 3190.447834308411, 'global/env_act_steps': 3899776, 'global/env_train_steps': 3896320, 'global/optimizer_steps': 6088, 'global/running_reward': 17398.125, 'global/running_step': 2790.9697115384615, 'global/steps_done': 3899776, 'global/episodes_done': 950, 'global/unclipped_grad_norm': 0.5007209155489417, 'global/model_version': 6088, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:06,893] calculate_sps 34560 steps in 10.0061
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:06,893] calculate_sps 32640 steps in 10.0061
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:06,893] {'local/mean_episode_return': 33366.666666666664, 'local/mean_episode_step': 5285.166666666667, 'local/SPS': 3453.897919364271, 'local/env_act_steps': 3938048, 'local/env_train_steps': 3936000, 'local/optimizer_steps': 6149, 'local/running_reward': 17284.058779761905, 'local/running_step': 2771.756820436508, 'local/steps_done': 3938048, 'local/episodes_done': 963, 'local/unclipped_grad_norm': 0.5739011910726439, 'local/model_version': 6149, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:06,894] {'global/mean_episode_return': 33640.0, 'global/mean_episode_step': 5389.8, 'global/SPS': 3262.0147016218116, 'global/env_act_steps': 3932544, 'global/env_train_steps': 3928960, 'global/optimizer_steps': 6138, 'global/running_reward': 17372.271728515625, 'global/running_step': 2784.9598999023438, 'global/steps_done': 3932544, 'global/episodes_done': 960, 'global/unclipped_grad_norm': 0.5639356362819672, 'global/model_version': 6138, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:16,914] calculate_sps 32000 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:16,914] calculate_sps 33920 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:16,915] {'local/mean_episode_return': 31942.85714285714, 'local/mean_episode_step': 5204.714285714285, 'local/SPS': 3193.284158970191, 'local/env_act_steps': 3971200, 'local/env_train_steps': 3968000, 'local/optimizer_steps': 6200, 'local/running_reward': 16683.289092664094, 'local/running_step': 2680.01788730695, 'local/steps_done': 3971200, 'local/episodes_done': 970, 'local/unclipped_grad_norm': 0.608854354158336, 'local/model_version': 6200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:16,916] {'global/mean_episode_return': 32575.0, 'global/mean_episode_step': 5184.125, 'global/SPS': 3384.8812085084023, 'global/env_act_steps': 3965440, 'global/env_train_steps': 3962880, 'global/optimizer_steps': 6192, 'global/running_reward': 16739.01994163424, 'global/running_step': 2688.435645671206, 'global/steps_done': 3965440, 'global/episodes_done': 968, 'global/unclipped_grad_norm': 0.6401894676188628, 'global/model_version': 6192, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:26,952] calculate_sps 32640 steps in 10.0382
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:26,952] calculate_sps 32000 steps in 10.0382
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:26,953] {'local/mean_episode_return': 31866.666666666668, 'local/mean_episode_step': 5396.25, 'local/SPS': 3251.5904301045284, 'local/env_act_steps': 4004224, 'local/env_train_steps': 4000640, 'local/optimizer_steps': 6250, 'local/running_reward': 16791.206395348836, 'local/running_step': 2693.3912609011627, 'local/steps_done': 4004224, 'local/episodes_done': 977, 'local/unclipped_grad_norm': 0.5319022530317307, 'local/model_version': 6250, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:26,954] {'global/mean_episode_return': 31514.285714285714, 'global/mean_episode_step': 5266.214285714285, 'global/SPS': 3187.83375500444, 'global/env_act_steps': 3998976, 'global/env_train_steps': 3994880, 'global/optimizer_steps': 6241, 'global/running_reward': 16803.7929389313, 'global/running_step': 2696.3786378816794, 'global/steps_done': 3998976, 'global/episodes_done': 976, 'global/unclipped_grad_norm': 0.4642602208317543, 'global/model_version': 6241, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:36,967] calculate_sps 33920 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:36,968] calculate_sps 34560 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:36,968] {'local/mean_episode_return': 32200.0, 'local/mean_episode_step': 5050.0, 'local/SPS': 3386.8092068897317, 'local/env_act_steps': 4037248, 'local/env_train_steps': 4034560, 'local/optimizer_steps': 6304, 'local/running_reward': 16907.32194767442, 'local/running_step': 2703.951308139535, 'local/steps_done': 4037248, 'local/episodes_done': 979, 'local/unclipped_grad_norm': 0.6763400060159189, 'local/model_version': 6304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:36,969] {'global/mean_episode_return': 31333.333333333332, 'global/mean_episode_step': 5165.333333333333, 'global/SPS': 3450.7112673970855, 'global/env_act_steps': 4031744, 'global/env_train_steps': 4029440, 'global/optimizer_steps': 6296, 'global/running_reward': 16821.258544921875, 'global/running_step': 2691.3690795898438, 'global/steps_done': 4031744, 'global/episodes_done': 979, 'global/unclipped_grad_norm': 0.6792699602517215, 'global/model_version': 6296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:46,972] calculate_sps 30720 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:46,982] calculate_sps 31360 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:46,982] {'local/mean_episode_return': 32711.11111111111, 'local/mean_episode_step': 5222.333333333333, 'local/SPS': 3070.711405004514, 'local/env_act_steps': 4070528, 'local/env_train_steps': 4065280, 'local/optimizer_steps': 6352, 'local/running_reward': 16935.45673076923, 'local/running_step': 2702.2840745192307, 'local/steps_done': 4070528, 'local/episodes_done': 988, 'local/unclipped_grad_norm': 0.7279364690184593, 'local/model_version': 6352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:46,984] {'global/mean_episode_return': 32711.11111111111, 'global/mean_episode_step': 5222.333333333333, 'global/SPS': 3134.684559275441, 'global/env_act_steps': 4065408, 'global/env_train_steps': 4060800, 'global/optimizer_steps': 6344, 'global/running_reward': 16980.471720532318, 'global/running_step': 2710.3643654942966, 'global/steps_done': 4065408, 'global/episodes_done': 988, 'global/unclipped_grad_norm': 0.7451954856514931, 'global/model_version': 6344, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:57,009] calculate_sps 35840 steps in 10.0373
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:36:57,009] calculate_sps 35200 steps in 10.0373
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:57,009] {'local/mean_episode_return': 34666.666666666664, 'local/mean_episode_step': 5373.222222222223, 'local/SPS': 3570.6836094647388, 'local/env_act_steps': 4102144, 'local/env_train_steps': 4101120, 'local/optimizer_steps': 6407, 'local/running_reward': 16744.053643724696, 'local/running_step': 2671.617472165992, 'local/steps_done': 4102144, 'local/episodes_done': 998, 'local/unclipped_grad_norm': 0.6695660564032468, 'local/model_version': 6407, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:36:57,010] {'global/mean_episode_return': 34800.0, 'global/mean_episode_step': 5366.285714285715, 'global/SPS': 3506.9214021528683, 'global/env_act_steps': 4097536, 'global/env_train_steps': 4096000, 'global/optimizer_steps': 6400, 'global/running_reward': 16785.557768924304, 'global/running_step': 2677.9709287848605, 'global/steps_done': 4097536, 'global/episodes_done': 996, 'global/unclipped_grad_norm': 0.6927326087440763, 'global/model_version': 6400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:07,021] calculate_sps 30720 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:07,021] calculate_sps 30720 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:07,022] {'local/mean_episode_return': 35177.77777777778, 'local/mean_episode_step': 5355.444444444444, 'local/SPS': 3068.3345058262603, 'local/env_act_steps': 4135680, 'local/env_train_steps': 4131840, 'local/optimizer_steps': 6456, 'local/running_reward': 16114.426288167939, 'local/running_step': 2577.5908277671756, 'local/steps_done': 4135680, 'local/episodes_done': 1007, 'local/unclipped_grad_norm': 0.48770079320790816, 'local/model_version': 6456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:07,031] {'global/mean_episode_return': 34680.0, 'global/mean_episode_step': 5359.9, 'global/SPS': 3068.3345058262603, 'global/env_act_steps': 4131200, 'global/env_train_steps': 4126720, 'global/optimizer_steps': 6448, 'global/running_reward': 16195.36002851711, 'global/running_step': 2589.3898229562737, 'global/steps_done': 4131200, 'global/episodes_done': 1006, 'global/unclipped_grad_norm': 0.47625301250567037, 'global/model_version': 6448, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:17,043] calculate_sps 33920 steps in 10.0228
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:17,044] calculate_sps 35840 steps in 10.0228
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:17,044] {'local/mean_episode_return': 33085.71428571428, 'local/mean_episode_step': 5397.428571428572, 'local/SPS': 3384.2928599025686, 'local/env_act_steps': 4168320, 'local/env_train_steps': 4165760, 'local/optimizer_steps': 6508, 'local/running_reward': 15700.612745098038, 'local/running_step': 2514.483363970588, 'local/steps_done': 4168320, 'local/episodes_done': 1014, 'local/unclipped_grad_norm': 0.5500930390105798, 'local/model_version': 6508, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:17,045] {'global/mean_episode_return': 33725.0, 'global/mean_episode_step': 5397.125, 'global/SPS': 3575.8566066895064, 'global/env_act_steps': 4163584, 'global/env_train_steps': 4162560, 'global/optimizer_steps': 6503, 'global/running_reward': 15731.595849802372, 'global/running_step': 2519.2776988636365, 'global/steps_done': 4163584, 'global/episodes_done': 1014, 'global/unclipped_grad_norm': 0.5746087220582095, 'global/model_version': 6503, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:27,066] calculate_sps 32640 steps in 10.0227
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:27,067] calculate_sps 30720 steps in 10.0227
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:27,078] {'local/mean_episode_return': 33241.666666666664, 'local/mean_episode_step': 5360.0, 'local/SPS': 3256.622119259446, 'local/env_act_steps': 4201472, 'local/env_train_steps': 4198400, 'local/optimizer_steps': 6560, 'local/running_reward': 15539.520994208495, 'local/running_step': 2489.9355694980695, 'local/steps_done': 4201472, 'local/episodes_done': 1027, 'local/unclipped_grad_norm': 0.47627866683671105, 'local/model_version': 6560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:27,080] {'global/mean_episode_return': 33270.0, 'global/mean_episode_step': 5352.9, 'global/SPS': 3065.056112244185, 'global/env_act_steps': 4197632, 'global/env_train_steps': 4193280, 'global/optimizer_steps': 6552, 'global/running_reward': 15630.227913533834, 'global/running_step': 2504.1121358082705, 'global/steps_done': 4197632, 'global/episodes_done': 1025, 'global/unclipped_grad_norm': 0.43557676627319686, 'global/model_version': 6552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:37,085] calculate_sps 31360 steps in 10.0188
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:37,085] calculate_sps 34560 steps in 10.0188
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:37,085] {'local/mean_episode_return': 34457.142857142855, 'local/mean_episode_step': 5396.285714285715, 'local/SPS': 3130.1306468221837, 'local/env_act_steps': 4234368, 'local/env_train_steps': 4229760, 'local/optimizer_steps': 6608, 'local/running_reward': 15045.361138132295, 'local/running_step': 2411.296510214008, 'local/steps_done': 4234368, 'local/episodes_done': 1034, 'local/unclipped_grad_norm': 0.49797168870766956, 'local/model_version': 6608, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:37,086] {'global/mean_episode_return': 34066.666666666664, 'global/mean_episode_step': 5395.833333333333, 'global/SPS': 3449.531733232611, 'global/env_act_steps': 4230016, 'global/env_train_steps': 4227840, 'global/optimizer_steps': 6605, 'global/running_reward': 15061.184535573122, 'global/running_step': 2413.9166872529645, 'global/steps_done': 4230016, 'global/episodes_done': 1031, 'global/unclipped_grad_norm': 0.5087849464056626, 'global/model_version': 6605, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:47,096] calculate_sps 35200 steps in 10.0114
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:47,097] calculate_sps 32000 steps in 10.0114
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:47,106] {'local/mean_episode_return': 35266.666666666664, 'local/mean_episode_step': 5398.666666666667, 'local/SPS': 3515.9905188913685, 'local/env_act_steps': 4266752, 'local/env_train_steps': 4264960, 'local/optimizer_steps': 6664, 'local/running_reward': 14913.61783596838, 'local/running_step': 2395.5620368083005, 'local/steps_done': 4266752, 'local/episodes_done': 1037, 'local/unclipped_grad_norm': 0.6236257260399205, 'local/model_version': 6664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:47,108] {'global/mean_episode_return': 34800.0, 'global/mean_episode_step': 5397.666666666667, 'global/SPS': 3196.355017173971, 'global/env_act_steps': 4263296, 'global/env_train_steps': 4259840, 'global/optimizer_steps': 6656, 'global/running_reward': 14889.495192307691, 'global/running_step': 2390.665955528846, 'global/steps_done': 4263296, 'global/episodes_done': 1037, 'global/unclipped_grad_norm': 0.6314622774428013, 'global/model_version': 6656, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:57,121] calculate_sps 30720 steps in 10.0243
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:37:57,121] calculate_sps 33280 steps in 10.0243
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:57,121] {'local/mean_episode_return': 33600.0, 'local/mean_episode_step': 5397.0, 'local/SPS': 3064.5447966368283, 'local/env_act_steps': 4300288, 'local/env_train_steps': 4295680, 'local/optimizer_steps': 6712, 'local/running_reward': 15429.228291984733, 'local/running_step': 2483.869334446565, 'local/steps_done': 4300288, 'local/episodes_done': 1040, 'local/unclipped_grad_norm': 0.540691818886747, 'local/model_version': 6712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:37:57,123] {'global/mean_episode_return': 35400.0, 'global/mean_episode_step': 5396.0, 'global/SPS': 3319.9235296898974, 'global/env_act_steps': 4296320, 'global/env_train_steps': 4293120, 'global/optimizer_steps': 6708, 'global/running_reward': 15377.713178294574, 'global/running_step': 2475.631480135659, 'global/steps_done': 4296320, 'global/episodes_done': 1039, 'global/unclipped_grad_norm': 0.557148155827935, 'global/model_version': 6708, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:07,141] calculate_sps 33920 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:07,141] calculate_sps 33280 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:07,151] {'local/mean_episode_return': 32560.0, 'local/mean_episode_step': 5255.4, 'local/SPS': 3385.7938876182084, 'local/env_act_steps': 4332288, 'local/env_train_steps': 4329600, 'local/optimizer_steps': 6764, 'local/running_reward': 15541.5875, 'local/running_step': 2498.9428125, 'local/steps_done': 4332288, 'local/episodes_done': 1045, 'local/unclipped_grad_norm': 0.64366626395629, 'local/model_version': 6764, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:07,153] {'global/mean_episode_return': 32133.333333333332, 'global/mean_episode_step': 5279.333333333333, 'global/SPS': 3321.910984078242, 'global/env_act_steps': 4328832, 'global/env_train_steps': 4326400, 'global/optimizer_steps': 6760, 'global/running_reward': 15530.013533464567, 'global/running_step': 2497.5051673228345, 'global/steps_done': 4328832, 'global/episodes_done': 1045, 'global/unclipped_grad_norm': 0.6311204513678184, 'global/model_version': 6760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:17,146] calculate_sps 32640 steps in 10.0072
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:17,147] calculate_sps 30720 steps in 10.0072
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:17,147] {'local/mean_episode_return': 30500.0, 'local/mean_episode_step': 5007.75, 'local/SPS': 3261.6589922356065, 'local/env_act_steps': 4365184, 'local/env_train_steps': 4362240, 'local/optimizer_steps': 6816, 'local/running_reward': 15953.751215953307, 'local/running_step': 2561.697258025292, 'local/steps_done': 4365184, 'local/episodes_done': 1049, 'local/unclipped_grad_norm': 0.6429406873022134, 'local/model_version': 6816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:17,148] {'global/mean_episode_return': 30500.0, 'global/mean_episode_step': 5007.75, 'global/SPS': 3069.7966985746884, 'global/env_act_steps': 4362368, 'global/env_train_steps': 4357120, 'global/optimizer_steps': 6808, 'global/running_reward': 15922.381917938932, 'global/running_step': 2556.779609971374, 'global/steps_done': 4362368, 'global/episodes_done': 1049, 'global/unclipped_grad_norm': 0.6079858577189347, 'global/model_version': 6808, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:27,170] calculate_sps 32640 steps in 10.024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:27,170] calculate_sps 35840 steps in 10.024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:27,170] {'local/mean_episode_return': 28800.0, 'local/mean_episode_step': 5395.0, 'local/SPS': 3256.183784494241, 'local/env_act_steps': 4398464, 'local/env_train_steps': 4394880, 'local/optimizer_steps': 6866, 'local/running_reward': 16405.21033653846, 'local/running_step': 2632.517578125, 'local/steps_done': 4398464, 'local/episodes_done': 1050, 'local/unclipped_grad_norm': 0.4590814036130905, 'local/model_version': 6866, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:27,171] {'global/mean_episode_return': 28800.0, 'global/mean_episode_step': 5395.0, 'global/SPS': 3575.4174888564216, 'global/env_act_steps': 4395136, 'global/env_train_steps': 4392960, 'global/optimizer_steps': 6864, 'global/running_reward': 16342.07763671875, 'global/running_step': 2622.5186157226562, 'global/steps_done': 4395136, 'global/episodes_done': 1050, 'global/unclipped_grad_norm': 0.507672513702086, 'global/model_version': 6864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:37,186] calculate_sps 33920 steps in 10.0156
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:37,186] calculate_sps 30720 steps in 10.0156
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:37,186] {'local/mean_episode_return': 34440.0, 'local/mean_episode_step': 5318.8, 'local/SPS': 3386.7231829945595, 'local/env_act_steps': 4430976, 'local/env_train_steps': 4428800, 'local/optimizer_steps': 6920, 'local/running_reward': 16657.34498031496, 'local/running_step': 2673.864726870079, 'local/steps_done': 4430976, 'local/episodes_done': 1055, 'local/unclipped_grad_norm': 0.5940283234748576, 'local/model_version': 6920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:37,199] {'global/mean_episode_return': 34440.0, 'global/mean_episode_step': 5318.8, 'global/SPS': 3067.220995919601, 'global/env_act_steps': 4428672, 'global/env_train_steps': 4423680, 'global/optimizer_steps': 6912, 'global/running_reward': 16648.3241889313, 'global/running_step': 2672.291626908397, 'global/steps_done': 4428672, 'global/episodes_done': 1055, 'global/unclipped_grad_norm': 0.5946508958004415, 'global/model_version': 6912, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:47,187] calculate_sps 30720 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:47,187] calculate_sps 35840 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:47,188] {'local/mean_episode_return': 34800.0, 'local/mean_episode_step': 5398.2, 'local/SPS': 3071.6533838399478, 'local/env_act_steps': 4464384, 'local/env_train_steps': 4459520, 'local/optimizer_steps': 6968, 'local/running_reward': 16917.22341954023, 'local/running_step': 2714.3191151819924, 'local/steps_done': 4464384, 'local/episodes_done': 1060, 'local/unclipped_grad_norm': 0.4305424632815023, 'local/model_version': 6968, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:47,189] {'global/mean_episode_return': 34800.0, 'global/mean_episode_step': 5398.2, 'global/SPS': 3583.5956144799393, 'global/env_act_steps': 4461312, 'global/env_train_steps': 4459520, 'global/optimizer_steps': 6968, 'global/running_reward': 16902.763480392157, 'global/running_step': 2712.3444546568626, 'global/steps_done': 4461312, 'global/episodes_done': 1060, 'global/unclipped_grad_norm': 0.4528148231495704, 'global/model_version': 6968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:57,205] calculate_sps 35840 steps in 10.0038
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:38:57,216] calculate_sps 30720 steps in 10.0038
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:57,217] {'local/mean_episode_return': 32050.0, 'local/mean_episode_step': 5395.0, 'local/SPS': 3582.6356392129624, 'local/env_act_steps': 4496512, 'local/env_train_steps': 4495360, 'local/optimizer_steps': 7023, 'local/running_reward': 17172.659362549803, 'local/running_step': 2746.9553971613545, 'local/steps_done': 4496512, 'local/episodes_done': 1064, 'local/unclipped_grad_norm': 0.39517554315653713, 'local/model_version': 7023, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:38:57,218] {'global/mean_episode_return': 32050.0, 'global/mean_episode_step': 5395.0, 'global/SPS': 3070.830547896825, 'global/env_act_steps': 4494848, 'global/env_train_steps': 4490240, 'global/optimizer_steps': 7016, 'global/running_reward': 17148.043893129772, 'global/running_step': 2743.7732287690837, 'global/steps_done': 4494848, 'global/episodes_done': 1064, 'global/unclipped_grad_norm': 0.3924287672465046, 'global/model_version': 7016, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:07,206] calculate_sps 30720 steps in 10.0156
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:07,207] calculate_sps 35840 steps in 10.0156
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:07,218] {'local/mean_episode_return': 32550.0, 'local/mean_episode_step': 5326.0, 'local/SPS': 3067.22398951637, 'local/env_act_steps': 4529792, 'local/env_train_steps': 4526080, 'local/optimizer_steps': 7072, 'local/running_reward': 17041.05168269231, 'local/running_step': 2717.417848557692, 'local/steps_done': 4529792, 'local/episodes_done': 1072, 'local/unclipped_grad_norm': 0.4465055637517754, 'local/model_version': 7072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:07,219] {'global/mean_episode_return': 32550.0, 'global/mean_episode_step': 5326.0, 'global/SPS': 3578.4279877690983, 'global/env_act_steps': 4527232, 'global/env_train_steps': 4526080, 'global/optimizer_steps': 7072, 'global/running_reward': 17049.505928853756, 'global/running_step': 2719.1332756916995, 'global/steps_done': 4527232, 'global/episodes_done': 1072, 'global/unclipped_grad_norm': 0.44244369052882704, 'global/model_version': 7072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:17,229] calculate_sps 33280 steps in 10.0227
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:17,229] calculate_sps 30720 steps in 10.0227
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:17,229] {'local/mean_episode_return': 33711.11111111111, 'local/mean_episode_step': 5396.222222222223, 'local/SPS': 3320.468292417431, 'local/env_act_steps': 4562432, 'local/env_train_steps': 4559360, 'local/optimizer_steps': 7123, 'local/running_reward': 17068.658088235294, 'local/running_step': 2717.536580882353, 'local/steps_done': 4562432, 'local/episodes_done': 1081, 'local/unclipped_grad_norm': 0.5023153909281188, 'local/model_version': 7123, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:17,230] {'global/mean_episode_return': 32775.0, 'global/mean_episode_step': 5396.25, 'global/SPS': 3065.0476545391666, 'global/env_act_steps': 4560896, 'global/env_train_steps': 4556800, 'global/optimizer_steps': 7120, 'global/running_reward': 17081.790636882128, 'global/running_step': 2719.962155418251, 'global/steps_done': 4560896, 'global/episodes_done': 1080, 'global/unclipped_grad_norm': 0.5024335818986098, 'global/model_version': 7120, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:27,246] calculate_sps 33280 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:27,247] calculate_sps 33920 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:27,247] {'local/mean_episode_return': 32971.42857142857, 'local/mean_episode_step': 5176.428571428572, 'local/SPS': 3322.2829033585617, 'local/env_act_steps': 4594944, 'local/env_train_steps': 4592640, 'local/optimizer_steps': 7176, 'local/running_reward': 16671.807332677166, 'local/running_step': 2659.138656496063, 'local/steps_done': 4594944, 'local/episodes_done': 1088, 'local/unclipped_grad_norm': 0.46137269769074785, 'local/model_version': 7176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:27,248] {'global/mean_episode_return': 34000.0, 'global/mean_episode_step': 5203.875, 'global/SPS': 3386.1729591923804, 'global/env_act_steps': 4593280, 'global/env_train_steps': 4590720, 'global/optimizer_steps': 7172, 'global/running_reward': 16685.251976284584, 'global/running_step': 2661.048171936759, 'global/steps_done': 4593280, 'global/episodes_done': 1088, 'global/unclipped_grad_norm': 0.4784904747055127, 'global/model_version': 7172, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:37,270] calculate_sps 30720 steps in 10.024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:37,271] calculate_sps 32640 steps in 10.024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:37,271] {'local/mean_episode_return': 35450.0, 'local/mean_episode_step': 5396.75, 'local/SPS': 3064.632409468262, 'local/env_act_steps': 4627968, 'local/env_train_steps': 4623360, 'local/optimizer_steps': 7224, 'local/running_reward': 16782.297722868218, 'local/running_step': 2675.0651041666665, 'local/steps_done': 4627968, 'local/episodes_done': 1092, 'local/unclipped_grad_norm': 0.5073783012727896, 'local/model_version': 7224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:37,272] {'global/mean_episode_return': 35733.333333333336, 'global/mean_episode_step': 5397.0, 'global/SPS': 3256.171935060028, 'global/env_act_steps': 4626304, 'global/env_train_steps': 4623360, 'global/optimizer_steps': 7224, 'global/running_reward': 16765.491763565893, 'global/running_step': 2672.4872214147285, 'global/steps_done': 4626304, 'global/episodes_done': 1091, 'global/unclipped_grad_norm': 0.48897461077341664, 'global/model_version': 7224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:47,290] calculate_sps 35840 steps in 10.0204
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:47,291] calculate_sps 32640 steps in 10.0204
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:47,291] {'local/mean_episode_return': 35000.0, 'local/mean_episode_step': 5397.714285714285, 'local/SPS': 3576.7080183183093, 'local/env_act_steps': 4660224, 'local/env_train_steps': 4659200, 'local/optimizer_steps': 7279, 'local/running_reward': 17090.38318452381, 'local/running_step': 2719.859840029762, 'local/steps_done': 4660224, 'local/episodes_done': 1099, 'local/unclipped_grad_norm': 0.42623360536315225, 'local/model_version': 7279, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:47,292] {'global/mean_episode_return': 35057.142857142855, 'global/mean_episode_step': 5397.428571428572, 'global/SPS': 3257.3590881113173, 'global/env_act_steps': 4659584, 'global/env_train_steps': 4656000, 'global/optimizer_steps': 7274, 'global/running_reward': 17089.795673076922, 'global/running_step': 2719.7982872596153, 'global/steps_done': 4659584, 'global/episodes_done': 1098, 'global/unclipped_grad_norm': 0.43423836201429367, 'global/model_version': 7274, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:57,294] calculate_sps 30720 steps in 10.0029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:39:57,294] calculate_sps 33920 steps in 10.0029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:57,294] {'local/mean_episode_return': 32314.285714285714, 'local/mean_episode_step': 5195.285714285715, 'local/SPS': 3071.108608336499, 'local/env_act_steps': 4693632, 'local/env_train_steps': 4689920, 'local/optimizer_steps': 7328, 'local/running_reward': 16678.66379310345, 'local/running_step': 2654.4008620689656, 'local/steps_done': 4693632, 'local/episodes_done': 1106, 'local/unclipped_grad_norm': 0.546080615447492, 'local/model_version': 7328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:39:57,296] {'global/mean_episode_return': 32550.0, 'global/mean_episode_step': 5220.625, 'global/SPS': 3391.015755038218, 'global/env_act_steps': 4692352, 'global/env_train_steps': 4689920, 'global/optimizer_steps': 7328, 'global/running_reward': 16675.872802734375, 'global/running_step': 2654.2150268554688, 'global/steps_done': 4692352, 'global/episodes_done': 1106, 'global/unclipped_grad_norm': 0.5275718583552925, 'global/model_version': 7328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:07,297] calculate_sps 32640 steps in 10.0036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:07,297] calculate_sps 30720 steps in 10.0036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:07,297] {'local/mean_episode_return': 35755.555555555555, 'local/mean_episode_step': 5380.444444444444, 'local/SPS': 3262.831098077781, 'local/env_act_steps': 4726144, 'local/env_train_steps': 4722560, 'local/optimizer_steps': 7378, 'local/running_reward': 16808.009350393702, 'local/running_step': 2666.9112635334645, 'local/steps_done': 4726144, 'local/episodes_done': 1115, 'local/unclipped_grad_norm': 0.45376289427280425, 'local/model_version': 7378, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:07,298] {'global/mean_episode_return': 35625.0, 'global/mean_episode_step': 5378.5, 'global/SPS': 3070.8998570143817, 'global/env_act_steps': 4725760, 'global/env_train_steps': 4720640, 'global/optimizer_steps': 7376, 'global/running_reward': 16811.51221264368, 'global/running_step': 2667.4057411398467, 'global/steps_done': 4725760, 'global/episodes_done': 1114, 'global/unclipped_grad_norm': 0.4407148069391648, 'global/model_version': 7376, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:17,302] calculate_sps 33920 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:17,302] calculate_sps 35840 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:17,303] {'local/mean_episode_return': 34000.0, 'local/mean_episode_step': 5397.166666666667, 'local/SPS': 3390.3271071956033, 'local/env_act_steps': 4758912, 'local/env_train_steps': 4756480, 'local/optimizer_steps': 7432, 'local/running_reward': 16584.716796875, 'local/running_step': 2639.6726989746094, 'local/steps_done': 4758912, 'local/episodes_done': 1119, 'local/unclipped_grad_norm': 0.4477330297231674, 'local/model_version': 7432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:17,315] {'global/mean_episode_return': 34700.0, 'global/mean_episode_step': 5396.875, 'global/SPS': 3582.2324151500716, 'global/env_act_steps': 4758400, 'global/env_train_steps': 4756480, 'global/optimizer_steps': 7432, 'global/running_reward': 16582.837009803923, 'global/running_step': 2639.412469362745, 'global/steps_done': 4758400, 'global/episodes_done': 1119, 'global/unclipped_grad_norm': 0.45913245688591686, 'global/model_version': 7432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:27,308] calculate_sps 30720 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:27,308] calculate_sps 30720 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:27,309] {'local/mean_episode_return': 34857.142857142855, 'local/mean_episode_step': 5398.142857142857, 'local/SPS': 3070.2061750286757, 'local/env_act_steps': 4792192, 'local/env_train_steps': 4787200, 'local/optimizer_steps': 7480, 'local/running_reward': 16728.85216346154, 'local/running_step': 2657.790745192308, 'local/steps_done': 4792192, 'local/episodes_done': 1126, 'local/unclipped_grad_norm': 0.5401647261654338, 'local/model_version': 7480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:27,319] {'global/mean_episode_return': 34857.142857142855, 'global/mean_episode_step': 5398.142857142857, 'global/SPS': 3070.2061750286757, 'global/env_act_steps': 4792064, 'global/env_train_steps': 4787200, 'global/optimizer_steps': 7480, 'global/running_reward': 16727.63783269962, 'global/running_step': 2657.5911062262358, 'global/steps_done': 4792064, 'global/episodes_done': 1126, 'global/unclipped_grad_norm': 0.5401647261654338, 'global/model_version': 7480, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:37,314] calculate_sps 35840 steps in 10.0057
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:37,314] calculate_sps 28160 steps in 10.0057
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:37,317] {'local/mean_episode_return': 33500.0, 'local/mean_episode_step': 5393.75, 'local/SPS': 3581.958073198076, 'local/env_act_steps': 4824192, 'local/env_train_steps': 4823040, 'local/optimizer_steps': 7536, 'local/running_reward': 16715.6375, 'local/running_step': 2652.4676875, 'local/steps_done': 4824192, 'local/episodes_done': 1130, 'local/unclipped_grad_norm': 0.47828870293285164, 'local/model_version': 7536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:37,318] {'global/mean_episode_return': 34333.333333333336, 'global/mean_episode_step': 5393.0, 'global/SPS': 2814.3956289413454, 'global/env_act_steps': 4818432, 'global/env_train_steps': 4815360, 'global/optimizer_steps': 7523, 'global/running_reward': 16666.315230582524, 'global/running_step': 2645.446412317961, 'global/steps_done': 4818432, 'global/episodes_done': 1129, 'global/unclipped_grad_norm': 0.4520532786846161, 'global/model_version': 7523, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:47,327] calculate_sps 30720 steps in 10.0134
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:47,327] calculate_sps 33280 steps in 10.0134
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:47,328] {'local/mean_episode_return': 33900.0, 'local/mean_episode_step': 5190.25, 'local/SPS': 3067.899815748415, 'local/env_act_steps': 4858112, 'local/env_train_steps': 4853760, 'local/optimizer_steps': 7584, 'local/running_reward': 17165.737028301886, 'local/running_step': 2716.0310731132076, 'local/steps_done': 4858112, 'local/episodes_done': 1134, 'local/unclipped_grad_norm': 0.5587477314596375, 'local/model_version': 7584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:47,329] {'global/mean_episode_return': 32066.666666666668, 'global/mean_episode_step': 5122.333333333333, 'global/SPS': 3323.55813372745, 'global/env_act_steps': 4851584, 'global/env_train_steps': 4848640, 'global/optimizer_steps': 7576, 'global/running_reward': 17114.394305019305, 'global/running_step': 2709.091427364865, 'global/steps_done': 4851584, 'global/episodes_done': 1132, 'global/unclipped_grad_norm': 0.5676053950809082, 'global/model_version': 7576, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:57,327] calculate_sps 34560 steps in 10.0001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:40:57,327] calculate_sps 32640 steps in 10.0001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:57,327] {'local/mean_episode_return': 28433.333333333332, 'local/mean_episode_step': 4760.666666666667, 'local/SPS': 3455.966794142293, 'local/env_act_steps': 4890368, 'local/env_train_steps': 4888320, 'local/optimizer_steps': 7637, 'local/running_reward': 17344.41964285714, 'local/running_step': 2739.7747085813494, 'local/steps_done': 4890368, 'local/episodes_done': 1140, 'local/unclipped_grad_norm': 0.4154781066584137, 'local/model_version': 7637, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:40:57,328] {'global/mean_episode_return': 30125.0, 'global/mean_episode_step': 4919.25, 'global/SPS': 3263.9686389121657, 'global/env_act_steps': 4884864, 'global/env_train_steps': 4881280, 'global/optimizer_steps': 7626, 'global/running_reward': 17327.15144230769, 'global/running_step': 2738.239813701923, 'global/steps_done': 4884864, 'global/episodes_done': 1140, 'global/unclipped_grad_norm': 0.4245816269516945, 'global/model_version': 7626, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:07,343] calculate_sps 32000 steps in 10.0158
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:07,343] calculate_sps 33920 steps in 10.0158
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:07,344] {'local/mean_episode_return': 33709.09090909091, 'local/mean_episode_step': 5350.636363636364, 'local/SPS': 3194.9439905316463, 'local/env_act_steps': 4923776, 'local/env_train_steps': 4920320, 'local/optimizer_steps': 7688, 'local/running_reward': 17113.481800766283, 'local/running_step': 2696.2572737068967, 'local/steps_done': 4923776, 'local/episodes_done': 1151, 'local/unclipped_grad_norm': 0.48439689564938637, 'local/model_version': 7688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:07,345] {'global/mean_episode_return': 33260.0, 'global/mean_episode_step': 5346.1, 'global/SPS': 3386.640629963545, 'global/env_act_steps': 4918144, 'global/env_train_steps': 4915200, 'global/optimizer_steps': 7680, 'global/running_reward': 17197.506009615383, 'global/running_step': 2710.0540264423075, 'global/steps_done': 4918144, 'global/episodes_done': 1150, 'global/unclipped_grad_norm': 0.46501675634472456, 'global/model_version': 7680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:17,350] calculate_sps 32640 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:17,360] calculate_sps 32000 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:17,361] {'local/mean_episode_return': 29900.0, 'local/mean_episode_step': 4790.5, 'local/SPS': 3261.799339349153, 'local/env_act_steps': 4956672, 'local/env_train_steps': 4952960, 'local/optimizer_steps': 7739, 'local/running_reward': 16745.044990272374, 'local/running_step': 2640.8686770428017, 'local/steps_done': 4956672, 'local/episodes_done': 1157, 'local/unclipped_grad_norm': 0.4574209364021526, 'local/model_version': 7739, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:17,362] {'global/mean_episode_return': 31085.714285714286, 'global/mean_episode_step': 4877.0, 'global/SPS': 3197.8424895579933, 'global/env_act_steps': 4951424, 'global/env_train_steps': 4947200, 'global/optimizer_steps': 7729, 'global/running_reward': 16748.05889423077, 'global/running_step': 2641.0869891826924, 'global/steps_done': 4951424, 'global/episodes_done': 1157, 'global/unclipped_grad_norm': 0.4902773724526775, 'global/model_version': 7729, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:27,378] calculate_sps 33920 steps in 10.0278
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:27,378] calculate_sps 34560 steps in 10.0278
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:27,378] {'local/mean_episode_return': 32257.14285714286, 'local/mean_episode_step': 5056.142857142857, 'local/SPS': 3382.5919307026866, 'local/env_act_steps': 4989184, 'local/env_train_steps': 4986880, 'local/optimizer_steps': 7792, 'local/running_reward': 16744.64812992126, 'local/running_step': 2634.961029773622, 'local/steps_done': 4989184, 'local/episodes_done': 1164, 'local/unclipped_grad_norm': 0.5647580528034354, 'local/model_version': 7792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:27,380] {'global/mean_episode_return': 31833.333333333332, 'global/mean_episode_step': 5000.0, 'global/SPS': 3446.414419961228, 'global/env_act_steps': 4984064, 'global/env_train_steps': 4981760, 'global/optimizer_steps': 7784, 'global/running_reward': 16745.32475490196, 'global/running_step': 2635.688051470588, 'global/steps_done': 4984064, 'global/episodes_done': 1163, 'global/unclipped_grad_norm': 0.49124196930365127, 'global/model_version': 7784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:37,395] calculate_sps 30720 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:37,395] calculate_sps 30720 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:37,396] {'local/mean_episode_return': 30977.777777777777, 'local/mean_episode_step': 4940.888888888889, 'local/SPS': 3066.669689646142, 'local/env_act_steps': 5022464, 'local/env_train_steps': 5017600, 'local/optimizer_steps': 7840, 'local/running_reward': 16744.471153846152, 'local/running_step': 2632.175480769231, 'local/steps_done': 5022464, 'local/episodes_done': 1173, 'local/unclipped_grad_norm': 0.4644378377124667, 'local/model_version': 7840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:37,407] {'global/mean_episode_return': 32555.555555555555, 'global/mean_episode_step': 5147.666666666667, 'global/SPS': 3066.669689646142, 'global/env_act_steps': 5017600, 'global/env_train_steps': 5012480, 'global/optimizer_steps': 7832, 'global/running_reward': 16780.480677480915, 'global/running_step': 2638.8216841603053, 'global/steps_done': 5017600, 'global/episodes_done': 1172, 'global/unclipped_grad_norm': 0.5305212011250356, 'global/model_version': 7832, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:47,422] calculate_sps 35200 steps in 10.0268
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:47,422] calculate_sps 35840 steps in 10.0268
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:47,423] {'local/mean_episode_return': 33425.0, 'local/mean_episode_step': 5110.875, 'local/SPS': 3510.603496990451, 'local/env_act_steps': 5054336, 'local/env_train_steps': 5052800, 'local/optimizer_steps': 7894, 'local/running_reward': 16423.456325301206, 'local/running_step': 2581.0756463353414, 'local/steps_done': 5054336, 'local/episodes_done': 1181, 'local/unclipped_grad_norm': 0.39484741166234016, 'local/model_version': 7894, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:47,424] {'global/mean_episode_return': 31775.0, 'global/mean_episode_step': 4877.625, 'global/SPS': 3574.4326514811864, 'global/env_act_steps': 5049728, 'global/env_train_steps': 5048320, 'global/optimizer_steps': 7888, 'global/running_reward': 16460.98107569721, 'global/running_step': 2586.1664902888447, 'global/steps_done': 5049728, 'global/episodes_done': 1180, 'global/unclipped_grad_norm': 0.39718588734311716, 'global/model_version': 7888, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:57,444] calculate_sps 31360 steps in 10.022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:41:57,444] calculate_sps 30720 steps in 10.022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:57,444] {'local/mean_episode_return': 34000.0, 'local/mean_episode_step': 5313.25, 'local/SPS': 3129.1191226263504, 'local/env_act_steps': 5087872, 'local/env_train_steps': 5084160, 'local/optimizer_steps': 7944, 'local/running_reward': 16380.313692748092, 'local/running_step': 2578.2148139312976, 'local/steps_done': 5087872, 'local/episodes_done': 1185, 'local/unclipped_grad_norm': 0.38427159875631334, 'local/model_version': 7944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:41:57,446] {'global/mean_episode_return': 33960.0, 'global/mean_episode_step': 5330.2, 'global/SPS': 3065.2595486952005, 'global/env_act_steps': 5083392, 'global/env_train_steps': 5079040, 'global/optimizer_steps': 7936, 'global/running_reward': 16341.967680608364, 'global/running_step': 2572.138337690114, 'global/steps_done': 5083392, 'global/episodes_done': 1185, 'global/unclipped_grad_norm': 0.3710037252555291, 'global/model_version': 7936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:07,485] calculate_sps 33920 steps in 10.0416
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:07,485] calculate_sps 35840 steps in 10.0416
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:07,485] {'local/mean_episode_return': 31600.0, 'local/mean_episode_step': 4955.166666666667, 'local/SPS': 3377.94717971353, 'local/env_act_steps': 5120640, 'local/env_train_steps': 5118080, 'local/optimizer_steps': 7996, 'local/running_reward': 16730.780029296875, 'local/running_step': 2629.368438720703, 'local/steps_done': 5120640, 'local/episodes_done': 1191, 'local/unclipped_grad_norm': 0.4258262373220462, 'local/model_version': 7996, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:07,486] {'global/mean_episode_return': 30720.0, 'global/mean_episode_step': 4866.8, 'global/SPS': 3569.1517370558054, 'global/env_act_steps': 5116288, 'global/env_train_steps': 5114880, 'global/optimizer_steps': 7992, 'global/running_reward': 16716.293774319067, 'global/running_step': 2626.779790856031, 'global/steps_done': 5116288, 'global/episodes_done': 1190, 'global/unclipped_grad_norm': 0.42886771434651955, 'global/model_version': 7992, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:17,502] calculate_sps 32640 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:17,503] calculate_sps 30720 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:17,503] {'local/mean_episode_return': 33055.555555555555, 'local/mean_episode_step': 5257.722222222223, 'local/SPS': 3258.4182850036805, 'local/env_act_steps': 5153152, 'local/env_train_steps': 5150720, 'local/optimizer_steps': 8048, 'local/running_reward': 16552.68208661417, 'local/running_step': 2606.808624507874, 'local/steps_done': 5153152, 'local/episodes_done': 1201, 'local/unclipped_grad_norm': 0.4658770211614095, 'local/model_version': 8048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:17,505] {'global/mean_episode_return': 33011.11111111111, 'global/mean_episode_step': 5257.722222222223, 'global/SPS': 3066.7466211799347, 'global/env_act_steps': 5149312, 'global/env_train_steps': 5145600, 'global/optimizer_steps': 8040, 'global/running_reward': 16603.512596899225, 'global/running_step': 2615.464480377907, 'global/steps_done': 5149312, 'global/episodes_done': 1200, 'global/unclipped_grad_norm': 0.44893153632680577, 'global/model_version': 8040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:27,527] calculate_sps 30720 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:27,527] calculate_sps 33280 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:27,528] {'local/mean_episode_return': 34100.0, 'local/mean_episode_step': 5395.25, 'local/SPS': 3064.420820649345, 'local/env_act_steps': 5186432, 'local/env_train_steps': 5181440, 'local/optimizer_steps': 8096, 'local/running_reward': 16280.727163461539, 'local/running_step': 2560.4247295673076, 'local/steps_done': 5186432, 'local/episodes_done': 1205, 'local/unclipped_grad_norm': 0.5207836531723539, 'local/model_version': 8096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:27,529] {'global/mean_episode_return': 34560.0, 'global/mean_episode_step': 5395.6, 'global/SPS': 3319.7892223701238, 'global/env_act_steps': 5181952, 'global/env_train_steps': 5178880, 'global/optimizer_steps': 8091, 'global/running_reward': 16260.404411764706, 'global/running_step': 2556.6380514705884, 'global/steps_done': 5181952, 'global/episodes_done': 1205, 'global/unclipped_grad_norm': 0.5384335427307615, 'global/model_version': 8091, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:37,556] calculate_sps 35840 steps in 10.0297
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:37,557] calculate_sps 33280 steps in 10.0297
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:37,557] {'local/mean_episode_return': 34400.0, 'local/mean_episode_step': 5308.285714285715, 'local/SPS': 3573.395775190677, 'local/env_act_steps': 5218304, 'local/env_train_steps': 5217280, 'local/optimizer_steps': 8151, 'local/running_reward': 16483.050953815262, 'local/running_step': 2596.660328815261, 'local/steps_done': 5218304, 'local/episodes_done': 1212, 'local/unclipped_grad_norm': 0.5676533563570543, 'local/model_version': 8151, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:37,558] {'global/mean_episode_return': 34433.333333333336, 'global/mean_episode_step': 5294.0, 'global/SPS': 3318.1532198199143, 'global/env_act_steps': 5214848, 'global/env_train_steps': 5212160, 'global/optimizer_steps': 8144, 'global/running_reward': 16481.322957198445, 'global/running_step': 2596.1367035505837, 'global/steps_done': 5214848, 'global/episodes_done': 1211, 'global/unclipped_grad_norm': 0.54009311041742, 'global/model_version': 8144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:47,577] calculate_sps 30720 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:47,577] calculate_sps 32640 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:47,577] {'local/mean_episode_return': 31400.0, 'local/mean_episode_step': 5397.0, 'local/SPS': 3065.8768044940075, 'local/env_act_steps': 5252096, 'local/env_train_steps': 5248000, 'local/optimizer_steps': 8200, 'local/running_reward': 16564.879261363636, 'local/running_step': 2607.7612156723485, 'local/steps_done': 5252096, 'local/episodes_done': 1215, 'local/unclipped_grad_norm': 0.49034409894018754, 'local/model_version': 8200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:47,580] {'global/mean_episode_return': 32100.0, 'global/mean_episode_step': 5396.25, 'global/SPS': 3257.494104774883, 'global/env_act_steps': 5248384, 'global/env_train_steps': 5244800, 'global/optimizer_steps': 8194, 'global/running_reward': 16522.668177480915, 'global/running_step': 2601.5354842557254, 'global/steps_done': 5248384, 'global/episodes_done': 1215, 'global/unclipped_grad_norm': 0.5091292056441307, 'global/model_version': 8194, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:57,607] calculate_sps 34560 steps in 10.031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:42:57,608] calculate_sps 33920 steps in 10.031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:57,608] {'local/mean_episode_return': 33760.0, 'local/mean_episode_step': 5317.6, 'local/SPS': 3445.305049955744, 'local/env_act_steps': 5284608, 'local/env_train_steps': 5282560, 'local/optimizer_steps': 8253, 'local/running_reward': 17004.207677165356, 'local/running_step': 2670.6021161417325, 'local/steps_done': 5284608, 'local/episodes_done': 1220, 'local/unclipped_grad_norm': 0.4481245020650468, 'local/model_version': 8253, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:42:57,609] {'global/mean_episode_return': 33760.0, 'global/mean_episode_step': 5317.6, 'global/SPS': 3381.503104586193, 'global/env_act_steps': 5281408, 'global/env_train_steps': 5278720, 'global/optimizer_steps': 8248, 'global/running_reward': 16981.782945736435, 'global/running_step': 2668.01023498062, 'global/steps_done': 5281408, 'global/episodes_done': 1220, 'global/unclipped_grad_norm': 0.46175344564296583, 'global/model_version': 8248, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:07,621] calculate_sps 32000 steps in 10.0127
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:07,630] calculate_sps 30720 steps in 10.0127
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:07,630] {'local/mean_episode_return': 33514.28571428572, 'local/mean_episode_step': 5317.0, 'local/SPS': 3195.9387698056253, 'local/env_act_steps': 5317504, 'local/env_train_steps': 5314560, 'local/optimizer_steps': 8304, 'local/running_reward': 17031.48711089494, 'local/running_step': 2672.3373662451363, 'local/steps_done': 5317504, 'local/episodes_done': 1227, 'local/unclipped_grad_norm': 0.5072776508681914, 'local/model_version': 8304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:07,632] {'global/mean_episode_return': 33514.28571428572, 'global/mean_episode_step': 5317.0, 'global/SPS': 3068.1012190134, 'global/env_act_steps': 5314688, 'global/env_train_steps': 5309440, 'global/optimizer_steps': 8296, 'global/running_reward': 17042.872596153848, 'global/running_step': 2673.8588341346153, 'global/steps_done': 5314688, 'global/episodes_done': 1227, 'global/unclipped_grad_norm': 0.497683013168474, 'global/model_version': 8296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:17,634] calculate_sps 31360 steps in 10.0115
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:17,646] calculate_sps 35840 steps in 10.0115
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:17,646] {'local/mean_episode_return': 34225.0, 'local/mean_episode_step': 5396.3125, 'local/SPS': 3132.3862171968476, 'local/env_act_steps': 5350656, 'local/env_train_steps': 5345920, 'local/optimizer_steps': 8352, 'local/running_reward': 16623.153957528957, 'local/running_step': 2607.131364623552, 'local/steps_done': 5350656, 'local/episodes_done': 1236, 'local/unclipped_grad_norm': 0.4677199359672765, 'local/model_version': 8352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:17,647] {'global/mean_episode_return': 34366.666666666664, 'global/mean_episode_step': 5395.75, 'global/SPS': 3579.869962510683, 'global/env_act_steps': 5346816, 'global/env_train_steps': 5345280, 'global/optimizer_steps': 8352, 'global/running_reward': 16638.421314741037, 'global/running_step': 2609.773032868526, 'global/steps_done': 5346816, 'global/episodes_done': 1234, 'global/unclipped_grad_norm': 0.47776402892278774, 'global/model_version': 8352, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:27,645] calculate_sps 35200 steps in 10.0125
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:27,645] calculate_sps 30720 steps in 10.0125
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:27,645] {'local/mean_episode_return': 36200.0, 'local/mean_episode_step': 5399.0, 'local/SPS': 3515.6057275325866, 'local/env_act_steps': 5383040, 'local/env_train_steps': 5381120, 'local/optimizer_steps': 8408, 'local/running_reward': 16926.327816205532, 'local/running_step': 2653.2966588438735, 'local/steps_done': 5383040, 'local/episodes_done': 1237, 'local/unclipped_grad_norm': 0.5005545986018011, 'local/model_version': 8408, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:27,647] {'global/mean_episode_return': 34600.0, 'global/mean_episode_step': 5398.333333333333, 'global/SPS': 3068.1649985738936, 'global/env_act_steps': 5380608, 'global/env_train_steps': 5376000, 'global/optimizer_steps': 8400, 'global/running_reward': 16881.800426136364, 'global/running_step': 2646.195194128788, 'global/steps_done': 5380608, 'global/episodes_done': 1237, 'global/unclipped_grad_norm': 0.5026631228004893, 'global/model_version': 8400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:37,655] calculate_sps 30720 steps in 10.0107
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:37,656] calculate_sps 35840 steps in 10.0107
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:37,656] {'local/mean_episode_return': 33840.0, 'local/mean_episode_step': 5240.6, 'local/SPS': 3068.713480721616, 'local/env_act_steps': 5416576, 'local/env_train_steps': 5411840, 'local/optimizer_steps': 8456, 'local/running_reward': 17207.03125, 'local/running_step': 2701.640923187023, 'local/steps_done': 5416576, 'local/episodes_done': 1242, 'local/unclipped_grad_norm': 0.4822478300581376, 'local/model_version': 8456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:37,657] {'global/mean_episode_return': 34200.0, 'global/mean_episode_step': 5258.5, 'global/SPS': 3580.1657275085527, 'global/env_act_steps': 5413248, 'global/env_train_steps': 5411840, 'global/optimizer_steps': 8456, 'global/running_reward': 17185.60661764706, 'global/running_step': 2698.3127144607843, 'global/steps_done': 5413248, 'global/episodes_done': 1241, 'global/unclipped_grad_norm': 0.4830557762512139, 'global/model_version': 8456, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:47,667] calculate_sps 35840 steps in 10.0121
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:47,667] calculate_sps 30720 steps in 10.0121
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:47,667] {'local/mean_episode_return': 34022.22222222222, 'local/mean_episode_step': 5318.333333333333, 'local/SPS': 3579.659912930673, 'local/env_act_steps': 5448704, 'local/env_train_steps': 5447680, 'local/optimizer_steps': 8511, 'local/running_reward': 17275.728336653385, 'local/running_step': 2708.964859312749, 'local/steps_done': 5448704, 'local/episodes_done': 1251, 'local/unclipped_grad_norm': 0.409555361894044, 'local/model_version': 8511, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:47,668] {'global/mean_episode_return': 34133.333333333336, 'global/mean_episode_step': 5299.888888888889, 'global/SPS': 3068.2799253691483, 'global/env_act_steps': 5447424, 'global/env_train_steps': 5442560, 'global/optimizer_steps': 8504, 'global/running_reward': 17295.880149812732, 'global/running_step': 2712.210469335206, 'global/steps_done': 5447424, 'global/episodes_done': 1250, 'global/unclipped_grad_norm': 0.3954770911174516, 'global/model_version': 8504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:57,676] calculate_sps 30720 steps in 10.0085
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:43:57,676] calculate_sps 35840 steps in 10.0085
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:57,677] {'local/mean_episode_return': 32755.555555555555, 'local/mean_episode_step': 5312.333333333333, 'local/SPS': 3069.383602334636, 'local/env_act_steps': 5482112, 'local/env_train_steps': 5478400, 'local/optimizer_steps': 8560, 'local/running_reward': 16676.53256704981, 'local/running_step': 2612.1022210249043, 'local/steps_done': 5482112, 'local/episodes_done': 1260, 'local/unclipped_grad_norm': 0.502344045864076, 'local/model_version': 8560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:43:57,678] {'global/mean_episode_return': 32620.0, 'global/mean_episode_step': 5314.6, 'global/SPS': 3580.9475360570755, 'global/env_act_steps': 5479808, 'global/env_train_steps': 5478400, 'global/optimizer_steps': 8560, 'global/running_reward': 16692.613636363636, 'global/running_step': 2614.8266119071145, 'global/steps_done': 5479808, 'global/episodes_done': 1260, 'global/unclipped_grad_norm': 0.5028125496049013, 'global/model_version': 8560, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:07,717] calculate_sps 33920 steps in 10.0413
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:07,717] calculate_sps 30720 steps in 10.0413
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:07,717] {'local/mean_episode_return': 35325.0, 'local/mean_episode_step': 5369.375, 'local/SPS': 3378.0609112256134, 'local/env_act_steps': 5514880, 'local/env_train_steps': 5512320, 'local/optimizer_steps': 8612, 'local/running_reward': 16599.47509765625, 'local/running_step': 2603.0772399902344, 'local/steps_done': 5514880, 'local/episodes_done': 1268, 'local/unclipped_grad_norm': 0.4731917707965924, 'local/model_version': 8612, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:07,718] {'global/mean_episode_return': 35314.28571428572, 'global/mean_episode_step': 5365.571428571428, 'global/SPS': 3059.375919600556, 'global/env_act_steps': 5513600, 'global/env_train_steps': 5509120, 'global/optimizer_steps': 8608, 'global/running_reward': 16606.25, 'global/running_step': 2603.897431344697, 'global/steps_done': 5513600, 'global/episodes_done': 1267, 'global/unclipped_grad_norm': 0.4719086205586791, 'global/model_version': 8608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:17,732] calculate_sps 32640 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:17,733] calculate_sps 35200 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:17,733] {'local/mean_episode_return': 34100.0, 'local/mean_episode_step': 5396.75, 'local/SPS': 3259.0284381733027, 'local/env_act_steps': 5547776, 'local/env_train_steps': 5544960, 'local/optimizer_steps': 8664, 'local/running_reward': 16500.224951361866, 'local/running_step': 2585.310949659533, 'local/steps_done': 5547776, 'local/episodes_done': 1272, 'local/unclipped_grad_norm': 0.45193094201385975, 'local/model_version': 8664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:17,743] {'global/mean_episode_return': 34360.0, 'global/mean_episode_step': 5396.6, 'global/SPS': 3514.6385117555224, 'global/env_act_steps': 5545856, 'global/env_train_steps': 5544320, 'global/optimizer_steps': 8662, 'global/running_reward': 16487.87822420635, 'global/running_step': 2583.531187996032, 'global/steps_done': 5545856, 'global/episodes_done': 1272, 'global/unclipped_grad_norm': 0.45785566985055254, 'global/model_version': 8662, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:27,740] calculate_sps 30720 steps in 10.0072
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:27,740] calculate_sps 31360 steps in 10.0072
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:27,740] {'local/mean_episode_return': 34145.454545454544, 'local/mean_episode_step': 5351.454545454545, 'local/SPS': 3069.776366577879, 'local/env_act_steps': 5580928, 'local/env_train_steps': 5575680, 'local/optimizer_steps': 8712, 'local/running_reward': 16559.3388030888, 'local/running_step': 2584.5078426640925, 'local/steps_done': 5580928, 'local/episodes_done': 1283, 'local/unclipped_grad_norm': 0.5347537732062241, 'local/model_version': 8712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:27,742] {'global/mean_episode_return': 34200.0, 'global/mean_episode_step': 5346.7, 'global/SPS': 3133.7300408815845, 'global/env_act_steps': 5579008, 'global/env_train_steps': 5575680, 'global/optimizer_steps': 8712, 'global/running_reward': 16589.23141891892, 'global/running_step': 2589.953426640927, 'global/steps_done': 5579008, 'global/episodes_done': 1282, 'global/unclipped_grad_norm': 0.5279748444259167, 'global/model_version': 8712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:37,755] calculate_sps 35840 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:37,756] calculate_sps 33280 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:37,756] {'local/mean_episode_return': 34450.0, 'local/mean_episode_step': 5395.875, 'local/SPS': 3578.3688712363937, 'local/env_act_steps': 5613312, 'local/env_train_steps': 5611520, 'local/optimizer_steps': 8768, 'local/running_reward': 16213.846343873518, 'local/running_step': 2521.3550209980235, 'local/steps_done': 5613312, 'local/episodes_done': 1291, 'local/unclipped_grad_norm': 0.4852123221914683, 'local/model_version': 8768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:37,767] {'global/mean_episode_return': 34457.142857142855, 'global/mean_episode_step': 5396.571428571428, 'global/SPS': 3322.7710947195087, 'global/env_act_steps': 5612032, 'global/env_train_steps': 5608960, 'global/optimizer_steps': 8763, 'global/running_reward': 16216.09132751938, 'global/running_step': 2522.0263444767443, 'global/steps_done': 5612032, 'global/episodes_done': 1289, 'global/unclipped_grad_norm': 0.49501267148583544, 'global/model_version': 8763, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:47,757] calculate_sps 30720 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:47,766] calculate_sps 33280 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:47,766] {'local/mean_episode_return': 33800.0, 'local/mean_episode_step': 5331.5, 'local/SPS': 3071.6129638072557, 'local/env_act_steps': 5646464, 'local/env_train_steps': 5642240, 'local/optimizer_steps': 8816, 'local/running_reward': 15951.5805984556, 'local/running_step': 2480.449897442085, 'local/steps_done': 5646464, 'local/episodes_done': 1295, 'local/unclipped_grad_norm': 0.583120101907601, 'local/model_version': 8816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:47,768] {'global/mean_episode_return': 33866.666666666664, 'global/mean_episode_step': 5352.666666666667, 'global/SPS': 3327.5807107911937, 'global/env_act_steps': 5645184, 'global/env_train_steps': 5642240, 'global/optimizer_steps': 8816, 'global/running_reward': 15947.99107142857, 'global/running_step': 2479.968237210425, 'global/steps_done': 5645184, 'global/episodes_done': 1295, 'global/unclipped_grad_norm': 0.5644529941228201, 'global/model_version': 8816, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:57,775] calculate_sps 34560 steps in 10.0188
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:44:57,775] calculate_sps 32640 steps in 10.0188
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:57,776] {'local/mean_episode_return': 34900.0, 'local/mean_episode_step': 5395.0, 'local/SPS': 3449.5089125530203, 'local/env_act_steps': 5678848, 'local/env_train_steps': 5676800, 'local/optimizer_steps': 8869, 'local/running_reward': 16532.126976284584, 'local/running_step': 2566.425117341897, 'local/steps_done': 5678848, 'local/episodes_done': 1297, 'local/unclipped_grad_norm': 0.5467175667016011, 'local/model_version': 8869, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:44:57,776] {'global/mean_episode_return': 34900.0, 'global/mean_episode_step': 5395.0, 'global/SPS': 3257.869528522297, 'global/env_act_steps': 5678464, 'global/env_train_steps': 5674880, 'global/optimizer_steps': 8866, 'global/running_reward': 16515.37860576923, 'global/running_step': 2563.84765625, 'global/steps_done': 5678464, 'global/episodes_done': 1297, 'global/unclipped_grad_norm': 0.5671486368775368, 'global/model_version': 8866, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:07,783] calculate_sps 32000 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:07,784] calculate_sps 33920 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:07,784] {'local/mean_episode_return': 35900.0, 'local/mean_episode_step': 5395.0, 'local/SPS': 3197.4783375632783, 'local/env_act_steps': 5712000, 'local/env_train_steps': 5708800, 'local/optimizer_steps': 8920, 'local/running_reward': 16879.09025096525, 'local/running_step': 2620.6698540057914, 'local/steps_done': 5712000, 'local/episodes_done': 1301, 'local/unclipped_grad_norm': 0.6164068283111441, 'local/model_version': 8920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:07,785] {'global/mean_episode_return': 35900.0, 'global/mean_episode_step': 5395.0, 'global/SPS': 3389.327037817075, 'global/env_act_steps': 5711360, 'global/env_train_steps': 5708800, 'global/optimizer_steps': 8920, 'global/running_reward': 16876.38010700389, 'global/running_step': 2620.309004134241, 'global/steps_done': 5711360, 'global/episodes_done': 1301, 'global/unclipped_grad_norm': 0.5936175450958587, 'global/model_version': 8920, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:17,795] calculate_sps 31360 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:17,795] calculate_sps 30720 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:17,795] {'local/mean_episode_return': 32033.333333333332, 'local/mean_episode_step': 5113.166666666667, 'local/SPS': 3132.2684347832383, 'local/env_act_steps': 5744768, 'local/env_train_steps': 5740160, 'local/optimizer_steps': 8968, 'local/running_reward': 17215.850830078125, 'local/running_step': 2669.340606689453, 'local/steps_done': 5744768, 'local/episodes_done': 1307, 'local/unclipped_grad_norm': 0.5551967723295093, 'local/model_version': 8968, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:17,796] {'global/mean_episode_return': 32033.333333333332, 'global/mean_episode_step': 5113.166666666667, 'global/SPS': 3068.344589175417, 'global/env_act_steps': 5744640, 'global/env_train_steps': 5739520, 'global/optimizer_steps': 8968, 'global/running_reward': 17211.23798076923, 'global/running_step': 2668.746033653846, 'global/steps_done': 5744640, 'global/episodes_done': 1307, 'global/unclipped_grad_norm': 0.5551967723295093, 'global/model_version': 8968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:27,813] calculate_sps 35200 steps in 10.0175
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:27,813] calculate_sps 35840 steps in 10.0175
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:27,813] {'local/mean_episode_return': 31600.0, 'local/mean_episode_step': 4898.0, 'local/SPS': 3513.8502861474767, 'local/env_act_steps': 5776512, 'local/env_train_steps': 5775360, 'local/optimizer_steps': 9024, 'local/running_reward': 17417.3828125, 'local/running_step': 2696.3560672883063, 'local/steps_done': 5776512, 'local/episodes_done': 1309, 'local/unclipped_grad_norm': 0.5362168908385294, 'local/model_version': 9024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:27,815] {'global/mean_episode_return': 31600.0, 'global/mean_episode_step': 4898.0, 'global/SPS': 3577.7384731683396, 'global/env_act_steps': 5776384, 'global/env_train_steps': 5775360, 'global/optimizer_steps': 9023, 'global/running_reward': 17415.228074596773, 'global/running_step': 2696.0259576612902, 'global/steps_done': 5776384, 'global/episodes_done': 1309, 'global/unclipped_grad_norm': 0.5429788756099614, 'global/model_version': 9023, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:37,815] calculate_sps 30720 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:37,816] calculate_sps 30720 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:37,816] {'local/mean_episode_return': 33250.0, 'local/mean_episode_step': 5395.25, 'local/SPS': 3071.596708224483, 'local/env_act_steps': 5809792, 'local/env_train_steps': 5806080, 'local/optimizer_steps': 9072, 'local/running_reward': 17814.19471153846, 'local/running_step': 2752.5753004807693, 'local/steps_done': 5809792, 'local/episodes_done': 1313, 'local/unclipped_grad_norm': 0.3736266734388967, 'local/model_version': 9072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:37,818] {'global/mean_episode_return': 33250.0, 'global/mean_episode_step': 5395.25, 'global/SPS': 3071.596708224483, 'global/env_act_steps': 5809792, 'global/env_train_steps': 5806080, 'global/optimizer_steps': 9072, 'global/running_reward': 17814.044540229886, 'global/running_step': 2752.520444204981, 'global/steps_done': 5809792, 'global/episodes_done': 1313, 'global/unclipped_grad_norm': 0.3693548582342206, 'global/model_version': 9072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:47,817] calculate_sps 33280 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:47,817] calculate_sps 25600 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:47,822] {'local/mean_episode_return': 34720.0, 'local/mean_episode_step': 5385.4, 'local/SPS': 3327.657341192803, 'local/env_act_steps': 5842560, 'local/env_train_steps': 5839360, 'local/optimizer_steps': 9123, 'local/running_reward': 18092.413330078125, 'local/running_step': 2790.981658935547, 'local/steps_done': 5842560, 'local/episodes_done': 1318, 'local/unclipped_grad_norm': 0.4754080854210199, 'local/model_version': 9123, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:47,826] {'global/mean_episode_return': 34720.0, 'global/mean_episode_step': 5385.4, 'global/SPS': 2559.736416302156, 'global/env_act_steps': 5836416, 'global/env_train_steps': 5831680, 'global/optimizer_steps': 9112, 'global/running_reward': 18088.333834134617, 'global/running_step': 2789.7181114783652, 'global/steps_done': 5836416, 'global/episodes_done': 1318, 'global/unclipped_grad_norm': 0.4964663304388523, 'global/model_version': 9112, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 11:45:52,113] saving global stats {'mean_episode_return': 34400.0, 'mean_episode_step': 5398.0, 'SPS': None, 'env_act_steps': 5849216, 'env_train_steps': 5847040, 'optimizer_steps': 9136, 'running_reward': 18199.671875, 'running_step': 2809.45703125, 'steps_done': 5849216, 'episodes_done': 1319, 'unclipped_grad_norm': 0.4516497316459815, 'model_version': 9136, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 11:45:52,207] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:57,840] calculate_sps 33280 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:45:57,840] calculate_sps 35840 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:57,840] {'local/mean_episode_return': 33320.0, 'local/mean_episode_step': 5375.2, 'local/SPS': 3319.7986180019348, 'local/env_act_steps': 5875200, 'local/env_train_steps': 5872640, 'local/optimizer_steps': 9176, 'local/running_reward': 18299.975490196077, 'local/running_step': 2825.932414215686, 'local/steps_done': 5875200, 'local/episodes_done': 1323, 'local/unclipped_grad_norm': 0.4848203777142291, 'local/model_version': 9176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:45:57,851] {'global/mean_episode_return': 33700.0, 'global/mean_episode_step': 5370.0, 'global/SPS': 3575.1677424636223, 'global/env_act_steps': 5868800, 'global/env_train_steps': 5867520, 'global/optimizer_steps': 9168, 'global/running_reward': 18270.460721343872, 'global/running_step': 2821.4812561758895, 'global/steps_done': 5868800, 'global/episodes_done': 1322, 'global/unclipped_grad_norm': 0.4668671286531857, 'global/model_version': 9168, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:07,882] calculate_sps 31360 steps in 10.0418
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:07,882] calculate_sps 30720 steps in 10.0418
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:07,882] {'local/mean_episode_return': 35228.57142857143, 'local/mean_episode_step': 5396.142857142857, 'local/SPS': 3122.9392569822244, 'local/env_act_steps': 5908608, 'local/env_train_steps': 5904000, 'local/optimizer_steps': 9224, 'local/running_reward': 18095.797413793105, 'local/running_step': 2794.9432471264367, 'local/steps_done': 5908608, 'local/episodes_done': 1330, 'local/unclipped_grad_norm': 0.5046870576528212, 'local/model_version': 9224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:07,884] {'global/mean_episode_return': 34800.0, 'global/mean_episode_step': 5396.125, 'global/SPS': 3059.2058027580974, 'global/env_act_steps': 5902464, 'global/env_train_steps': 5898240, 'global/optimizer_steps': 9216, 'global/running_reward': 18123.47908745247, 'global/running_step': 2798.463432747148, 'global/steps_done': 5902464, 'global/episodes_done': 1330, 'global/unclipped_grad_norm': 0.520943526023378, 'global/model_version': 9216, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:17,903] calculate_sps 35200 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:17,903] calculate_sps 34560 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:17,903] {'local/mean_episode_return': 34900.0, 'local/mean_episode_step': 5397.0, 'local/SPS': 3512.614831297799, 'local/env_act_steps': 5940608, 'local/env_train_steps': 5939200, 'local/optimizer_steps': 9280, 'local/running_reward': 18163.18125, 'local/running_step': 2809.1299375, 'local/steps_done': 5940608, 'local/episodes_done': 1338, 'local/unclipped_grad_norm': 0.5701993948646954, 'local/model_version': 9280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:17,905] {'global/mean_episode_return': 34880.0, 'global/mean_episode_step': 5397.2, 'global/SPS': 3448.7491070923843, 'global/env_act_steps': 5934848, 'global/env_train_steps': 5932800, 'global/optimizer_steps': 9269, 'global/running_reward': 18163.889575098816, 'global/running_step': 2809.4328372035575, 'global/steps_done': 5934848, 'global/episodes_done': 1335, 'global/unclipped_grad_norm': 0.5533906370401382, 'global/model_version': 9269, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:27,922] calculate_sps 30720 steps in 10.0196
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:27,923] calculate_sps 32000 steps in 10.0196
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:27,923] {'local/mean_episode_return': 36000.0, 'local/mean_episode_step': 5360.777777777777, 'local/SPS': 3065.988349869412, 'local/env_act_steps': 5973760, 'local/env_train_steps': 5969920, 'local/optimizer_steps': 9328, 'local/running_reward': 17664.94329150579, 'local/running_step': 2738.538700530888, 'local/steps_done': 5973760, 'local/episodes_done': 1347, 'local/unclipped_grad_norm': 0.5763701616475979, 'local/model_version': 9328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:27,925] {'global/mean_episode_return': 35781.818181818184, 'global/mean_episode_step': 5367.545454545455, 'global/SPS': 3193.737864447304, 'global/env_act_steps': 5968000, 'global/env_train_steps': 5964800, 'global/optimizer_steps': 9320, 'global/running_reward': 17785.587596525096, 'global/running_step': 2754.881213803089, 'global/steps_done': 5968000, 'global/episodes_done': 1346, 'global/unclipped_grad_norm': 0.5747609708239051, 'global/model_version': 9320, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:37,972] calculate_sps 34560 steps in 10.0501
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:37,972] calculate_sps 33920 steps in 10.0501
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:37,972] {'local/mean_episode_return': 34800.0, 'local/mean_episode_step': 5396.333333333333, 'local/SPS': 3438.762423496776, 'local/env_act_steps': 6006528, 'local/env_train_steps': 6004480, 'local/optimizer_steps': 9381, 'local/running_reward': 17608.16650390625, 'local/running_step': 2730.344696044922, 'local/steps_done': 6006528, 'local/episodes_done': 1350, 'local/unclipped_grad_norm': 0.629550611494847, 'local/model_version': 9381, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:37,973] {'global/mean_episode_return': 34900.0, 'global/mean_episode_step': 5395.75, 'global/SPS': 3375.0816378764657, 'global/env_act_steps': 6001280, 'global/env_train_steps': 5998720, 'global/optimizer_steps': 9372, 'global/running_reward': 17538.76201923077, 'global/running_step': 2720.7240084134614, 'global/steps_done': 6001280, 'global/episodes_done': 1350, 'global/unclipped_grad_norm': 0.6251911353319883, 'global/model_version': 9372, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:47,985] calculate_sps 32000 steps in 10.0126
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:47,985] calculate_sps 32640 steps in 10.0126
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:47,986] {'local/mean_episode_return': 32966.666666666664, 'local/mean_episode_step': 5282.666666666667, 'local/SPS': 3195.959469252204, 'local/env_act_steps': 6039680, 'local/env_train_steps': 6036480, 'local/optimizer_steps': 9432, 'local/running_reward': 18027.135617760618, 'local/running_step': 2790.3269787644786, 'local/steps_done': 6039680, 'local/episodes_done': 1356, 'local/unclipped_grad_norm': 0.5190145047564133, 'local/model_version': 9432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:47,987] {'global/mean_episode_return': 31800.0, 'global/mean_episode_step': 5225.5, 'global/SPS': 3259.878658637248, 'global/env_act_steps': 6034560, 'global/env_train_steps': 6031360, 'global/optimizer_steps': 9424, 'global/running_reward': 17979.248798076922, 'global/running_step': 2783.7263221153844, 'global/steps_done': 6034560, 'global/episodes_done': 1354, 'global/unclipped_grad_norm': 0.5261079557240009, 'global/model_version': 9424, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:58,018] calculate_sps 32640 steps in 10.0336
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:46:58,019] calculate_sps 32640 steps in 10.0336
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:58,019] {'local/mean_episode_return': 35275.0, 'local/mean_episode_step': 5388.25, 'local/SPS': 3253.0652499834496, 'local/env_act_steps': 6072704, 'local/env_train_steps': 6069120, 'local/optimizer_steps': 9482, 'local/running_reward': 17566.55159883721, 'local/running_step': 2721.8539546996126, 'local/steps_done': 6072704, 'local/episodes_done': 1364, 'local/unclipped_grad_norm': 0.447221147865057, 'local/model_version': 9482, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:46:58,020] {'global/mean_episode_return': 35280.0, 'global/mean_episode_step': 5390.0, 'global/SPS': 3253.0652499834496, 'global/env_act_steps': 6067712, 'global/env_train_steps': 6064000, 'global/optimizer_steps': 9475, 'global/running_reward': 17642.645994208495, 'global/running_step': 2733.077853523166, 'global/steps_done': 6067712, 'global/episodes_done': 1364, 'global/unclipped_grad_norm': 0.468901160885306, 'global/model_version': 9475, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:08,032] calculate_sps 33920 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:08,032] calculate_sps 33920 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:08,032] {'local/mean_episode_return': 34555.555555555555, 'local/mean_episode_step': 5370.111111111111, 'local/SPS': 3387.6425829565405, 'local/env_act_steps': 6105344, 'local/env_train_steps': 6103040, 'local/optimizer_steps': 9536, 'local/running_reward': 17730.47181372549, 'local/running_step': 2741.5483149509805, 'local/steps_done': 6105344, 'local/episodes_done': 1373, 'local/unclipped_grad_norm': 0.48766740701264805, 'local/model_version': 9536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:08,033] {'global/mean_episode_return': 34371.42857142857, 'global/mean_episode_step': 5362.428571428572, 'global/SPS': 3387.6425829565405, 'global/env_act_steps': 6100608, 'global/env_train_steps': 6097920, 'global/optimizer_steps': 9528, 'global/running_reward': 17757.763861867705, 'global/running_step': 2747.014439445525, 'global/steps_done': 6100608, 'global/episodes_done': 1371, 'global/unclipped_grad_norm': 0.45697656737745934, 'global/model_version': 9528, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:18,051] calculate_sps 30720 steps in 10.019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:18,051] calculate_sps 32000 steps in 10.019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:18,062] {'local/mean_episode_return': 37400.0, 'local/mean_episode_step': 5396.25, 'local/SPS': 3066.1641834553425, 'local/env_act_steps': 6138880, 'local/env_train_steps': 6133760, 'local/optimizer_steps': 9584, 'local/running_reward': 17556.03530534351, 'local/running_step': 2716.1630188454196, 'local/steps_done': 6138880, 'local/episodes_done': 1377, 'local/unclipped_grad_norm': 0.532881544282039, 'local/model_version': 9584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:18,064] {'global/mean_episode_return': 36600.0, 'global/mean_episode_step': 5396.75, 'global/SPS': 3193.921024432648, 'global/env_act_steps': 6134016, 'global/env_train_steps': 6129920, 'global/optimizer_steps': 9577, 'global/running_reward': 17525.03591954023, 'global/running_step': 2710.0635476532566, 'global/steps_done': 6134016, 'global/episodes_done': 1375, 'global/unclipped_grad_norm': 0.558715934351999, 'global/model_version': 9577, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:28,065] calculate_sps 35840 steps in 10.0148
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:28,066] calculate_sps 34560 steps in 10.0148
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:28,066] {'local/mean_episode_return': 33857.142857142855, 'local/mean_episode_step': 5343.428571428572, 'local/SPS': 3578.7182322804247, 'local/env_act_steps': 6171136, 'local/env_train_steps': 6169600, 'local/optimizer_steps': 9640, 'local/running_reward': 17727.97619047619, 'local/running_step': 2748.7923487103176, 'local/steps_done': 6171136, 'local/episodes_done': 1384, 'local/unclipped_grad_norm': 0.5382610603368708, 'local/model_version': 9640, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:28,067] {'global/mean_episode_return': 35566.666666666664, 'global/mean_episode_step': 5397.0, 'global/SPS': 3450.906866841838, 'global/env_act_steps': 6167296, 'global/env_train_steps': 6164480, 'global/optimizer_steps': 9632, 'global/running_reward': 17724.71153846154, 'global/running_step': 2748.144170673077, 'global/steps_done': 6167296, 'global/episodes_done': 1381, 'global/unclipped_grad_norm': 0.518823592364788, 'global/model_version': 9632, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:38,075] calculate_sps 30720 steps in 10.0098
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:38,075] calculate_sps 31360 steps in 10.0098
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:38,076] {'local/mean_episode_return': 35400.0, 'local/mean_episode_step': 5333.666666666667, 'local/SPS': 3068.9888918190923, 'local/env_act_steps': 6204160, 'local/env_train_steps': 6200320, 'local/optimizer_steps': 9688, 'local/running_reward': 17517.2238372093, 'local/running_step': 2715.486343265504, 'local/steps_done': 6204160, 'local/episodes_done': 1388, 'local/unclipped_grad_norm': 0.44756818904230994, 'local/model_version': 9688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:38,077] {'global/mean_episode_return': 33900.0, 'global/mean_episode_step': 5302.5, 'global/SPS': 3132.9261603986565, 'global/env_act_steps': 6200448, 'global/env_train_steps': 6195840, 'global/optimizer_steps': 9680, 'global/running_reward': 17519.34724903475, 'global/running_step': 2715.3689370173747, 'global/steps_done': 6200448, 'global/episodes_done': 1388, 'global/unclipped_grad_norm': 0.4665780399615566, 'global/model_version': 9680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:48,082] calculate_sps 33280 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:48,082] calculate_sps 35200 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:48,096] {'local/mean_episode_return': 33040.0, 'local/mean_episode_step': 5320.0, 'local/SPS': 3325.825049036264, 'local/env_act_steps': 6236800, 'local/env_train_steps': 6233600, 'local/optimizer_steps': 9740, 'local/running_reward': 17908.799019607843, 'local/running_step': 2773.797886029412, 'local/steps_done': 6236800, 'local/episodes_done': 1393, 'local/unclipped_grad_norm': 0.5381659214886335, 'local/model_version': 9740, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:48,098] {'global/mean_episode_return': 33266.666666666664, 'global/mean_episode_step': 5270.333333333333, 'global/SPS': 3517.6995710960487, 'global/env_act_steps': 6233344, 'global/env_train_steps': 6231040, 'global/optimizer_steps': 9736, 'global/running_reward': 17874.82368677043, 'global/running_step': 2769.5156553988327, 'global/steps_done': 6233344, 'global/episodes_done': 1391, 'global/unclipped_grad_norm': 0.5100495788667884, 'global/model_version': 9736, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:58,103] calculate_sps 33280 steps in 10.0215
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:47:58,104] calculate_sps 30720 steps in 10.0215
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:58,104] {'local/mean_episode_return': 33800.0, 'local/mean_episode_step': 5259.6, 'local/SPS': 3320.857980867287, 'local/env_act_steps': 6269568, 'local/env_train_steps': 6266880, 'local/optimizer_steps': 9792, 'local/running_reward': 18007.65380859375, 'local/running_step': 2785.1630859375, 'local/steps_done': 6269568, 'local/episodes_done': 1398, 'local/unclipped_grad_norm': 0.5380987254186318, 'local/model_version': 9792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:47:58,106] {'global/mean_episode_return': 33485.71428571428, 'global/mean_episode_step': 5298.142857142857, 'global/SPS': 3065.407366954419, 'global/env_act_steps': 6266752, 'global/env_train_steps': 6261760, 'global/optimizer_steps': 9784, 'global/running_reward': 17999.97006704981, 'global/running_step': 2783.767031848659, 'global/steps_done': 6266752, 'global/episodes_done': 1398, 'global/unclipped_grad_norm': 0.549822331716617, 'global/model_version': 9784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:08,118] calculate_sps 31360 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:08,118] calculate_sps 35840 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:08,127] {'local/mean_episode_return': 32945.454545454544, 'local/mean_episode_step': 5236.909090909091, 'local/SPS': 3131.9701022510935, 'local/env_act_steps': 6302976, 'local/env_train_steps': 6298240, 'local/optimizer_steps': 9840, 'local/running_reward': 17793.06752873563, 'local/running_step': 2756.442049808429, 'local/steps_done': 6302976, 'local/episodes_done': 1409, 'local/unclipped_grad_norm': 0.4819055609405041, 'local/model_version': 9840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:08,128] {'global/mean_episode_return': 32945.454545454544, 'global/mean_episode_step': 5236.909090909091, 'global/SPS': 3579.3944025726787, 'global/env_act_steps': 6299648, 'global/env_train_steps': 6297600, 'global/optimizer_steps': 9840, 'global/running_reward': 17850.474221789882, 'global/running_step': 2765.4722762645915, 'global/steps_done': 6299648, 'global/episodes_done': 1409, 'global/unclipped_grad_norm': 0.4943036089784333, 'global/model_version': 9840, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:18,151] calculate_sps 35200 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:18,151] calculate_sps 30720 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:18,151] {'local/mean_episode_return': 32542.85714285714, 'local/mean_episode_step': 5341.857142857143, 'local/SPS': 3507.8784569701916, 'local/env_act_steps': 6335360, 'local/env_train_steps': 6333440, 'local/optimizer_steps': 9896, 'local/running_reward': 17491.230237154152, 'local/running_step': 2703.2916872529645, 'local/steps_done': 6335360, 'local/episodes_done': 1416, 'local/unclipped_grad_norm': 0.48721610887774397, 'local/model_version': 9896, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:18,153] {'global/mean_episode_return': 32966.666666666664, 'global/mean_episode_step': 5396.0, 'global/SPS': 3061.421198810349, 'global/env_act_steps': 6333440, 'global/env_train_steps': 6328320, 'global/optimizer_steps': 9888, 'global/running_reward': 17487.6953125, 'global/running_step': 2703.1665187026515, 'global/steps_done': 6333440, 'global/episodes_done': 1415, 'global/unclipped_grad_norm': 0.4908173192913334, 'global/model_version': 9888, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:28,160] calculate_sps 30720 steps in 10.0094
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:28,160] calculate_sps 35840 steps in 10.0094
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:28,161] {'local/mean_episode_return': 34371.42857142857, 'local/mean_episode_step': 5397.714285714285, 'local/SPS': 3069.1042458671104, 'local/env_act_steps': 6368512, 'local/env_train_steps': 6364160, 'local/optimizer_steps': 9944, 'local/running_reward': 17341.638513513513, 'local/running_step': 2672.7815818050194, 'local/steps_done': 6368512, 'local/episodes_done': 1423, 'local/unclipped_grad_norm': 0.4753433141546945, 'local/model_version': 9944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:28,162] {'global/mean_episode_return': 33571.42857142857, 'global/mean_episode_step': 5343.0, 'global/SPS': 3580.621620178296, 'global/env_act_steps': 6365312, 'global/env_train_steps': 6364160, 'global/optimizer_steps': 9944, 'global/running_reward': 17348.343373493975, 'global/running_step': 2673.9447791164657, 'global/steps_done': 6365312, 'global/episodes_done': 1422, 'global/unclipped_grad_norm': 0.4739526759034821, 'global/model_version': 9944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:38,181] calculate_sps 34560 steps in 10.0192
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:38,181] calculate_sps 30720 steps in 10.0192
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:38,188] {'local/mean_episode_return': 33800.0, 'local/mean_episode_step': 5328.0, 'local/SPS': 3449.394074939025, 'local/env_act_steps': 6400896, 'local/env_train_steps': 6398720, 'local/optimizer_steps': 9997, 'local/running_reward': 17125.284090909092, 'local/running_step': 2636.004539278656, 'local/steps_done': 6400896, 'local/episodes_done': 1434, 'local/unclipped_grad_norm': 0.43818623614761065, 'local/model_version': 9997, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:38,189] {'global/mean_episode_return': 33950.0, 'global/mean_episode_step': 5334.0, 'global/SPS': 3066.1280666124667, 'global/env_act_steps': 6398848, 'global/env_train_steps': 6394880, 'global/optimizer_steps': 9992, 'global/running_reward': 17176.848759541987, 'global/running_step': 2644.5115100190837, 'global/steps_done': 6398848, 'global/episodes_done': 1434, 'global/unclipped_grad_norm': 0.42445120587944984, 'global/model_version': 9992, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:48,189] calculate_sps 32000 steps in 10.0094
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:48,189] calculate_sps 34560 steps in 10.0094
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:48,189] {'local/mean_episode_return': 34333.333333333336, 'local/mean_episode_step': 5314.5, 'local/SPS': 3197.007957688067, 'local/env_act_steps': 6434048, 'local/env_train_steps': 6430720, 'local/optimizer_steps': 10048, 'local/running_reward': 16670.734797297297, 'local/running_step': 2559.405435569498, 'local/steps_done': 6434048, 'local/episodes_done': 1440, 'local/unclipped_grad_norm': 0.4558463301144394, 'local/model_version': 10048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:48,191] {'global/mean_episode_return': 34333.333333333336, 'global/mean_episode_step': 5314.5, 'global/SPS': 3452.7685943031124, 'global/env_act_steps': 6431488, 'global/env_train_steps': 6429440, 'global/optimizer_steps': 10045, 'global/running_reward': 16666.433823529413, 'global/running_step': 2559.023743872549, 'global/steps_done': 6431488, 'global/episodes_done': 1440, 'global/unclipped_grad_norm': 0.4551454889324476, 'global/model_version': 10045, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:58,197] calculate_sps 32640 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:48:58,198] calculate_sps 32000 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:58,199] {'local/mean_episode_return': 37700.0, 'local/mean_episode_step': 5395.25, 'local/SPS': 3261.1660079997637, 'local/env_act_steps': 6467072, 'local/env_train_steps': 6463360, 'local/optimizer_steps': 10099, 'local/running_reward': 16804.953972868218, 'local/running_step': 2583.3977410368216, 'local/steps_done': 6467072, 'local/episodes_done': 1444, 'local/unclipped_grad_norm': 0.43901455563073066, 'local/model_version': 10099, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:48:58,201] {'global/mean_episode_return': 37700.0, 'global/mean_episode_step': 5395.25, 'global/SPS': 3197.221576470357, 'global/env_act_steps': 6465024, 'global/env_train_steps': 6461440, 'global/optimizer_steps': 10096, 'global/running_reward': 16788.263358778626, 'global/running_step': 2580.3714515744273, 'global/steps_done': 6465024, 'global/episodes_done': 1444, 'global/unclipped_grad_norm': 0.45532409043288696, 'global/model_version': 10096, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:08,198] calculate_sps 33920 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:08,198] calculate_sps 33280 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:08,198] {'local/mean_episode_return': 33742.857142857145, 'local/mean_episode_step': 5187.142857142857, 'local/SPS': 3391.920343362374, 'local/env_act_steps': 6499584, 'local/env_train_steps': 6497280, 'local/optimizer_steps': 10152, 'local/running_reward': 17071.844242125986, 'local/running_step': 2625.1107591043306, 'local/steps_done': 6499584, 'local/episodes_done': 1451, 'local/unclipped_grad_norm': 0.49644874936004857, 'local/model_version': 10152, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:08,200] {'global/mean_episode_return': 33366.666666666664, 'global/mean_episode_step': 5151.833333333333, 'global/SPS': 3327.921846317801, 'global/env_act_steps': 6497920, 'global/env_train_steps': 6494720, 'global/optimizer_steps': 10148, 'global/running_reward': 17065.98370622568, 'global/running_step': 2624.397859922179, 'global/steps_done': 6497920, 'global/episodes_done': 1450, 'global/unclipped_grad_norm': 0.49888826075654763, 'global/model_version': 10148, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:18,233] calculate_sps 30720 steps in 10.0358
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:18,234] calculate_sps 33280 steps in 10.0358
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:18,234] {'local/mean_episode_return': 36200.0, 'local/mean_episode_step': 5397.125, 'local/SPS': 3061.0520948232547, 'local/env_act_steps': 6533120, 'local/env_train_steps': 6528000, 'local/optimizer_steps': 10200, 'local/running_reward': 16869.16746183206, 'local/running_step': 2595.5944358301526, 'local/steps_done': 6533120, 'local/episodes_done': 1459, 'local/unclipped_grad_norm': 0.4192002459118764, 'local/model_version': 10200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:18,235] {'global/mean_episode_return': 36177.77777777778, 'global/mean_episode_step': 5397.333333333333, 'global/SPS': 3316.1397693918593, 'global/env_act_steps': 6531072, 'global/env_train_steps': 6528000, 'global/optimizer_steps': 10200, 'global/running_reward': 16895.939913127415, 'global/running_step': 2599.202944015444, 'global/steps_done': 6531072, 'global/episodes_done': 1459, 'global/unclipped_grad_norm': 0.41605931233901244, 'global/model_version': 10200, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:28,246] calculate_sps 35840 steps in 10.0125
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:28,246] calculate_sps 33280 steps in 10.0125
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:28,246] {'local/mean_episode_return': 33920.0, 'local/mean_episode_step': 5291.2, 'local/SPS': 3579.528900168423, 'local/env_act_steps': 6565632, 'local/env_train_steps': 6563840, 'local/optimizer_steps': 10256, 'local/running_reward': 16658.833661417324, 'local/running_step': 2572.333907480315, 'local/steps_done': 6565632, 'local/episodes_done': 1464, 'local/unclipped_grad_norm': 0.5321791420823762, 'local/model_version': 10256, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:28,260] {'global/mean_episode_return': 33920.0, 'global/mean_episode_step': 5291.2, 'global/SPS': 3323.848264442107, 'global/env_act_steps': 6564480, 'global/env_train_steps': 6561280, 'global/optimizer_steps': 10251, 'global/running_reward': 16649.173850574713, 'global/running_step': 2570.6060823754788, 'global/steps_done': 6564480, 'global/episodes_done': 1464, 'global/unclipped_grad_norm': 0.5391719389487716, 'global/model_version': 10251, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:38,264] calculate_sps 30720 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:38,274] calculate_sps 33280 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:38,274] {'local/mean_episode_return': 36257.142857142855, 'local/mean_episode_step': 5396.428571428572, 'local/SPS': 3066.4013353761884, 'local/env_act_steps': 6598528, 'local/env_train_steps': 6594560, 'local/optimizer_steps': 10304, 'local/running_reward': 16798.31590466926, 'local/running_step': 2595.4446133268484, 'local/steps_done': 6598528, 'local/episodes_done': 1471, 'local/unclipped_grad_norm': 0.4685265024503072, 'local/model_version': 10304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:38,276] {'global/mean_episode_return': 36000.0, 'global/mean_episode_step': 5395.833333333333, 'global/SPS': 3321.934779990871, 'global/env_act_steps': 6596992, 'global/env_train_steps': 6594560, 'global/optimizer_steps': 10304, 'global/running_reward': 16803.623277559054, 'global/running_step': 2596.0562869094488, 'global/steps_done': 6596992, 'global/episodes_done': 1470, 'global/unclipped_grad_norm': 0.467802550713971, 'global/model_version': 10304, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:48,310] calculate_sps 33920 steps in 10.0465
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:48,311] calculate_sps 30720 steps in 10.0465
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:48,311] {'local/mean_episode_return': 37066.666666666664, 'local/mean_episode_step': 5397.666666666667, 'local/SPS': 3376.2865938056984, 'local/env_act_steps': 6631040, 'local/env_train_steps': 6628480, 'local/optimizer_steps': 10356, 'local/running_reward': 16778.5187007874, 'local/running_step': 2602.0630536417325, 'local/steps_done': 6631040, 'local/episodes_done': 1474, 'local/unclipped_grad_norm': 0.4208362687092561, 'local/model_version': 10356, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:48,312] {'global/mean_episode_return': 37250.0, 'global/mean_episode_step': 5398.25, 'global/SPS': 3057.7689906164815, 'global/env_act_steps': 6630528, 'global/env_train_steps': 6625280, 'global/optimizer_steps': 10352, 'global/running_reward': 16773.1393129771, 'global/running_step': 2600.947876908397, 'global/steps_done': 6630528, 'global/episodes_done': 1474, 'global/unclipped_grad_norm': 0.42525646431992453, 'global/model_version': 10352, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:58,345] calculate_sps 32640 steps in 10.0343
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:49:58,345] calculate_sps 35840 steps in 10.0343
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:58,345] {'local/mean_episode_return': 34640.0, 'local/mean_episode_step': 5396.8, 'local/SPS': 3252.8461212633556, 'local/env_act_steps': 6664064, 'local/env_train_steps': 6661120, 'local/optimizer_steps': 10408, 'local/running_reward': 17156.9949127907, 'local/running_step': 2665.8266109496126, 'local/steps_done': 6664064, 'local/episodes_done': 1479, 'local/unclipped_grad_norm': 0.5060748902077858, 'local/model_version': 10408, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:49:58,347] {'global/mean_episode_return': 34640.0, 'global/mean_episode_step': 5396.8, 'global/SPS': 3571.7526037401553, 'global/env_act_steps': 6663168, 'global/env_train_steps': 6661120, 'global/optimizer_steps': 10408, 'global/running_reward': 17156.917892156864, 'global/running_step': 2665.743504901961, 'global/steps_done': 6663168, 'global/episodes_done': 1479, 'global/unclipped_grad_norm': 0.4961976781487465, 'global/model_version': 10408, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:08,386] calculate_sps 32000 steps in 10.0417
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:08,386] calculate_sps 30720 steps in 10.0417
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:08,387] {'local/mean_episode_return': 34700.0, 'local/mean_episode_step': 5396.0, 'local/SPS': 3186.7035806931785, 'local/env_act_steps': 6697216, 'local/env_train_steps': 6693120, 'local/optimizer_steps': 10457, 'local/running_reward': 17157.53499034749, 'local/running_step': 2670.2542833011585, 'local/steps_done': 6697216, 'local/episodes_done': 1485, 'local/unclipped_grad_norm': 0.5414966329628107, 'local/model_version': 10457, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:08,388] {'global/mean_episode_return': 34700.0, 'global/mean_episode_step': 5396.0, 'global/SPS': 3059.2354374654515, 'global/env_act_steps': 6696832, 'global/env_train_steps': 6691840, 'global/optimizer_steps': 10456, 'global/running_reward': 17155.89947718631, 'global/running_step': 2669.8470769961978, 'global/steps_done': 6696832, 'global/episodes_done': 1485, 'global/unclipped_grad_norm': 0.5473534033323327, 'global/model_version': 10456, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:18,396] calculate_sps 34560 steps in 10.0091
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:18,396] calculate_sps 35840 steps in 10.0091
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:18,396] {'local/mean_episode_return': 35342.857142857145, 'local/mean_episode_step': 5394.428571428572, 'local/SPS': 3452.8723886539997, 'local/env_act_steps': 6729984, 'local/env_train_steps': 6727680, 'local/optimizer_steps': 10512, 'local/running_reward': 16772.467041015625, 'local/running_step': 2621.7450256347656, 'local/steps_done': 6729984, 'local/episodes_done': 1492, 'local/unclipped_grad_norm': 0.5691472267562693, 'local/model_version': 10512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:18,407] {'global/mean_episode_return': 35342.857142857145, 'global/mean_episode_step': 5394.428571428572, 'global/SPS': 3580.7565511967405, 'global/env_act_steps': 6729472, 'global/env_train_steps': 6727680, 'global/optimizer_steps': 10512, 'global/running_reward': 16774.350490196077, 'global/running_step': 2621.894087009804, 'global/steps_done': 6729472, 'global/episodes_done': 1492, 'global/unclipped_grad_norm': 0.5636333772646529, 'global/model_version': 10512, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:28,412] calculate_sps 30720 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:28,412] calculate_sps 30720 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:28,412] {'local/mean_episode_return': 36300.0, 'local/mean_episode_step': 5398.0, 'local/SPS': 3067.12294060229, 'local/env_act_steps': 6763264, 'local/env_train_steps': 6758400, 'local/optimizer_steps': 10560, 'local/running_reward': 17101.778846153848, 'local/running_step': 2685.3622896634615, 'local/steps_done': 6763264, 'local/episodes_done': 1494, 'local/unclipped_grad_norm': 0.5008767464508613, 'local/model_version': 10560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:28,423] {'global/mean_episode_return': 36300.0, 'global/mean_episode_step': 5398.0, 'global/SPS': 3067.12294060229, 'global/env_act_steps': 6762880, 'global/env_train_steps': 6758400, 'global/optimizer_steps': 10560, 'global/running_reward': 17095.055076628352, 'global/running_step': 2684.106830699234, 'global/steps_done': 6762880, 'global/episodes_done': 1494, 'global/unclipped_grad_norm': 0.5008767464508613, 'global/model_version': 10560, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:38,427] calculate_sps 35840 steps in 10.0158
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:38,428] calculate_sps 35840 steps in 10.0158
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:38,428] {'local/mean_episode_return': 35900.0, 'local/mean_episode_step': 5396.0, 'local/SPS': 3578.3365879602775, 'local/env_act_steps': 6795264, 'local/env_train_steps': 6794240, 'local/optimizer_steps': 10615, 'local/running_reward': 17343.75625, 'local/running_step': 2733.12353125, 'local/steps_done': 6795264, 'local/episodes_done': 1498, 'local/unclipped_grad_norm': 0.4986591951413588, 'local/model_version': 10615, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:38,429] {'global/mean_episode_return': 35900.0, 'global/mean_episode_step': 5396.0, 'global/SPS': 3578.3365879602775, 'global/env_act_steps': 6795264, 'global/env_train_steps': 6794240, 'global/optimizer_steps': 10615, 'global/running_reward': 17343.885869565216, 'global/running_step': 2733.129477519763, 'global/steps_done': 6795264, 'global/episodes_done': 1498, 'global/unclipped_grad_norm': 0.4986591951413588, 'global/model_version': 10615, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:48,443] calculate_sps 30720 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:48,444] calculate_sps 25600 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:48,444] {'local/mean_episode_return': 34654.545454545456, 'local/mean_episode_step': 5369.181818181818, 'local/SPS': 3067.1766767681534, 'local/env_act_steps': 6828800, 'local/env_train_steps': 6824960, 'local/optimizer_steps': 10664, 'local/running_reward': 17266.805820610687, 'local/running_step': 2727.3314646946565, 'local/steps_done': 6828800, 'local/episodes_done': 1509, 'local/unclipped_grad_norm': 0.49882485823971884, 'local/model_version': 10664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:48,445] {'global/mean_episode_return': 34333.333333333336, 'global/mean_episode_step': 5363.222222222223, 'global/SPS': 2555.980563973461, 'global/env_act_steps': 6822016, 'global/env_train_steps': 6819840, 'global/optimizer_steps': 10656, 'global/running_reward': 17333.91148325359, 'global/running_step': 2737.725067284689, 'global/steps_done': 6822016, 'global/episodes_done': 1507, 'global/unclipped_grad_norm': 0.5027552116207961, 'global/model_version': 10656, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:58,455] calculate_sps 32640 steps in 10.0121
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:50:58,455] calculate_sps 30720 steps in 10.0121
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:58,455] {'local/mean_episode_return': 34155.555555555555, 'local/mean_episode_step': 5395.888888888889, 'local/SPS': 3260.0701668825727, 'local/env_act_steps': 6861184, 'local/env_train_steps': 6857600, 'local/optimizer_steps': 10714, 'local/running_reward': 16580.187747035572, 'local/running_step': 2620.9036252470355, 'local/steps_done': 6861184, 'local/episodes_done': 1518, 'local/unclipped_grad_norm': 0.5419221375882626, 'local/model_version': 10714, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:50:58,456] {'global/mean_episode_return': 34300.0, 'global/mean_episode_step': 5396.1, 'global/SPS': 3068.301333536539, 'global/env_act_steps': 6855552, 'global/env_train_steps': 6850560, 'global/optimizer_steps': 10704, 'global/running_reward': 16680.11092557252, 'global/running_step': 2636.198294370229, 'global/steps_done': 6855552, 'global/episodes_done': 1517, 'global/unclipped_grad_norm': 0.528232719283551, 'global/model_version': 10704, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:08,475] calculate_sps 33920 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:08,475] calculate_sps 35840 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:08,476] {'local/mean_episode_return': 34950.0, 'local/mean_episode_step': 5396.0, 'local/SPS': 3385.2352663552865, 'local/env_act_steps': 6893952, 'local/env_train_steps': 6891520, 'local/optimizer_steps': 10768, 'local/running_reward': 16664.593505859375, 'local/running_step': 2640.762481689453, 'local/steps_done': 6893952, 'local/episodes_done': 1522, 'local/unclipped_grad_norm': 0.5594389364123344, 'local/model_version': 10768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:08,477] {'global/mean_episode_return': 35650.0, 'global/mean_episode_step': 5396.25, 'global/SPS': 3576.852356903699, 'global/env_act_steps': 6887936, 'global/env_train_steps': 6886400, 'global/optimizer_steps': 10760, 'global/running_reward': 16629.039031620552, 'global/running_step': 2633.72665513834, 'global/steps_done': 6887936, 'global/episodes_done': 1521, 'global/unclipped_grad_norm': 0.5765381487352508, 'global/model_version': 10760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:18,500] calculate_sps 30720 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:18,500] calculate_sps 30720 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:18,500] {'local/mean_episode_return': 32075.0, 'local/mean_episode_step': 5105.0, 'local/SPS': 3064.46950608438, 'local/env_act_steps': 6926848, 'local/env_train_steps': 6922240, 'local/optimizer_steps': 10816, 'local/running_reward': 16472.805204280157, 'local/running_step': 2612.4280155642023, 'local/steps_done': 6926848, 'local/episodes_done': 1530, 'local/unclipped_grad_norm': 0.49969222489744425, 'local/model_version': 10816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:18,511] {'global/mean_episode_return': 31875.0, 'global/mean_episode_step': 5104.75, 'global/SPS': 3064.46950608438, 'global/env_act_steps': 6921216, 'global/env_train_steps': 6917120, 'global/optimizer_steps': 10808, 'global/running_reward': 16506.06971153846, 'global/running_step': 2617.621213942308, 'global/steps_done': 6921216, 'global/episodes_done': 1529, 'global/unclipped_grad_norm': 0.48226147952179116, 'global/model_version': 10808, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:28,517] calculate_sps 35200 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:28,517] calculate_sps 33920 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:28,525] {'local/mean_episode_return': 35533.333333333336, 'local/mean_episode_step': 5396.111111111111, 'local/SPS': 3519.612149063278, 'local/env_act_steps': 6959104, 'local/env_train_steps': 6957440, 'local/optimizer_steps': 10870, 'local/running_reward': 16449.658978174604, 'local/running_step': 2613.309585813492, 'local/steps_done': 6959104, 'local/episodes_done': 1539, 'local/unclipped_grad_norm': 0.533962503351547, 'local/model_version': 10870, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:28,526] {'global/mean_episode_return': 35533.333333333336, 'global/mean_episode_step': 5396.5, 'global/SPS': 3391.6262527337044, 'global/env_act_steps': 6953728, 'global/env_train_steps': 6951040, 'global/optimizer_steps': 10861, 'global/running_reward': 16490.889517716536, 'global/running_step': 2618.9057886318897, 'global/steps_done': 6953728, 'global/episodes_done': 1535, 'global/unclipped_grad_norm': 0.5230894847860876, 'global/model_version': 10861, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:38,522] calculate_sps 31360 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:38,523] calculate_sps 32640 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:38,523] {'local/mean_episode_return': 35000.0, 'local/mean_episode_step': 5397.166666666667, 'local/SPS': 3129.416688882267, 'local/env_act_steps': 6992384, 'local/env_train_steps': 6988800, 'local/optimizer_steps': 10920, 'local/running_reward': 16053.653846153846, 'local/running_step': 2557.766376201923, 'local/steps_done': 6992384, 'local/episodes_done': 1545, 'local/unclipped_grad_norm': 0.5496766024827957, 'local/model_version': 10920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:38,524] {'global/mean_episode_return': 35175.0, 'global/mean_episode_step': 5395.625, 'global/SPS': 3257.1479823060326, 'global/env_act_steps': 6987136, 'global/env_train_steps': 6983680, 'global/optimizer_steps': 10912, 'global/running_reward': 16084.94372605364, 'global/running_step': 2561.4663852969347, 'global/steps_done': 6987136, 'global/episodes_done': 1543, 'global/unclipped_grad_norm': 0.5779896846004561, 'global/model_version': 10912, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:48,530] calculate_sps 32640 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:48,531] calculate_sps 32640 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:48,531] {'local/mean_episode_return': 34200.0, 'local/mean_episode_step': 5397.0, 'local/SPS': 3261.425651096562, 'local/env_act_steps': 7025152, 'local/env_train_steps': 7021440, 'local/optimizer_steps': 10971, 'local/running_reward': 15756.927490234375, 'local/running_step': 2514.3304138183594, 'local/steps_done': 7025152, 'local/episodes_done': 1551, 'local/unclipped_grad_norm': 0.46125402622947503, 'local/model_version': 10971, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:48,532] {'global/mean_episode_return': 34475.0, 'global/mean_episode_step': 5397.625, 'global/SPS': 3261.425651096562, 'global/env_act_steps': 7019904, 'global/env_train_steps': 7016320, 'global/optimizer_steps': 10962, 'global/running_reward': 15769.04296875, 'global/running_step': 2516.231170654297, 'global/steps_done': 7019904, 'global/episodes_done': 1551, 'global/unclipped_grad_norm': 0.4900450409948826, 'global/model_version': 10962, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:58,557] calculate_sps 33920 steps in 10.0271
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:51:58,557] calculate_sps 33920 steps in 10.0271
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:58,557] {'local/mean_episode_return': 32100.0, 'local/mean_episode_step': 5226.0, 'local/SPS': 3382.8246121602583, 'local/env_act_steps': 7057792, 'local/env_train_steps': 7055360, 'local/optimizer_steps': 11024, 'local/running_reward': 16170.361519607843, 'local/running_step': 2575.5489583333333, 'local/steps_done': 7057792, 'local/episodes_done': 1555, 'local/unclipped_grad_norm': 0.47067466785885254, 'local/model_version': 11024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:51:58,558] {'global/mean_episode_return': 32100.0, 'global/mean_episode_step': 5226.0, 'global/SPS': 3382.8246121602583, 'global/env_act_steps': 7052928, 'global/env_train_steps': 7050240, 'global/optimizer_steps': 11016, 'global/running_reward': 16121.57218992248, 'global/running_step': 2568.734859496124, 'global/steps_done': 7052928, 'global/episodes_done': 1555, 'global/unclipped_grad_norm': 0.4433523213697804, 'global/model_version': 11016, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:08,576] calculate_sps 30720 steps in 10.0195
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:08,577] calculate_sps 31360 steps in 10.0195
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:08,577] {'local/mean_episode_return': 35500.0, 'local/mean_episode_step': 5396.5, 'local/SPS': 3066.0124984327763, 'local/env_act_steps': 7091328, 'local/env_train_steps': 7086080, 'local/optimizer_steps': 11072, 'local/running_reward': 16555.945849236643, 'local/running_step': 2632.766966841603, 'local/steps_done': 7091328, 'local/episodes_done': 1559, 'local/unclipped_grad_norm': 0.5092048281803727, 'local/model_version': 11072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:08,578] {'global/mean_episode_return': 35500.0, 'global/mean_episode_step': 5396.5, 'global/SPS': 3129.8877588167925, 'global/env_act_steps': 7086336, 'global/env_train_steps': 7081600, 'global/optimizer_steps': 11064, 'global/running_reward': 16510.488505747126, 'global/running_step': 2625.997066570881, 'global/steps_done': 7086336, 'global/episodes_done': 1559, 'global/unclipped_grad_norm': 0.5132442774871985, 'global/model_version': 11064, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:18,581] calculate_sps 35840 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:18,582] calculate_sps 35200 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:18,582] {'local/mean_episode_return': 34280.0, 'local/mean_episode_step': 5359.2, 'local/SPS': 3582.201769393573, 'local/env_act_steps': 7123328, 'local/env_train_steps': 7121920, 'local/optimizer_steps': 11128, 'local/running_reward': 16751.45625, 'local/running_step': 2663.03625, 'local/steps_done': 7123328, 'local/episodes_done': 1564, 'local/unclipped_grad_norm': 0.40333693141915966, 'local/model_version': 11128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:18,583] {'global/mean_episode_return': 34280.0, 'global/mean_episode_step': 5359.2, 'global/SPS': 3518.233880654402, 'global/env_act_steps': 7118720, 'global/env_train_steps': 7116800, 'global/optimizer_steps': 11120, 'global/running_reward': 16727.58769762846, 'global/running_step': 2659.7691761363635, 'global/steps_done': 7118720, 'global/episodes_done': 1564, 'global/unclipped_grad_norm': 0.4178975662216544, 'global/model_version': 11120, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:28,583] calculate_sps 30720 steps in 10.0018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:28,584] calculate_sps 30720 steps in 10.0018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:28,594] {'local/mean_episode_return': 35100.0, 'local/mean_episode_step': 5397.75, 'local/SPS': 3071.438481562695, 'local/env_act_steps': 7156736, 'local/env_train_steps': 7152640, 'local/optimizer_steps': 11176, 'local/running_reward': 16921.563697318008, 'local/running_step': 2685.4257064176245, 'local/steps_done': 7156736, 'local/episodes_done': 1567, 'local/unclipped_grad_norm': 0.41584390262141824, 'local/model_version': 11176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:28,596] {'global/mean_episode_return': 35100.0, 'global/mean_episode_step': 5397.75, 'global/SPS': 3071.438481562695, 'global/env_act_steps': 7152512, 'global/env_train_steps': 7147520, 'global/optimizer_steps': 11168, 'global/running_reward': 16862.38162878788, 'global/running_step': 2676.8171164772725, 'global/steps_done': 7152512, 'global/episodes_done': 1567, 'global/unclipped_grad_norm': 0.37373018187160295, 'global/model_version': 11168, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:38,602] calculate_sps 33280 steps in 10.0193
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:38,603] calculate_sps 35200 steps in 10.0193
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:38,603] {'local/mean_episode_return': 34950.0, 'local/mean_episode_step': 5396.75, 'local/SPS': 3321.5909977470237, 'local/env_act_steps': 7188992, 'local/env_train_steps': 7185920, 'local/optimizer_steps': 11227, 'local/running_reward': 17424.71478174603, 'local/running_step': 2755.288132440476, 'local/steps_done': 7188992, 'local/episodes_done': 1571, 'local/unclipped_grad_norm': 0.3925427854353306, 'local/model_version': 11227, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:38,604] {'global/mean_episode_return': 34950.0, 'global/mean_episode_step': 5396.75, 'global/SPS': 3513.2212476170444, 'global/env_act_steps': 7184384, 'global/env_train_steps': 7182720, 'global/optimizer_steps': 11223, 'global/running_reward': 17382.61169678715, 'global/running_step': 2749.5092871485945, 'global/steps_done': 7184384, 'global/episodes_done': 1571, 'global/unclipped_grad_norm': 0.4336666806177659, 'global/model_version': 11223, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:48,624] calculate_sps 33280 steps in 10.0217
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:48,625] calculate_sps 31360 steps in 10.0217
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:48,625] {'local/mean_episode_return': 35750.0, 'local/mean_episode_step': 5397.25, 'local/SPS': 3320.7912225529326, 'local/env_act_steps': 7222272, 'local/env_train_steps': 7219200, 'local/optimizer_steps': 11280, 'local/running_reward': 17786.50841346154, 'local/running_step': 2808.06171875, 'local/steps_done': 7222272, 'local/episodes_done': 1575, 'local/unclipped_grad_norm': 0.4214071757950873, 'local/model_version': 11280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:48,626] {'global/mean_episode_return': 35750.0, 'global/mean_episode_step': 5397.25, 'global/SPS': 3129.2071135594942, 'global/env_act_steps': 7218432, 'global/env_train_steps': 7214080, 'global/optimizer_steps': 11272, 'global/running_reward': 17745.048167293233, 'global/running_step': 2801.9508047462405, 'global/steps_done': 7218432, 'global/episodes_done': 1575, 'global/unclipped_grad_norm': 0.4244750243972759, 'global/model_version': 11272, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:58,634] calculate_sps 31360 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:52:58,634] calculate_sps 35200 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:58,643] {'local/mean_episode_return': 36000.0, 'local/mean_episode_step': 5397.0, 'local/SPS': 3133.506450538644, 'local/env_act_steps': 7255296, 'local/env_train_steps': 7250560, 'local/optimizer_steps': 11328, 'local/running_reward': 18102.02882751938, 'local/running_step': 2851.4609677810076, 'local/steps_done': 7255296, 'local/episodes_done': 1580, 'local/unclipped_grad_norm': 0.5825384485845765, 'local/model_version': 11328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:52:58,644] {'global/mean_episode_return': 36000.0, 'global/mean_episode_step': 5397.0, 'global/SPS': 3517.2011179515393, 'global/env_act_steps': 7250816, 'global/env_train_steps': 7249280, 'global/optimizer_steps': 11326, 'global/running_reward': 18085.579298418972, 'global/running_step': 2849.378705533597, 'global/steps_done': 7250816, 'global/episodes_done': 1580, 'global/unclipped_grad_norm': 0.5489452147373447, 'global/model_version': 11326, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:08,647] calculate_sps 35200 steps in 10.015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:08,647] calculate_sps 31360 steps in 10.015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:08,648] {'local/mean_episode_return': 35142.857142857145, 'local/mean_episode_step': 5397.571428571428, 'local/SPS': 3514.7380793519796, 'local/env_act_steps': 7287552, 'local/env_train_steps': 7285760, 'local/optimizer_steps': 11384, 'local/running_reward': 17905.003720238095, 'local/running_step': 2822.0428447420636, 'local/steps_done': 7287552, 'local/episodes_done': 1587, 'local/unclipped_grad_norm': 0.43358427312757286, 'local/model_version': 11384, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:08,649] {'global/mean_episode_return': 35142.857142857145, 'global/mean_episode_step': 5397.571428571428, 'global/SPS': 3131.3121070590364, 'global/env_act_steps': 7284224, 'global/env_train_steps': 7280640, 'global/optimizer_steps': 11376, 'global/running_reward': 17922.749042145595, 'global/running_step': 2824.297024664751, 'global/steps_done': 7284224, 'global/episodes_done': 1587, 'global/unclipped_grad_norm': 0.4235442873835564, 'global/model_version': 11376, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:18,668] calculate_sps 30720 steps in 10.0211
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:18,669] calculate_sps 35200 steps in 10.0211
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:18,669] {'local/mean_episode_return': 34914.28571428572, 'local/mean_episode_step': 5396.785714285715, 'local/SPS': 3065.526609140121, 'local/env_act_steps': 7321344, 'local/env_train_steps': 7316480, 'local/optimizer_steps': 11432, 'local/running_reward': 17953.284801136364, 'local/running_step': 2836.076260653409, 'local/steps_done': 7321344, 'local/episodes_done': 1595, 'local/unclipped_grad_norm': 0.4135319620060424, 'local/model_version': 11432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:18,670] {'global/mean_episode_return': 35000.0, 'global/mean_episode_step': 5397.375, 'global/SPS': 3512.5825729730554, 'global/env_act_steps': 7317376, 'global/env_train_steps': 7315840, 'global/optimizer_steps': 11430, 'global/running_reward': 17963.845318532818, 'global/running_step': 2837.2557311776063, 'global/steps_done': 7317376, 'global/episodes_done': 1592, 'global/unclipped_grad_norm': 0.42132559984370516, 'global/model_version': 11430, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:28,690] calculate_sps 35840 steps in 10.0221
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:28,691] calculate_sps 31360 steps in 10.0221
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:28,691] {'local/mean_episode_return': 34100.0, 'local/mean_episode_step': 5378.4, 'local/SPS': 3576.09555999585, 'local/env_act_steps': 7353728, 'local/env_train_steps': 7352320, 'local/optimizer_steps': 11488, 'local/running_reward': 17471.955286561264, 'local/running_step': 2763.8331583498025, 'local/steps_done': 7353728, 'local/episodes_done': 1605, 'local/unclipped_grad_norm': 0.39554319410984007, 'local/model_version': 11488, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:28,692] {'global/mean_episode_return': 34261.53846153846, 'global/mean_episode_step': 5382.461538461538, 'global/SPS': 3129.083614996369, 'global/env_act_steps': 7351040, 'global/env_train_steps': 7347200, 'global/optimizer_steps': 11480, 'global/running_reward': 17538.23075095057, 'global/running_step': 2774.2223443441067, 'global/steps_done': 7351040, 'global/episodes_done': 1605, 'global/unclipped_grad_norm': 0.3737430803477764, 'global/model_version': 11480, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:38,701] calculate_sps 30720 steps in 10.0104
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:38,701] calculate_sps 35200 steps in 10.0104
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:38,702] {'local/mean_episode_return': 36333.333333333336, 'local/mean_episode_step': 5396.666666666667, 'local/SPS': 3068.8162424570496, 'local/env_act_steps': 7387520, 'local/env_train_steps': 7383040, 'local/optimizer_steps': 11536, 'local/running_reward': 17288.20430871212, 'local/running_step': 2732.7631096117425, 'local/steps_done': 7387520, 'local/episodes_done': 1608, 'local/unclipped_grad_norm': 0.40701643548284966, 'local/model_version': 11536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:38,703] {'global/mean_episode_return': 36333.333333333336, 'global/mean_episode_step': 5396.666666666667, 'global/SPS': 3516.351944482036, 'global/env_act_steps': 7383936, 'global/env_train_steps': 7382400, 'global/optimizer_steps': 11534, 'global/running_reward': 17247.531614785992, 'global/running_step': 2726.704857733463, 'global/steps_done': 7383936, 'global/episodes_done': 1608, 'global/unclipped_grad_norm': 0.4198534743929351, 'global/model_version': 11534, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:48,725] calculate_sps 34560 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:48,725] calculate_sps 31360 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:48,725] {'local/mean_episode_return': 34400.0, 'local/mean_episode_step': 5396.75, 'local/SPS': 3447.522126800428, 'local/env_act_steps': 7419648, 'local/env_train_steps': 7417600, 'local/optimizer_steps': 11589, 'local/running_reward': 17780.65239043825, 'local/running_step': 2807.7639753486055, 'local/steps_done': 7419648, 'local/episodes_done': 1612, 'local/unclipped_grad_norm': 0.3831803502058083, 'local/model_version': 11589, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:48,726] {'global/mean_episode_return': 34333.333333333336, 'global/mean_episode_step': 5397.0, 'global/SPS': 3128.3071150596475, 'global/env_act_steps': 7417344, 'global/env_train_steps': 7413760, 'global/optimizer_steps': 11584, 'global/running_reward': 17744.88745210728, 'global/running_step': 2802.2187799329504, 'global/steps_done': 7417344, 'global/episodes_done': 1611, 'global/unclipped_grad_norm': 0.3904664443433285, 'global/model_version': 11584, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:58,736] calculate_sps 32000 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:53:58,737] calculate_sps 33280 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:58,737] {'local/mean_episode_return': 35377.77777777778, 'local/mean_episode_step': 5397.555555555556, 'local/SPS': 3196.4389800019608, 'local/env_act_steps': 7452544, 'local/env_train_steps': 7449600, 'local/optimizer_steps': 11640, 'local/running_reward': 17374.276507782102, 'local/running_step': 2749.0928684338523, 'local/steps_done': 7452544, 'local/episodes_done': 1621, 'local/unclipped_grad_norm': 0.3774668843138452, 'local/model_version': 11640, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:53:58,738] {'global/mean_episode_return': 35300.0, 'global/mean_episode_step': 5397.4, 'global/SPS': 3324.296539202039, 'global/env_act_steps': 7450240, 'global/env_train_steps': 7447040, 'global/optimizer_steps': 11635, 'global/running_reward': 17413.98346303502, 'global/running_step': 2754.531523589494, 'global/steps_done': 7450240, 'global/episodes_done': 1621, 'global/unclipped_grad_norm': 0.39216575318691776, 'global/model_version': 11635, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:08,764] calculate_sps 31360 steps in 10.0274
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:08,764] calculate_sps 33280 steps in 10.0274
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:08,764] {'local/mean_episode_return': 32975.0, 'local/mean_episode_step': 5366.625, 'local/SPS': 3127.424364956902, 'local/env_act_steps': 7485568, 'local/env_train_steps': 7480960, 'local/optimizer_steps': 11688, 'local/running_reward': 17469.53730620155, 'local/running_step': 2762.7260477228683, 'local/steps_done': 7485568, 'local/episodes_done': 1629, 'local/unclipped_grad_norm': 0.4129231519376238, 'local/model_version': 11688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:08,765] {'global/mean_episode_return': 32975.0, 'global/mean_episode_step': 5366.625, 'global/SPS': 3318.8993260767124, 'global/env_act_steps': 7483008, 'global/env_train_steps': 7480320, 'global/optimizer_steps': 11688, 'global/running_reward': 17484.088134765625, 'global/running_step': 2765.860565185547, 'global/steps_done': 7483008, 'global/episodes_done': 1629, 'global/unclipped_grad_norm': 0.39421277563526946, 'global/model_version': 11688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:18,796] calculate_sps 35200 steps in 10.0323
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:18,797] calculate_sps 31360 steps in 10.0323
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:18,797] {'local/mean_episode_return': 33960.0, 'local/mean_episode_step': 5372.6, 'local/SPS': 3508.6519981512733, 'local/env_act_steps': 7518080, 'local/env_train_steps': 7516160, 'local/optimizer_steps': 11744, 'local/running_reward': 17346.979576771653, 'local/running_step': 2733.9409756397636, 'local/steps_done': 7518080, 'local/episodes_done': 1634, 'local/unclipped_grad_norm': 0.4588958386863981, 'local/model_version': 11744, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:18,798] {'global/mean_episode_return': 32650.0, 'global/mean_episode_step': 5366.75, 'global/SPS': 3125.8899619893164, 'global/env_act_steps': 7516416, 'global/env_train_steps': 7511680, 'global/optimizer_steps': 11737, 'global/running_reward': 17331.96240421456, 'global/running_step': 2732.0157447318006, 'global/steps_done': 7516416, 'global/episodes_done': 1633, 'global/unclipped_grad_norm': 0.4658242327218153, 'global/model_version': 11737, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:28,807] calculate_sps 30720 steps in 10.0106
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:28,807] calculate_sps 35200 steps in 10.0106
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:28,808] {'local/mean_episode_return': 33640.0, 'local/mean_episode_step': 5276.6, 'local/SPS': 3068.748196754342, 'local/env_act_steps': 7550848, 'local/env_train_steps': 7546880, 'local/optimizer_steps': 11792, 'local/running_reward': 17619.7998046875, 'local/running_step': 2774.4976501464844, 'local/steps_done': 7550848, 'local/episodes_done': 1639, 'local/unclipped_grad_norm': 0.4305632213751475, 'local/model_version': 11792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:28,809] {'global/mean_episode_return': 35850.0, 'global/mean_episode_step': 5397.0, 'global/SPS': 3516.273975447684, 'global/env_act_steps': 7548544, 'global/env_train_steps': 7546880, 'global/optimizer_steps': 11792, 'global/running_reward': 17600.11827689243, 'global/running_step': 2771.711062001992, 'global/steps_done': 7548544, 'global/episodes_done': 1637, 'global/unclipped_grad_norm': 0.42799662161957136, 'global/model_version': 11792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:38,830] calculate_sps 33920 steps in 10.0235
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:38,830] calculate_sps 30720 steps in 10.0235
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:38,830] {'local/mean_episode_return': 35600.0, 'local/mean_episode_step': 5397.0, 'local/SPS': 3384.060298400291, 'local/env_act_steps': 7583360, 'local/env_train_steps': 7580800, 'local/optimizer_steps': 11844, 'local/running_reward': 17416.646161417324, 'local/running_step': 2738.0848302165355, 'local/steps_done': 7583360, 'local/episodes_done': 1645, 'local/unclipped_grad_norm': 0.4109124303437196, 'local/model_version': 11844, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:38,831] {'global/mean_episode_return': 34700.0, 'global/mean_episode_step': 5321.625, 'global/SPS': 3064.8093268530934, 'global/env_act_steps': 7582080, 'global/env_train_steps': 7577600, 'global/optimizer_steps': 11840, 'global/running_reward': 17432.23998091603, 'global/running_step': 2740.663823950382, 'global/steps_done': 7582080, 'global/episodes_done': 1645, 'global/unclipped_grad_norm': 0.411449062017103, 'global/model_version': 11840, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:48,846] calculate_sps 32640 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:48,846] calculate_sps 35200 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:48,846] {'local/mean_episode_return': 33171.42857142857, 'local/mean_episode_step': 5183.428571428572, 'local/SPS': 3259.0025256766335, 'local/env_act_steps': 7616256, 'local/env_train_steps': 7613440, 'local/optimizer_steps': 11896, 'local/running_reward': 17751.0031614786, 'local/running_step': 2789.659107490272, 'local/steps_done': 7616256, 'local/episodes_done': 1652, 'local/unclipped_grad_norm': 0.4139650809363677, 'local/model_version': 11896, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:48,848] {'global/mean_episode_return': 32440.0, 'global/mean_episode_step': 5098.2, 'global/SPS': 3514.610566906173, 'global/env_act_steps': 7614336, 'global/env_train_steps': 7612800, 'global/optimizer_steps': 11894, 'global/running_reward': 17753.038194444445, 'global/running_step': 2789.9133804563494, 'global/steps_done': 7614336, 'global/episodes_done': 1650, 'global/unclipped_grad_norm': 0.4181857358802248, 'global/model_version': 11894, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:58,846] calculate_sps 32000 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:54:58,846] calculate_sps 31360 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:58,846] {'local/mean_episode_return': 32142.85714285714, 'local/mean_episode_step': 5203.142857142857, 'local/SPS': 3199.795926711465, 'local/env_act_steps': 7649536, 'local/env_train_steps': 7645440, 'local/optimizer_steps': 11945, 'local/running_reward': 17448.72596153846, 'local/running_step': 2742.350060096154, 'local/steps_done': 7649536, 'local/episodes_done': 1659, 'local/unclipped_grad_norm': 0.41098272587571827, 'local/model_version': 11945, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:54:58,847] {'global/mean_episode_return': 32777.77777777778, 'global/mean_episode_step': 5246.111111111111, 'global/SPS': 3135.8000081772357, 'global/env_act_steps': 7648512, 'global/env_train_steps': 7644160, 'global/optimizer_steps': 11944, 'global/running_reward': 17458.625936329587, 'global/running_step': 2743.910375702247, 'global/steps_done': 7648512, 'global/episodes_done': 1659, 'global/unclipped_grad_norm': 0.4062049749493599, 'global/model_version': 11944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:08,871] calculate_sps 34560 steps in 10.0245
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:08,871] calculate_sps 35200 steps in 10.0245
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:08,871] {'local/mean_episode_return': 34444.444444444445, 'local/mean_episode_step': 5394.333333333333, 'local/SPS': 3447.5409854546524, 'local/env_act_steps': 7682176, 'local/env_train_steps': 7680000, 'local/optimizer_steps': 12000, 'local/running_reward': 17245.526960784315, 'local/running_step': 2709.50318627451, 'local/steps_done': 7682176, 'local/episodes_done': 1669, 'local/unclipped_grad_norm': 0.4475281177596612, 'local/model_version': 12000, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:08,873] {'global/mean_episode_return': 34444.444444444445, 'global/mean_episode_step': 5394.333333333333, 'global/SPS': 3511.384337037146, 'global/env_act_steps': 7680896, 'global/env_train_steps': 7679360, 'global/optimizer_steps': 11998, 'global/running_reward': 17265.550889328064, 'global/running_step': 2712.5725049407115, 'global/steps_done': 7680896, 'global/episodes_done': 1669, 'global/unclipped_grad_norm': 0.44374991829196614, 'global/model_version': 11998, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:18,872] calculate_sps 30720 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:18,872] calculate_sps 31360 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:18,872] {'local/mean_episode_return': 33680.0, 'local/mean_episode_step': 5283.8, 'local/SPS': 3071.7592717951206, 'local/env_act_steps': 7715328, 'local/env_train_steps': 7710720, 'local/optimizer_steps': 12048, 'local/running_reward': 16982.34194015444, 'local/running_step': 2675.035261824324, 'local/steps_done': 7715328, 'local/episodes_done': 1674, 'local/unclipped_grad_norm': 0.40313225487867993, 'local/model_version': 12048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:18,874] {'global/mean_episode_return': 33680.0, 'global/mean_episode_step': 5283.8, 'global/SPS': 3135.7542566241855, 'global/env_act_steps': 7714304, 'global/env_train_steps': 7710720, 'global/optimizer_steps': 12048, 'global/running_reward': 16978.119013409963, 'global/running_step': 2674.0660021551726, 'global/steps_done': 7714304, 'global/episodes_done': 1674, 'global/unclipped_grad_norm': 0.4078369963169098, 'global/model_version': 12048, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:28,890] calculate_sps 35200 steps in 10.0187
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:28,890] calculate_sps 33280 steps in 10.0187
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:28,890] {'local/mean_episode_return': 34114.28571428572, 'local/mean_episode_step': 5396.285714285715, 'local/SPS': 3513.4279200000897, 'local/env_act_steps': 7747456, 'local/env_train_steps': 7745920, 'local/optimizer_steps': 12102, 'local/running_reward': 16839.91533864542, 'local/running_step': 2654.180092131474, 'local/steps_done': 7747456, 'local/episodes_done': 1681, 'local/unclipped_grad_norm': 0.4004162918362353, 'local/model_version': 12102, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:28,891] {'global/mean_episode_return': 34114.28571428572, 'global/mean_episode_step': 5396.285714285715, 'global/SPS': 3321.786397090994, 'global/env_act_steps': 7747200, 'global/env_train_steps': 7744000, 'global/optimizer_steps': 12100, 'global/running_reward': 16844.905155642024, 'global/running_step': 2655.002401507782, 'global/steps_done': 7747200, 'global/episodes_done': 1681, 'global/unclipped_grad_norm': 0.4008121815725015, 'global/model_version': 12100, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:38,903] calculate_sps 31360 steps in 10.0131
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:38,904] calculate_sps 33280 steps in 10.0131
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:38,904] {'local/mean_episode_return': 34166.666666666664, 'local/mean_episode_step': 5396.166666666667, 'local/SPS': 3131.8997786344385, 'local/env_act_steps': 7780608, 'local/env_train_steps': 7777280, 'local/optimizer_steps': 12152, 'local/running_reward': 16625.452461389963, 'local/running_step': 2622.4083614864867, 'local/steps_done': 7780608, 'local/episodes_done': 1693, 'local/unclipped_grad_norm': 0.38262374728918075, 'local/model_version': 12152, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:38,905] {'global/mean_episode_return': 34166.666666666664, 'global/mean_episode_step': 5396.166666666667, 'global/SPS': 3323.6487446732817, 'global/env_act_steps': 7779968, 'global/env_train_steps': 7777280, 'global/optimizer_steps': 12152, 'global/running_reward': 16638.177490234375, 'global/running_step': 2624.3785400390625, 'global/steps_done': 7779968, 'global/episodes_done': 1693, 'global/unclipped_grad_norm': 0.3829121861893397, 'global/model_version': 12152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:48,947] calculate_sps 33280 steps in 10.0441
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:48,947] calculate_sps 32000 steps in 10.0441
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:48,948] {'local/mean_episode_return': 32857.142857142855, 'local/mean_episode_step': 5380.714285714285, 'local/SPS': 3313.3804720953026, 'local/env_act_steps': 7813632, 'local/env_train_steps': 7810560, 'local/optimizer_steps': 12203, 'local/running_reward': 15958.57558139535, 'local/running_step': 2525.331062257752, 'local/steps_done': 7813632, 'local/episodes_done': 1700, 'local/unclipped_grad_norm': 0.4568917023784974, 'local/model_version': 12203, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:48,948] {'global/mean_episode_return': 32857.142857142855, 'global/mean_episode_step': 5380.714285714285, 'global/SPS': 3185.9427616300986, 'global/env_act_steps': 7813504, 'global/env_train_steps': 7809280, 'global/optimizer_steps': 12201, 'global/running_reward': 15959.291507633588, 'global/running_step': 2525.3470002385498, 'global/steps_done': 7813504, 'global/episodes_done': 1700, 'global/unclipped_grad_norm': 0.44957759885155424, 'global/model_version': 12201, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 11:55:52,115] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 7813632, 'env_train_steps': 7810560, 'optimizer_steps': 12203, 'running_reward': 16340.625, 'running_step': 2581.3515625, 'steps_done': 7813632, 'episodes_done': 1700, 'unclipped_grad_norm': 0.6360872387886047, 'model_version': 12203, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 11:55:52,212] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:58,968] calculate_sps 33280 steps in 10.0206
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:55:58,968] calculate_sps 34560 steps in 10.0206
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:58,969] {'local/mean_episode_return': 32200.0, 'local/mean_episode_step': 5397.333333333333, 'local/SPS': 3321.162970145768, 'local/env_act_steps': 7846016, 'local/env_train_steps': 7843840, 'local/optimizer_steps': 12256, 'local/running_reward': 16147.51111660079, 'local/running_step': 2549.095386610672, 'local/steps_done': 7846016, 'local/episodes_done': 1703, 'local/unclipped_grad_norm': 0.4445663535932325, 'local/model_version': 12256, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:55:58,970] {'global/mean_episode_return': 32200.0, 'global/mean_episode_step': 5397.333333333333, 'global/SPS': 3448.900007459067, 'global/env_act_steps': 7845632, 'global/env_train_steps': 7843840, 'global/optimizer_steps': 12256, 'global/running_reward': 16148.842131474104, 'global/running_step': 2549.307364292829, 'global/steps_done': 7845632, 'global/episodes_done': 1703, 'global/unclipped_grad_norm': 0.4515307494185188, 'global/model_version': 12256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:08,982] calculate_sps 30720 steps in 10.0139
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:08,982] calculate_sps 30720 steps in 10.0139
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:08,983] {'local/mean_episode_return': 34066.666666666664, 'local/mean_episode_step': 5315.666666666667, 'local/SPS': 3067.721737972713, 'local/env_act_steps': 7879552, 'local/env_train_steps': 7874560, 'local/optimizer_steps': 12304, 'local/running_reward': 16574.564646946565, 'local/running_step': 2614.0259720896947, 'local/steps_done': 7879552, 'local/episodes_done': 1709, 'local/unclipped_grad_norm': 0.37237604909266037, 'local/model_version': 12304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:08,984] {'global/mean_episode_return': 34066.666666666664, 'global/mean_episode_step': 5315.666666666667, 'global/SPS': 3067.721737972713, 'global/env_act_steps': 7879424, 'global/env_train_steps': 7874560, 'global/optimizer_steps': 12304, 'global/running_reward': 16571.851325757576, 'global/running_step': 2613.6155303030305, 'global/steps_done': 7879424, 'global/episodes_done': 1709, 'global/unclipped_grad_norm': 0.37237604909266037, 'global/model_version': 12304, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:18,987] calculate_sps 35840 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:18,987] calculate_sps 27520 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:18,987] {'local/mean_episode_return': 35000.0, 'local/mean_episode_step': 5396.5, 'local/SPS': 3582.1986963104277, 'local/env_act_steps': 7911424, 'local/env_train_steps': 7910400, 'local/optimizer_steps': 12359, 'local/running_reward': 16331.275100401606, 'local/running_step': 2580.53874874498, 'local/steps_done': 7911424, 'local/episodes_done': 1717, 'local/unclipped_grad_norm': 0.4146704750982198, 'local/model_version': 12359, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:18,989] {'global/mean_episode_return': 34680.0, 'global/mean_episode_step': 5396.8, 'global/SPS': 2750.616856095507, 'global/env_act_steps': 7905664, 'global/env_train_steps': 7902080, 'global/optimizer_steps': 12346, 'global/running_reward': 16357.210365853658, 'global/running_step': 2584.5834984756098, 'global/steps_done': 7905664, 'global/episodes_done': 1714, 'global/unclipped_grad_norm': 0.40678142099863007, 'global/model_version': 12346, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:28,992] calculate_sps 30720 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:28,993] calculate_sps 33920 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:28,993] {'local/mean_episode_return': 31233.333333333332, 'local/mean_episode_step': 5099.5, 'local/SPS': 3070.4160027154267, 'local/env_act_steps': 7944448, 'local/env_train_steps': 7941120, 'local/optimizer_steps': 12408, 'local/running_reward': 16087.324370155038, 'local/running_step': 2542.806504360465, 'local/steps_done': 7944448, 'local/episodes_done': 1723, 'local/unclipped_grad_norm': 0.3749645761385256, 'local/model_version': 12408, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:28,994] {'global/mean_episode_return': 32550.0, 'global/mean_episode_step': 5173.375, 'global/SPS': 3390.2510029982836, 'global/env_act_steps': 7937920, 'global/env_train_steps': 7936000, 'global/optimizer_steps': 12400, 'global/running_reward': 16092.491319444445, 'global/running_step': 2543.3864397321427, 'global/steps_done': 7937920, 'global/episodes_done': 1722, 'global/unclipped_grad_norm': 0.39253171616130406, 'global/model_version': 12400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:38,995] calculate_sps 32000 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:38,995] calculate_sps 30720 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:39,003] {'local/mean_episode_return': 33933.333333333336, 'local/mean_episode_step': 5396.0, 'local/SPS': 3199.606524218275, 'local/env_act_steps': 7977344, 'local/env_train_steps': 7973120, 'local/optimizer_steps': 12457, 'local/running_reward': 16235.27480544747, 'local/running_step': 2572.4527906128405, 'local/steps_done': 7977344, 'local/episodes_done': 1729, 'local/unclipped_grad_norm': 0.3306081976209368, 'local/model_version': 12457, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:39,005] {'global/mean_episode_return': 34080.0, 'global/mean_episode_step': 5396.4, 'global/SPS': 3071.622263249544, 'global/env_act_steps': 7971456, 'global/env_train_steps': 7966720, 'global/optimizer_steps': 12448, 'global/running_reward': 16220.610687022901, 'global/running_step': 2568.8938752385498, 'global/steps_done': 7971456, 'global/episodes_done': 1727, 'global/unclipped_grad_norm': 0.3534004863662024, 'global/model_version': 12448, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:49,004] calculate_sps 34560 steps in 10.0108
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:49,005] calculate_sps 35840 steps in 10.0108
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:49,005] {'local/mean_episode_return': 32600.0, 'local/mean_episode_step': 5320.25, 'local/SPS': 3452.2626245262177, 'local/env_act_steps': 8009472, 'local/env_train_steps': 8007680, 'local/optimizer_steps': 12512, 'local/running_reward': 16172.273406374503, 'local/running_step': 2564.415400896414, 'local/steps_done': 8009472, 'local/episodes_done': 1733, 'local/unclipped_grad_norm': 0.39755098630081526, 'local/model_version': 12512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:49,006] {'global/mean_episode_return': 32866.666666666664, 'global/mean_episode_step': 5345.5, 'global/SPS': 3580.124203212374, 'global/env_act_steps': 8003584, 'global/env_train_steps': 8002560, 'global/optimizer_steps': 12503, 'global/running_reward': 16156.480328685258, 'global/running_step': 2561.690083416335, 'global/steps_done': 8003584, 'global/episodes_done': 1733, 'global/unclipped_grad_norm': 0.365789872136983, 'global/model_version': 12503, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:59,027] calculate_sps 30720 steps in 10.0224
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:56:59,027] calculate_sps 30720 steps in 10.0224
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:59,027] {'local/mean_episode_return': 35080.0, 'local/mean_episode_step': 5361.6, 'local/SPS': 3065.1350044651163, 'local/env_act_steps': 8043008, 'local/env_train_steps': 8038400, 'local/optimizer_steps': 12560, 'local/running_reward': 16693.320610687024, 'local/running_step': 2642.001938215649, 'local/steps_done': 8043008, 'local/episodes_done': 1738, 'local/unclipped_grad_norm': 0.41768889284382266, 'local/model_version': 12560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:56:59,029] {'global/mean_episode_return': 36200.0, 'global/mean_episode_step': 5399.0, 'global/SPS': 3065.1350044651163, 'global/env_act_steps': 8037632, 'global/env_train_steps': 8033280, 'global/optimizer_steps': 12552, 'global/running_reward': 16625.052866541355, 'global/running_step': 2632.2519384398497, 'global/steps_done': 8037632, 'global/episodes_done': 1736, 'global/unclipped_grad_norm': 0.42254011880378334, 'global/model_version': 12552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:09,039] calculate_sps 35200 steps in 10.0124
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:09,039] calculate_sps 35200 steps in 10.0124
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:09,039] {'local/mean_episode_return': 34833.333333333336, 'local/mean_episode_step': 5395.333333333333, 'local/SPS': 3515.6272421456456, 'local/env_act_steps': 8075136, 'local/env_train_steps': 8073600, 'local/optimizer_steps': 12614, 'local/running_reward': 16684.947709163345, 'local/running_step': 2637.8955117031874, 'local/steps_done': 8075136, 'local/episodes_done': 1744, 'local/unclipped_grad_norm': 0.42409789507035855, 'local/model_version': 12614, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:09,040] {'global/mean_episode_return': 34200.0, 'global/mean_episode_step': 5365.666666666667, 'global/SPS': 3515.6272421456456, 'global/env_act_steps': 8070144, 'global/env_train_steps': 8068480, 'global/optimizer_steps': 12607, 'global/running_reward': 16697.391732283464, 'global/running_step': 2639.942052165354, 'global/steps_done': 8070144, 'global/episodes_done': 1742, 'global/unclipped_grad_norm': 0.41247820095582444, 'global/model_version': 12607, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:19,047] calculate_sps 31360 steps in 10.0081
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:19,048] calculate_sps 31360 steps in 10.0081
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:19,048] {'local/mean_episode_return': 33520.0, 'local/mean_episode_step': 5399.0, 'local/SPS': 3133.4642743015684, 'local/env_act_steps': 8108672, 'local/env_train_steps': 8104960, 'local/optimizer_steps': 12664, 'local/running_reward': 16667.10400763359, 'local/running_step': 2635.132931774809, 'local/steps_done': 8108672, 'local/episodes_done': 1749, 'local/unclipped_grad_norm': 0.4384167206287384, 'local/model_version': 12664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:19,049] {'global/mean_episode_return': 34028.57142857143, 'global/mean_episode_step': 5397.714285714285, 'global/SPS': 3133.4642743015684, 'global/env_act_steps': 8103680, 'global/env_train_steps': 8099840, 'global/optimizer_steps': 12656, 'global/running_reward': 16657.03125, 'global/running_step': 2633.983897900763, 'global/steps_done': 8103680, 'global/episodes_done': 1749, 'global/unclipped_grad_norm': 0.415901925490827, 'global/model_version': 12656, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:29,093] calculate_sps 33920 steps in 10.046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:29,093] calculate_sps 35200 steps in 10.046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:29,093] {'local/mean_episode_return': 26133.333333333332, 'local/mean_episode_step': 4496.666666666667, 'local/SPS': 3376.4572666464387, 'local/env_act_steps': 8141440, 'local/env_train_steps': 8138880, 'local/optimizer_steps': 12716, 'local/running_reward': 16931.329345703125, 'local/running_step': 2676.461212158203, 'local/steps_done': 8141440, 'local/episodes_done': 1752, 'local/unclipped_grad_norm': 0.3759930652494614, 'local/model_version': 12716, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:29,094] {'global/mean_episode_return': 26133.333333333332, 'global/mean_episode_step': 4496.666666666667, 'global/SPS': 3503.8707484066817, 'global/env_act_steps': 8136576, 'global/env_train_steps': 8135040, 'global/optimizer_steps': 12710, 'global/running_reward': 16859.05885214008, 'global/running_step': 2665.006809338521, 'global/steps_done': 8136576, 'global/episodes_done': 1752, 'global/unclipped_grad_norm': 0.41715596864620846, 'global/model_version': 12710, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:39,100] calculate_sps 32640 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:39,100] calculate_sps 31360 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:39,100] {'local/mean_episode_return': 34133.333333333336, 'local/mean_episode_step': 5325.0, 'local/SPS': 3261.809986328483, 'local/env_act_steps': 8174464, 'local/env_train_steps': 8171520, 'local/optimizer_steps': 12768, 'local/running_reward': 17145.91206395349, 'local/running_step': 2711.11839874031, 'local/steps_done': 8174464, 'local/episodes_done': 1758, 'local/unclipped_grad_norm': 0.42509006436627644, 'local/model_version': 12768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:39,102] {'global/mean_episode_return': 34133.333333333336, 'global/mean_episode_step': 5325.0, 'global/SPS': 3133.895869217562, 'global/env_act_steps': 8170112, 'global/env_train_steps': 8166400, 'global/optimizer_steps': 12760, 'global/running_reward': 17145.908874045803, 'global/running_step': 2710.5341722328244, 'global/steps_done': 8170112, 'global/episodes_done': 1758, 'global/unclipped_grad_norm': 0.40890787199139594, 'global/model_version': 12760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:49,127] calculate_sps 31360 steps in 10.027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:49,127] calculate_sps 33920 steps in 10.027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:49,127] {'local/mean_episode_return': 33366.666666666664, 'local/mean_episode_step': 5229.75, 'local/SPS': 3127.5592592841817, 'local/env_act_steps': 8207616, 'local/env_train_steps': 8202880, 'local/optimizer_steps': 12817, 'local/running_reward': 16982.420366795366, 'local/running_step': 2687.462566361004, 'local/steps_done': 8207616, 'local/episodes_done': 1770, 'local/unclipped_grad_norm': 0.4003847946926039, 'local/model_version': 12817, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:49,128] {'global/mean_episode_return': 33600.0, 'global/mean_episode_step': 5214.909090909091, 'global/SPS': 3382.870219225748, 'global/env_act_steps': 8202880, 'global/env_train_steps': 8200320, 'global/optimizer_steps': 12812, 'global/running_reward': 17071.551513671875, 'global/running_step': 2701.2108154296875, 'global/steps_done': 8202880, 'global/episodes_done': 1769, 'global/unclipped_grad_norm': 0.4233826814362636, 'global/model_version': 12812, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:59,154] calculate_sps 35200 steps in 10.0273
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:57:59,155] calculate_sps 32640 steps in 10.0273
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:59,155] {'local/mean_episode_return': 32350.0, 'local/mean_episode_step': 5181.0, 'local/SPS': 3510.427037855081, 'local/env_act_steps': 8239872, 'local/env_train_steps': 8238080, 'local/optimizer_steps': 12872, 'local/running_reward': 16286.619543650793, 'local/running_step': 2580.144500248016, 'local/steps_done': 8239872, 'local/episodes_done': 1778, 'local/unclipped_grad_norm': 0.42729043527082966, 'local/model_version': 12872, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:57:59,156] {'global/mean_episode_return': 33400.0, 'global/mean_episode_step': 5395.375, 'global/SPS': 3255.123253283802, 'global/env_act_steps': 8236032, 'global/env_train_steps': 8232960, 'global/optimizer_steps': 12864, 'global/running_reward': 16324.070945945947, 'global/running_step': 2585.9886281370655, 'global/steps_done': 8236032, 'global/episodes_done': 1777, 'global/unclipped_grad_norm': 0.4312084589440089, 'global/model_version': 12864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:09,156] calculate_sps 30720 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:09,156] calculate_sps 32640 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:09,157] {'local/mean_episode_return': 35500.0, 'local/mean_episode_step': 5394.75, 'local/SPS': 3071.5570951149166, 'local/env_act_steps': 8273408, 'local/env_train_steps': 8268800, 'local/optimizer_steps': 12920, 'local/running_reward': 16439.688692748092, 'local/running_step': 2602.8239503816794, 'local/steps_done': 8273408, 'local/episodes_done': 1782, 'local/unclipped_grad_norm': 0.3574357784042756, 'local/model_version': 12920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:09,158] {'global/mean_episode_return': 31900.0, 'global/mean_episode_step': 4965.75, 'global/SPS': 3263.5294135595987, 'global/env_act_steps': 8269184, 'global/env_train_steps': 8265600, 'global/optimizer_steps': 12914, 'global/running_reward': 16395.680501930503, 'global/running_step': 2596.2717784749034, 'global/steps_done': 8269184, 'global/episodes_done': 1781, 'global/unclipped_grad_norm': 0.34854223012924196, 'global/model_version': 12914, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:19,185] calculate_sps 35840 steps in 10.0294
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:19,185] calculate_sps 33920 steps in 10.0294
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:19,185] {'local/mean_episode_return': 35000.0, 'local/mean_episode_step': 5366.25, 'local/SPS': 3573.5039975292298, 'local/env_act_steps': 8305664, 'local/env_train_steps': 8304640, 'local/optimizer_steps': 12975, 'local/running_reward': 16272.922867063493, 'local/running_step': 2575.0205853174602, 'local/steps_done': 8305664, 'local/episodes_done': 1790, 'local/unclipped_grad_norm': 0.5160010341893543, 'local/model_version': 12975, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:19,186] {'global/mean_episode_return': 35200.0, 'global/mean_episode_step': 5369.333333333333, 'global/SPS': 3382.0662833758784, 'global/env_act_steps': 8302592, 'global/env_train_steps': 8299520, 'global/optimizer_steps': 12968, 'global/running_reward': 16319.92337164751, 'global/running_step': 2582.597222222222, 'global/steps_done': 8302592, 'global/episodes_done': 1790, 'global/unclipped_grad_norm': 0.5084796420953892, 'global/model_version': 12968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:29,205] calculate_sps 30720 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:29,205] calculate_sps 32000 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:29,206] {'local/mean_episode_return': 34771.42857142857, 'local/mean_episode_step': 5396.142857142857, 'local/SPS': 3065.8792848130747, 'local/env_act_steps': 8339072, 'local/env_train_steps': 8335360, 'local/optimizer_steps': 13024, 'local/running_reward': 16382.471264367816, 'local/running_step': 2589.926664272031, 'local/steps_done': 8339072, 'local/episodes_done': 1797, 'local/unclipped_grad_norm': 0.3618600021819679, 'local/model_version': 13024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:29,207] {'global/mean_episode_return': 33680.0, 'global/mean_episode_step': 5395.6, 'global/SPS': 3193.6242550136194, 'global/env_act_steps': 8335616, 'global/env_train_steps': 8331520, 'global/optimizer_steps': 13017, 'global/running_reward': 16397.34132751938, 'global/running_step': 2591.7369791666665, 'global/steps_done': 8335616, 'global/episodes_done': 1795, 'global/unclipped_grad_norm': 0.38413375296763014, 'global/model_version': 13017, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:39,225] calculate_sps 32000 steps in 10.0201
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:39,225] calculate_sps 34560 steps in 10.0201
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:39,225] {'local/mean_episode_return': 33150.0, 'local/mean_episode_step': 5165.5, 'local/SPS': 3193.570150887204, 'local/env_act_steps': 8371456, 'local/env_train_steps': 8367360, 'local/optimizer_steps': 13073, 'local/running_reward': 16087.197381422924, 'local/running_step': 2553.0008028656125, 'local/steps_done': 8371456, 'local/episodes_done': 1805, 'local/unclipped_grad_norm': 0.4024970706324188, 'local/model_version': 13073, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:39,226] {'global/mean_episode_return': 33375.0, 'global/mean_episode_step': 5166.125, 'global/SPS': 3449.0557629581804, 'global/env_act_steps': 8367744, 'global/env_train_steps': 8366080, 'global/optimizer_steps': 13072, 'global/running_reward': 16095.928784860558, 'global/running_step': 2554.20437001992, 'global/steps_done': 8367744, 'global/episodes_done': 1803, 'global/unclipped_grad_norm': 0.38135044181888755, 'global/model_version': 13072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:49,259] calculate_sps 34560 steps in 10.0335
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:49,259] calculate_sps 30720 steps in 10.0335
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:49,259] {'local/mean_episode_return': 33933.333333333336, 'local/mean_episode_step': 5396.666666666667, 'local/SPS': 3444.474411826083, 'local/env_act_steps': 8404096, 'local/env_train_steps': 8401920, 'local/optimizer_steps': 13128, 'local/running_reward': 15722.34681372549, 'local/running_step': 2497.0688112745097, 'local/steps_done': 8404096, 'local/episodes_done': 1811, 'local/unclipped_grad_norm': 0.39190185489979656, 'local/model_version': 13128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:49,261] {'global/mean_episode_return': 34600.0, 'global/mean_episode_step': 5396.25, 'global/SPS': 3061.7550327342956, 'global/env_act_steps': 8401536, 'global/env_train_steps': 8396800, 'global/optimizer_steps': 13120, 'global/running_reward': 15748.052793560606, 'global/running_step': 2500.647668087121, 'global/steps_done': 8401536, 'global/episodes_done': 1811, 'global/unclipped_grad_norm': 0.38357228273525834, 'global/model_version': 13120, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:59,280] calculate_sps 30720 steps in 10.0218
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:58:59,281] calculate_sps 35840 steps in 10.0218
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:59,281] {'local/mean_episode_return': 35600.0, 'local/mean_episode_step': 5397.25, 'local/SPS': 3065.311688190267, 'local/env_act_steps': 8437504, 'local/env_train_steps': 8432640, 'local/optimizer_steps': 13176, 'local/running_reward': 16046.785201149425, 'local/running_step': 2553.869492337165, 'local/steps_done': 8437504, 'local/episodes_done': 1815, 'local/unclipped_grad_norm': 0.38418502764155466, 'local/model_version': 13176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:58:59,283] {'global/mean_episode_return': 35600.0, 'global/mean_episode_step': 5397.25, 'global/SPS': 3576.196969555311, 'global/env_act_steps': 8433792, 'global/env_train_steps': 8432640, 'global/optimizer_steps': 13176, 'global/running_reward': 16023.828125, 'global/running_step': 2549.896949404762, 'global/steps_done': 8433792, 'global/episodes_done': 1815, 'global/unclipped_grad_norm': 0.3971699329891375, 'global/model_version': 13176, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:09,284] calculate_sps 35840 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:09,285] calculate_sps 30720 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:09,285] {'local/mean_episode_return': 34200.0, 'local/mean_episode_step': 5395.0, 'local/SPS': 3582.438754129726, 'local/env_act_steps': 8469504, 'local/env_train_steps': 8468480, 'local/optimizer_steps': 13231, 'local/running_reward': 16379.54375, 'local/running_step': 2609.0015, 'local/steps_done': 8469504, 'local/episodes_done': 1819, 'local/unclipped_grad_norm': 0.41221136396581476, 'local/model_version': 13231, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:09,286] {'global/mean_episode_return': 34200.0, 'global/mean_episode_step': 5395.0, 'global/SPS': 3070.6617892540507, 'global/env_act_steps': 8467584, 'global/env_train_steps': 8463360, 'global/optimizer_steps': 13224, 'global/running_reward': 16352.40293560606, 'global/running_step': 2604.5346531723485, 'global/steps_done': 8467584, 'global/episodes_done': 1819, 'global/unclipped_grad_norm': 0.4051095802957813, 'global/model_version': 13224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:19,288] calculate_sps 30720 steps in 10.0028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:19,288] calculate_sps 35200 steps in 10.0028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:19,288] {'local/mean_episode_return': 34640.0, 'local/mean_episode_step': 5395.6, 'local/SPS': 3071.1325448212983, 'local/env_act_steps': 8503040, 'local/env_train_steps': 8499200, 'local/optimizer_steps': 13280, 'local/running_reward': 16580.25405534351, 'local/running_step': 2640.2179448950383, 'local/steps_done': 8503040, 'local/episodes_done': 1824, 'local/unclipped_grad_norm': 0.3673235663041777, 'local/model_version': 13280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:19,290] {'global/mean_episode_return': 34640.0, 'global/mean_episode_step': 5395.6, 'global/SPS': 3519.0060409410708, 'global/env_act_steps': 8500224, 'global/env_train_steps': 8498560, 'global/optimizer_steps': 13278, 'global/running_reward': 16571.513480392157, 'global/running_step': 2638.651256127451, 'global/steps_done': 8500224, 'global/episodes_done': 1824, 'global/unclipped_grad_norm': 0.3708839208163597, 'global/model_version': 13278, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:29,297] calculate_sps 33280 steps in 10.0088
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:29,297] calculate_sps 31360 steps in 10.0088
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:29,297] {'local/mean_episode_return': 36600.0, 'local/mean_episode_step': 5393.666666666667, 'local/SPS': 3325.0734498149545, 'local/env_act_steps': 8535680, 'local/env_train_steps': 8532480, 'local/optimizer_steps': 13332, 'local/running_reward': 16660.226715686276, 'local/running_step': 2659.129871323529, 'local/steps_done': 8535680, 'local/episodes_done': 1827, 'local/unclipped_grad_norm': 0.3988050680894118, 'local/model_version': 13332, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:29,298] {'global/mean_episode_return': 36600.0, 'global/mean_episode_step': 5393.666666666667, 'global/SPS': 3133.242289248707, 'global/env_act_steps': 8533760, 'global/env_train_steps': 8529920, 'global/optimizer_steps': 13328, 'global/running_reward': 16635.388835877864, 'global/running_step': 2654.523318225191, 'global/steps_done': 8533760, 'global/episodes_done': 1827, 'global/unclipped_grad_norm': 0.41630024790763853, 'global/model_version': 13328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:39,319] calculate_sps 33280 steps in 10.0227
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:39,319] calculate_sps 33920 steps in 10.0227
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:39,320] {'local/mean_episode_return': 31433.333333333332, 'local/mean_episode_step': 4995.0, 'local/SPS': 3320.4689243133084, 'local/env_act_steps': 8568320, 'local/env_train_steps': 8565760, 'local/optimizer_steps': 13384, 'local/running_reward': 17001.74019607843, 'local/running_step': 2723.3008578431372, 'local/steps_done': 8568320, 'local/episodes_done': 1833, 'local/unclipped_grad_norm': 0.42004871425720364, 'local/model_version': 13384, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:39,321] {'global/mean_episode_return': 31433.333333333332, 'global/mean_episode_step': 4995.0, 'global/SPS': 3384.3240959347186, 'global/env_act_steps': 8566400, 'global/env_train_steps': 8563840, 'global/optimizer_steps': 13380, 'global/running_reward': 17006.11519607843, 'global/running_step': 2723.5015625, 'global/steps_done': 8566400, 'global/episodes_done': 1833, 'global/unclipped_grad_norm': 0.41257631664092725, 'global/model_version': 13380, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:49,322] calculate_sps 30720 steps in 10.0025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:49,322] calculate_sps 32640 steps in 10.0025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:49,322] {'local/mean_episode_return': 35133.333333333336, 'local/mean_episode_step': 5396.666666666667, 'local/SPS': 3071.2424964040447, 'local/env_act_steps': 8601344, 'local/env_train_steps': 8596480, 'local/optimizer_steps': 13432, 'local/running_reward': 17207.237160852714, 'local/running_step': 2759.5911458333335, 'local/steps_done': 8601344, 'local/episodes_done': 1836, 'local/unclipped_grad_norm': 0.4303611973300576, 'local/model_version': 13432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:49,323] {'global/mean_episode_return': 35133.333333333336, 'global/mean_episode_step': 5396.666666666667, 'global/SPS': 3263.195152429297, 'global/env_act_steps': 8599424, 'global/env_train_steps': 8596480, 'global/optimizer_steps': 13432, 'global/running_reward': 17184.920058139534, 'global/running_step': 2755.6863493217056, 'global/steps_done': 8599424, 'global/episodes_done': 1836, 'global/unclipped_grad_norm': 0.42627387465192723, 'global/model_version': 13432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:59,324] calculate_sps 35840 steps in 10.0024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 11:59:59,324] calculate_sps 32000 steps in 10.0024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:59,324] {'local/mean_episode_return': 30850.0, 'local/mean_episode_step': 4937.25, 'local/SPS': 3583.1381101514503, 'local/env_act_steps': 8633344, 'local/env_train_steps': 8632320, 'local/optimizer_steps': 13487, 'local/running_reward': 17382.4875, 'local/running_step': 2788.8094375, 'local/steps_done': 8633344, 'local/episodes_done': 1844, 'local/unclipped_grad_norm': 0.36217865022746, 'local/model_version': 13487, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 11:59:59,325] {'global/mean_episode_return': 30850.0, 'global/mean_episode_step': 4937.25, 'global/SPS': 3199.230455492366, 'global/env_act_steps': 8632704, 'global/env_train_steps': 8628480, 'global/optimizer_steps': 13482, 'global/running_reward': 17383.377403846152, 'global/running_step': 2789.197355769231, 'global/steps_done': 8632704, 'global/episodes_done': 1844, 'global/unclipped_grad_norm': 0.3388001221418381, 'global/model_version': 13482, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:09,336] calculate_sps 30720 steps in 10.012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:09,336] calculate_sps 34560 steps in 10.012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:09,337] {'local/mean_episode_return': 34625.0, 'local/mean_episode_step': 5285.625, 'local/SPS': 3068.3147046595423, 'local/env_act_steps': 8666240, 'local/env_train_steps': 8663040, 'local/optimizer_steps': 13536, 'local/running_reward': 17053.16755836576, 'local/running_step': 2734.9712731031127, 'local/steps_done': 8666240, 'local/episodes_done': 1852, 'local/unclipped_grad_norm': 0.3982806114517913, 'local/model_version': 13536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:09,338] {'global/mean_episode_return': 34625.0, 'global/mean_episode_step': 5285.625, 'global/SPS': 3451.854042741985, 'global/env_act_steps': 8664832, 'global/env_train_steps': 8663040, 'global/optimizer_steps': 13536, 'global/running_reward': 17054.92405378486, 'global/running_step': 2735.2403510956174, 'global/steps_done': 8664832, 'global/episodes_done': 1852, 'global/unclipped_grad_norm': 0.4165846225288179, 'global/model_version': 13536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:19,353] calculate_sps 33280 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:19,353] calculate_sps 30720 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:19,353] {'local/mean_episode_return': 34600.0, 'local/mean_episode_step': 5396.5, 'local/SPS': 3322.329003746647, 'local/env_act_steps': 8699392, 'local/env_train_steps': 8696320, 'local/optimizer_steps': 13587, 'local/running_reward': 17137.216457528957, 'local/running_step': 2750.8991916023165, 'local/steps_done': 8699392, 'local/episodes_done': 1856, 'local/unclipped_grad_norm': 0.4821870265638127, 'local/model_version': 13587, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:19,354] {'global/mean_episode_return': 34600.0, 'global/mean_episode_step': 5396.5, 'global/SPS': 3066.7652342276742, 'global/env_act_steps': 8698880, 'global/env_train_steps': 8693760, 'global/optimizer_steps': 13584, 'global/running_reward': 17130.034069548874, 'global/running_step': 2749.6702890037595, 'global/steps_done': 8698880, 'global/episodes_done': 1856, 'global/unclipped_grad_norm': 0.48147236586858827, 'global/model_version': 13584, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:29,391] calculate_sps 33280 steps in 10.0376
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:29,391] calculate_sps 35840 steps in 10.0376
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:29,391] {'local/mean_episode_return': 33640.0, 'local/mean_episode_step': 5305.7, 'local/SPS': 3315.530115230617, 'local/env_act_steps': 8732288, 'local/env_train_steps': 8729600, 'local/optimizer_steps': 13640, 'local/running_reward': 16806.961332684827, 'local/running_step': 2704.6106213521402, 'local/steps_done': 8732288, 'local/episodes_done': 1866, 'local/unclipped_grad_norm': 0.44287558223279017, 'local/model_version': 13640, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:29,393] {'global/mean_episode_return': 33640.0, 'global/mean_episode_step': 5305.7, 'global/SPS': 3570.5708933252795, 'global/env_act_steps': 8731264, 'global/env_train_steps': 8729600, 'global/optimizer_steps': 13640, 'global/running_reward': 16817.687747035572, 'global/running_step': 2706.1872838438735, 'global/steps_done': 8731264, 'global/episodes_done': 1866, 'global/unclipped_grad_norm': 0.4455941187750016, 'global/model_version': 13640, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:39,395] calculate_sps 30720 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:39,395] calculate_sps 30720 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:39,395] {'local/mean_episode_return': 33200.0, 'local/mean_episode_step': 5189.875, 'local/SPS': 3070.7120636314535, 'local/env_act_steps': 8765568, 'local/env_train_steps': 8760320, 'local/optimizer_steps': 13688, 'local/running_reward': 16660.576923076922, 'local/running_step': 2679.171844951923, 'local/steps_done': 8765568, 'local/episodes_done': 1871, 'local/unclipped_grad_norm': 0.4769344702363014, 'local/model_version': 13688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:39,397] {'global/mean_episode_return': 33200.0, 'global/mean_episode_step': 5189.875, 'global/SPS': 3070.7120636314535, 'global/env_act_steps': 8764672, 'global/env_train_steps': 8760320, 'global/optimizer_steps': 13688, 'global/running_reward': 16652.8436302682, 'global/running_step': 2677.920168821839, 'global/steps_done': 8764672, 'global/episodes_done': 1871, 'global/unclipped_grad_norm': 0.4769344702363014, 'global/model_version': 13688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:49,400] calculate_sps 35840 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:49,401] calculate_sps 35200 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:49,401] {'local/mean_episode_return': 33480.0, 'local/mean_episode_step': 5175.8, 'local/SPS': 3582.1266510941564, 'local/env_act_steps': 8797824, 'local/env_train_steps': 8796160, 'local/optimizer_steps': 13744, 'local/running_reward': 17035.038442460318, 'local/running_step': 2740.6847098214284, 'local/steps_done': 8797824, 'local/episodes_done': 1876, 'local/unclipped_grad_norm': 0.4724593596266849, 'local/model_version': 13744, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:49,402] {'global/mean_episode_return': 33480.0, 'global/mean_episode_step': 5175.8, 'global/SPS': 3518.1601037531896, 'global/env_act_steps': 8797184, 'global/env_train_steps': 8795520, 'global/optimizer_steps': 13743, 'global/running_reward': 17029.527559055117, 'global/running_step': 2739.8914862204724, 'global/steps_done': 8797184, 'global/episodes_done': 1876, 'global/unclipped_grad_norm': 0.4653331526301124, 'global/model_version': 13743, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:59,421] calculate_sps 30720 steps in 10.0206
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:00:59,421] calculate_sps 31360 steps in 10.0206
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:59,421] {'local/mean_episode_return': 35675.0, 'local/mean_episode_step': 5396.875, 'local/SPS': 3065.684154325122, 'local/env_act_steps': 8831232, 'local/env_train_steps': 8826880, 'local/optimizer_steps': 13792, 'local/running_reward': 16774.70665708812, 'local/running_step': 2704.902328783525, 'local/steps_done': 8831232, 'local/episodes_done': 1884, 'local/unclipped_grad_norm': 0.4536794535815716, 'local/model_version': 13792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:00:59,423] {'global/mean_episode_return': 35675.0, 'global/mean_episode_step': 5396.875, 'global/SPS': 3129.5525742068953, 'global/env_act_steps': 8830592, 'global/env_train_steps': 8826880, 'global/optimizer_steps': 13792, 'global/running_reward': 16785.72198275862, 'global/running_step': 2706.5293342911878, 'global/steps_done': 8830592, 'global/episodes_done': 1884, 'global/unclipped_grad_norm': 0.46206152074191037, 'global/model_version': 13792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:09,424] calculate_sps 34560 steps in 10.0035
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:09,424] calculate_sps 34560 steps in 10.0035
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:09,425] {'local/mean_episode_return': 32457.14285714286, 'local/mean_episode_step': 5397.571428571428, 'local/SPS': 3454.8023560939405, 'local/env_act_steps': 8863488, 'local/env_train_steps': 8861440, 'local/optimizer_steps': 13845, 'local/running_reward': 17033.358134920636, 'local/running_step': 2741.8421378968255, 'local/steps_done': 8863488, 'local/episodes_done': 1891, 'local/unclipped_grad_norm': 0.44578048614960797, 'local/model_version': 13845, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:09,425] {'global/mean_episode_return': 32457.14285714286, 'global/mean_episode_step': 5397.571428571428, 'global/SPS': 3454.8023560939405, 'global/env_act_steps': 8863488, 'global/env_train_steps': 8861440, 'global/optimizer_steps': 13845, 'global/running_reward': 17025.887645914398, 'global/running_step': 2740.717199659533, 'global/steps_done': 8863488, 'global/episodes_done': 1891, 'global/unclipped_grad_norm': 0.44578048614960797, 'global/model_version': 13845, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:19,449] calculate_sps 32000 steps in 10.0253
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:19,450] calculate_sps 26880 steps in 10.0253
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:19,450] {'local/mean_episode_return': 33200.0, 'local/mean_episode_step': 5288.5, 'local/SPS': 3191.936720293475, 'local/env_act_steps': 8896384, 'local/env_train_steps': 8893440, 'local/optimizer_steps': 13896, 'local/running_reward': 16970.37329766537, 'local/running_step': 2718.579584143969, 'local/steps_done': 8896384, 'local/episodes_done': 1895, 'local/unclipped_grad_norm': 0.4637092404505786, 'local/model_version': 13896, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:19,451] {'global/mean_episode_return': 34300.0, 'global/mean_episode_step': 5399.5, 'global/SPS': 2681.226845046519, 'global/env_act_steps': 8889856, 'global/env_train_steps': 8888320, 'global/optimizer_steps': 13888, 'global/running_reward': 16922.299757281555, 'global/running_step': 2712.644379550971, 'global/steps_done': 8889856, 'global/episodes_done': 1893, 'global/unclipped_grad_norm': 0.43624937430370686, 'global/model_version': 13888, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:29,458] calculate_sps 31360 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:29,458] calculate_sps 30720 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:29,459] {'local/mean_episode_return': 35550.0, 'local/mean_episode_step': 5396.5, 'local/SPS': 3133.906920086089, 'local/env_act_steps': 8929536, 'local/env_train_steps': 8924800, 'local/optimizer_steps': 13944, 'local/running_reward': 17174.776785714286, 'local/running_step': 2749.066722972973, 'local/steps_done': 8929536, 'local/episodes_done': 1899, 'local/unclipped_grad_norm': 0.3935175407677889, 'local/model_version': 13944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:29,460] {'global/mean_episode_return': 34240.0, 'global/mean_episode_step': 5309.2, 'global/SPS': 3069.949636002699, 'global/env_act_steps': 8923392, 'global/env_train_steps': 8919040, 'global/optimizer_steps': 13936, 'global/running_reward': 17153.983778625956, 'global/running_step': 2744.643606870229, 'global/steps_done': 8923392, 'global/episodes_done': 1898, 'global/unclipped_grad_norm': 0.4386945854251583, 'global/model_version': 13936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:39,472] calculate_sps 35200 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:39,472] calculate_sps 35840 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:39,473] {'local/mean_episode_return': 33666.666666666664, 'local/mean_episode_step': 5397.333333333333, 'local/SPS': 3514.398150378663, 'local/env_act_steps': 8962048, 'local/env_train_steps': 8960000, 'local/optimizer_steps': 14000, 'local/running_reward': 17213.884104330707, 'local/running_step': 2754.564314714567, 'local/steps_done': 8962048, 'local/episodes_done': 1905, 'local/unclipped_grad_norm': 0.3667268459019916, 'local/model_version': 14000, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:39,474] {'global/mean_episode_return': 33885.71428571428, 'global/mean_episode_step': 5397.0, 'global/SPS': 3578.296298567366, 'global/env_act_steps': 8955904, 'global/env_train_steps': 8954880, 'global/optimizer_steps': 13991, 'global/running_reward': 17213.287401574802, 'global/running_step': 2755.2995201771655, 'global/steps_done': 8955904, 'global/episodes_done': 1905, 'global/unclipped_grad_norm': 0.36731779155406086, 'global/model_version': 13991, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:49,488] calculate_sps 30720 steps in 10.0155
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:49,488] calculate_sps 30720 steps in 10.0155
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:49,488] {'local/mean_episode_return': 31866.666666666668, 'local/mean_episode_step': 5270.333333333333, 'local/SPS': 3067.250201991331, 'local/env_act_steps': 8994688, 'local/env_train_steps': 8990720, 'local/optimizer_steps': 14048, 'local/running_reward': 17582.285539215685, 'local/running_step': 2803.506954656863, 'local/steps_done': 8994688, 'local/episodes_done': 1911, 'local/unclipped_grad_norm': 0.402222137277325, 'local/model_version': 14048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:49,490] {'global/mean_episode_return': 32500.0, 'global/mean_episode_step': 5394.5, 'global/SPS': 3067.250201991331, 'global/env_act_steps': 8989184, 'global/env_train_steps': 8985600, 'global/optimizer_steps': 14040, 'global/running_reward': 17510.138221153848, 'global/running_step': 2794.4877403846153, 'global/steps_done': 8989184, 'global/episodes_done': 1907, 'global/unclipped_grad_norm': 0.3919495961495808, 'global/model_version': 14040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:59,514] calculate_sps 33920 steps in 10.027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:01:59,514] calculate_sps 33280 steps in 10.027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:59,515] {'local/mean_episode_return': 29900.0, 'local/mean_episode_step': 5007.2, 'local/SPS': 3382.851236241327, 'local/env_act_steps': 9027200, 'local/env_train_steps': 9024640, 'local/optimizer_steps': 14100, 'local/running_reward': 17132.4187992126, 'local/running_step': 2720.179779773622, 'local/steps_done': 9027200, 'local/episodes_done': 1921, 'local/unclipped_grad_norm': 0.36969663116794366, 'local/model_version': 14100, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:01:59,516] {'global/mean_episode_return': 31016.666666666668, 'global/mean_episode_step': 5119.5, 'global/SPS': 3319.023854425453, 'global/env_act_steps': 9022080, 'global/env_train_steps': 9018880, 'global/optimizer_steps': 14092, 'global/running_reward': 17222.37354085603, 'global/running_step': 2735.8607125486383, 'global/steps_done': 9022080, 'global/episodes_done': 1919, 'global/unclipped_grad_norm': 0.3699276146407311, 'global/model_version': 14092, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:09,526] calculate_sps 32640 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:09,527] calculate_sps 33280 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:09,527] {'local/mean_episode_return': 35825.0, 'local/mean_episode_step': 5395.5, 'local/SPS': 3260.187629159751, 'local/env_act_steps': 9059968, 'local/env_train_steps': 9057280, 'local/optimizer_steps': 14152, 'local/running_reward': 16945.660400390625, 'local/running_step': 2689.6356201171875, 'local/steps_done': 9059968, 'local/episodes_done': 1929, 'local/unclipped_grad_norm': 0.43394824833824086, 'local/model_version': 14152, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:09,528] {'global/mean_episode_return': 33960.0, 'global/mean_episode_step': 5263.5, 'global/SPS': 3324.112876790334, 'global/env_act_steps': 9055104, 'global/env_train_steps': 9052160, 'global/optimizer_steps': 14144, 'global/running_reward': 17007.37039728682, 'global/running_step': 2698.493156492248, 'global/steps_done': 9055104, 'global/episodes_done': 1929, 'global/unclipped_grad_norm': 0.43054687031186545, 'global/model_version': 14144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:19,563] calculate_sps 31360 steps in 10.0368
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:19,563] calculate_sps 32000 steps in 10.0368
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:19,564] {'local/mean_episode_return': 33683.333333333336, 'local/mean_episode_step': 5126.75, 'local/SPS': 3124.494291488909, 'local/env_act_steps': 9093248, 'local/env_train_steps': 9088640, 'local/optimizer_steps': 14200, 'local/running_reward': 16514.77764423077, 'local/running_step': 2629.9982872596156, 'local/steps_done': 9093248, 'local/episodes_done': 1936, 'local/unclipped_grad_norm': 0.3985233792724709, 'local/model_version': 14200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:19,565] {'global/mean_episode_return': 33683.333333333336, 'global/mean_episode_step': 5126.75, 'global/SPS': 3188.259481111131, 'global/env_act_steps': 9088256, 'global/env_train_steps': 9084160, 'global/optimizer_steps': 14193, 'global/running_reward': 16530.32697876448, 'global/running_step': 2631.538429054054, 'global/steps_done': 9088256, 'global/episodes_done': 1936, 'global/unclipped_grad_norm': 0.4288286347778476, 'global/model_version': 14193, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:29,580] calculate_sps 35200 steps in 10.017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:29,580] calculate_sps 34560 steps in 10.017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:29,581] {'local/mean_episode_return': 34966.666666666664, 'local/mean_episode_step': 5396.5, 'local/SPS': 3514.0340316448355, 'local/env_act_steps': 9125632, 'local/env_train_steps': 9123840, 'local/optimizer_steps': 14256, 'local/running_reward': 16478.761116600792, 'local/running_step': 2625.4504384881425, 'local/steps_done': 9125632, 'local/episodes_done': 1942, 'local/unclipped_grad_norm': 0.4752750540418284, 'local/model_version': 14256, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:29,582] {'global/mean_episode_return': 34966.666666666664, 'global/mean_episode_step': 5396.5, 'global/SPS': 3450.1425037967474, 'global/env_act_steps': 9121280, 'global/env_train_steps': 9118720, 'global/optimizer_steps': 14248, 'global/running_reward': 16479.275678294573, 'global/running_step': 2625.799176356589, 'global/steps_done': 9121280, 'global/episodes_done': 1942, 'global/unclipped_grad_norm': 0.44524102387103165, 'global/model_version': 14248, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:39,595] calculate_sps 30720 steps in 10.0149
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:39,595] calculate_sps 30720 steps in 10.0149
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:39,606] {'local/mean_episode_return': 32853.333333333336, 'local/mean_episode_step': 5181.733333333334, 'local/SPS': 3067.4431950903013, 'local/env_act_steps': 9158272, 'local/env_train_steps': 9154560, 'local/optimizer_steps': 14304, 'local/running_reward': 16224.987745098038, 'local/running_step': 2581.8511029411766, 'local/steps_done': 9158272, 'local/episodes_done': 1957, 'local/unclipped_grad_norm': 0.3810930180673798, 'local/model_version': 14304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:39,608] {'global/mean_episode_return': 33384.61538461538, 'global/mean_episode_step': 5249.076923076923, 'global/SPS': 3067.4431950903013, 'global/env_act_steps': 9154432, 'global/env_train_steps': 9149440, 'global/optimizer_steps': 14296, 'global/running_reward': 16337.9041988417, 'global/running_step': 2599.3349722490348, 'global/steps_done': 9154432, 'global/episodes_done': 1955, 'global/unclipped_grad_norm': 0.3690362147366007, 'global/model_version': 14296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:49,619] calculate_sps 33280 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:49,620] calculate_sps 35840 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:49,620] {'local/mean_episode_return': 34320.0, 'local/mean_episode_step': 5395.8, 'local/SPS': 3319.73742891748, 'local/env_act_steps': 9190912, 'local/env_train_steps': 9187840, 'local/optimizer_steps': 14355, 'local/running_reward': 15621.936274509804, 'local/running_step': 2492.851225490196, 'local/steps_done': 9190912, 'local/episodes_done': 1962, 'local/unclipped_grad_norm': 0.3730761721438053, 'local/model_version': 14355, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:49,621] {'global/mean_episode_return': 32914.28571428572, 'global/mean_episode_step': 5209.571428571428, 'global/SPS': 3575.101846526517, 'global/env_act_steps': 9186432, 'global/env_train_steps': 9185280, 'global/optimizer_steps': 14352, 'global/running_reward': 15629.275, 'global/running_step': 2494.0256875, 'global/steps_done': 9186432, 'global/episodes_done': 1962, 'global/unclipped_grad_norm': 0.3899678167487894, 'global/model_version': 14352, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:59,620] calculate_sps 33280 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:02:59,621] calculate_sps 30720 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:59,621] {'local/mean_episode_return': 34850.0, 'local/mean_episode_step': 5311.75, 'local/SPS': 3327.789350492345, 'local/env_act_steps': 9223808, 'local/env_train_steps': 9221120, 'local/optimizer_steps': 14408, 'local/running_reward': 15917.765077821012, 'local/running_step': 2535.4189263132293, 'local/steps_done': 9223808, 'local/episodes_done': 1966, 'local/unclipped_grad_norm': 0.4017848167217003, 'local/model_version': 14408, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:02:59,631] {'global/mean_episode_return': 33066.666666666664, 'global/mean_episode_step': 5284.0, 'global/SPS': 3071.805554300626, 'global/env_act_steps': 9220480, 'global/env_train_steps': 9216000, 'global/optimizer_steps': 14400, 'global/running_reward': 15868.315319548872, 'global/running_step': 2528.047814849624, 'global/steps_done': 9220480, 'global/episodes_done': 1965, 'global/unclipped_grad_norm': 0.388321530384322, 'global/model_version': 14400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:09,631] calculate_sps 30720 steps in 10.0101
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:09,631] calculate_sps 35200 steps in 10.0101
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:09,631] {'local/mean_episode_return': 34440.0, 'local/mean_episode_step': 5206.0, 'local/SPS': 3068.88582614583, 'local/env_act_steps': 9256960, 'local/env_train_steps': 9251840, 'local/optimizer_steps': 14456, 'local/running_reward': 16244.130067567568, 'local/running_step': 2583.5591216216217, 'local/steps_done': 9256960, 'local/episodes_done': 1972, 'local/unclipped_grad_norm': 0.3860006889638801, 'local/model_version': 14456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:09,632] {'global/mean_episode_return': 35266.666666666664, 'global/mean_episode_step': 5079.0, 'global/SPS': 3516.4316757920965, 'global/env_act_steps': 9252736, 'global/env_train_steps': 9251200, 'global/optimizer_steps': 14454, 'global/running_reward': 16238.355654761905, 'global/running_step': 2583.1275731646824, 'global/steps_done': 9252736, 'global/episodes_done': 1968, 'global/unclipped_grad_norm': 0.40707958365480107, 'global/model_version': 14454, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:19,631] calculate_sps 35840 steps in 10.0007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:19,632] calculate_sps 31360 steps in 10.0007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:19,632] {'local/mean_episode_return': 35157.142857142855, 'local/mean_episode_step': 5397.857142857143, 'local/SPS': 3583.7392279595438, 'local/env_act_steps': 9289088, 'local/env_train_steps': 9287680, 'local/optimizer_steps': 14512, 'local/running_reward': 16009.511952191235, 'local/running_step': 2546.9827564741036, 'local/steps_done': 9289088, 'local/episodes_done': 1980, 'local/unclipped_grad_norm': 0.4150431120236005, 'local/model_version': 14512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:19,633] {'global/mean_episode_return': 35737.5, 'global/mean_episode_step': 5397.125, 'global/SPS': 3135.7718244646007, 'global/env_act_steps': 9286528, 'global/env_train_steps': 9282560, 'global/optimizer_steps': 14504, 'global/running_reward': 16029.018702651516, 'global/running_step': 2549.9596058238635, 'global/steps_done': 9286528, 'global/episodes_done': 1978, 'global/unclipped_grad_norm': 0.41774250254034995, 'global/model_version': 14504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:29,640] calculate_sps 30720 steps in 10.0084
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:29,640] calculate_sps 34560 steps in 10.0084
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:29,640] {'local/mean_episode_return': 31885.714285714286, 'local/mean_episode_step': 5238.285714285715, 'local/SPS': 3069.432153110016, 'local/env_act_steps': 9322752, 'local/env_train_steps': 9318400, 'local/optimizer_steps': 14560, 'local/running_reward': 15732.46791825095, 'local/running_step': 2499.3429479562737, 'local/steps_done': 9322752, 'local/episodes_done': 1987, 'local/unclipped_grad_norm': 0.38549455379446346, 'local/model_version': 14560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:29,642] {'global/mean_episode_return': 32250.0, 'global/mean_episode_step': 5258.875, 'global/SPS': 3453.111172248768, 'global/env_act_steps': 9319296, 'global/env_train_steps': 9317120, 'global/optimizer_steps': 14558, 'global/running_reward': 15743.3837890625, 'global/running_step': 2501.05517578125, 'global/steps_done': 9319296, 'global/episodes_done': 1986, 'global/unclipped_grad_norm': 0.38372410530293427, 'global/model_version': 14558, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:39,669] calculate_sps 34560 steps in 10.0292
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:39,669] calculate_sps 32000 steps in 10.0292
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:39,669] {'local/mean_episode_return': 33400.0, 'local/mean_episode_step': 5196.0, 'local/SPS': 3445.9349678284243, 'local/env_act_steps': 9355008, 'local/env_train_steps': 9352960, 'local/optimizer_steps': 14613, 'local/running_reward': 15688.082837301587, 'local/running_step': 2495.7981460813494, 'local/steps_done': 9355008, 'local/episodes_done': 1992, 'local/unclipped_grad_norm': 0.4592998592921023, 'local/model_version': 14613, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:39,670] {'global/mean_episode_return': 33166.666666666664, 'global/mean_episode_step': 5228.833333333333, 'global/SPS': 3190.6805257670594, 'global/env_act_steps': 9352704, 'global/env_train_steps': 9349120, 'global/optimizer_steps': 14608, 'global/running_reward': 15692.013888888889, 'global/running_step': 2495.9766822318006, 'global/steps_done': 9352704, 'global/episodes_done': 1992, 'global/unclipped_grad_norm': 0.4605600172281265, 'global/model_version': 14608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:49,680] calculate_sps 32000 steps in 10.0112
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:49,681] calculate_sps 33920 steps in 10.0112
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:49,681] {'local/mean_episode_return': 32900.0, 'local/mean_episode_step': 5191.0, 'local/SPS': 3196.404724462367, 'local/env_act_steps': 9388160, 'local/env_train_steps': 9384960, 'local/optimizer_steps': 14664, 'local/running_reward': 15751.5625, 'local/running_step': 2505.390082046332, 'local/steps_done': 9388160, 'local/episodes_done': 1998, 'local/unclipped_grad_norm': 0.4054335209668851, 'local/model_version': 14664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:49,682] {'global/mean_episode_return': 32900.0, 'global/mean_episode_step': 5191.0, 'global/SPS': 3388.1890079301093, 'global/env_act_steps': 9385600, 'global/env_train_steps': 9383040, 'global/optimizer_steps': 14660, 'global/running_reward': 15745.65296692607, 'global/running_step': 2504.6953125, 'global/steps_done': 9385600, 'global/episodes_done': 1998, 'global/unclipped_grad_norm': 0.38517988903018147, 'global/model_version': 14660, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:59,692] calculate_sps 32000 steps in 10.012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:03:59,692] calculate_sps 32640 steps in 10.012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:59,692] {'local/mean_episode_return': 32500.0, 'local/mean_episode_step': 5094.833333333333, 'local/SPS': 3196.1735568289137, 'local/env_act_steps': 9421056, 'local/env_train_steps': 9416960, 'local/optimizer_steps': 14713, 'local/running_reward': 16100.310068093386, 'local/running_step': 2556.035505836576, 'local/steps_done': 9421056, 'local/episodes_done': 2004, 'local/unclipped_grad_norm': 0.4079137027871852, 'local/model_version': 14713, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:03:59,693] {'global/mean_episode_return': 32500.0, 'global/mean_episode_step': 5094.833333333333, 'global/SPS': 3260.0970279654916, 'global/env_act_steps': 9419008, 'global/env_train_steps': 9415680, 'global/optimizer_steps': 14712, 'global/running_reward': 16091.139846743295, 'global/running_step': 2554.997186302682, 'global/steps_done': 9419008, 'global/episodes_done': 2004, 'global/unclipped_grad_norm': 0.42968110654216546, 'global/model_version': 14712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:09,707] calculate_sps 34560 steps in 10.0146
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:09,707] calculate_sps 32640 steps in 10.0146
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:09,707] {'local/mean_episode_return': 34000.0, 'local/mean_episode_step': 5398.5, 'local/SPS': 3450.9678267657087, 'local/env_act_steps': 9453568, 'local/env_train_steps': 9451520, 'local/optimizer_steps': 14768, 'local/running_reward': 16277.971210629921, 'local/running_step': 2583.985543799213, 'local/steps_done': 9453568, 'local/episodes_done': 2006, 'local/unclipped_grad_norm': 0.36621153327551753, 'local/model_version': 14768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:09,709] {'global/mean_episode_return': 34000.0, 'global/mean_episode_step': 5398.5, 'global/SPS': 3259.2473919453914, 'global/env_act_steps': 9451904, 'global/env_train_steps': 9448320, 'global/optimizer_steps': 14762, 'global/running_reward': 16247.373540856031, 'global/running_step': 2579.021491974708, 'global/steps_done': 9451904, 'global/episodes_done': 2006, 'global/unclipped_grad_norm': 0.361343714594841, 'global/model_version': 14762, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:19,737] calculate_sps 30720 steps in 10.0304
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:19,737] calculate_sps 33920 steps in 10.0304
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:19,738] {'local/mean_episode_return': 32800.0, 'local/mean_episode_step': 5301.166666666667, 'local/SPS': 3062.704336465817, 'local/env_act_steps': 9487104, 'local/env_train_steps': 9482240, 'local/optimizer_steps': 14816, 'local/running_reward': 16443.046278625956, 'local/running_step': 2608.84231870229, 'local/steps_done': 9487104, 'local/episodes_done': 2012, 'local/unclipped_grad_norm': 0.35053040863325197, 'local/model_version': 14816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:19,739] {'global/mean_episode_return': 32800.0, 'global/mean_episode_step': 5301.166666666667, 'global/SPS': 3381.7360381810063, 'global/env_act_steps': 9484928, 'global/env_train_steps': 9482240, 'global/optimizer_steps': 14816, 'global/running_reward': 16439.462209302324, 'global/running_step': 2608.3781492248063, 'global/steps_done': 9484928, 'global/episodes_done': 2012, 'global/unclipped_grad_norm': 0.355166291197141, 'global/model_version': 14816, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:29,763] calculate_sps 35200 steps in 10.0264
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:29,763] calculate_sps 30720 steps in 10.0264
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:29,764] {'local/mean_episode_return': 31466.666666666668, 'local/mean_episode_step': 5054.833333333333, 'local/SPS': 3510.7142729755556, 'local/env_act_steps': 9518976, 'local/env_train_steps': 9517440, 'local/optimizer_steps': 14870, 'local/running_reward': 16753.488955823294, 'local/running_step': 2657.4796686746986, 'local/steps_done': 9518976, 'local/episodes_done': 2018, 'local/unclipped_grad_norm': 0.41609785540236366, 'local/model_version': 14870, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:29,765] {'global/mean_episode_return': 31466.666666666668, 'global/mean_episode_step': 5054.833333333333, 'global/SPS': 3063.8960927786666, 'global/env_act_steps': 9518208, 'global/env_train_steps': 9512960, 'global/optimizer_steps': 14864, 'global/running_reward': 16743.876201923078, 'global/running_step': 2656.06953125, 'global/steps_done': 9518208, 'global/episodes_done': 2018, 'global/unclipped_grad_norm': 0.40035545639693737, 'global/model_version': 14864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:39,766] calculate_sps 31360 steps in 10.0028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:39,767] calculate_sps 35840 steps in 10.0028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:39,778] {'local/mean_episode_return': 30900.0, 'local/mean_episode_step': 5019.4, 'local/SPS': 3135.107224447994, 'local/env_act_steps': 9552384, 'local/env_train_steps': 9548800, 'local/optimizer_steps': 14920, 'local/running_reward': 16642.8280651341, 'local/running_step': 2636.7871168582374, 'local/steps_done': 9552384, 'local/episodes_done': 2024, 'local/unclipped_grad_norm': 0.4046841034293175, 'local/model_version': 14920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:39,780] {'global/mean_episode_return': 30900.0, 'global/mean_episode_step': 5019.4, 'global/SPS': 3582.979685083422, 'global/env_act_steps': 9550592, 'global/env_train_steps': 9548800, 'global/optimizer_steps': 14920, 'global/running_reward': 16639.896245059288, 'global/running_step': 2636.202785326087, 'global/steps_done': 9550592, 'global/episodes_done': 2024, 'global/unclipped_grad_norm': 0.4194004902882235, 'global/model_version': 14920, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:49,805] calculate_sps 33280 steps in 10.0391
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:49,805] calculate_sps 30720 steps in 10.0391
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:49,805] {'local/mean_episode_return': 34955.555555555555, 'local/mean_episode_step': 5396.666666666667, 'local/SPS': 3315.0457024402294, 'local/env_act_steps': 9585152, 'local/env_train_steps': 9582080, 'local/optimizer_steps': 14971, 'local/running_reward': 16720.39794921875, 'local/running_step': 2648.363037109375, 'local/steps_done': 9585152, 'local/episodes_done': 2033, 'local/unclipped_grad_norm': 0.42821074496297273, 'local/model_version': 14971, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:49,806] {'global/mean_episode_return': 34955.555555555555, 'global/mean_episode_step': 5396.666666666667, 'global/SPS': 3060.042186867904, 'global/env_act_steps': 9584384, 'global/env_train_steps': 9579520, 'global/optimizer_steps': 14968, 'global/running_reward': 16728.264086174244, 'global/running_step': 2649.7163233901515, 'global/steps_done': 9584384, 'global/episodes_done': 2033, 'global/unclipped_grad_norm': 0.42964207598318654, 'global/model_version': 14968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:59,817] calculate_sps 33280 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:04:59,817] calculate_sps 35840 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:59,818] {'local/mean_episode_return': 33733.333333333336, 'local/mean_episode_step': 5257.888888888889, 'local/SPS': 3324.099261247174, 'local/env_act_steps': 9617664, 'local/env_train_steps': 9615360, 'local/optimizer_steps': 15024, 'local/running_reward': 16060.362327755905, 'local/running_step': 2550.5302042322833, 'local/steps_done': 9617664, 'local/episodes_done': 2042, 'local/unclipped_grad_norm': 0.38973834210971614, 'local/model_version': 15024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:04:59,819] {'global/mean_episode_return': 33750.0, 'global/mean_episode_step': 5297.125, 'global/SPS': 3579.7992044200337, 'global/env_act_steps': 9616384, 'global/env_train_steps': 9615360, 'global/optimizer_steps': 15023, 'global/running_reward': 16069.640625, 'global/running_step': 2551.81309375, 'global/steps_done': 9616384, 'global/episodes_done': 2041, 'global/unclipped_grad_norm': 0.39311168410561304, 'global/model_version': 15023, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:09,828] calculate_sps 30720 steps in 10.0114
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:09,829] calculate_sps 30720 steps in 10.0114
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:09,829] {'local/mean_episode_return': 32550.0, 'local/mean_episode_step': 5320.0, 'local/SPS': 3068.511047081106, 'local/env_act_steps': 9650944, 'local/env_train_steps': 9646080, 'local/optimizer_steps': 15072, 'local/running_reward': 16057.178485576924, 'local/running_step': 2555.2373497596154, 'local/steps_done': 9650944, 'local/episodes_done': 2046, 'local/unclipped_grad_norm': 0.4241295851146181, 'local/model_version': 15072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:09,830] {'global/mean_episode_return': 32760.0, 'global/mean_episode_step': 5244.8, 'global/SPS': 3068.511047081106, 'global/env_act_steps': 9650048, 'global/env_train_steps': 9646080, 'global/optimizer_steps': 15072, 'global/running_reward': 16048.048360266159, 'global/running_step': 2553.807182747148, 'global/steps_done': 9650048, 'global/episodes_done': 2046, 'global/unclipped_grad_norm': 0.4205946517842157, 'global/model_version': 15072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:19,846] calculate_sps 34560 steps in 10.0177
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:19,846] calculate_sps 32640 steps in 10.0177
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:19,846] {'local/mean_episode_return': 31533.333333333332, 'local/mean_episode_step': 5046.444444444444, 'local/SPS': 3449.897397815382, 'local/env_act_steps': 9682688, 'local/env_train_steps': 9680640, 'local/optimizer_steps': 15125, 'local/running_reward': 16000.126008064517, 'local/running_step': 2541.705141129032, 'local/steps_done': 9682688, 'local/episodes_done': 2055, 'local/unclipped_grad_norm': 0.40720094965313963, 'local/model_version': 15125, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:19,847] {'global/mean_episode_return': 31533.333333333332, 'global/mean_episode_step': 5046.444444444444, 'global/SPS': 3258.236431270083, 'global/env_act_steps': 9682432, 'global/env_train_steps': 9678720, 'global/optimizer_steps': 15122, 'global/running_reward': 16009.047677865612, 'global/running_step': 2543.144145256917, 'global/steps_done': 9682432, 'global/episodes_done': 2055, 'global/unclipped_grad_norm': 0.4169132015109062, 'global/model_version': 15122, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:29,874] calculate_sps 32000 steps in 10.0272
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:29,874] calculate_sps 33920 steps in 10.0272
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:29,874] {'local/mean_episode_return': 33271.42857142857, 'local/mean_episode_step': 5198.642857142857, 'local/SPS': 3191.3049709922066, 'local/env_act_steps': 9715584, 'local/env_train_steps': 9712640, 'local/optimizer_steps': 15176, 'local/running_reward': 15912.642874513618, 'local/running_step': 2525.847610651751, 'local/steps_done': 9715584, 'local/episodes_done': 2064, 'local/unclipped_grad_norm': 0.40125205733028113, 'local/model_version': 15176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:29,876] {'global/mean_episode_return': 33271.42857142857, 'global/mean_episode_step': 5198.642857142857, 'global/SPS': 3382.7832692517386, 'global/env_act_steps': 9714816, 'global/env_train_steps': 9712640, 'global/optimizer_steps': 15176, 'global/running_reward': 15921.56929347826, 'global/running_step': 2527.136610671937, 'global/steps_done': 9714816, 'global/episodes_done': 2064, 'global/unclipped_grad_norm': 0.3925897255539894, 'global/model_version': 15176, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:39,919] calculate_sps 32000 steps in 10.0463
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:39,920] calculate_sps 30720 steps in 10.0463
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:39,920] {'local/mean_episode_return': 32066.666666666668, 'local/mean_episode_step': 5141.333333333333, 'local/SPS': 3185.260239953214, 'local/env_act_steps': 9748736, 'local/env_train_steps': 9744640, 'local/optimizer_steps': 15225, 'local/running_reward': 15211.326616795366, 'local/running_step': 2418.55559242278, 'local/steps_done': 9748736, 'local/episodes_done': 2073, 'local/unclipped_grad_norm': 0.3945784261640237, 'local/model_version': 15225, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:39,921] {'global/mean_episode_return': 32066.666666666668, 'global/mean_episode_step': 5141.333333333333, 'global/SPS': 3057.849830355085, 'global/env_act_steps': 9748480, 'global/env_train_steps': 9743360, 'global/optimizer_steps': 15224, 'global/running_reward': 15218.669795627377, 'global/running_step': 2419.739157557034, 'global/steps_done': 9748480, 'global/episodes_done': 2073, 'global/unclipped_grad_norm': 0.3924191305413842, 'global/model_version': 15224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:49,947] calculate_sps 34560 steps in 10.0272
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:49,947] calculate_sps 35840 steps in 10.0272
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:49,947] {'local/mean_episode_return': 34514.28571428572, 'local/mean_episode_step': 5339.0, 'local/SPS': 3446.6277256341104, 'local/env_act_steps': 9780992, 'local/env_train_steps': 9779200, 'local/optimizer_steps': 15280, 'local/running_reward': 15019.822668650793, 'local/running_step': 2390.370132688492, 'local/steps_done': 9780992, 'local/episodes_done': 2080, 'local/unclipped_grad_norm': 0.4552381472154097, 'local/model_version': 15280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:49,949] {'global/mean_episode_return': 34514.28571428572, 'global/mean_episode_step': 5339.0, 'global/SPS': 3574.2806043613, 'global/env_act_steps': 9780608, 'global/env_train_steps': 9779200, 'global/optimizer_steps': 15280, 'global/running_reward': 15020.3125, 'global/running_step': 2390.481262450199, 'global/steps_done': 9780608, 'global/episodes_done': 2080, 'global/unclipped_grad_norm': 0.45600576273032595, 'global/model_version': 15280, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 12:05:52,120] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 9780992, 'env_train_steps': 9779200, 'optimizer_steps': 15280, 'running_reward': 15125.78125, 'running_step': 2401.4921875, 'steps_done': 9780992, 'episodes_done': 2080, 'unclipped_grad_norm': None, 'model_version': 15280, 'virtual_batch_size': None, 'num_gradients': None}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 12:05:52,213] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:59,980] calculate_sps 30720 steps in 10.0327
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:05:59,980] calculate_sps 30720 steps in 10.0327
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:59,980] {'local/mean_episode_return': 31400.0, 'local/mean_episode_step': 4715.5, 'local/SPS': 3061.9994345535947, 'local/env_act_steps': 9813888, 'local/env_train_steps': 9809920, 'local/optimizer_steps': 15328, 'local/running_reward': 15250.671814202335, 'local/running_step': 2424.9053684338523, 'local/steps_done': 9813888, 'local/episodes_done': 2084, 'local/unclipped_grad_norm': 0.33805834827944636, 'local/model_version': 15328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:05:59,981] {'global/mean_episode_return': 31400.0, 'global/mean_episode_step': 4715.5, 'global/SPS': 3061.9994345535947, 'global/env_act_steps': 9813632, 'global/env_train_steps': 9809920, 'global/optimizer_steps': 15328, 'global/running_reward': 15247.635053294574, 'global/running_step': 2424.3933805717056, 'global/steps_done': 9813632, 'global/episodes_done': 2084, 'global/unclipped_grad_norm': 0.33805834827944636, 'global/model_version': 15328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:06:09,986] calculate_sps 33280 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:06:09,986] calculate_sps 33280 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:06:09,986] {'local/mean_episode_return': 30033.333333333332, 'local/mean_episode_step': 4801.833333333333, 'local/SPS': 3326.017301307092, 'local/env_act_steps': 9846400, 'local/env_train_steps': 9843200, 'local/optimizer_steps': 15380, 'local/running_reward': 15481.8374753937, 'local/running_step': 2455.2036786417325, 'local/steps_done': 9846400, 'local/episodes_done': 2090, 'local/unclipped_grad_norm': 0.39677597453387886, 'local/model_version': 15380, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:06:09,987] {'global/mean_episode_return': 30033.333333333332, 'global/mean_episode_step': 4801.833333333333, 'global/SPS': 3326.017301307092, 'global/env_act_steps': 9846272, 'global/env_train_steps': 9843200, 'global/optimizer_steps': 15379, 'global/running_reward': 15481.302083333334, 'global/running_step': 2455.1063419117645, 'global/steps_done': 9846272, 'global/episodes_done': 2090, 'global/unclipped_grad_norm': 0.3970194808116146, 'global/model_version': 15379, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:06:20,008] calculate_sps 33280 steps in 10.0222
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:06:20,008] calculate_sps 27520 steps in 10.0222
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:06:20,018] {'local/mean_episode_return': 26000.0, 'local/mean_episode_step': 4602.5, 'local/SPS': 3320.627458790661, 'local/env_act_steps': 9879168, 'local/env_train_steps': 9876480, 'local/optimizer_steps': 15432, 'local/running_reward': 15955.2734375, 'local/running_step': 2527.0274963378906, 'local/steps_done': 9879168, 'local/episodes_done': 2092, 'local/unclipped_grad_norm': 0.4017514649492044, 'local/model_version': 15432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:06:20,020] {'global/mean_episode_return': 30800.0, 'global/mean_episode_step': 5398.0, 'global/SPS': 2745.903475538431, 'global/env_act_steps': 9872384, 'global/env_train_steps': 9870720, 'global/optimizer_steps': 15423, 'global/running_reward': 15891.038602941177, 'global/running_step': 2517.5680147058824, 'global/steps_done': 9872384, 'global/episodes_done': 2091, 'global/unclipped_grad_norm': 0.3898854631591927, 'global/model_version': 15423, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:06:30,043] calculate_sps 31360 steps in 10.0352
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:06:30,043] calculate_sps 31360 steps in 10.0352
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:06:30,043] {'local/mean_episode_return': 31914.285714285714, 'local/mean_episode_step': 5131.285714285715, 'local/SPS': 3125.0005568929855, 'local/env_act_steps': 9912448, 'local/env_train_steps': 9907840, 'local/optimizer_steps': 15480, 'local/running_reward': 16264.140625, 'local/running_step': 2566.2651141826923, 'local/steps_done': 9912448, 'local/episodes_done': 2099, 'local/unclipped_grad_norm': 0.4612053297460079, 'local/model_version': 15480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:06:30,044] {'global/mean_episode_return': 30033.333333333332, 'global/mean_episode_step': 4920.5, 'global/SPS': 3125.0005568929855, 'global/env_act_steps': 9906176, 'global/env_train_steps': 9902080, 'global/optimizer_steps': 15472, 'global/running_reward': 16257.350852272728, 'global/running_step': 2566.306492660985, 'global/steps_done': 9906176, 'global/episodes_done': 2097, 'global/unclipped_grad_norm': 0.4688899489689846, 'global/model_version': 15472, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:06:40,053] calculate_sps 35200 steps in 10.0105
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:06:40,054] calculate_sps 33920 steps in 10.0105
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:06:40,054] {'local/mean_episode_return': 29750.0, 'local/mean_episode_step': 4776.75, 'local/SPS': 3516.292232118847, 'local/env_act_steps': 9944704, 'local/env_train_steps': 9943040, 'local/optimizer_steps': 15536, 'local/running_reward': 16178.621031746032, 'local/running_step': 2551.7066592261904, 'local/steps_done': 9944704, 'local/episodes_done': 2107, 'local/unclipped_grad_norm': 0.45167791098356247, 'local/model_version': 15536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:06:40,055] {'global/mean_episode_return': 29300.0, 'global/mean_episode_step': 4703.5, 'global/SPS': 3388.427060041798, 'global/env_act_steps': 9938560, 'global/env_train_steps': 9936000, 'global/optimizer_steps': 15524, 'global/running_reward': 16199.47196146245, 'global/running_step': 2556.0825407608695, 'global/steps_done': 9938560, 'global/episodes_done': 2105, 'global/unclipped_grad_norm': 0.45401934820872086, 'global/model_version': 15524, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:06:50,069] calculate_sps 30720 steps in 10.016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:06:50,070] calculate_sps 32640 steps in 10.016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:06:50,070] {'local/mean_episode_return': 25783.333333333332, 'local/mean_episode_step': 4262.833333333333, 'local/SPS': 3067.0846109280114, 'local/env_act_steps': 9978112, 'local/env_train_steps': 9973760, 'local/optimizer_steps': 15584, 'local/running_reward': 16138.194444444445, 'local/running_step': 2536.424030172414, 'local/steps_done': 9978112, 'local/episodes_done': 2113, 'local/unclipped_grad_norm': 0.4391686810801427, 'local/model_version': 15584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:06:50,077] {'global/mean_episode_return': 27414.285714285714, 'global/mean_episode_step': 4455.285714285715, 'global/SPS': 3258.7773991110125, 'global/env_act_steps': 9971840, 'global/env_train_steps': 9968640, 'global/optimizer_steps': 15576, 'global/running_reward': 16115.727163461539, 'global/running_step': 2534.3155348557693, 'global/steps_done': 9971840, 'global/episodes_done': 2112, 'global/unclipped_grad_norm': 0.4274062674779158, 'global/model_version': 15576, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:00,077] calculate_sps 34560 steps in 10.0056
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:00,086] calculate_sps 33280 steps in 10.0056
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:00,086] {'local/mean_episode_return': 30080.0, 'local/mean_episode_step': 4735.6, 'local/SPS': 3454.059558740077, 'local/env_act_steps': 10010496, 'local/env_train_steps': 10008320, 'local/optimizer_steps': 15637, 'local/running_reward': 16344.460227272728, 'local/running_step': 2569.223659832016, 'local/steps_done': 10010496, 'local/episodes_done': 2118, 'local/unclipped_grad_norm': 0.4459793196534211, 'local/model_version': 15637, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:00,088] {'global/mean_episode_return': 30200.0, 'global/mean_episode_step': 4809.5, 'global/SPS': 3326.131426934889, 'global/env_act_steps': 10004992, 'global/env_train_steps': 10001920, 'global/optimizer_steps': 15627, 'global/running_reward': 16306.672297297297, 'global/running_step': 2562.971434604247, 'global/steps_done': 10004992, 'global/episodes_done': 2118, 'global/unclipped_grad_norm': 0.45282120739712434, 'global/model_version': 15627, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:10,115] calculate_sps 32000 steps in 10.0397
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:10,115] calculate_sps 33280 steps in 10.0397
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:10,115] {'local/mean_episode_return': 30522.222222222223, 'local/mean_episode_step': 4741.111111111111, 'local/SPS': 3187.3527350191175, 'local/env_act_steps': 10043392, 'local/env_train_steps': 10040320, 'local/optimizer_steps': 15688, 'local/running_reward': 16335.049854085602, 'local/running_step': 2567.5912876945526, 'local/steps_done': 10043392, 'local/episodes_done': 2127, 'local/unclipped_grad_norm': 0.4234132432177955, 'local/model_version': 15688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:10,117] {'global/mean_episode_return': 30522.222222222223, 'global/mean_episode_step': 4741.111111111111, 'global/SPS': 3314.846844419882, 'global/env_act_steps': 10037760, 'global/env_train_steps': 10035200, 'global/optimizer_steps': 15680, 'global/running_reward': 16379.052734375, 'global/running_step': 2574.5150146484375, 'global/steps_done': 10037760, 'global/episodes_done': 2127, 'global/unclipped_grad_norm': 0.42969693468426756, 'global/model_version': 15680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:20,122] calculate_sps 31360 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:20,122] calculate_sps 31360 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:20,122] {'local/mean_episode_return': 35360.0, 'local/mean_episode_step': 5308.0, 'local/SPS': 3134.336769736194, 'local/env_act_steps': 10076416, 'local/env_train_steps': 10071680, 'local/optimizer_steps': 15736, 'local/running_reward': 16395.22468507752, 'local/running_step': 2578.8819343507753, 'local/steps_done': 10076416, 'local/episodes_done': 2132, 'local/unclipped_grad_norm': 0.4747949596494436, 'local/model_version': 15736, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:20,124] {'global/mean_episode_return': 34400.0, 'global/mean_episode_step': 5285.25, 'global/SPS': 3134.336769736194, 'global/env_act_steps': 10071168, 'global/env_train_steps': 10066560, 'global/optimizer_steps': 15728, 'global/running_reward': 16356.32183908046, 'global/running_step': 2572.268558429119, 'global/steps_done': 10071168, 'global/episodes_done': 2131, 'global/unclipped_grad_norm': 0.4602855830453336, 'global/model_version': 15728, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:30,126] calculate_sps 35200 steps in 10.0054
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:30,126] calculate_sps 35200 steps in 10.0054
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:30,126] {'local/mean_episode_return': 30040.0, 'local/mean_episode_step': 4611.2, 'local/SPS': 3518.0989886408197, 'local/env_act_steps': 10109056, 'local/env_train_steps': 10106880, 'local/optimizer_steps': 15792, 'local/running_reward': 16412.276348039217, 'local/running_step': 2589.0001838235294, 'local/steps_done': 10109056, 'local/episodes_done': 2137, 'local/unclipped_grad_norm': 0.3708689212799072, 'local/model_version': 15792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:30,128] {'global/mean_episode_return': 34880.0, 'global/mean_episode_step': 5120.2, 'global/SPS': 3518.0989886408197, 'global/env_act_steps': 10103936, 'global/env_train_steps': 10101760, 'global/optimizer_steps': 15784, 'global/running_reward': 16388.922119140625, 'global/running_step': 2583.985870361328, 'global/steps_done': 10103936, 'global/episodes_done': 2136, 'global/unclipped_grad_norm': 0.3953265747321503, 'global/model_version': 15784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:40,132] calculate_sps 30720 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:40,132] calculate_sps 30720 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:40,133] {'local/mean_episode_return': 32714.285714285714, 'local/mean_episode_step': 5032.0, 'local/SPS': 3070.0036175568375, 'local/env_act_steps': 10142464, 'local/env_train_steps': 10137600, 'local/optimizer_steps': 15840, 'local/running_reward': 16641.543941570882, 'local/running_step': 2627.6132064176245, 'local/steps_done': 10142464, 'local/episodes_done': 2144, 'local/unclipped_grad_norm': 0.46716789963344735, 'local/model_version': 15840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:40,143] {'global/mean_episode_return': 30833.333333333332, 'global/mean_episode_step': 4699.166666666667, 'global/SPS': 3070.0036175568375, 'global/env_act_steps': 10137728, 'global/env_train_steps': 10132480, 'global/optimizer_steps': 15832, 'global/running_reward': 16624.496922348484, 'global/running_step': 2625.077059659091, 'global/steps_done': 10137728, 'global/episodes_done': 2142, 'global/unclipped_grad_norm': 0.42785612897326547, 'global/model_version': 15832, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:50,138] calculate_sps 35200 steps in 10.0066
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:07:50,138] calculate_sps 35840 steps in 10.0066
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:50,139] {'local/mean_episode_return': 35200.0, 'local/mean_episode_step': 5173.0, 'local/SPS': 3517.6909383079173, 'local/env_act_steps': 10174336, 'local/env_train_steps': 10172800, 'local/optimizer_steps': 15894, 'local/running_reward': 16830.8546686747, 'local/running_step': 2652.729700050201, 'local/steps_done': 10174336, 'local/episodes_done': 2148, 'local/unclipped_grad_norm': 0.3813201883048923, 'local/model_version': 15894, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:07:50,139] {'global/mean_episode_return': 32400.0, 'global/mean_episode_step': 5035.8, 'global/SPS': 3581.6489553680613, 'global/env_act_steps': 10169728, 'global/env_train_steps': 10168320, 'global/optimizer_steps': 15888, 'global/running_reward': 16807.253125, 'global/running_step': 2648.81440625, 'global/steps_done': 10169728, 'global/episodes_done': 2147, 'global/unclipped_grad_norm': 0.41592974135918276, 'global/model_version': 15888, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:00,154] calculate_sps 31360 steps in 10.0158
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:00,155] calculate_sps 30720 steps in 10.0158
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:00,155] {'local/mean_episode_return': 35040.0, 'local/mean_episode_step': 5264.1, 'local/SPS': 3131.0425766355565, 'local/env_act_steps': 10207744, 'local/env_train_steps': 10204160, 'local/optimizer_steps': 15944, 'local/running_reward': 16477.12823275862, 'local/running_step': 2607.0025143678163, 'local/steps_done': 10207744, 'local/episodes_done': 2158, 'local/unclipped_grad_norm': 0.45550341084599494, 'local/model_version': 15944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:00,157] {'global/mean_episode_return': 35320.0, 'global/mean_episode_step': 5264.0, 'global/SPS': 3067.1437485409533, 'global/env_act_steps': 10203392, 'global/env_train_steps': 10199040, 'global/optimizer_steps': 15936, 'global/running_reward': 16551.782319391634, 'global/running_step': 2617.4276081273765, 'global/steps_done': 10203392, 'global/episodes_done': 2157, 'global/unclipped_grad_norm': 0.434089793668439, 'global/model_version': 15936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:10,177] calculate_sps 32640 steps in 10.0048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:10,184] calculate_sps 35200 steps in 10.0048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:10,184] {'local/mean_episode_return': 27390.0, 'local/mean_episode_step': 4345.7, 'local/SPS': 3262.423431860438, 'local/env_act_steps': 10240512, 'local/env_train_steps': 10236800, 'local/optimizer_steps': 15994, 'local/running_reward': 16429.122924804688, 'local/running_step': 2604.571563720703, 'local/steps_done': 10240512, 'local/episodes_done': 2168, 'local/unclipped_grad_norm': 0.36588186979293824, 'local/model_version': 15994, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:10,185] {'global/mean_episode_return': 26200.0, 'global/mean_episode_step': 4230.571428571428, 'global/SPS': 3518.299779457335, 'global/env_act_steps': 10235776, 'global/env_train_steps': 10234240, 'global/optimizer_steps': 15990, 'global/running_reward': 16448.369565217392, 'global/running_step': 2607.432682806324, 'global/steps_done': 10235776, 'global/episodes_done': 2164, 'global/unclipped_grad_norm': 0.38328963007639955, 'global/model_version': 15990, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:20,169] calculate_sps 33920 steps in 10.0101
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:20,170] calculate_sps 31360 steps in 10.0101
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:20,171] {'local/mean_episode_return': 34000.0, 'local/mean_episode_step': 5106.714285714285, 'local/SPS': 3388.5824978770565, 'local/env_act_steps': 10272512, 'local/env_train_steps': 10270720, 'local/optimizer_steps': 16048, 'local/running_reward': 15814.125, 'local/running_step': 2520.72565625, 'local/steps_done': 10272512, 'local/episodes_done': 2175, 'local/unclipped_grad_norm': 0.38239777005381054, 'local/model_version': 16048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:20,173] {'global/mean_episode_return': 33045.454545454544, 'global/mean_episode_step': 4998.818181818182, 'global/SPS': 3132.840422565581, 'global/env_act_steps': 10268928, 'global/env_train_steps': 10265600, 'global/optimizer_steps': 16040, 'global/running_reward': 15869.805743243243, 'global/running_step': 2527.4748129826253, 'global/steps_done': 10268928, 'global/episodes_done': 2175, 'global/unclipped_grad_norm': 0.37156266927719117, 'global/model_version': 16040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:30,187] calculate_sps 30720 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:30,187] calculate_sps 33280 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:30,187] {'local/mean_episode_return': 28044.444444444445, 'local/mean_episode_step': 4597.666666666667, 'local/SPS': 3066.6554570055914, 'local/env_act_steps': 10306048, 'local/env_train_steps': 10301440, 'local/optimizer_steps': 16096, 'local/running_reward': 15604.693463740457, 'local/running_step': 2479.7087010973282, 'local/steps_done': 10306048, 'local/episodes_done': 2184, 'local/unclipped_grad_norm': 0.4315717755816877, 'local/model_version': 16096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:30,189] {'global/mean_episode_return': 27050.0, 'global/mean_episode_step': 4498.0, 'global/SPS': 3322.210078422724, 'global/env_act_steps': 10302080, 'global/env_train_steps': 10298880, 'global/optimizer_steps': 16092, 'global/running_reward': 15608.62693050193, 'global/running_step': 2482.121229488417, 'global/steps_done': 10302080, 'global/episodes_done': 2183, 'global/unclipped_grad_norm': 0.4407882895320654, 'global/model_version': 16092, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:40,228] calculate_sps 35200 steps in 10.0413
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:40,228] calculate_sps 33280 steps in 10.0413
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:40,228] {'local/mean_episode_return': 31700.0, 'local/mean_episode_step': 4814.0, 'local/SPS': 3505.519675935407, 'local/env_act_steps': 10338176, 'local/env_train_steps': 10336640, 'local/optimizer_steps': 16150, 'local/running_reward': 15648.947958167331, 'local/running_step': 2480.617436503984, 'local/steps_done': 10338176, 'local/episodes_done': 2194, 'local/unclipped_grad_norm': 0.45182215725934066, 'local/model_version': 16150, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:40,229] {'global/mean_episode_return': 32090.909090909092, 'global/mean_episode_step': 4866.818181818182, 'global/SPS': 3314.309511793476, 'global/env_act_steps': 10334720, 'global/env_train_steps': 10332160, 'global/optimizer_steps': 16144, 'global/running_reward': 15699.613970588236, 'global/running_step': 2488.220404411765, 'global/steps_done': 10334720, 'global/episodes_done': 2194, 'global/unclipped_grad_norm': 0.43752214083304775, 'global/model_version': 16144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:50,233] calculate_sps 31360 steps in 10.0051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:08:50,234] calculate_sps 31360 steps in 10.0051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:50,234] {'local/mean_episode_return': 30942.85714285714, 'local/mean_episode_step': 4770.857142857143, 'local/SPS': 3134.3948786831083, 'local/env_act_steps': 10371328, 'local/env_train_steps': 10368000, 'local/optimizer_steps': 16200, 'local/running_reward': 15247.224903474904, 'local/running_step': 2420.5729669401544, 'local/steps_done': 10371328, 'local/episodes_done': 2201, 'local/unclipped_grad_norm': 0.5124717715382576, 'local/model_version': 16200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:08:50,235] {'global/mean_episode_return': 30942.85714285714, 'global/mean_episode_step': 4770.857142857143, 'global/SPS': 3134.3948786831083, 'global/env_act_steps': 10368256, 'global/env_train_steps': 10363520, 'global/optimizer_steps': 16193, 'global/running_reward': 15248.938454198473, 'global/running_step': 2420.5446684160306, 'global/steps_done': 10368256, 'global/episodes_done': 2201, 'global/unclipped_grad_norm': 0.5097089598373491, 'global/model_version': 16193, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:00,253] calculate_sps 32000 steps in 10.0204
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:00,253] calculate_sps 35200 steps in 10.0204
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:00,254] {'local/mean_episode_return': 29700.0, 'local/mean_episode_step': 4635.833333333333, 'local/SPS': 3193.482235591517, 'local/env_act_steps': 10404096, 'local/env_train_steps': 10400000, 'local/optimizer_steps': 16249, 'local/running_reward': 14954.608154296875, 'local/running_step': 2376.7462158203125, 'local/steps_done': 10404096, 'local/episodes_done': 2213, 'local/unclipped_grad_norm': 0.5423154715372591, 'local/model_version': 16249, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:00,255] {'global/mean_episode_return': 28900.0, 'global/mean_episode_step': 4522.1, 'global/SPS': 3512.830459150669, 'global/env_act_steps': 10400384, 'global/env_train_steps': 10398720, 'global/optimizer_steps': 16248, 'global/running_reward': 14995.567729083665, 'global/running_step': 2383.68625498008, 'global/steps_done': 10400384, 'global/episodes_done': 2211, 'global/unclipped_grad_norm': 0.5374012849547646, 'global/model_version': 16248, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:10,283] calculate_sps 34560 steps in 10.0292
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:10,283] calculate_sps 30720 steps in 10.0292
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:10,284] {'local/mean_episode_return': 27283.333333333332, 'local/mean_episode_step': 4242.25, 'local/SPS': 3445.923253562547, 'local/env_act_steps': 10436736, 'local/env_train_steps': 10434560, 'local/optimizer_steps': 16304, 'local/running_reward': 14207.726715686274, 'local/running_step': 2262.4179227941177, 'local/steps_done': 10436736, 'local/episodes_done': 2227, 'local/unclipped_grad_norm': 0.41931746141477066, 'local/model_version': 16304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:10,285] {'global/mean_episode_return': 28050.0, 'global/mean_episode_step': 4365.75, 'global/SPS': 3063.0428920555973, 'global/env_act_steps': 10433920, 'global/env_train_steps': 10429440, 'global/optimizer_steps': 16296, 'global/running_reward': 14288.752385496184, 'global/running_step': 2274.3495646469464, 'global/steps_done': 10433920, 'global/episodes_done': 2225, 'global/unclipped_grad_norm': 0.41195643444856006, 'global/model_version': 16296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:20,311] calculate_sps 30720 steps in 10.0285
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:20,312] calculate_sps 35200 steps in 10.0285
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:20,312] {'local/mean_episode_return': 29400.0, 'local/mean_episode_step': 4601.884615384615, 'local/SPS': 3063.2623014810824, 'local/env_act_steps': 10469760, 'local/env_train_steps': 10465280, 'local/optimizer_steps': 16352, 'local/running_reward': 13462.760416666666, 'local/running_step': 2142.9121850775196, 'local/steps_done': 10469760, 'local/episodes_done': 2241, 'local/unclipped_grad_norm': 0.4217650617162387, 'local/model_version': 16352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:20,313] {'global/mean_episode_return': 29360.0, 'global/mean_episode_step': 4583.433333333333, 'global/SPS': 3509.988053780407, 'global/env_act_steps': 10466176, 'global/env_train_steps': 10464640, 'global/optimizer_steps': 16350, 'global/running_reward': 13536.495535714286, 'global/running_step': 2155.1266741071427, 'global/steps_done': 10466176, 'global/episodes_done': 2241, 'global/unclipped_grad_norm': 0.4258707516171314, 'global/model_version': 16350, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:30,316] calculate_sps 34560 steps in 10.0043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:30,316] calculate_sps 31360 steps in 10.0043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:30,317] {'local/mean_episode_return': 26375.0, 'local/mean_episode_step': 4152.1875, 'local/SPS': 3454.524232740349, 'local/env_act_steps': 10502016, 'local/env_train_steps': 10499840, 'local/optimizer_steps': 16406, 'local/running_reward': 13130.357142857143, 'local/running_step': 2087.1319754464284, 'local/steps_done': 10502016, 'local/episodes_done': 2250, 'local/unclipped_grad_norm': 0.49311367118800126, 'local/model_version': 16406, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:30,318] {'global/mean_episode_return': 26375.0, 'global/mean_episode_step': 4152.1875, 'global/SPS': 3134.660877856983, 'global/env_act_steps': 10499840, 'global/env_train_steps': 10496000, 'global/optimizer_steps': 16400, 'global/running_reward': 13142.056796577946, 'global/running_step': 2088.928766634981, 'global/steps_done': 10499840, 'global/episodes_done': 2250, 'global/unclipped_grad_norm': 0.5118021953105927, 'global/model_version': 16400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:40,327] calculate_sps 32000 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:40,327] calculate_sps 33280 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:40,327] {'local/mean_episode_return': 30487.5, 'local/mean_episode_step': 4651.6875, 'local/SPS': 3196.481610143292, 'local/env_act_steps': 10534656, 'local/env_train_steps': 10531840, 'local/optimizer_steps': 16456, 'local/running_reward': 12627.316176470587, 'local/running_step': 2007.5790134803922, 'local/steps_done': 10534656, 'local/episodes_done': 2266, 'local/unclipped_grad_norm': 0.4202078352868557, 'local/model_version': 16456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:40,328] {'global/mean_episode_return': 31026.666666666668, 'global/mean_episode_step': 4715.8, 'global/SPS': 3324.340874549024, 'global/env_act_steps': 10532352, 'global/env_train_steps': 10529280, 'global/optimizer_steps': 16451, 'global/running_reward': 12699.39714566929, 'global/running_step': 2018.9377460629921, 'global/steps_done': 10532352, 'global/episodes_done': 2265, 'global/unclipped_grad_norm': 0.4235917728613405, 'global/model_version': 16451, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:50,327] calculate_sps 31360 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:09:50,327] calculate_sps 33280 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:50,327] {'local/mean_episode_return': 28388.88888888889, 'local/mean_episode_step': 4506.111111111111, 'local/SPS': 3135.8067364594044, 'local/env_act_steps': 10567808, 'local/env_train_steps': 10563200, 'local/optimizer_steps': 16504, 'local/running_reward': 12218.273407335908, 'local/running_step': 1943.8672478281853, 'local/steps_done': 10567808, 'local/episodes_done': 2276, 'local/unclipped_grad_norm': 0.4565777536481619, 'local/model_version': 16504, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:09:50,328] {'global/mean_episode_return': 26962.5, 'global/mean_episode_step': 4317.75, 'global/SPS': 3327.794903997735, 'global/env_act_steps': 10565504, 'global/env_train_steps': 10562560, 'global/optimizer_steps': 16504, 'global/running_reward': 12226.248793436293, 'global/running_step': 1945.778112934363, 'global/steps_done': 10565504, 'global/episodes_done': 2274, 'global/unclipped_grad_norm': 0.43978570907745723, 'global/model_version': 16504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:00,343] calculate_sps 35200 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:00,344] calculate_sps 32000 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:00,344] {'local/mean_episode_return': 22000.0, 'local/mean_episode_step': 3640.5, 'local/SPS': 3514.253012457431, 'local/env_act_steps': 10599936, 'local/env_train_steps': 10598400, 'local/optimizer_steps': 16560, 'local/running_reward': 12079.874252988047, 'local/running_step': 1916.6385707171314, 'local/steps_done': 10599936, 'local/episodes_done': 2280, 'local/unclipped_grad_norm': 0.4232052146856274, 'local/model_version': 16560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:00,345] {'global/mean_episode_return': 25033.333333333332, 'global/mean_episode_step': 4044.1666666666665, 'global/SPS': 3194.775465870392, 'global/env_act_steps': 10598656, 'global/env_train_steps': 10594560, 'global/optimizer_steps': 16553, 'global/running_reward': 12066.33083976834, 'global/running_step': 1914.482293677606, 'global/steps_done': 10598656, 'global/episodes_done': 2280, 'global/unclipped_grad_norm': 0.43323484884232893, 'global/model_version': 16553, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:10,356] calculate_sps 30720 steps in 10.0127
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:10,357] calculate_sps 34560 steps in 10.0127
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:10,357] {'local/mean_episode_return': 30640.0, 'local/mean_episode_step': 4789.0, 'local/SPS': 3068.1036298763993, 'local/env_act_steps': 10633728, 'local/env_train_steps': 10629120, 'local/optimizer_steps': 16608, 'local/running_reward': 12495.188210227272, 'local/running_step': 1972.9097123579545, 'local/steps_done': 10633728, 'local/episodes_done': 2285, 'local/unclipped_grad_norm': 0.42067190663268167, 'local/model_version': 16608, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:10,358] {'global/mean_episode_return': 30640.0, 'global/mean_episode_step': 4789.0, 'global/SPS': 3451.616583610949, 'global/env_act_steps': 10631680, 'global/env_train_steps': 10629120, 'global/optimizer_steps': 16608, 'global/running_reward': 12480.601986434109, 'global/running_step': 1971.0556262112402, 'global/steps_done': 10631680, 'global/episodes_done': 2285, 'global/unclipped_grad_norm': 0.4120588354089043, 'global/model_version': 16608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:20,398] calculate_sps 35840 steps in 10.0418
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:20,398] calculate_sps 31360 steps in 10.0418
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:20,398] {'local/mean_episode_return': 24300.0, 'local/mean_episode_step': 3873.6428571428573, 'local/SPS': 3569.0674200960266, 'local/env_act_steps': 10665984, 'local/env_train_steps': 10664960, 'local/optimizer_steps': 16663, 'local/running_reward': 12372.71205357143, 'local/running_step': 1943.8000062003969, 'local/steps_done': 10665984, 'local/episodes_done': 2299, 'local/unclipped_grad_norm': 0.5811779488216747, 'local/model_version': 16663, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:20,399] {'global/mean_episode_return': 23876.923076923078, 'global/mean_episode_step': 3812.0, 'global/SPS': 3122.933992584023, 'global/env_act_steps': 10665216, 'global/env_train_steps': 10660480, 'global/optimizer_steps': 16657, 'global/running_reward': 12391.97876908397, 'global/running_step': 1947.371719942748, 'global/steps_done': 10665216, 'global/episodes_done': 2298, 'global/unclipped_grad_norm': 0.6022533199616841, 'global/model_version': 16657, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:30,399] calculate_sps 30720 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:30,400] calculate_sps 35200 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:30,400] {'local/mean_episode_return': 23366.666666666668, 'local/mean_episode_step': 3776.3333333333335, 'local/SPS': 3071.686189286206, 'local/env_act_steps': 10699136, 'local/env_train_steps': 10695680, 'local/optimizer_steps': 16712, 'local/running_reward': 12001.24276061776, 'local/running_step': 1870.2456563706564, 'local/steps_done': 10699136, 'local/episodes_done': 2311, 'local/unclipped_grad_norm': 0.4691503078353648, 'local/model_version': 16712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:30,411] {'global/mean_episode_return': 23861.53846153846, 'global/mean_episode_step': 3845.4615384615386, 'global/SPS': 3519.6404252237776, 'global/env_act_steps': 10697472, 'global/env_train_steps': 10695680, 'global/optimizer_steps': 16712, 'global/running_reward': 12010.47867063492, 'global/running_step': 1872.2902095734128, 'global/steps_done': 10697472, 'global/episodes_done': 2311, 'global/unclipped_grad_norm': 0.4625952652909539, 'global/model_version': 16712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:40,439] calculate_sps 32640 steps in 10.0405
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:40,439] calculate_sps 30720 steps in 10.0405
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:40,440] {'local/mean_episode_return': 27857.14285714286, 'local/mean_episode_step': 4125.428571428572, 'local/SPS': 3250.8315985143, 'local/env_act_steps': 10731904, 'local/env_train_steps': 10728320, 'local/optimizer_steps': 16762, 'local/running_reward': 12021.951293945312, 'local/running_step': 1870.6298828125, 'local/steps_done': 10731904, 'local/episodes_done': 2318, 'local/unclipped_grad_norm': 0.5762152253836393, 'local/model_version': 16762, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:40,441] {'global/mean_episode_return': 29066.666666666668, 'global/mean_episode_step': 4293.833333333333, 'global/SPS': 3059.6062103664, 'global/env_act_steps': 10731008, 'global/env_train_steps': 10726400, 'global/optimizer_steps': 16760, 'global/running_reward': 12023.031965648855, 'global/running_step': 1869.8999284351146, 'global/steps_done': 10731008, 'global/episodes_done': 2317, 'global/unclipped_grad_norm': 0.5924062096358588, 'global/model_version': 16760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:50,443] calculate_sps 33920 steps in 10.0038
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:10:50,444] calculate_sps 34560 steps in 10.0038
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:50,444] {'local/mean_episode_return': 22594.827586206895, 'local/mean_episode_step': 3563.7586206896553, 'local/SPS': 3390.718427199688, 'local/env_act_steps': 10764032, 'local/env_train_steps': 10762240, 'local/optimizer_steps': 16816, 'local/running_reward': 10433.83030378486, 'local/running_step': 1694.5958354083666, 'local/steps_done': 10764032, 'local/episodes_done': 2348, 'local/unclipped_grad_norm': 0.25853819286243784, 'local/model_version': 16816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:10:50,445] {'global/mean_episode_return': 22528.333333333332, 'global/mean_episode_step': 3548.8, 'global/SPS': 3454.6942465808143, 'global/env_act_steps': 10763008, 'global/env_train_steps': 10760960, 'global/optimizer_steps': 16813, 'global/running_reward': 10502.784375, 'global/running_step': 1702.90615625, 'global/steps_done': 10763008, 'global/episodes_done': 2348, 'global/unclipped_grad_norm': 0.2566983745837549, 'global/model_version': 16813, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:00,456] calculate_sps 30720 steps in 10.0118
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:00,466] calculate_sps 32000 steps in 10.0118
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:00,466] {'local/mean_episode_return': 19243.75, 'local/mean_episode_step': 3222.4375, 'local/SPS': 3068.364317658925, 'local/env_act_steps': 10797312, 'local/env_train_steps': 10792960, 'local/optimizer_steps': 16864, 'local/running_reward': 8990.282451923076, 'local/running_step': 1516.1175480769232, 'local/steps_done': 10797312, 'local/episodes_done': 2364, 'local/unclipped_grad_norm': 0.4363676419792076, 'local/model_version': 16864, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:00,468] {'global/mean_episode_return': 19243.75, 'global/mean_episode_step': 3222.4375, 'global/SPS': 3196.212830894713, 'global/env_act_steps': 10796288, 'global/env_train_steps': 10792960, 'global/optimizer_steps': 16864, 'global/running_reward': 9007.21454326923, 'global/running_step': 1518.3145432692309, 'global/steps_done': 10796288, 'global/episodes_done': 2364, 'global/unclipped_grad_norm': 0.4250384035940264, 'global/model_version': 16864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:10,488] calculate_sps 35200 steps in 10.0331
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:10,488] calculate_sps 33280 steps in 10.0331
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:10,488] {'local/mean_episode_return': 23728.571428571428, 'local/mean_episode_step': 3676.5714285714284, 'local/SPS': 3508.3893610560717, 'local/env_act_steps': 10829696, 'local/env_train_steps': 10828160, 'local/optimizer_steps': 16918, 'local/running_reward': 8892.641427865612, 'local/running_step': 1508.7513278162055, 'local/steps_done': 10829696, 'local/episodes_done': 2371, 'local/unclipped_grad_norm': 0.5169883940230917, 'local/model_version': 16918, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:10,489] {'global/mean_episode_return': 23728.571428571428, 'global/mean_episode_step': 3676.5714285714284, 'global/SPS': 3317.0226686348315, 'global/env_act_steps': 10829312, 'global/env_train_steps': 10826240, 'global/optimizer_steps': 16915, 'global/running_reward': 8892.617490310078, 'global/running_step': 1508.5757025193798, 'global/steps_done': 10829312, 'global/episodes_done': 2371, 'global/unclipped_grad_norm': 0.5286021824268734, 'global/model_version': 16915, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:20,521] calculate_sps 31360 steps in 10.0325
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:20,521] calculate_sps 33280 steps in 10.0325
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:20,521] {'local/mean_episode_return': 18177.777777777777, 'local/mean_episode_step': 3035.8888888888887, 'local/SPS': 3125.8518533463875, 'local/env_act_steps': 10863104, 'local/env_train_steps': 10859520, 'local/optimizer_steps': 16968, 'local/running_reward': 9237.24856321839, 'local/running_step': 1553.6124580938697, 'local/steps_done': 10863104, 'local/episodes_done': 2380, 'local/unclipped_grad_norm': 0.43726912528276446, 'local/model_version': 16968, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:20,523] {'global/mean_episode_return': 18177.777777777777, 'global/mean_episode_step': 3035.8888888888887, 'global/SPS': 3317.2305382451464, 'global/env_act_steps': 10862720, 'global/env_train_steps': 10859520, 'global/optimizer_steps': 16968, 'global/running_reward': 9232.246767241379, 'global/running_step': 1553.0507962164752, 'global/steps_done': 10862720, 'global/episodes_done': 2380, 'global/unclipped_grad_norm': 0.43060600448329495, 'global/model_version': 16968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:30,570] calculate_sps 33920 steps in 10.049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:30,570] calculate_sps 33280 steps in 10.049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:30,570] {'local/mean_episode_return': 26357.14285714286, 'local/mean_episode_step': 4031.1428571428573, 'local/SPS': 3375.456152150396, 'local/env_act_steps': 10896000, 'local/env_train_steps': 10893440, 'local/optimizer_steps': 17020, 'local/running_reward': 9446.513253891051, 'local/running_step': 1576.4565904669262, 'local/steps_done': 10896000, 'local/episodes_done': 2387, 'local/unclipped_grad_norm': 0.482514945933452, 'local/model_version': 17020, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:30,571] {'global/mean_episode_return': 26357.14285714286, 'global/mean_episode_step': 4031.1428571428573, 'global/SPS': 3311.76830022303, 'global/env_act_steps': 10895872, 'global/env_train_steps': 10892800, 'global/optimizer_steps': 17019, 'global/running_reward': 9447.520511583012, 'global/running_step': 1576.6391771235521, 'global/steps_done': 10895872, 'global/episodes_done': 2387, 'global/unclipped_grad_norm': 0.48797865533361245, 'global/model_version': 17019, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:40,591] calculate_sps 32640 steps in 10.0208
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:40,591] calculate_sps 33280 steps in 10.0208
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:40,591] {'local/mean_episode_return': 14586.363636363636, 'local/mean_episode_step': 2546.909090909091, 'local/SPS': 3257.2157904754654, 'local/env_act_steps': 10928896, 'local/env_train_steps': 10926080, 'local/optimizer_steps': 17072, 'local/running_reward': 9529.377431906614, 'local/running_step': 1575.9549793287938, 'local/steps_done': 10928896, 'local/episodes_done': 2399, 'local/unclipped_grad_norm': 0.38507110768785846, 'local/model_version': 17072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:40,593] {'global/mean_episode_return': 14586.363636363636, 'global/mean_episode_step': 2546.909090909091, 'global/SPS': 3321.082766759298, 'global/env_act_steps': 10928768, 'global/env_train_steps': 10926080, 'global/optimizer_steps': 17072, 'global/running_reward': 9527.070160505837, 'global/running_step': 1575.7506991731518, 'global/steps_done': 10928768, 'global/episodes_done': 2399, 'global/unclipped_grad_norm': 0.3816521389866775, 'global/model_version': 17072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:50,614] calculate_sps 31360 steps in 10.0232
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:11:50,614] calculate_sps 25600 steps in 10.0232
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:50,614] {'local/mean_episode_return': 24475.0, 'local/mean_episode_step': 3820.75, 'local/SPS': 3128.7356530942693, 'local/env_act_steps': 10962048, 'local/env_train_steps': 10957440, 'local/optimizer_steps': 17120, 'local/running_reward': 9905.694980694981, 'local/running_step': 1622.3137065637065, 'local/steps_done': 10962048, 'local/episodes_done': 2403, 'local/unclipped_grad_norm': 0.4339682140077154, 'local/model_version': 17120, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:11:50,615] {'global/mean_episode_return': 27633.333333333332, 'global/mean_episode_step': 4190.0, 'global/SPS': 2554.069920893281, 'global/env_act_steps': 10955520, 'global/env_train_steps': 10951680, 'global/optimizer_steps': 17112, 'global/running_reward': 9859.898325358852, 'global/running_step': 1615.9500224282297, 'global/steps_done': 10955520, 'global/episodes_done': 2402, 'global/unclipped_grad_norm': 0.41913547553122044, 'global/model_version': 17112, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:00,650] calculate_sps 35200 steps in 10.0358
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:00,650] calculate_sps 33280 steps in 10.0358
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:00,650] {'local/mean_episode_return': 21680.0, 'local/mean_episode_step': 3345.7, 'local/SPS': 3507.4396934044516, 'local/env_act_steps': 10994176, 'local/env_train_steps': 10992640, 'local/optimizer_steps': 17176, 'local/running_reward': 10099.081797808765, 'local/running_step': 1637.8076755478087, 'local/steps_done': 10994176, 'local/episodes_done': 2414, 'local/unclipped_grad_norm': 0.47378717123397757, 'local/model_version': 17176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:00,652] {'global/mean_episode_return': 21072.727272727272, 'global/mean_episode_step': 3288.181818181818, 'global/SPS': 3316.124801036936, 'global/env_act_steps': 10988160, 'global/env_train_steps': 10984960, 'global/optimizer_steps': 17164, 'global/running_reward': 10102.199754901962, 'global/running_step': 1641.8345281862746, 'global/steps_done': 10988160, 'global/episodes_done': 2414, 'global/unclipped_grad_norm': 0.4823802915903238, 'global/model_version': 17164, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:10,650] calculate_sps 30720 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:10,651] calculate_sps 33280 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:10,651] {'local/mean_episode_return': 20427.272727272728, 'local/mean_episode_step': 3255.909090909091, 'local/SPS': 3071.807165425621, 'local/env_act_steps': 11027200, 'local/env_train_steps': 11023360, 'local/optimizer_steps': 17224, 'local/running_reward': 10440.410004844962, 'local/running_step': 1674.3697311046512, 'local/steps_done': 11027200, 'local/episodes_done': 2425, 'local/unclipped_grad_norm': 0.507391870332261, 'local/model_version': 17224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:10,652] {'global/mean_episode_return': 19471.428571428572, 'global/mean_episode_step': 3097.4285714285716, 'global/SPS': 3327.791095877756, 'global/env_act_steps': 11020800, 'global/env_train_steps': 11018240, 'global/optimizer_steps': 17216, 'global/running_reward': 10398.59681372549, 'global/running_step': 1671.6207414215687, 'global/steps_done': 11020800, 'global/episodes_done': 2421, 'global/unclipped_grad_norm': 0.4886019373169312, 'global/model_version': 17216, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:20,663] calculate_sps 33920 steps in 10.0125
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:20,663] calculate_sps 31360 steps in 10.0125
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:20,663] {'local/mean_episode_return': 19300.0, 'local/mean_episode_step': 3040.3571428571427, 'local/SPS': 3387.749385377053, 'local/env_act_steps': 11059840, 'local/env_train_steps': 11057280, 'local/optimizer_steps': 17276, 'local/running_reward': 10014.114583333334, 'local/running_step': 1587.963756127451, 'local/steps_done': 11059840, 'local/episodes_done': 2439, 'local/unclipped_grad_norm': 0.5696191744735608, 'local/model_version': 17276, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:20,664] {'global/mean_episode_return': 19922.222222222223, 'global/mean_episode_step': 3149.8888888888887, 'global/SPS': 3132.0701864806715, 'global/env_act_steps': 11054336, 'global/env_train_steps': 11049600, 'global/optimizer_steps': 17265, 'global/running_reward': 10067.259064885497, 'global/running_step': 1599.886092557252, 'global/steps_done': 11054336, 'global/episodes_done': 2439, 'global/unclipped_grad_norm': 0.5467194704985132, 'global/model_version': 17265, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:30,686] calculate_sps 32640 steps in 10.0226
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:30,686] calculate_sps 35200 steps in 10.0226
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:30,686] {'local/mean_episode_return': 15675.0, 'local/mean_episode_step': 2529.0, 'local/SPS': 3256.6366059178777, 'local/env_act_steps': 11093120, 'local/env_train_steps': 11089920, 'local/optimizer_steps': 17328, 'local/running_reward': 10373.13701923077, 'local/running_step': 1617.4310697115384, 'local/steps_done': 11093120, 'local/episodes_done': 2447, 'local/unclipped_grad_norm': 0.6256783171915091, 'local/model_version': 17328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:30,687] {'global/mean_episode_return': 15675.0, 'global/mean_episode_step': 2529.0, 'global/SPS': 3512.0590848133975, 'global/env_act_steps': 11087360, 'global/env_train_steps': 11084800, 'global/optimizer_steps': 17320, 'global/running_reward': 10284.332606589147, 'global/running_step': 1609.0706153100775, 'global/steps_done': 11087360, 'global/episodes_done': 2447, 'global/unclipped_grad_norm': 0.6061499993909489, 'global/model_version': 17320, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:40,701] calculate_sps 31360 steps in 10.0151
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:40,703] calculate_sps 31360 steps in 10.0151
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:40,703] {'local/mean_episode_return': 18131.57894736842, 'local/mean_episode_step': 2874.8684210526317, 'local/SPS': 3131.275953298263, 'local/env_act_steps': 11125888, 'local/env_train_steps': 11121280, 'local/optimizer_steps': 17376, 'local/running_reward': 10352.252197265625, 'local/running_step': 1583.8138732910156, 'local/steps_done': 11125888, 'local/episodes_done': 2470, 'local/unclipped_grad_norm': 0.6304772558311621, 'local/model_version': 17376, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:40,704] {'global/mean_episode_return': 19533.333333333332, 'global/mean_episode_step': 3053.3333333333335, 'global/SPS': 3131.275953298263, 'global/env_act_steps': 11120896, 'global/env_train_steps': 11116160, 'global/optimizer_steps': 17368, 'global/running_reward': 10415.082299618321, 'global/running_step': 1597.4960639312976, 'global/steps_done': 11120896, 'global/episodes_done': 2464, 'global/unclipped_grad_norm': 0.6791891884058714, 'global/model_version': 17368, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:50,708] calculate_sps 35200 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:12:50,708] calculate_sps 35200 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:50,708] {'local/mean_episode_return': 18980.76923076923, 'local/mean_episode_step': 2898.096153846154, 'local/SPS': 3517.235053201338, 'local/env_act_steps': 11157504, 'local/env_train_steps': 11156480, 'local/optimizer_steps': 17431, 'local/running_reward': 9484.647014170041, 'local/running_step': 1448.1879428137652, 'local/steps_done': 11157504, 'local/episodes_done': 2498, 'local/unclipped_grad_norm': 0.5593049537051807, 'local/model_version': 17431, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:12:50,709] {'global/mean_episode_return': 17929.62962962963, 'global/mean_episode_step': 2787.1111111111113, 'global/SPS': 3517.235053201338, 'global/env_act_steps': 11152384, 'global/env_train_steps': 11151360, 'global/optimizer_steps': 17423, 'global/running_reward': 9738.646468495936, 'global/running_step': 1482.2975419207316, 'global/steps_done': 11152384, 'global/episodes_done': 2495, 'global/unclipped_grad_norm': 0.5689625114202499, 'global/model_version': 17423, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:00,728] calculate_sps 30720 steps in 10.0197
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:00,729] calculate_sps 30720 steps in 10.0197
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:00,729] {'local/mean_episode_return': 18329.166666666668, 'local/mean_episode_step': 2829.7083333333335, 'local/SPS': 3065.9606998667173, 'local/env_act_steps': 11191040, 'local/env_train_steps': 11187200, 'local/optimizer_steps': 17480, 'local/running_reward': 7756.57800572519, 'local/running_step': 1212.1165314885495, 'local/steps_done': 11191040, 'local/episodes_done': 2522, 'local/unclipped_grad_norm': 0.5860181426515385, 'local/model_version': 17480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:00,739] {'global/mean_episode_return': 18548.14814814815, 'global/mean_episode_step': 2845.703703703704, 'global/SPS': 3065.9606998667173, 'global/env_act_steps': 11186304, 'global/env_train_steps': 11182080, 'global/optimizer_steps': 17472, 'global/running_reward': 7904.398584905661, 'global/running_step': 1234.1813384433963, 'global/steps_done': 11186304, 'global/episodes_done': 2522, 'global/unclipped_grad_norm': 0.5690109510811008, 'global/model_version': 17472, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:10,746] calculate_sps 33280 steps in 10.0184
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:10,747] calculate_sps 33920 steps in 10.0184
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:10,747] {'local/mean_episode_return': 17207.69230769231, 'local/mean_episode_step': 2704.5384615384614, 'local/SPS': 3321.872958759414, 'local/env_act_steps': 11223552, 'local/env_train_steps': 11220480, 'local/optimizer_steps': 17531, 'local/running_reward': 7509.073572834645, 'local/running_step': 1163.5907357283465, 'local/steps_done': 11223552, 'local/episodes_done': 2535, 'local/unclipped_grad_norm': 0.6014540595751182, 'local/model_version': 17531, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:10,748] {'global/mean_episode_return': 17207.69230769231, 'global/mean_episode_step': 2704.5384615384614, 'global/SPS': 3385.755131043249, 'global/env_act_steps': 11218560, 'global/env_train_steps': 11216000, 'global/optimizer_steps': 17524, 'global/running_reward': 7500.886656746032, 'global/running_step': 1165.424107142857, 'global/steps_done': 11218560, 'global/episodes_done': 2535, 'global/unclipped_grad_norm': 0.5789865410098662, 'global/model_version': 17524, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:20,768] calculate_sps 33280 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:20,768] calculate_sps 32640 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:20,769] {'local/mean_episode_return': 15757.142857142857, 'local/mean_episode_step': 2513.1666666666665, 'local/SPS': 3320.936672220418, 'local/env_act_steps': 11256320, 'local/env_train_steps': 11253760, 'local/optimizer_steps': 17584, 'local/running_reward': 7580.92041015625, 'local/running_step': 1152.6752014160156, 'local/steps_done': 11256320, 'local/episodes_done': 2557, 'local/unclipped_grad_norm': 0.5289519842503205, 'local/model_version': 17584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:20,770] {'global/mean_episode_return': 15475.0, 'global/mean_episode_step': 2492.5625, 'global/SPS': 3257.0725054469485, 'global/env_act_steps': 11251712, 'global/env_train_steps': 11248640, 'global/optimizer_steps': 17576, 'global/running_reward': 7627.292471042471, 'global/running_step': 1161.1896114864865, 'global/steps_done': 11251712, 'global/episodes_done': 2551, 'global/unclipped_grad_norm': 0.574088775481169, 'global/model_version': 17576, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:30,787] calculate_sps 30720 steps in 10.0192
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:30,787] calculate_sps 32000 steps in 10.0192
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:30,788] {'local/mean_episode_return': 15442.857142857143, 'local/mean_episode_step': 2373.214285714286, 'local/SPS': 3066.104572880528, 'local/env_act_steps': 11289600, 'local/env_train_steps': 11284480, 'local/optimizer_steps': 17632, 'local/running_reward': 7215.303485576923, 'local/running_step': 1094.3786057692307, 'local/steps_done': 11289600, 'local/episodes_done': 2571, 'local/unclipped_grad_norm': 0.5519936649749676, 'local/model_version': 17632, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:30,789] {'global/mean_episode_return': 16316.666666666666, 'global/mean_episode_step': 2487.8611111111113, 'global/SPS': 3193.8589300838835, 'global/env_act_steps': 11284736, 'global/env_train_steps': 11280640, 'global/optimizer_steps': 17625, 'global/running_reward': 7231.813226744186, 'global/running_step': 1097.8154069767443, 'global/steps_done': 11284736, 'global/episodes_done': 2570, 'global/unclipped_grad_norm': 0.5126310964019931, 'global/model_version': 17625, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:40,826] calculate_sps 35840 steps in 10.0389
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:40,826] calculate_sps 34560 steps in 10.0389
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:40,826] {'local/mean_episode_return': 11900.0, 'local/mean_episode_step': 2042.75, 'local/SPS': 3570.1156061278352, 'local/env_act_steps': 11321344, 'local/env_train_steps': 11320320, 'local/optimizer_steps': 17687, 'local/running_reward': 7587.815020161291, 'local/running_step': 1116.9893523185483, 'local/steps_done': 11321344, 'local/episodes_done': 2579, 'local/unclipped_grad_norm': 0.6831519441171126, 'local/model_version': 17687, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:40,827] {'global/mean_episode_return': 11222.222222222223, 'global/mean_episode_step': 1964.5555555555557, 'global/SPS': 3442.6114773375552, 'global/env_act_steps': 11317248, 'global/env_train_steps': 11315200, 'global/optimizer_steps': 17680, 'global/running_reward': 7488.308932086614, 'global/running_step': 1108.6863312007874, 'global/steps_done': 11317248, 'global/episodes_done': 2579, 'global/unclipped_grad_norm': 0.6770704860037023, 'global/model_version': 17680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:50,842] calculate_sps 30720 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:13:50,842] calculate_sps 31360 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:50,843] {'local/mean_episode_return': 17311.11111111111, 'local/mean_episode_step': 2585.222222222222, 'local/SPS': 3067.116296723445, 'local/env_act_steps': 11355136, 'local/env_train_steps': 11351040, 'local/optimizer_steps': 17736, 'local/running_reward': 8229.444839015152, 'local/running_step': 1185.3781960227273, 'local/steps_done': 11355136, 'local/episodes_done': 2588, 'local/unclipped_grad_norm': 0.697722294500896, 'local/model_version': 17736, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:13:50,844] {'global/mean_episode_return': 17311.11111111111, 'global/mean_episode_step': 2585.222222222222, 'global/SPS': 3131.0145529051833, 'global/env_act_steps': 11351168, 'global/env_train_steps': 11346560, 'global/optimizer_steps': 17728, 'global/running_reward': 8181.0259433962265, 'global/running_step': 1180.3522405660378, 'global/steps_done': 11351168, 'global/episodes_done': 2588, 'global/unclipped_grad_norm': 0.6844706305613121, 'global/model_version': 17728, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:00,855] calculate_sps 33920 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:00,855] calculate_sps 35200 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:00,856] {'local/mean_episode_return': 14384.615384615385, 'local/mean_episode_step': 2163.153846153846, 'local/SPS': 3387.3795582793064, 'local/env_act_steps': 11387520, 'local/env_train_steps': 11384960, 'local/optimizer_steps': 17788, 'local/running_reward': 8568.064476284584, 'local/running_step': 1212.2541069664032, 'local/steps_done': 11387520, 'local/episodes_done': 2601, 'local/unclipped_grad_norm': 0.6320802689744875, 'local/model_version': 17788, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:00,856] {'global/mean_episode_return': 14290.90909090909, 'global/mean_episode_step': 2171.090909090909, 'global/SPS': 3515.2052019879598, 'global/env_act_steps': 11383680, 'global/env_train_steps': 11381760, 'global/optimizer_steps': 17784, 'global/running_reward': 8530.957800196851, 'global/running_step': 1209.550842765748, 'global/steps_done': 11383680, 'global/episodes_done': 2599, 'global/unclipped_grad_norm': 0.6508526307131562, 'global/model_version': 17784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:10,874] calculate_sps 32640 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:10,874] calculate_sps 30720 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:10,874] {'local/mean_episode_return': 17690.909090909092, 'local/mean_episode_step': 2477.0, 'local/SPS': 3258.032112379979, 'local/env_act_steps': 11420544, 'local/env_train_steps': 11417600, 'local/optimizer_steps': 17840, 'local/running_reward': 8810.907218992248, 'local/running_step': 1235.8409641472867, 'local/steps_done': 11420544, 'local/episodes_done': 2613, 'local/unclipped_grad_norm': 0.6064279864613826, 'local/model_version': 17840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:10,887] {'global/mean_episode_return': 16890.909090909092, 'global/mean_episode_step': 2386.7272727272725, 'global/SPS': 3066.3831645929217, 'global/env_act_steps': 11417344, 'global/env_train_steps': 11412480, 'global/optimizer_steps': 17832, 'global/running_reward': 8800.83471958175, 'global/running_step': 1234.095443203422, 'global/steps_done': 11417344, 'global/episodes_done': 2610, 'global/unclipped_grad_norm': 0.6226559995363156, 'global/model_version': 17832, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:20,890] calculate_sps 31360 steps in 10.0142
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:20,890] calculate_sps 35840 steps in 10.0142
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:20,899] {'local/mean_episode_return': 21027.272727272728, 'local/mean_episode_step': 2889.181818181818, 'local/SPS': 3131.555738084091, 'local/env_act_steps': 11453696, 'local/env_train_steps': 11448960, 'local/optimizer_steps': 17888, 'local/running_reward': 8778.131032818534, 'local/running_step': 1225.796965492278, 'local/steps_done': 11453696, 'local/episodes_done': 2624, 'local/unclipped_grad_norm': 0.7501472899069389, 'local/model_version': 17888, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:20,900] {'global/mean_episode_return': 20791.666666666668, 'global/mean_episode_step': 2857.5833333333335, 'global/SPS': 3578.920843524675, 'global/env_act_steps': 11449344, 'global/env_train_steps': 11448320, 'global/optimizer_steps': 17887, 'global/running_reward': 8751.23125, 'global/running_step': 1224.7236875, 'global/steps_done': 11449344, 'global/episodes_done': 2623, 'global/unclipped_grad_norm': 0.7116531214930795, 'global/model_version': 17887, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:30,892] calculate_sps 35200 steps in 10.0041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:30,893] calculate_sps 30720 steps in 10.0041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:30,893] {'local/mean_episode_return': 17436.363636363636, 'local/mean_episode_step': 2432.181818181818, 'local/SPS': 3518.5720364283543, 'local/env_act_steps': 11485696, 'local/env_train_steps': 11484160, 'local/optimizer_steps': 17944, 'local/running_reward': 9158.35, 'local/running_step': 1251.97021875, 'local/steps_done': 11485696, 'local/episodes_done': 2635, 'local/unclipped_grad_norm': 0.6360984543072326, 'local/model_version': 17944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:30,894] {'global/mean_episode_return': 16760.0, 'global/mean_episode_step': 2377.1, 'global/SPS': 3070.7537772465635, 'global/env_act_steps': 11482880, 'global/env_train_steps': 11479040, 'global/optimizer_steps': 17936, 'global/running_reward': 9112.64909351145, 'global/running_step': 1248.4034470419847, 'global/steps_done': 11482880, 'global/episodes_done': 2633, 'global/unclipped_grad_norm': 0.6563720475046002, 'global/model_version': 17936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:40,900] calculate_sps 30720 steps in 10.0082
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:40,901] calculate_sps 33280 steps in 10.0082
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:40,901] {'local/mean_episode_return': 15325.0, 'local/mean_episode_step': 2177.625, 'local/SPS': 3069.4905769375996, 'local/env_act_steps': 11518848, 'local/env_train_steps': 11514880, 'local/optimizer_steps': 17992, 'local/running_reward': 9507.8305984556, 'local/running_step': 1287.2844172297298, 'local/steps_done': 11518848, 'local/episodes_done': 2643, 'local/unclipped_grad_norm': 0.6747804045056304, 'local/model_version': 17992, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:40,902] {'global/mean_episode_return': 18314.285714285714, 'global/mean_episode_step': 2453.714285714286, 'global/SPS': 3325.281458349066, 'global/env_act_steps': 11515520, 'global/env_train_steps': 11512320, 'global/optimizer_steps': 17988, 'global/running_reward': 9467.285539215687, 'global/running_step': 1282.541911764706, 'global/steps_done': 11515520, 'global/episodes_done': 2640, 'global/unclipped_grad_norm': 0.669523821427272, 'global/model_version': 17988, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:50,906] calculate_sps 33920 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:14:50,906] calculate_sps 33280 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:50,922] {'local/mean_episode_return': 17000.0, 'local/mean_episode_step': 2406.9444444444443, 'local/SPS': 3390.573863408607, 'local/env_act_steps': 11551488, 'local/env_train_steps': 11548800, 'local/optimizer_steps': 18044, 'local/running_reward': 10001.262254901962, 'local/running_step': 1328.3977022058823, 'local/steps_done': 11551488, 'local/episodes_done': 2653, 'local/unclipped_grad_norm': 0.6650378563656256, 'local/model_version': 18044, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:14:50,924] {'global/mean_episode_return': 16000.0, 'global/mean_episode_step': 2301.0416666666665, 'global/SPS': 3326.6007716461804, 'global/env_act_steps': 11548416, 'global/env_train_steps': 11545600, 'global/optimizer_steps': 18040, 'global/running_reward': 9957.636186770427, 'global/running_step': 1325.8640868190662, 'global/steps_done': 11548416, 'global/episodes_done': 2653, 'global/unclipped_grad_norm': 0.6567780902752509, 'global/model_version': 18040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:00,907] calculate_sps 32640 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:00,908] calculate_sps 32000 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:00,908] {'local/mean_episode_return': 18053.846153846152, 'local/mean_episode_step': 2439.769230769231, 'local/SPS': 3263.113483949909, 'local/env_act_steps': 11584256, 'local/env_train_steps': 11581440, 'local/optimizer_steps': 18096, 'local/running_reward': 10348.153686523438, 'local/running_step': 1350.2966918945312, 'local/steps_done': 11584256, 'local/episodes_done': 2666, 'local/unclipped_grad_norm': 0.7128328927434407, 'local/model_version': 18096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:00,909] {'global/mean_episode_return': 18908.333333333332, 'global/mean_episode_step': 2488.1666666666665, 'global/SPS': 3199.130866617558, 'global/env_act_steps': 11581696, 'global/env_train_steps': 11577600, 'global/optimizer_steps': 18089, 'global/running_reward': 10328.46454326923, 'global/running_step': 1349.199158653846, 'global/steps_done': 11581696, 'global/episodes_done': 2665, 'global/unclipped_grad_norm': 0.7279104249817985, 'global/model_version': 18089, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:10,939] calculate_sps 31360 steps in 10.0322
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:10,939] calculate_sps 34560 steps in 10.0322
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:10,940] {'local/mean_episode_return': 20200.0, 'local/mean_episode_step': 2665.3333333333335, 'local/SPS': 3125.9272543873913, 'local/env_act_steps': 11617408, 'local/env_train_steps': 11612800, 'local/optimizer_steps': 18144, 'local/running_reward': 10710.095921814673, 'local/running_step': 1377.4500482625483, 'local/steps_done': 11617408, 'local/episodes_done': 2672, 'local/unclipped_grad_norm': 0.6290565834691128, 'local/model_version': 18144, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:10,940] {'global/mean_episode_return': 18428.571428571428, 'global/mean_episode_step': 2550.1428571428573, 'global/SPS': 3444.899423202431, 'global/env_act_steps': 11614336, 'global/env_train_steps': 11612160, 'global/optimizer_steps': 18144, 'global/running_reward': 10657.135416666666, 'global/running_step': 1372.2998161764706, 'global/steps_done': 11614336, 'global/episodes_done': 2672, 'global/unclipped_grad_norm': 0.6224976360797883, 'global/model_version': 18144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:20,950] calculate_sps 35200 steps in 10.0108
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:20,951] calculate_sps 30720 steps in 10.0108
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:20,951] {'local/mean_episode_return': 17981.81818181818, 'local/mean_episode_step': 2341.090909090909, 'local/SPS': 3516.2144332183266, 'local/env_act_steps': 11649664, 'local/env_train_steps': 11648000, 'local/optimizer_steps': 18200, 'local/running_reward': 11197.619047619048, 'local/running_step': 1423.1023375496031, 'local/steps_done': 11649664, 'local/episodes_done': 2683, 'local/unclipped_grad_norm': 0.639905385406954, 'local/model_version': 18200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:20,963] {'global/mean_episode_return': 17981.81818181818, 'global/mean_episode_step': 2341.090909090909, 'global/SPS': 3068.696232626903, 'global/env_act_steps': 11647744, 'global/env_train_steps': 11642880, 'global/optimizer_steps': 18192, 'global/running_reward': 11169.836566091954, 'global/running_step': 1421.1939655172414, 'global/steps_done': 11647744, 'global/episodes_done': 2683, 'global/unclipped_grad_norm': 0.6516161253675818, 'global/model_version': 18192, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:30,971] calculate_sps 30720 steps in 10.0209
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:30,971] calculate_sps 34560 steps in 10.0209
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:30,972] {'local/mean_episode_return': 17383.333333333332, 'local/mean_episode_step': 2348.5555555555557, 'local/SPS': 3065.6023892704193, 'local/env_act_steps': 11682304, 'local/env_train_steps': 11678720, 'local/optimizer_steps': 18248, 'local/running_reward': 11718.74693627451, 'local/running_step': 1471.4496936274509, 'local/steps_done': 11682304, 'local/episodes_done': 2693, 'local/unclipped_grad_norm': 0.6876611957947413, 'local/model_version': 18248, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:30,973] {'global/mean_episode_return': 17806.25, 'global/mean_episode_step': 2380.625, 'global/SPS': 3448.802687929222, 'global/env_act_steps': 11679616, 'global/env_train_steps': 11677440, 'global/optimizer_steps': 18245, 'global/running_reward': 11696.115712851406, 'global/running_step': 1469.3004831827309, 'global/steps_done': 11679616, 'global/episodes_done': 2692, 'global/unclipped_grad_norm': 0.679717426030141, 'global/model_version': 18245, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:40,971] calculate_sps 32000 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:40,972] calculate_sps 32000 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:40,972] {'local/mean_episode_return': 22077.777777777777, 'local/mean_episode_step': 2709.6111111111113, 'local/SPS': 3199.927598684045, 'local/env_act_steps': 11714944, 'local/env_train_steps': 11710720, 'local/optimizer_steps': 18298, 'local/running_reward': 11670.337009803921, 'local/running_step': 1467.5718443627452, 'local/steps_done': 11714944, 'local/episodes_done': 2711, 'local/unclipped_grad_norm': 0.650572259426117, 'local/model_version': 18298, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:40,973] {'global/mean_episode_return': 20847.058823529413, 'global/mean_episode_step': 2612.1176470588234, 'global/SPS': 3199.927598684045, 'global/env_act_steps': 11712640, 'global/env_train_steps': 11709440, 'global/optimizer_steps': 18296, 'global/running_reward': 11708.187984496124, 'global/running_step': 1471.2242308624031, 'global/steps_done': 11712640, 'global/episodes_done': 2709, 'global/unclipped_grad_norm': 0.6228007095701554, 'global/model_version': 18296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:50,976] calculate_sps 34560 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:15:50,976] calculate_sps 33280 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:50,976] {'local/mean_episode_return': 21675.0, 'local/mean_episode_step': 2693.75, 'local/SPS': 3454.4467646709695, 'local/env_act_steps': 11747584, 'local/env_train_steps': 11745280, 'local/optimizer_steps': 18352, 'local/running_reward': 11145.367647058823, 'local/running_step': 1429.3717524509805, 'local/steps_done': 11747584, 'local/episodes_done': 2720, 'local/unclipped_grad_norm': 0.6020734690957599, 'local/model_version': 18352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:15:50,978] {'global/mean_episode_return': 23040.0, 'global/mean_episode_step': 2800.9, 'global/SPS': 3326.504291905378, 'global/env_act_steps': 11745792, 'global/env_train_steps': 11742720, 'global/optimizer_steps': 18347, 'global/running_reward': 11150.265444015444, 'global/running_step': 1428.0218689671815, 'global/steps_done': 11745792, 'global/episodes_done': 2720, 'global/unclipped_grad_norm': 0.646816261843139, 'global/model_version': 18347, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 12:15:52,108] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 11745792, 'env_train_steps': 11742720, 'optimizer_steps': 18347, 'running_reward': None, 'running_step': None, 'steps_done': 11745792, 'episodes_done': 2720, 'unclipped_grad_norm': None, 'model_version': 18347, 'virtual_batch_size': None, 'num_gradients': None}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 12:15:52,187] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint_v18357.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 12:15:52,194] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 11745792, 'env_train_steps': 11742720, 'optimizer_steps': 18347, 'running_reward': None, 'running_step': None, 'steps_done': 11745792, 'episodes_done': 2720, 'unclipped_grad_norm': None, 'model_version': 18347, 'virtual_batch_size': None, 'num_gradients': None}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 12:15:52,286] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:00,980] calculate_sps 30720 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:00,981] calculate_sps 33280 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:00,981] {'local/mean_episode_return': 17896.0, 'local/mean_episode_step': 2427.76, 'local/SPS': 3070.562123521135, 'local/env_act_steps': 11780224, 'local/env_train_steps': 11776000, 'local/optimizer_steps': 18400, 'local/running_reward': 10768.296568627451, 'local/running_step': 1401.699754901961, 'local/steps_done': 11780224, 'local/episodes_done': 2745, 'local/unclipped_grad_norm': 0.5857486957684159, 'local/model_version': 18400, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:00,982] {'global/mean_episode_return': 18226.08695652174, 'global/mean_episode_step': 2463.5652173913045, 'global/SPS': 3326.44230048123, 'global/env_act_steps': 11778176, 'global/env_train_steps': 11776000, 'global/optimizer_steps': 18400, 'global/running_reward': 10823.53631422925, 'global/running_step': 1407.906589673913, 'global/steps_done': 11778176, 'global/episodes_done': 2743, 'global/unclipped_grad_norm': 0.565016859263744, 'global/model_version': 18400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:10,993] calculate_sps 33920 steps in 10.0106
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:10,993] calculate_sps 30720 steps in 10.0106
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:11,001] {'local/mean_episode_return': 19640.909090909092, 'local/mean_episode_step': 2548.090909090909, 'local/SPS': 3388.4236705905587, 'local/env_act_steps': 11812608, 'local/env_train_steps': 11809920, 'local/optimizer_steps': 18452, 'local/running_reward': 9806.827445652174, 'local/running_step': 1299.0195158102767, 'local/steps_done': 11812608, 'local/episodes_done': 2768, 'local/unclipped_grad_norm': 0.5511887543476545, 'local/model_version': 18452, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:11,003] {'global/mean_episode_return': 19179.166666666668, 'global/mean_episode_step': 2503.75, 'global/SPS': 3068.761060157487, 'global/env_act_steps': 11811712, 'global/env_train_steps': 11806720, 'global/optimizer_steps': 18448, 'global/running_reward': 9850.18189408397, 'global/running_step': 1303.2364623091603, 'global/steps_done': 11811712, 'global/episodes_done': 2768, 'global/unclipped_grad_norm': 0.5467724340657393, 'global/model_version': 18448, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:21,018] calculate_sps 32640 steps in 10.0273
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:21,019] calculate_sps 35840 steps in 10.0273
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:21,030] {'local/mean_episode_return': 17125.0, 'local/mean_episode_step': 2283.9375, 'local/SPS': 3255.099105560402, 'local/env_act_steps': 11845248, 'local/env_train_steps': 11842560, 'local/optimizer_steps': 18504, 'local/running_reward': 9008.523284313726, 'local/running_step': 1222.5095894607844, 'local/steps_done': 11845248, 'local/episodes_done': 2784, 'local/unclipped_grad_norm': 0.5562235165673953, 'local/model_version': 18504, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:21,032] {'global/mean_episode_return': 17125.0, 'global/mean_episode_step': 2283.9375, 'global/SPS': 3574.2264688506375, 'global/env_act_steps': 11843712, 'global/env_train_steps': 11842560, 'global/optimizer_steps': 18504, 'global/running_reward': 9016.9875, 'global/running_step': 1223.14546875, 'global/steps_done': 11843712, 'global/episodes_done': 2784, 'global/unclipped_grad_norm': 0.5596493080790553, 'global/model_version': 18504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:31,019] calculate_sps 30720 steps in 10
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:31,019] calculate_sps 30720 steps in 10
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:31,019] {'local/mean_episode_return': 18271.428571428572, 'local/mean_episode_step': 2430.035714285714, 'local/SPS': 3071.99663086307, 'local/env_act_steps': 11878016, 'local/env_train_steps': 11873280, 'local/optimizer_steps': 18552, 'local/running_reward': 9063.150024414062, 'local/running_step': 1229.4642639160156, 'local/steps_done': 11878016, 'local/episodes_done': 2799, 'local/unclipped_grad_norm': 0.6254382077604532, 'local/model_version': 18552, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:31,021] {'global/mean_episode_return': 18261.53846153846, 'global/mean_episode_step': 2429.3076923076924, 'global/SPS': 3071.99663086307, 'global/env_act_steps': 11876992, 'global/env_train_steps': 11873280, 'global/optimizer_steps': 18552, 'global/running_reward': 9059.221754807691, 'global/running_step': 1229.263701923077, 'global/steps_done': 11876992, 'global/episodes_done': 2797, 'global/unclipped_grad_norm': 0.6254382077604532, 'global/model_version': 18552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:41,061] calculate_sps 35840 steps in 10.043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:41,061] calculate_sps 33280 steps in 10.043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:41,061] {'local/mean_episode_return': 19561.53846153846, 'local/mean_episode_step': 2500.846153846154, 'local/SPS': 3568.668006750383, 'local/env_act_steps': 11910144, 'local/env_train_steps': 11909120, 'local/optimizer_steps': 18607, 'local/running_reward': 8890.540961155379, 'local/running_step': 1199.3784860557769, 'local/steps_done': 11910144, 'local/episodes_done': 2812, 'local/unclipped_grad_norm': 0.6866854039105502, 'local/model_version': 18607, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:41,062] {'global/mean_episode_return': 19478.571428571428, 'global/mean_episode_step': 2496.464285714286, 'global/SPS': 3313.7631491253555, 'global/env_act_steps': 11909632, 'global/env_train_steps': 11906560, 'global/optimizer_steps': 18603, 'global/running_reward': 8893.949142156862, 'global/running_step': 1199.9189644607843, 'global/steps_done': 11909632, 'global/episodes_done': 2812, 'global/unclipped_grad_norm': 0.7023971355428883, 'global/model_version': 18603, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:51,072] calculate_sps 30720 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:16:51,073] calculate_sps 33280 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:51,073] {'local/mean_episode_return': 18171.428571428572, 'local/mean_episode_step': 2342.5714285714284, 'local/SPS': 3068.625268989023, 'local/env_act_steps': 11943296, 'local/env_train_steps': 11939840, 'local/optimizer_steps': 18656, 'local/running_reward': 9111.513634169884, 'local/running_step': 1239.339255550193, 'local/steps_done': 11943296, 'local/episodes_done': 2819, 'local/unclipped_grad_norm': 0.517127195487217, 'local/model_version': 18656, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:16:51,074] {'global/mean_episode_return': 18171.428571428572, 'global/mean_episode_step': 2342.5714285714284, 'global/SPS': 3324.3440414047745, 'global/env_act_steps': 11942528, 'global/env_train_steps': 11939840, 'global/optimizer_steps': 18656, 'global/running_reward': 9104.778696498055, 'global/running_step': 1238.096060311284, 'global/steps_done': 11942528, 'global/episodes_done': 2819, 'global/unclipped_grad_norm': 0.5148052053069169, 'global/model_version': 18656, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:01,090] calculate_sps 32000 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:01,090] calculate_sps 30720 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:01,090] {'local/mean_episode_return': 20185.714285714286, 'local/mean_episode_step': 2599.714285714286, 'local/SPS': 3194.2477245538, 'local/env_act_steps': 11975936, 'local/env_train_steps': 11971840, 'local/optimizer_steps': 18705, 'local/running_reward': 9043.955269607843, 'local/running_step': 1247.755912990196, 'local/steps_done': 11975936, 'local/episodes_done': 2834, 'local/unclipped_grad_norm': 0.647794558685653, 'local/model_version': 18705, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:01,091] {'global/mean_episode_return': 20185.714285714286, 'global/mean_episode_step': 2599.714285714286, 'global/SPS': 3066.4778155716476, 'global/env_act_steps': 11975808, 'global/env_train_steps': 11970560, 'global/optimizer_steps': 18704, 'global/running_reward': 9048.629807692309, 'global/running_step': 1248.1985276442308, 'global/steps_done': 11975808, 'global/episodes_done': 2834, 'global/unclipped_grad_norm': 0.6470413996527592, 'global/model_version': 18704, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:11,118] calculate_sps 34560 steps in 10.0275
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:11,118] calculate_sps 35840 steps in 10.0275
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:11,119] {'local/mean_episode_return': 20057.14285714286, 'local/mean_episode_step': 2635.1428571428573, 'local/SPS': 3446.5330746413147, 'local/env_act_steps': 12008448, 'local/env_train_steps': 12006400, 'local/optimizer_steps': 18760, 'local/running_reward': 9129.213828740158, 'local/running_step': 1281.6406557578741, 'local/steps_done': 12008448, 'local/episodes_done': 2841, 'local/unclipped_grad_norm': 0.6570574952797457, 'local/model_version': 18760, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:11,120] {'global/mean_episode_return': 20057.14285714286, 'global/mean_episode_step': 2635.1428571428573, 'global/SPS': 3574.1824477761784, 'global/env_act_steps': 12008192, 'global/env_train_steps': 12006400, 'global/optimizer_steps': 18760, 'global/running_reward': 9128.847579051384, 'global/running_step': 1281.410542243083, 'global/steps_done': 12008192, 'global/episodes_done': 2841, 'global/unclipped_grad_norm': 0.6575376505830458, 'global/model_version': 18760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:21,150] calculate_sps 30720 steps in 10.0321
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:21,150] calculate_sps 30720 steps in 10.0321
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:21,150] {'local/mean_episode_return': 20062.5, 'local/mean_episode_step': 2688.0625, 'local/SPS': 3062.1720454716406, 'local/env_act_steps': 12041856, 'local/env_train_steps': 12037120, 'local/optimizer_steps': 18808, 'local/running_reward': 9013.466834291188, 'local/running_step': 1282.9005926724137, 'local/steps_done': 12041856, 'local/episodes_done': 2857, 'local/unclipped_grad_norm': 0.6129489919791619, 'local/model_version': 18808, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:21,152] {'global/mean_episode_return': 20062.5, 'global/mean_episode_step': 2688.0625, 'global/SPS': 3062.1720454716406, 'global/env_act_steps': 12041728, 'global/env_train_steps': 12037120, 'global/optimizer_steps': 18808, 'global/running_reward': 9017.974713740457, 'global/running_step': 1283.257693225191, 'global/steps_done': 12041728, 'global/episodes_done': 2857, 'global/unclipped_grad_norm': 0.6129489919791619, 'global/model_version': 18808, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:31,151] calculate_sps 34560 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:31,151] calculate_sps 26240 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:31,151] {'local/mean_episode_return': 18500.0, 'local/mean_episode_step': 2489.0, 'local/SPS': 3455.623731766153, 'local/env_act_steps': 12073728, 'local/env_train_steps': 12071680, 'local/optimizer_steps': 18861, 'local/running_reward': 8811.458333333334, 'local/running_step': 1270.6025037650602, 'local/steps_done': 12073728, 'local/episodes_done': 2868, 'local/unclipped_grad_norm': 0.5878902274482655, 'local/model_version': 18861, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:31,152] {'global/mean_episode_return': 19390.0, 'global/mean_episode_step': 2563.7, 'global/SPS': 2623.7143148594864, 'global/env_act_steps': 12067968, 'global/env_train_steps': 12063360, 'global/optimizer_steps': 18848, 'global/running_reward': 8801.684451219513, 'global/running_step': 1269.0390625, 'global/steps_done': 12067968, 'global/episodes_done': 2867, 'global/unclipped_grad_norm': 0.5773003384470939, 'global/model_version': 18848, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:41,183] calculate_sps 32000 steps in 10.0319
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:41,183] calculate_sps 35200 steps in 10.0319
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:41,184] {'local/mean_episode_return': 20337.5, 'local/mean_episode_step': 2749.25, 'local/SPS': 3189.816825791439, 'local/env_act_steps': 12106752, 'local/env_train_steps': 12103680, 'local/optimizer_steps': 18912, 'local/running_reward': 9256.47710755814, 'local/running_step': 1327.0379118217054, 'local/steps_done': 12106752, 'local/episodes_done': 2876, 'local/unclipped_grad_norm': 0.6348623113304961, 'local/model_version': 18912, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:41,185] {'global/mean_episode_return': 16200.0, 'global/mean_episode_step': 2389.0, 'global/SPS': 3508.7985083705826, 'global/env_act_steps': 12100352, 'global/env_train_steps': 12098560, 'global/optimizer_steps': 18904, 'global/running_reward': 9149.895009881422, 'global/running_step': 1314.9943799407115, 'global/steps_done': 12100352, 'global/episodes_done': 2871, 'global/unclipped_grad_norm': 0.6438549379152911, 'global/model_version': 18904, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:51,206] calculate_sps 32000 steps in 10.0227
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:17:51,206] calculate_sps 30720 steps in 10.0227
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:51,206] {'local/mean_episode_return': 19321.428571428572, 'local/mean_episode_step': 2536.714285714286, 'local/SPS': 3192.760479797574, 'local/env_act_steps': 12139904, 'local/env_train_steps': 12135680, 'local/optimizer_steps': 18962, 'local/running_reward': 9337.931346525096, 'local/running_step': 1323.4343026061777, 'local/steps_done': 12139904, 'local/episodes_done': 2890, 'local/unclipped_grad_norm': 0.7283995795249939, 'local/model_version': 18962, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:17:51,208] {'global/mean_episode_return': 20225.0, 'global/mean_episode_step': 2655.0, 'global/SPS': 3065.050060605671, 'global/env_act_steps': 12133888, 'global/env_train_steps': 12129280, 'global/optimizer_steps': 18952, 'global/running_reward': 9342.578125, 'global/running_step': 1326.7296636450383, 'global/steps_done': 12133888, 'global/episodes_done': 2887, 'global/unclipped_grad_norm': 0.7016711588948965, 'global/model_version': 18952, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:01,218] calculate_sps 34560 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:01,218] calculate_sps 35840 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:01,218] {'local/mean_episode_return': 20683.333333333332, 'local/mean_episode_step': 2683.8333333333335, 'local/SPS': 3451.764858171196, 'local/env_act_steps': 12172032, 'local/env_train_steps': 12170240, 'local/optimizer_steps': 19016, 'local/running_reward': 9111.535109561753, 'local/running_step': 1285.7639753486055, 'local/steps_done': 12172032, 'local/episodes_done': 2906, 'local/unclipped_grad_norm': 0.7231425883041488, 'local/model_version': 19016, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:01,220] {'global/mean_episode_return': 20906.666666666668, 'global/mean_episode_step': 2682.733333333333, 'global/SPS': 3579.6080010664255, 'global/env_act_steps': 12166144, 'global/env_train_steps': 12165120, 'global/optimizer_steps': 19007, 'global/running_reward': 9165.488591269841, 'global/running_step': 1294.1483134920634, 'global/steps_done': 12166144, 'global/episodes_done': 2902, 'global/unclipped_grad_norm': 0.7206295335834677, 'global/model_version': 19007, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:11,252] calculate_sps 30720 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:11,253] calculate_sps 30720 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:11,253] {'local/mean_episode_return': 14350.0, 'local/mean_episode_step': 2219.25, 'local/SPS': 3061.400686657088, 'local/env_act_steps': 12205440, 'local/env_train_steps': 12200960, 'local/optimizer_steps': 19064, 'local/running_reward': 9588.35308908046, 'local/running_step': 1323.703783524904, 'local/steps_done': 12205440, 'local/episodes_done': 2910, 'local/unclipped_grad_norm': 0.637515782378614, 'local/model_version': 19064, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:11,254] {'global/mean_episode_return': 15441.666666666666, 'global/mean_episode_step': 2281.25, 'global/SPS': 3061.400686657088, 'global/env_act_steps': 12199936, 'global/env_train_steps': 12195840, 'global/optimizer_steps': 19056, 'global/running_reward': 9430.977746212122, 'global/running_step': 1308.8520063920455, 'global/steps_done': 12199936, 'global/episodes_done': 2909, 'global/unclipped_grad_norm': 0.6917686693522395, 'global/model_version': 19056, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:21,295] calculate_sps 35200 steps in 10.0425
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:21,295] calculate_sps 34560 steps in 10.0425
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:21,295] {'local/mean_episode_return': 20912.5, 'local/mean_episode_step': 2729.5, 'local/SPS': 3505.1127075365994, 'local/env_act_steps': 12237696, 'local/env_train_steps': 12236160, 'local/optimizer_steps': 19118, 'local/running_reward': 10053.738839285714, 'local/running_step': 1363.5537574404761, 'local/steps_done': 12237696, 'local/episodes_done': 2926, 'local/unclipped_grad_norm': 0.6752192378044128, 'local/model_version': 19118, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:21,296] {'global/mean_episode_return': 21353.846153846152, 'global/mean_episode_step': 2764.3846153846152, 'global/SPS': 3441.3833855813887, 'global/env_act_steps': 12232448, 'global/env_train_steps': 12230400, 'global/optimizer_steps': 19109, 'global/running_reward': 10083.686023622047, 'global/running_step': 1369.0161171259842, 'global/steps_done': 12232448, 'global/episodes_done': 2922, 'global/unclipped_grad_norm': 0.627021424331755, 'global/model_version': 19109, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:31,320] calculate_sps 31360 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:31,320] calculate_sps 32000 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:31,321] {'local/mean_episode_return': 18385.714285714286, 'local/mean_episode_step': 2498.5714285714284, 'local/SPS': 3128.1044579827008, 'local/env_act_steps': 12270720, 'local/env_train_steps': 12267520, 'local/optimizer_steps': 19168, 'local/running_reward': 9942.002785852714, 'local/running_step': 1336.6231528585272, 'local/steps_done': 12270720, 'local/episodes_done': 2940, 'local/unclipped_grad_norm': 0.7461813771724701, 'local/model_version': 19168, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:31,322] {'global/mean_episode_return': 18600.0, 'global/mean_episode_step': 2534.375, 'global/SPS': 3191.943324472144, 'global/env_act_steps': 12265344, 'global/env_train_steps': 12262400, 'global/optimizer_steps': 19160, 'global/running_reward': 9951.68409533074, 'global/running_step': 1339.6913910505837, 'global/steps_done': 12265344, 'global/episodes_done': 2938, 'global/unclipped_grad_norm': 0.7408578319876802, 'global/model_version': 19160, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:41,366] calculate_sps 32640 steps in 10.0458
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:41,366] calculate_sps 32640 steps in 10.0458
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:41,366] {'local/mean_episode_return': 20909.090909090908, 'local/mean_episode_step': 2755.5454545454545, 'local/SPS': 3249.108017361792, 'local/env_act_steps': 12303744, 'local/env_train_steps': 12300160, 'local/optimizer_steps': 19218, 'local/running_reward': 9922.202034883721, 'local/running_step': 1323.1410489341085, 'local/steps_done': 12303744, 'local/episodes_done': 2951, 'local/unclipped_grad_norm': 0.6863504183292389, 'local/model_version': 19218, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:41,367] {'global/mean_episode_return': 20209.090909090908, 'global/mean_episode_step': 2672.181818181818, 'global/SPS': 3249.108017361792, 'global/env_act_steps': 12298624, 'global/env_train_steps': 12295040, 'global/optimizer_steps': 19210, 'global/running_reward': 9877.496995192309, 'global/running_step': 1320.0008713942307, 'global/steps_done': 12298624, 'global/episodes_done': 2949, 'global/unclipped_grad_norm': 0.7102771866321563, 'global/model_version': 19210, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:51,376] calculate_sps 33920 steps in 10.0095
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:18:51,376] calculate_sps 33920 steps in 10.0095
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:51,376] {'local/mean_episode_return': 16820.0, 'local/mean_episode_step': 2314.0, 'local/SPS': 3388.786622487317, 'local/env_act_steps': 12336256, 'local/env_train_steps': 12334080, 'local/optimizer_steps': 19272, 'local/running_reward': 10380.779404527559, 'local/running_step': 1365.7528912401574, 'local/steps_done': 12336256, 'local/episodes_done': 2956, 'local/unclipped_grad_norm': 0.7601569107285252, 'local/model_version': 19272, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:18:51,378] {'global/mean_episode_return': 17771.428571428572, 'global/mean_episode_step': 2438.8571428571427, 'global/SPS': 3388.786622487317, 'global/env_act_steps': 12331648, 'global/env_train_steps': 12328960, 'global/optimizer_steps': 19264, 'global/running_reward': 10294.779554263567, 'global/running_step': 1356.2923934108528, 'global/steps_done': 12331648, 'global/episodes_done': 2956, 'global/unclipped_grad_norm': 0.749892293854996, 'global/model_version': 19264, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:01,384] calculate_sps 30720 steps in 10.0086
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:01,384] calculate_sps 31360 steps in 10.0086
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:01,385] {'local/mean_episode_return': 19609.090909090908, 'local/mean_episode_step': 2576.2727272727275, 'local/SPS': 3069.3543556208906, 'local/env_act_steps': 12369408, 'local/env_train_steps': 12364800, 'local/optimizer_steps': 19320, 'local/running_reward': 10905.694980694981, 'local/running_step': 1415.5526966698842, 'local/steps_done': 12369408, 'local/episodes_done': 2967, 'local/unclipped_grad_norm': 0.7242925850053629, 'local/model_version': 19320, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:01,391] {'global/mean_episode_return': 19650.0, 'global/mean_episode_step': 2574.2, 'global/SPS': 3133.299238029659, 'global/env_act_steps': 12365056, 'global/env_train_steps': 12360320, 'global/optimizer_steps': 19312, 'global/running_reward': 10849.158884099617, 'global/running_step': 1411.837943007663, 'global/steps_done': 12365056, 'global/episodes_done': 2966, 'global/unclipped_grad_norm': 0.7140808198601007, 'global/model_version': 19312, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:11,415] calculate_sps 35840 steps in 10.0314
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:11,415] calculate_sps 35200 steps in 10.0314
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:11,416] {'local/mean_episode_return': 16700.0, 'local/mean_episode_step': 2374.6666666666665, 'local/SPS': 3572.767977107492, 'local/env_act_steps': 12401664, 'local/env_train_steps': 12400640, 'local/optimizer_steps': 19375, 'local/running_reward': 11362.251984126984, 'local/running_step': 1448.7342819940477, 'local/steps_done': 12401664, 'local/episodes_done': 2976, 'local/unclipped_grad_norm': 0.7077496742660349, 'local/model_version': 19375, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:11,416] {'global/mean_episode_return': 17211.11111111111, 'global/mean_episode_step': 2418.6666666666665, 'global/SPS': 3508.968548944858, 'global/env_act_steps': 12397440, 'global/env_train_steps': 12395520, 'global/optimizer_steps': 19368, 'global/running_reward': 11297.137475296442, 'global/running_step': 1443.7426815711462, 'global/steps_done': 12397440, 'global/episodes_done': 2975, 'global/unclipped_grad_norm': 0.6826387752911874, 'global/model_version': 19368, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:21,438] calculate_sps 30720 steps in 10.0225
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:21,439] calculate_sps 30720 steps in 10.0225
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:21,439] {'local/mean_episode_return': 20278.571428571428, 'local/mean_episode_step': 2633.285714285714, 'local/SPS': 3065.089214400591, 'local/env_act_steps': 12435072, 'local/env_train_steps': 12431360, 'local/optimizer_steps': 19424, 'local/running_reward': 11551.894755747126, 'local/running_step': 1459.8266283524904, 'local/steps_done': 12435072, 'local/episodes_done': 2990, 'local/unclipped_grad_norm': 0.7573338975103534, 'local/model_version': 19424, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:21,440] {'global/mean_episode_return': 19878.571428571428, 'global/mean_episode_step': 2599.714285714286, 'global/SPS': 3065.089214400591, 'global/env_act_steps': 12430976, 'global/env_train_steps': 12426240, 'global/optimizer_steps': 19416, 'global/running_reward': 11556.327528625954, 'global/running_step': 1460.9907562022902, 'global/steps_done': 12430976, 'global/episodes_done': 2989, 'global/unclipped_grad_norm': 0.7949490556493402, 'global/model_version': 19416, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:31,485] calculate_sps 33280 steps in 10.0472
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:31,485] calculate_sps 35840 steps in 10.0472
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:31,485] {'local/mean_episode_return': 21500.0, 'local/mean_episode_step': 2597.625, 'local/SPS': 3312.361401402646, 'local/env_act_steps': 12467712, 'local/env_train_steps': 12464640, 'local/optimizer_steps': 19475, 'local/running_reward': 11807.791053921568, 'local/running_step': 1484.8737132352942, 'local/steps_done': 12467712, 'local/episodes_done': 2998, 'local/unclipped_grad_norm': 0.6789115053765914, 'local/model_version': 19475, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:31,487] {'global/mean_episode_return': 21355.555555555555, 'global/mean_episode_step': 2605.777777777778, 'global/SPS': 3567.1584322797726, 'global/env_act_steps': 12463360, 'global/env_train_steps': 12462080, 'global/optimizer_steps': 19472, 'global/running_reward': 11760.900444664032, 'global/running_step': 1479.900660820158, 'global/steps_done': 12463360, 'global/episodes_done': 2998, 'global/unclipped_grad_norm': 0.6646491677633354, 'global/model_version': 19472, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:41,496] calculate_sps 33280 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:41,497] calculate_sps 30720 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:41,497] {'local/mean_episode_return': 21480.0, 'local/mean_episode_step': 2694.3, 'local/SPS': 3324.34554566337, 'local/env_act_steps': 12500480, 'local/env_train_steps': 12497920, 'local/optimizer_steps': 19528, 'local/running_reward': 12011.749267578125, 'local/running_step': 1508.5801696777344, 'local/steps_done': 12500480, 'local/episodes_done': 3008, 'local/unclipped_grad_norm': 0.7059585845695352, 'local/model_version': 19528, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:41,498] {'global/mean_episode_return': 22225.0, 'global/mean_episode_step': 2738.0, 'global/SPS': 3068.6266575354184, 'global/env_act_steps': 12497280, 'global/env_train_steps': 12492800, 'global/optimizer_steps': 19520, 'global/running_reward': 11978.443396226416, 'global/running_step': 1504.585554245283, 'global/steps_done': 12497280, 'global/episodes_done': 3006, 'global/unclipped_grad_norm': 0.7361919668813547, 'global/model_version': 19520, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:51,520] calculate_sps 31360 steps in 10.0239
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:19:51,520] calculate_sps 35840 steps in 10.0239
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:51,520] {'local/mean_episode_return': 19750.0, 'local/mean_episode_step': 2576.125, 'local/SPS': 3128.514337494795, 'local/env_act_steps': 12533888, 'local/env_train_steps': 12529280, 'local/optimizer_steps': 19576, 'local/running_reward': 12483.438098659004, 'local/running_step': 1559.6405950670498, 'local/steps_done': 12533888, 'local/episodes_done': 3016, 'local/unclipped_grad_norm': 0.7318486422300339, 'local/model_version': 19576, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:19:51,521] {'global/mean_episode_return': 20025.0, 'global/mean_episode_step': 2576.125, 'global/SPS': 3575.4449571369087, 'global/env_act_steps': 12529664, 'global/env_train_steps': 12528640, 'global/optimizer_steps': 19575, 'global/running_reward': 12434.21442687747, 'global/running_step': 1554.9258584486165, 'global/steps_done': 12529664, 'global/episodes_done': 3014, 'global/unclipped_grad_norm': 0.7163903756575151, 'global/model_version': 19575, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:01,538] calculate_sps 35200 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:01,538] calculate_sps 30720 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:01,538] {'local/mean_episode_return': 22809.090909090908, 'local/mean_episode_step': 2889.818181818182, 'local/SPS': 3513.7135558380214, 'local/env_act_steps': 12565504, 'local/env_train_steps': 12564480, 'local/optimizer_steps': 19631, 'local/running_reward': 12690.982413967611, 'local/running_step': 1569.0278656376518, 'local/steps_done': 12565504, 'local/episodes_done': 3027, 'local/unclipped_grad_norm': 0.7167623609304428, 'local/model_version': 19631, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:01,539] {'global/mean_episode_return': 21976.923076923078, 'global/mean_episode_step': 2832.846153846154, 'global/SPS': 3066.513648731364, 'global/env_act_steps': 12563200, 'global/env_train_steps': 12559360, 'global/optimizer_steps': 19624, 'global/running_reward': 12683.692151717558, 'global/running_step': 1569.6966841603053, 'global/steps_done': 12563200, 'global/episodes_done': 3027, 'global/unclipped_grad_norm': 0.7224631166579772, 'global/model_version': 19624, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:11,567] calculate_sps 30720 steps in 10.0287
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:11,567] calculate_sps 32640 steps in 10.0287
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:11,567] {'local/mean_episode_return': 21470.833333333332, 'local/mean_episode_step': 2789.625, 'local/SPS': 3063.2165673516824, 'local/env_act_steps': 12598656, 'local/env_train_steps': 12595200, 'local/optimizer_steps': 19680, 'local/running_reward': 12831.482263513513, 'local/running_step': 1570.726472007722, 'local/steps_done': 12598656, 'local/episodes_done': 3040, 'local/unclipped_grad_norm': 0.6601913547029301, 'local/model_version': 19680, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:11,569] {'global/mean_episode_return': 21470.833333333332, 'global/mean_episode_step': 2789.625, 'global/SPS': 3254.667602811163, 'global/env_act_steps': 12595712, 'global/env_train_steps': 12592000, 'global/optimizer_steps': 19674, 'global/running_reward': 12832.63718011811, 'global/running_step': 1572.103592519685, 'global/steps_done': 12595712, 'global/episodes_done': 3040, 'global/unclipped_grad_norm': 0.6754958975315094, 'global/model_version': 19674, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:21,614] calculate_sps 32000 steps in 10.0478
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:21,614] calculate_sps 33920 steps in 10.0478
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:21,615] {'local/mean_episode_return': 23377.777777777777, 'local/mean_episode_step': 2929.5555555555557, 'local/SPS': 3184.7822633431456, 'local/env_act_steps': 12631296, 'local/env_train_steps': 12627200, 'local/optimizer_steps': 19729, 'local/running_reward': 12817.50612745098, 'local/running_step': 1564.6098039215685, 'local/steps_done': 12631296, 'local/episodes_done': 3049, 'local/unclipped_grad_norm': 0.6399429361430966, 'local/model_version': 19729, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:21,616] {'global/mean_episode_return': 23175.0, 'global/mean_episode_step': 2894.625, 'global/SPS': 3375.869199143734, 'global/env_act_steps': 12628096, 'global/env_train_steps': 12625920, 'global/optimizer_steps': 19728, 'global/running_reward': 12788.148468379446, 'global/running_step': 1560.9487092391305, 'global/steps_done': 12628096, 'global/episodes_done': 3048, 'global/unclipped_grad_norm': 0.6332972016599443, 'global/model_version': 19728, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:31,618] calculate_sps 34560 steps in 10.0039
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:31,619] calculate_sps 30720 steps in 10.0039
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:31,619] {'local/mean_episode_return': 20500.0, 'local/mean_episode_step': 2743.7, 'local/SPS': 3454.662794817117, 'local/env_act_steps': 12663424, 'local/env_train_steps': 12661760, 'local/optimizer_steps': 19784, 'local/running_reward': 13160.841010956176, 'local/running_step': 1594.5559947709164, 'local/steps_done': 12663424, 'local/episodes_done': 3059, 'local/unclipped_grad_norm': 0.7673239380121231, 'local/model_version': 19784, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:31,620] {'global/mean_episode_return': 21000.0, 'global/mean_episode_step': 2814.7, 'global/SPS': 3070.811373170771, 'global/env_act_steps': 12661504, 'global/env_train_steps': 12656640, 'global/optimizer_steps': 19776, 'global/running_reward': 13142.887931034482, 'global/running_step': 1593.7579022988505, 'global/steps_done': 12661504, 'global/episodes_done': 3058, 'global/unclipped_grad_norm': 0.8033958505839109, 'global/model_version': 19776, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:41,635] calculate_sps 30720 steps in 10.0167
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:41,636] calculate_sps 35840 steps in 10.0167
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:41,636] {'local/mean_episode_return': 25235.29411764706, 'local/mean_episode_step': 2994.176470588235, 'local/SPS': 3066.8869180317593, 'local/env_act_steps': 12696576, 'local/env_train_steps': 12692480, 'local/optimizer_steps': 19832, 'local/running_reward': 13231.349541505791, 'local/running_step': 1595.686866554054, 'local/steps_done': 12696576, 'local/episodes_done': 3076, 'local/unclipped_grad_norm': 0.7392122208451232, 'local/model_version': 19832, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:41,637] {'global/mean_episode_return': 24528.571428571428, 'global/mean_episode_step': 2917.214285714286, 'global/SPS': 3578.0347377037187, 'global/env_act_steps': 12693504, 'global/env_train_steps': 12692480, 'global/optimizer_steps': 19831, 'global/running_reward': 13276.934375, 'global/running_step': 1601.1770625, 'global/steps_done': 12693504, 'global/episodes_done': 3072, 'global/unclipped_grad_norm': 0.7045658723874526, 'global/model_version': 19831, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:51,638] calculate_sps 35200 steps in 10.0031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:20:51,638] calculate_sps 30720 steps in 10.0031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:51,638] {'local/mean_episode_return': 30160.0, 'local/mean_episode_step': 3401.0, 'local/SPS': 3518.9168830642616, 'local/env_act_steps': 12729216, 'local/env_train_steps': 12727680, 'local/optimizer_steps': 19886, 'local/running_reward': 12727.438725490196, 'local/running_step': 1541.9229166666667, 'local/steps_done': 12729216, 'local/episodes_done': 3086, 'local/unclipped_grad_norm': 0.6633549321580816, 'local/model_version': 19886, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:20:51,639] {'global/mean_episode_return': 29615.384615384617, 'global/mean_episode_step': 3372.923076923077, 'global/SPS': 3071.054734310628, 'global/env_act_steps': 12727808, 'global/env_train_steps': 12723200, 'global/optimizer_steps': 19880, 'global/running_reward': 12735.459421641792, 'global/running_step': 1542.2782474347016, 'global/steps_done': 12727808, 'global/episodes_done': 3085, 'global/unclipped_grad_norm': 0.6261888182893092, 'global/model_version': 19880, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:01,644] calculate_sps 31360 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:01,644] calculate_sps 35840 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:01,645] {'local/mean_episode_return': 23769.23076923077, 'local/mean_episode_step': 2950.846153846154, 'local/SPS': 3134.173433889913, 'local/env_act_steps': 12762368, 'local/env_train_steps': 12759040, 'local/optimizer_steps': 19936, 'local/running_reward': 12533.071911196912, 'local/running_step': 1514.9980393339767, 'local/steps_done': 12762368, 'local/episodes_done': 3099, 'local/unclipped_grad_norm': 0.7198051238059997, 'local/model_version': 19936, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:01,655] {'global/mean_episode_return': 24050.0, 'global/mean_episode_step': 2982.8333333333335, 'global/SPS': 3581.912495874187, 'global/env_act_steps': 12760448, 'global/env_train_steps': 12759040, 'global/optimizer_steps': 19936, 'global/running_reward': 12535.879289215687, 'global/running_step': 1515.9285845588236, 'global/steps_done': 12760448, 'global/episodes_done': 3097, 'global/unclipped_grad_norm': 0.749368184379169, 'global/model_version': 19936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:11,651] calculate_sps 32000 steps in 10.0054
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:11,651] calculate_sps 30720 steps in 10.0054
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:11,651] {'local/mean_episode_return': 23942.85714285714, 'local/mean_episode_step': 2923.5714285714284, 'local/SPS': 3198.262967338658, 'local/env_act_steps': 12795264, 'local/env_train_steps': 12791040, 'local/optimizer_steps': 19985, 'local/running_reward': 12739.633998054474, 'local/running_step': 1526.6878647859921, 'local/steps_done': 12795264, 'local/episodes_done': 3106, 'local/unclipped_grad_norm': 0.662488731498621, 'local/model_version': 19985, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:11,653] {'global/mean_episode_return': 23355.555555555555, 'global/mean_episode_step': 2861.4444444444443, 'global/SPS': 3070.3324486451115, 'global/env_act_steps': 12794112, 'global/env_train_steps': 12789760, 'global/optimizer_steps': 19984, 'global/running_reward': 12721.138307984791, 'global/running_step': 1525.120247148289, 'global/steps_done': 12794112, 'global/episodes_done': 3106, 'global/unclipped_grad_norm': 0.6618198500946164, 'global/model_version': 19984, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:21,686] calculate_sps 34560 steps in 10.0367
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:21,687] calculate_sps 34560 steps in 10.0367
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:21,698] {'local/mean_episode_return': 22072.727272727272, 'local/mean_episode_step': 2748.7272727272725, 'local/SPS': 3443.360400898867, 'local/env_act_steps': 12827392, 'local/env_train_steps': 12825600, 'local/optimizer_steps': 20040, 'local/running_reward': 13074.45841633466, 'local/running_step': 1557.4559262948208, 'local/steps_done': 12827392, 'local/episodes_done': 3117, 'local/unclipped_grad_norm': 0.6865960283712907, 'local/model_version': 20040, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:21,700] {'global/mean_episode_return': 21940.0, 'global/mean_episode_step': 2747.4, 'global/SPS': 3443.360400898867, 'global/env_act_steps': 12826368, 'global/env_train_steps': 12824320, 'global/optimizer_steps': 20037, 'global/running_reward': 13069.18712797619, 'global/running_step': 1556.9464905753969, 'global/steps_done': 12826368, 'global/episodes_done': 3116, 'global/unclipped_grad_norm': 0.6827005181672439, 'global/model_version': 20037, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:31,715] calculate_sps 30720 steps in 10.0287
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:31,715] calculate_sps 32000 steps in 10.0287
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:31,716] {'local/mean_episode_return': 25140.0, 'local/mean_episode_step': 3095.0, 'local/SPS': 3063.2071730897114, 'local/env_act_steps': 12860672, 'local/env_train_steps': 12856320, 'local/optimizer_steps': 20088, 'local/running_reward': 13337.5390625, 'local/running_step': 1596.6493990384615, 'local/steps_done': 12860672, 'local/episodes_done': 3122, 'local/unclipped_grad_norm': 0.5875398879870772, 'local/model_version': 20088, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:31,717] {'global/mean_episode_return': 24850.0, 'global/mean_episode_step': 3039.5, 'global/SPS': 3190.840805301783, 'global/env_act_steps': 12859648, 'global/env_train_steps': 12856320, 'global/optimizer_steps': 20088, 'global/running_reward': 13325.94951923077, 'global/running_step': 1594.8413461538462, 'global/steps_done': 12859648, 'global/episodes_done': 3122, 'global/unclipped_grad_norm': 0.5975718384279924, 'global/model_version': 20088, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:41,754] calculate_sps 35200 steps in 10.039
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:41,754] calculate_sps 33280 steps in 10.039
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:41,754] {'local/mean_episode_return': 21547.36842105263, 'local/mean_episode_step': 2723.842105263158, 'local/SPS': 3506.339808700065, 'local/env_act_steps': 12893056, 'local/env_train_steps': 12891520, 'local/optimizer_steps': 20142, 'local/running_reward': 13111.70331027668, 'local/running_step': 1573.9168416501977, 'local/steps_done': 12893056, 'local/episodes_done': 3142, 'local/unclipped_grad_norm': 0.6249879129506923, 'local/model_version': 20142, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:41,755] {'global/mean_episode_return': 21547.36842105263, 'global/mean_episode_step': 2723.842105263158, 'global/SPS': 3315.0849100436976, 'global/env_act_steps': 12892672, 'global/env_train_steps': 12889600, 'global/optimizer_steps': 20139, 'global/running_reward': 13131.056201550387, 'global/running_step': 1576.2650496608528, 'global/steps_done': 12892672, 'global/episodes_done': 3142, 'global/unclipped_grad_norm': 0.6141512294610342, 'global/model_version': 20139, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:51,757] calculate_sps 31360 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:21:51,757] calculate_sps 33280 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:51,757] {'local/mean_episode_return': 25633.333333333332, 'local/mean_episode_step': 3022.222222222222, 'local/SPS': 3135.1677532728922, 'local/env_act_steps': 12926336, 'local/env_train_steps': 12922880, 'local/optimizer_steps': 20192, 'local/running_reward': 13117.124399038461, 'local/running_step': 1572.291015625, 'local/steps_done': 12926336, 'local/episodes_done': 3151, 'local/unclipped_grad_norm': 0.709433171749115, 'local/model_version': 20192, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:21:51,759] {'global/mean_episode_return': 25633.333333333332, 'global/mean_episode_step': 3022.222222222222, 'global/SPS': 3327.116799391641, 'global/env_act_steps': 12925824, 'global/env_train_steps': 12922880, 'global/optimizer_steps': 20192, 'global/running_reward': 13112.81973938224, 'global/running_step': 1571.845469353282, 'global/steps_done': 12925824, 'global/episodes_done': 3151, 'global/unclipped_grad_norm': 0.7150810034769886, 'global/model_version': 20192, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:01,775] calculate_sps 32000 steps in 10.0186
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:01,775] calculate_sps 31360 steps in 10.0186
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:01,775] {'local/mean_episode_return': 26775.0, 'local/mean_episode_step': 3144.125, 'local/SPS': 3194.063234907861, 'local/env_act_steps': 12958976, 'local/env_train_steps': 12954880, 'local/optimizer_steps': 20241, 'local/running_reward': 13191.859681372549, 'local/running_step': 1579.8508578431372, 'local/steps_done': 12958976, 'local/episodes_done': 3159, 'local/unclipped_grad_norm': 0.6551148170719341, 'local/model_version': 20241, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:01,776] {'global/mean_episode_return': 26775.0, 'global/mean_episode_step': 3144.125, 'global/SPS': 3130.181970209704, 'global/env_act_steps': 12958848, 'global/env_train_steps': 12954240, 'global/optimizer_steps': 20240, 'global/running_reward': 13190.388808139534, 'global/running_step': 1579.7128149224807, 'global/steps_done': 12958848, 'global/episodes_done': 3159, 'global/unclipped_grad_norm': 0.6569226666664084, 'global/model_version': 20240, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:11,793] calculate_sps 34560 steps in 10.0182
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:11,794] calculate_sps 35200 steps in 10.0182
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:11,794] {'local/mean_episode_return': 27112.5, 'local/mean_episode_step': 3193.375, 'local/SPS': 3449.7379539284634, 'local/env_act_steps': 12991488, 'local/env_train_steps': 12989440, 'local/optimizer_steps': 20296, 'local/running_reward': 13555.770177165354, 'local/running_step': 1617.726377952756, 'local/steps_done': 12991488, 'local/episodes_done': 3167, 'local/unclipped_grad_norm': 0.7467123771255667, 'local/model_version': 20296, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:11,807] {'global/mean_episode_return': 27112.5, 'global/mean_episode_step': 3193.375, 'global/SPS': 3513.621990112324, 'global/env_act_steps': 12991360, 'global/env_train_steps': 12989440, 'global/optimizer_steps': 20296, 'global/running_reward': 13553.94315944882, 'global/running_step': 1617.5173474409448, 'global/steps_done': 12991360, 'global/episodes_done': 3167, 'global/unclipped_grad_norm': 0.7435271210436311, 'global/model_version': 20296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:21,831] calculate_sps 30720 steps in 10.0373
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:21,831] calculate_sps 25600 steps in 10.0373
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:21,831] {'local/mean_episode_return': 22885.714285714286, 'local/mean_episode_step': 2798.0, 'local/SPS': 3060.5992549325906, 'local/env_act_steps': 13025280, 'local/env_train_steps': 13020160, 'local/optimizer_steps': 20344, 'local/running_reward': 14014.115767045454, 'local/running_step': 1659.412079782197, 'local/steps_done': 13025280, 'local/episodes_done': 3174, 'local/unclipped_grad_norm': 0.728460431098938, 'local/model_version': 20344, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:21,832] {'global/mean_episode_return': 22080.0, 'global/mean_episode_step': 2733.6, 'global/SPS': 2550.499379110492, 'global/env_act_steps': 13018368, 'global/env_train_steps': 13015040, 'global/optimizer_steps': 20336, 'global/running_reward': 13959.286137440758, 'global/running_step': 1654.7975784952607, 'global/steps_done': 13018368, 'global/episodes_done': 3172, 'global/unclipped_grad_norm': 0.6993164978921413, 'global/model_version': 20336, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:31,855] calculate_sps 35200 steps in 10.0245
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:31,855] calculate_sps 32640 steps in 10.0245
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:31,855] {'local/mean_episode_return': 28550.0, 'local/mean_episode_step': 3155.25, 'local/SPS': 3511.3958618711517, 'local/env_act_steps': 13057024, 'local/env_train_steps': 13055360, 'local/optimizer_steps': 20399, 'local/running_reward': 14471.490675403225, 'local/running_step': 1702.9787046370968, 'local/steps_done': 13057024, 'local/episodes_done': 3182, 'local/unclipped_grad_norm': 0.6803006283261559, 'local/model_version': 20399, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:31,856] {'global/mean_episode_return': 26000.0, 'global/mean_episode_step': 2970.0, 'global/SPS': 3256.0216173714316, 'global/env_act_steps': 13051392, 'global/env_train_steps': 13047680, 'global/optimizer_steps': 20387, 'global/running_reward': 14415.22831879845, 'global/running_step': 1697.0252846414728, 'global/steps_done': 13051392, 'global/episodes_done': 3180, 'global/unclipped_grad_norm': 0.7470138312554827, 'global/model_version': 20387, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:41,858] calculate_sps 31360 steps in 10.0032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:41,859] calculate_sps 33920 steps in 10.0032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:41,859] {'local/mean_episode_return': 25415.384615384617, 'local/mean_episode_step': 3059.846153846154, 'local/SPS': 3134.998577333948, 'local/env_act_steps': 13090560, 'local/env_train_steps': 13086720, 'local/optimizer_steps': 20448, 'local/running_reward': 14385.251669847328, 'local/running_step': 1702.8624165076335, 'local/steps_done': 13090560, 'local/episodes_done': 3195, 'local/unclipped_grad_norm': 0.719812563791567, 'local/model_version': 20448, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:41,860] {'global/mean_episode_return': 27184.615384615383, 'global/mean_episode_step': 3163.153846153846, 'global/SPS': 3390.9168285448827, 'global/env_act_steps': 13084288, 'global/env_train_steps': 13081600, 'global/optimizer_steps': 20440, 'global/running_reward': 14434.745865758754, 'global/running_step': 1706.2417619163425, 'global/steps_done': 13084288, 'global/episodes_done': 3193, 'global/unclipped_grad_norm': 0.674378474928298, 'global/model_version': 20440, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:51,882] calculate_sps 33280 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:22:51,883] calculate_sps 32000 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:51,883] {'local/mean_episode_return': 24480.0, 'local/mean_episode_step': 2974.6, 'local/SPS': 3319.8465444471826, 'local/env_act_steps': 13123072, 'local/env_train_steps': 13120000, 'local/optimizer_steps': 20499, 'local/running_reward': 13690.960260826772, 'local/running_step': 1636.4247354822835, 'local/steps_done': 13123072, 'local/episodes_done': 3215, 'local/unclipped_grad_norm': 0.5901787508936489, 'local/model_version': 20499, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:22:51,884] {'global/mean_episode_return': 24000.0, 'global/mean_episode_step': 2971.7894736842104, 'global/SPS': 3192.1601388915215, 'global/env_act_steps': 13117696, 'global/env_train_steps': 13113600, 'global/optimizer_steps': 20489, 'global/running_reward': 13882.623922413793, 'global/running_step': 1654.5611530172414, 'global/steps_done': 13117696, 'global/episodes_done': 3212, 'global/unclipped_grad_norm': 0.6114211173690095, 'global/model_version': 20489, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:01,913] calculate_sps 33280 steps in 10.0303
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:01,913] calculate_sps 34560 steps in 10.0303
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:01,914] {'local/mean_episode_return': 30658.823529411766, 'local/mean_episode_step': 3473.9411764705883, 'local/SPS': 3317.954698624496, 'local/env_act_steps': 13155456, 'local/env_train_steps': 13153280, 'local/optimizer_steps': 20552, 'local/running_reward': 12285.21800889328, 'local/running_step': 1520.1082942193675, 'local/steps_done': 13155456, 'local/episodes_done': 3232, 'local/unclipped_grad_norm': 0.49037281437864844, 'local/model_version': 20552, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:01,915] {'global/mean_episode_return': 30000.0, 'global/mean_episode_step': 3397.4210526315787, 'global/SPS': 3445.568340879284, 'global/env_act_steps': 13150080, 'global/env_train_steps': 13148160, 'global/optimizer_steps': 20544, 'global/running_reward': 12537.311635375494, 'global/running_step': 1539.4814414525692, 'global/steps_done': 13150080, 'global/episodes_done': 3231, 'global/unclipped_grad_norm': 0.475351884690198, 'global/model_version': 20544, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:11,932] calculate_sps 30720 steps in 10.0185
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:11,932] calculate_sps 30720 steps in 10.0185
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:11,932] {'local/mean_episode_return': 24609.090909090908, 'local/mean_episode_step': 2996.6363636363635, 'local/SPS': 3066.333688611907, 'local/env_act_steps': 13188608, 'local/env_train_steps': 13184000, 'local/optimizer_steps': 20600, 'local/running_reward': 11435.020511583012, 'local/running_step': 1476.6612270752896, 'local/steps_done': 13188608, 'local/episodes_done': 3243, 'local/unclipped_grad_norm': 0.45824703853577375, 'local/model_version': 20600, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:11,933] {'global/mean_episode_return': 24688.88888888889, 'global/mean_episode_step': 3002.8888888888887, 'global/SPS': 3066.333688611907, 'global/env_act_steps': 13183360, 'global/env_train_steps': 13178880, 'global/optimizer_steps': 20592, 'global/running_reward': 11488.03485576923, 'global/running_step': 1474.288671875, 'global/steps_done': 13183360, 'global/episodes_done': 3240, 'global/unclipped_grad_norm': 0.5154816418265303, 'global/model_version': 20592, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:21,935] calculate_sps 35200 steps in 10.0032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:21,935] calculate_sps 35200 steps in 10.0032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:21,950] {'local/mean_episode_return': 20768.75, 'local/mean_episode_step': 2716.1875, 'local/SPS': 3518.8854314575933, 'local/env_act_steps': 13220864, 'local/env_train_steps': 13219200, 'local/optimizer_steps': 20655, 'local/running_reward': 10886.46763392857, 'local/running_step': 1456.7645399305557, 'local/steps_done': 13220864, 'local/episodes_done': 3260, 'local/unclipped_grad_norm': 0.47438381043347444, 'local/model_version': 20655, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:21,951] {'global/mean_episode_return': 21875.0, 'global/mean_episode_step': 2806.5, 'global/SPS': 3518.8854314575933, 'global/env_act_steps': 13215744, 'global/env_train_steps': 13214080, 'global/optimizer_steps': 20647, 'global/running_reward': 10997.186882411068, 'global/running_step': 1464.8316143774703, 'global/steps_done': 13215744, 'global/episodes_done': 3257, 'global/unclipped_grad_norm': 0.4655219893563877, 'global/model_version': 20647, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:31,936] calculate_sps 31360 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:31,937] calculate_sps 31360 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:31,937] {'local/mean_episode_return': 24231.57894736842, 'local/mean_episode_step': 2972.0526315789475, 'local/SPS': 3135.5737304351105, 'local/env_act_steps': 13253888, 'local/env_train_steps': 13250560, 'local/optimizer_steps': 20704, 'local/running_reward': 10296.79324127907, 'local/running_step': 1408.5358527131782, 'local/steps_done': 13253888, 'local/episodes_done': 3279, 'local/unclipped_grad_norm': 0.6361388658382454, 'local/model_version': 20704, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:31,939] {'global/mean_episode_return': 24110.0, 'global/mean_episode_step': 2964.25, 'global/SPS': 3135.5737304351105, 'global/env_act_steps': 13249024, 'global/env_train_steps': 13245440, 'global/optimizer_steps': 20696, 'global/running_reward': 10447.5, 'global/running_step': 1424.1993389423078, 'global/steps_done': 13249024, 'global/episodes_done': 3277, 'global/unclipped_grad_norm': 0.5684496507960923, 'global/model_version': 20696, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:41,956] calculate_sps 32640 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:41,957] calculate_sps 33920 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:41,957] {'local/mean_episode_return': 19687.5, 'local/mean_episode_step': 2612.375, 'local/SPS': 3257.502320845868, 'local/env_act_steps': 13286784, 'local/env_train_steps': 13283200, 'local/optimizer_steps': 20754, 'local/running_reward': 9438.37852626459, 'local/running_step': 1311.5106699902724, 'local/steps_done': 13286784, 'local/episodes_done': 3294, 'local/unclipped_grad_norm': 0.6636448019742965, 'local/model_version': 20754, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:41,958] {'global/mean_episode_return': 20219.23076923077, 'global/mean_episode_step': 2638.5, 'global/SPS': 3385.247509898647, 'global/env_act_steps': 13281920, 'global/env_train_steps': 13279360, 'global/optimizer_steps': 20748, 'global/running_reward': 9478.471546692606, 'global/running_step': 1315.9545233463034, 'global/steps_done': 13281920, 'global/episodes_done': 3293, 'global/unclipped_grad_norm': 0.6907326172177608, 'global/model_version': 20748, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:51,957] calculate_sps 33920 steps in 10.0007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:23:51,957] calculate_sps 32640 steps in 10.0007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:51,957] {'local/mean_episode_return': 20066.666666666668, 'local/mean_episode_step': 2653.6, 'local/SPS': 3391.757726045913, 'local/env_act_steps': 13319424, 'local/env_train_steps': 13317120, 'local/optimizer_steps': 20808, 'local/running_reward': 9270.903799019608, 'local/running_step': 1291.630637254902, 'local/steps_done': 13319424, 'local/episodes_done': 3309, 'local/unclipped_grad_norm': 0.6664852660011362, 'local/model_version': 20808, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:23:51,958] {'global/mean_episode_return': 19614.285714285714, 'global/mean_episode_step': 2637.5, 'global/SPS': 3263.7668684592745, 'global/env_act_steps': 13315200, 'global/env_train_steps': 13312000, 'global/optimizer_steps': 20800, 'global/running_reward': 9287.223557692309, 'global/running_step': 1293.882421875, 'global/steps_done': 13315200, 'global/episodes_done': 3307, 'global/unclipped_grad_norm': 0.6765276233737285, 'global/model_version': 20800, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:01,977] calculate_sps 30720 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:01,977] calculate_sps 33280 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:01,986] {'local/mean_episode_return': 20866.666666666668, 'local/mean_episode_step': 2619.0, 'local/SPS': 3065.907589914879, 'local/env_act_steps': 13352832, 'local/env_train_steps': 13347840, 'local/optimizer_steps': 20856, 'local/running_reward': 9523.320761494253, 'local/running_step': 1325.1637033045977, 'local/steps_done': 13352832, 'local/episodes_done': 3312, 'local/unclipped_grad_norm': 0.601919835122923, 'local/model_version': 20856, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:01,988] {'global/mean_episode_return': 20680.0, 'global/mean_episode_step': 2610.2, 'global/SPS': 3321.3998890744524, 'global/env_act_steps': 13348352, 'global/env_train_steps': 13345280, 'global/optimizer_steps': 20851, 'global/running_reward': 9440.830115830116, 'global/running_step': 1313.8502654440153, 'global/steps_done': 13348352, 'global/episodes_done': 3312, 'global/unclipped_grad_norm': 0.5978922274182824, 'global/model_version': 20851, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:11,978] calculate_sps 35200 steps in 10.002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:11,978] calculate_sps 33280 steps in 10.002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:11,979] {'local/mean_episode_return': 18454.545454545456, 'local/mean_episode_step': 2527.318181818182, 'local/SPS': 3519.299127921688, 'local/env_act_steps': 13384576, 'local/env_train_steps': 13383040, 'local/optimizer_steps': 20910, 'local/running_reward': 9966.985887096775, 'local/running_step': 1373.9395476310483, 'local/steps_done': 13384576, 'local/episodes_done': 3324, 'local/unclipped_grad_norm': 0.760002174311214, 'local/model_version': 20910, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:11,979] {'global/mean_episode_return': 18700.0, 'global/mean_episode_step': 2537.55, 'global/SPS': 3327.3373573077774, 'global/env_act_steps': 13380992, 'global/env_train_steps': 13378560, 'global/optimizer_steps': 20904, 'global/running_reward': 9931.482843137255, 'global/running_step': 1372.1990196078432, 'global/steps_done': 13380992, 'global/episodes_done': 3323, 'global/unclipped_grad_norm': 0.7281070913908616, 'global/model_version': 20904, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:21,984] calculate_sps 31360 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:21,984] calculate_sps 30720 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:21,984] {'local/mean_episode_return': 21607.14285714286, 'local/mean_episode_step': 2741.0714285714284, 'local/SPS': 3134.3579068030335, 'local/env_act_steps': 13417344, 'local/env_train_steps': 13414400, 'local/optimizer_steps': 20960, 'local/running_reward': 10036.285400390625, 'local/running_step': 1368.628662109375, 'local/steps_done': 13417344, 'local/episodes_done': 3338, 'local/unclipped_grad_norm': 0.6704503247141838, 'local/model_version': 20960, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:21,986] {'global/mean_episode_return': 21291.666666666668, 'global/mean_episode_step': 2733.5833333333335, 'global/SPS': 3070.391418909094, 'global/env_act_steps': 13414272, 'global/env_train_steps': 13409280, 'global/optimizer_steps': 20952, 'global/running_reward': 10046.243990384615, 'global/running_step': 1370.4169170673076, 'global/steps_done': 13414272, 'global/episodes_done': 3335, 'global/unclipped_grad_norm': 0.6694153258576989, 'global/model_version': 20952, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:31,987] calculate_sps 31360 steps in 10.0031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:31,987] calculate_sps 35840 steps in 10.0031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:31,988] {'local/mean_episode_return': 22250.0, 'local/mean_episode_step': 2929.125, 'local/SPS': 3135.0395993277607, 'local/env_act_steps': 13450496, 'local/env_train_steps': 13445760, 'local/optimizer_steps': 21009, 'local/running_reward': 10242.26291023166, 'local/running_step': 1384.2464406370657, 'local/steps_done': 13450496, 'local/episodes_done': 3346, 'local/unclipped_grad_norm': 0.7891538945996032, 'local/model_version': 21009, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:31,989] {'global/mean_episode_return': 21909.090909090908, 'global/mean_episode_step': 2857.2727272727275, 'global/SPS': 3582.9023992317266, 'global/env_act_steps': 13446784, 'global/env_train_steps': 13445120, 'global/optimizer_steps': 21008, 'global/running_reward': 10204.173843503937, 'global/running_step': 1381.3132074311025, 'global/steps_done': 13446784, 'global/episodes_done': 3346, 'global/unclipped_grad_norm': 0.7944290696510247, 'global/model_version': 21008, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:41,999] calculate_sps 35200 steps in 10.0126
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:42,000] calculate_sps 30720 steps in 10.0126
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:42,000] {'local/mean_episode_return': 19650.0, 'local/mean_episode_step': 2654.4166666666665, 'local/SPS': 3515.5693960600915, 'local/env_act_steps': 13483008, 'local/env_train_steps': 13480960, 'local/optimizer_steps': 21064, 'local/running_reward': 10525.36909448819, 'local/running_step': 1403.568620816929, 'local/steps_done': 13483008, 'local/episodes_done': 3358, 'local/unclipped_grad_norm': 0.9067131627689708, 'local/model_version': 21064, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:42,002] {'global/mean_episode_return': 20500.0, 'global/mean_episode_step': 2737.0, 'global/SPS': 3068.133291106989, 'global/env_act_steps': 13480448, 'global/env_train_steps': 13475840, 'global/optimizer_steps': 21056, 'global/running_reward': 10506.264852661598, 'global/running_step': 1402.5125059410645, 'global/steps_done': 13480448, 'global/episodes_done': 3357, 'global/unclipped_grad_norm': 0.9447967025140921, 'global/model_version': 21056, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:52,038] calculate_sps 30720 steps in 10.0387
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:24:52,039] calculate_sps 35200 steps in 10.0387
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:52,039] {'local/mean_episode_return': 22641.666666666668, 'local/mean_episode_step': 2904.9166666666665, 'local/SPS': 3060.1462582925606, 'local/env_act_steps': 13516160, 'local/env_train_steps': 13511680, 'local/optimizer_steps': 21112, 'local/running_reward': 10328.173262548262, 'local/running_step': 1371.1575772200772, 'local/steps_done': 13516160, 'local/episodes_done': 3371, 'local/unclipped_grad_norm': 0.7464764825999737, 'local/model_version': 21112, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:24:52,041] {'global/mean_episode_return': 21692.30769230769, 'global/mean_episode_step': 2815.769230769231, 'global/SPS': 3506.4175876268923, 'global/env_act_steps': 13512704, 'global/env_train_steps': 13511040, 'global/optimizer_steps': 21111, 'global/running_reward': 10341.121031746032, 'global/running_step': 1373.1582651289682, 'global/steps_done': 13512704, 'global/episodes_done': 3371, 'global/unclipped_grad_norm': 0.7500934573737058, 'global/model_version': 21111, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:02,084] calculate_sps 34560 steps in 10.0467
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:02,085] calculate_sps 31360 steps in 10.0467
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:02,085] {'local/mean_episode_return': 20250.0, 'local/mean_episode_step': 2695.25, 'local/SPS': 3439.9472561728785, 'local/env_act_steps': 13548288, 'local/env_train_steps': 13546240, 'local/optimizer_steps': 21165, 'local/running_reward': 10706.495891434262, 'local/running_step': 1406.4553971613545, 'local/steps_done': 13548288, 'local/episodes_done': 3379, 'local/unclipped_grad_norm': 0.7484918731563496, 'local/model_version': 21165, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:02,086] {'global/mean_episode_return': 20250.0, 'global/mean_episode_step': 2695.25, 'global/SPS': 3121.433621342056, 'global/env_act_steps': 13545984, 'global/env_train_steps': 13542400, 'global/optimizer_steps': 21160, 'global/running_reward': 10658.689903846154, 'global/running_step': 1402.0522836538462, 'global/steps_done': 13545984, 'global/episodes_done': 3379, 'global/unclipped_grad_norm': 0.7492100097695176, 'global/model_version': 21160, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:12,119] calculate_sps 32000 steps in 10.0341
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:12,119] calculate_sps 33280 steps in 10.0341
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:12,120] {'local/mean_episode_return': 22042.85714285714, 'local/mean_episode_step': 2777.4285714285716, 'local/SPS': 3189.128627252675, 'local/env_act_steps': 13581440, 'local/env_train_steps': 13578240, 'local/optimizer_steps': 21216, 'local/running_reward': 11176.007480694981, 'local/running_step': 1447.1639418436293, 'local/steps_done': 13581440, 'local/episodes_done': 3386, 'local/unclipped_grad_norm': 0.8454481556135065, 'local/model_version': 21216, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:12,121] {'global/mean_episode_return': 20183.333333333332, 'global/mean_episode_step': 2609.0, 'global/SPS': 3316.6937723427823, 'global/env_act_steps': 13578880, 'global/env_train_steps': 13575680, 'global/optimizer_steps': 21212, 'global/running_reward': 11132.411235408561, 'global/running_step': 1442.675735651751, 'global/steps_done': 13578880, 'global/episodes_done': 3385, 'global/unclipped_grad_norm': 0.8101408561834922, 'global/model_version': 21212, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:22,143] calculate_sps 32640 steps in 10.0241
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:22,143] calculate_sps 33280 steps in 10.0241
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:22,143] {'local/mean_episode_return': 23636.363636363636, 'local/mean_episode_step': 2983.090909090909, 'local/SPS': 3256.1679852677885, 'local/env_act_steps': 13614464, 'local/env_train_steps': 13610880, 'local/optimizer_steps': 21266, 'local/running_reward': 11637.881540697674, 'local/running_step': 1491.0731589147288, 'local/steps_done': 13614464, 'local/episodes_done': 3397, 'local/unclipped_grad_norm': 0.7642604517936706, 'local/model_version': 21266, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:22,144] {'global/mean_episode_return': 25790.909090909092, 'global/mean_episode_step': 3154.5454545454545, 'global/SPS': 3320.0144163514706, 'global/env_act_steps': 13612160, 'global/env_train_steps': 13608960, 'global/optimizer_steps': 21264, 'global/running_reward': 11631.487379807691, 'global/running_step': 1491.2930889423078, 'global/steps_done': 13612160, 'global/episodes_done': 3396, 'global/unclipped_grad_norm': 0.8065542807945838, 'global/model_version': 21264, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:32,146] calculate_sps 33920 steps in 10.0033
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:32,147] calculate_sps 32640 steps in 10.0033
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:32,158] {'local/mean_episode_return': 23528.571428571428, 'local/mean_episode_step': 2982.714285714286, 'local/SPS': 3390.87399451743, 'local/env_act_steps': 13647104, 'local/env_train_steps': 13644800, 'local/optimizer_steps': 21320, 'local/running_reward': 11786.599264705883, 'local/running_step': 1502.0016544117648, 'local/steps_done': 13647104, 'local/episodes_done': 3404, 'local/unclipped_grad_norm': 0.8542090372906791, 'local/model_version': 21320, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:32,160] {'global/mean_episode_return': 21557.14285714286, 'global/mean_episode_step': 2828.5714285714284, 'global/SPS': 3262.9164852903573, 'global/env_act_steps': 13645312, 'global/env_train_steps': 13641600, 'global/optimizer_steps': 21315, 'global/running_reward': 11756.97997104247, 'global/running_step': 1498.8728281853282, 'global/steps_done': 13645312, 'global/episodes_done': 3403, 'global/unclipped_grad_norm': 0.8309305193377476, 'global/model_version': 21315, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:42,158] calculate_sps 30720 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:42,158] calculate_sps 33920 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:42,159] {'local/mean_episode_return': 19100.0, 'local/mean_episode_step': 2693.3333333333335, 'local/SPS': 3068.4064790092607, 'local/env_act_steps': 13680384, 'local/env_train_steps': 13675520, 'local/optimizer_steps': 21368, 'local/running_reward': 12563.329326923076, 'local/running_step': 1576.070703125, 'local/steps_done': 13680384, 'local/episodes_done': 3407, 'local/unclipped_grad_norm': 0.7115631146977345, 'local/model_version': 21368, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:42,171] {'global/mean_episode_return': 20150.0, 'global/mean_episode_step': 2765.25, 'global/SPS': 3388.0321539060587, 'global/env_act_steps': 13678464, 'global/env_train_steps': 13675520, 'global/optimizer_steps': 21368, 'global/running_reward': 12509.24831081081, 'global/running_step': 1570.8540661196912, 'global/steps_done': 13678464, 'global/episodes_done': 3407, 'global/unclipped_grad_norm': 0.728301965965415, 'global/model_version': 21368, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:52,167] calculate_sps 35200 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:25:52,182] calculate_sps 32000 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:52,182] {'local/mean_episode_return': 20507.14285714286, 'local/mean_episode_step': 2750.0714285714284, 'local/SPS': 3516.845381884512, 'local/env_act_steps': 13712384, 'local/env_train_steps': 13710720, 'local/optimizer_steps': 21423, 'local/running_reward': 13329.340625, 'local/running_step': 1651.90015625, 'local/steps_done': 13712384, 'local/episodes_done': 3415, 'local/unclipped_grad_norm': 0.5892771590839733, 'local/model_version': 21423, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:25:52,183] {'global/mean_episode_return': 20507.14285714286, 'global/mean_episode_step': 2750.0714285714284, 'global/SPS': 3197.132165349556, 'global/env_act_steps': 13711744, 'global/env_train_steps': 13707520, 'global/optimizer_steps': 21417, 'global/running_reward': 13311.129807692309, 'global/running_step': 1650.239393028846, 'global/steps_done': 13711744, 'global/episodes_done': 3415, 'global/unclipped_grad_norm': 0.5775875893174386, 'global/model_version': 21417, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 12:25:52,233] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 13711744, 'env_train_steps': 13707520, 'optimizer_steps': 21417, 'running_reward': None, 'running_step': None, 'steps_done': 13711744, 'episodes_done': 3415, 'unclipped_grad_norm': None, 'model_version': 21417, 'virtual_batch_size': None, 'num_gradients': None}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 12:25:52,312] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:02,180] calculate_sps 31360 steps in 10.0132
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:02,180] calculate_sps 34560 steps in 10.0132
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:02,181] {'local/mean_episode_return': 23578.571428571428, 'local/mean_episode_step': 2952.6428571428573, 'local/SPS': 3131.875095271754, 'local/env_act_steps': 13745152, 'local/env_train_steps': 13742080, 'local/optimizer_steps': 21472, 'local/running_reward': 13322.491455078125, 'local/running_step': 1638.0692138671875, 'local/steps_done': 13745152, 'local/episodes_done': 3429, 'local/unclipped_grad_norm': 0.7594816848939779, 'local/model_version': 21472, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:02,191] {'global/mean_episode_return': 23578.571428571428, 'global/mean_episode_step': 2952.6428571428573, 'global/SPS': 3451.4541866260147, 'global/env_act_steps': 13743744, 'global/env_train_steps': 13742080, 'global/optimizer_steps': 21472, 'global/running_reward': 13328.8375, 'global/running_step': 1639.21915625, 'global/steps_done': 13743744, 'global/episodes_done': 3429, 'global/unclipped_grad_norm': 0.7513282624157992, 'global/model_version': 21472, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:12,222] calculate_sps 31360 steps in 10.0424
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:12,222] calculate_sps 30720 steps in 10.0424
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:12,223] {'local/mean_episode_return': 21654.545454545456, 'local/mean_episode_step': 2741.2727272727275, 'local/SPS': 3122.759906709436, 'local/env_act_steps': 13778048, 'local/env_train_steps': 13773440, 'local/optimizer_steps': 21520, 'local/running_reward': 13215.913788910506, 'local/running_step': 1614.192698200389, 'local/steps_done': 13778048, 'local/episodes_done': 3440, 'local/unclipped_grad_norm': 0.8042707747469345, 'local/model_version': 21520, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:12,223] {'global/mean_episode_return': 21654.545454545456, 'global/mean_episode_step': 2741.2727272727275, 'global/SPS': 3059.0301126949576, 'global/env_act_steps': 13777280, 'global/env_train_steps': 13772800, 'global/optimizer_steps': 21520, 'global/running_reward': 13208.608659351145, 'global/running_step': 1613.6782562022902, 'global/steps_done': 13777280, 'global/episodes_done': 3440, 'global/unclipped_grad_norm': 0.8042707747469345, 'global/model_version': 21520, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:22,237] calculate_sps 35200 steps in 10.0142
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:22,237] calculate_sps 35200 steps in 10.0142
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:22,237] {'local/mean_episode_return': 25236.363636363636, 'local/mean_episode_step': 3090.090909090909, 'local/SPS': 3515.01321646105, 'local/env_act_steps': 13810304, 'local/env_train_steps': 13808640, 'local/optimizer_steps': 21576, 'local/running_reward': 13367.420014880952, 'local/running_step': 1620.2697172619048, 'local/steps_done': 13810304, 'local/episodes_done': 3451, 'local/unclipped_grad_norm': 0.7858303189277649, 'local/model_version': 21576, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:22,239] {'global/mean_episode_return': 25236.363636363636, 'global/mean_episode_step': 3090.090909090909, 'global/SPS': 3515.01321646105, 'global/env_act_steps': 13809536, 'global/env_train_steps': 13808000, 'global/optimizer_steps': 21574, 'global/running_reward': 13366.502356150793, 'global/running_step': 1620.4310825892858, 'global/steps_done': 13809536, 'global/episodes_done': 3451, 'global/unclipped_grad_norm': 0.7817416974791774, 'global/model_version': 21574, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:32,254] calculate_sps 30720 steps in 10.017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:32,254] calculate_sps 31360 steps in 10.017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:32,254] {'local/mean_episode_return': 25925.0, 'local/mean_episode_step': 3130.375, 'local/SPS': 3066.8009281159952, 'local/env_act_steps': 13843584, 'local/env_train_steps': 13839360, 'local/optimizer_steps': 21624, 'local/running_reward': 13793.161057692309, 'local/running_step': 1659.123798076923, 'local/steps_done': 13843584, 'local/episodes_done': 3459, 'local/unclipped_grad_norm': 0.7442276667182645, 'local/model_version': 21624, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:32,256] {'global/mean_episode_return': 25925.0, 'global/mean_episode_step': 3130.375, 'global/SPS': 3130.6926141184117, 'global/env_act_steps': 13843072, 'global/env_train_steps': 13839360, 'global/optimizer_steps': 21624, 'global/running_reward': 13784.864026717558, 'global/running_step': 1658.3816197519084, 'global/steps_done': 13843072, 'global/episodes_done': 3459, 'global/unclipped_grad_norm': 0.7503074839711189, 'global/model_version': 21624, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:42,258] calculate_sps 33280 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:42,258] calculate_sps 32640 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:42,258] {'local/mean_episode_return': 24290.0, 'local/mean_episode_step': 2925.1, 'local/SPS': 3326.4512581784793, 'local/env_act_steps': 13875712, 'local/env_train_steps': 13872640, 'local/optimizer_steps': 21675, 'local/running_reward': 14032.096613545817, 'local/running_step': 1677.3497260956176, 'local/steps_done': 13875712, 'local/episodes_done': 3470, 'local/unclipped_grad_norm': 0.7782169931075152, 'local/model_version': 21675, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:42,259] {'global/mean_episode_return': 24290.0, 'global/mean_episode_step': 2925.1, 'global/SPS': 3262.481041675047, 'global/env_act_steps': 13875584, 'global/env_train_steps': 13872000, 'global/optimizer_steps': 21674, 'global/running_reward': 14033.833661417322, 'global/running_step': 1677.658403051181, 'global/steps_done': 13875584, 'global/episodes_done': 3470, 'global/unclipped_grad_norm': 0.7852357858419419, 'global/model_version': 21674, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:52,284] calculate_sps 33280 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:26:52,284] calculate_sps 33920 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:52,284] {'local/mean_episode_return': 27672.727272727272, 'local/mean_episode_step': 3227.090909090909, 'local/SPS': 3319.640873182724, 'local/env_act_steps': 13908608, 'local/env_train_steps': 13905920, 'local/optimizer_steps': 21728, 'local/running_reward': 13884.669868677043, 'local/running_step': 1654.7968446011673, 'local/steps_done': 13908608, 'local/episodes_done': 3481, 'local/unclipped_grad_norm': 0.7404644191265106, 'local/model_version': 21728, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:26:52,286] {'global/mean_episode_return': 27672.727272727272, 'global/mean_episode_step': 3227.090909090909, 'global/SPS': 3383.4801207439305, 'global/env_act_steps': 13908480, 'global/env_train_steps': 13905920, 'global/optimizer_steps': 21728, 'global/running_reward': 13877.577821011673, 'global/running_step': 1653.9163424124513, 'global/steps_done': 13908480, 'global/episodes_done': 3481, 'global/unclipped_grad_norm': 0.7346646587053934, 'global/model_version': 21728, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:02,286] calculate_sps 31360 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:02,286] calculate_sps 25600 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:02,286] {'local/mean_episode_return': 23500.0, 'local/mean_episode_step': 2981.1666666666665, 'local/SPS': 3135.269088240985, 'local/env_act_steps': 13941888, 'local/env_train_steps': 13937280, 'local/optimizer_steps': 21776, 'local/running_reward': 14136.598557692309, 'local/running_step': 1677.3525540865385, 'local/steps_done': 13941888, 'local/episodes_done': 3487, 'local/unclipped_grad_norm': 0.6458743040760359, 'local/model_version': 21776, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:02,287] {'global/mean_episode_return': 23500.0, 'global/mean_episode_step': 2981.1666666666665, 'global/SPS': 2559.40333733958, 'global/env_act_steps': 13935232, 'global/env_train_steps': 13931520, 'global/optimizer_steps': 21768, 'global/running_reward': 14080.67808014354, 'global/running_step': 1672.3397129186603, 'global/steps_done': 13935232, 'global/episodes_done': 3487, 'global/unclipped_grad_norm': 0.6396400693804025, 'global/model_version': 21768, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:12,288] calculate_sps 35200 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:12,288] calculate_sps 34560 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:12,289] {'local/mean_episode_return': 22500.0, 'local/mean_episode_step': 2692.3333333333335, 'local/SPS': 3519.273877236042, 'local/env_act_steps': 13974400, 'local/env_train_steps': 13972480, 'local/optimizer_steps': 21832, 'local/running_reward': 14835.147022637795, 'local/running_step': 1747.4424827755906, 'local/steps_done': 13974400, 'local/episodes_done': 3493, 'local/unclipped_grad_norm': 0.7164844258555344, 'local/model_version': 21832, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:12,290] {'global/mean_episode_return': 20900.0, 'global/mean_episode_step': 2574.75, 'global/SPS': 3455.287079468114, 'global/env_act_steps': 13968256, 'global/env_train_steps': 13966080, 'global/optimizer_steps': 21821, 'global/running_reward': 14699.13093507752, 'global/running_step': 1732.8896862887598, 'global/steps_done': 13968256, 'global/episodes_done': 3491, 'global/unclipped_grad_norm': 0.6822940811233701, 'global/model_version': 21821, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:22,318] calculate_sps 30720 steps in 10.0302
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:22,319] calculate_sps 32000 steps in 10.0302
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:22,319] {'local/mean_episode_return': 26814.285714285714, 'local/mean_episode_step': 3236.4285714285716, 'local/SPS': 3062.7552242361553, 'local/env_act_steps': 14007808, 'local/env_train_steps': 14003200, 'local/optimizer_steps': 21880, 'local/running_reward': 15228.780531609196, 'local/running_step': 1788.3109734195402, 'local/steps_done': 14007808, 'local/episodes_done': 3500, 'local/unclipped_grad_norm': 0.7277023339023193, 'local/model_version': 21880, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:22,320] {'global/mean_episode_return': 26566.666666666668, 'global/mean_episode_step': 3167.777777777778, 'global/SPS': 3190.3700252459953, 'global/env_act_steps': 14001536, 'global/env_train_steps': 13998080, 'global/optimizer_steps': 21872, 'global/running_reward': 15165.036057692309, 'global/running_step': 1782.4391225961538, 'global/steps_done': 14001536, 'global/episodes_done': 3500, 'global/unclipped_grad_norm': 0.7588782865627139, 'global/model_version': 21872, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:32,343] calculate_sps 34560 steps in 10.025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:32,343] calculate_sps 33280 steps in 10.025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:32,343] {'local/mean_episode_return': 24972.727272727272, 'local/mean_episode_step': 3009.181818181818, 'local/SPS': 3447.376758099728, 'local/env_act_steps': 14039808, 'local/env_train_steps': 14037760, 'local/optimizer_steps': 21933, 'local/running_reward': 15631.684375, 'local/running_step': 1818.67728125, 'local/steps_done': 14039808, 'local/episodes_done': 3511, 'local/unclipped_grad_norm': 0.7187915939205097, 'local/model_version': 21933, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:32,344] {'global/mean_episode_return': 24175.0, 'global/mean_episode_step': 2953.75, 'global/SPS': 3319.6961374293674, 'global/env_act_steps': 14034432, 'global/env_train_steps': 14031360, 'global/optimizer_steps': 21923, 'global/running_reward': 15586.51811770428, 'global/running_step': 1816.9540369649806, 'global/steps_done': 14034432, 'global/episodes_done': 3508, 'global/unclipped_grad_norm': 0.7268706034211552, 'global/model_version': 21923, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:42,375] calculate_sps 32000 steps in 10.0315
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:42,375] calculate_sps 33280 steps in 10.0315
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:42,375] {'local/mean_episode_return': 27828.571428571428, 'local/mean_episode_step': 3276.0, 'local/SPS': 3189.9595049865293, 'local/env_act_steps': 14072576, 'local/env_train_steps': 14069760, 'local/optimizer_steps': 21984, 'local/running_reward': 15846.88720703125, 'local/running_step': 1830.8636779785156, 'local/steps_done': 14072576, 'local/episodes_done': 3518, 'local/unclipped_grad_norm': 0.7815504044878716, 'local/model_version': 21984, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:42,377] {'global/mean_episode_return': 27610.0, 'global/mean_episode_step': 3240.3, 'global/SPS': 3317.5578851859905, 'global/env_act_steps': 14067072, 'global/env_train_steps': 14064640, 'global/optimizer_steps': 21976, 'global/running_reward': 15792.18443627451, 'global/running_step': 1826.222518382353, 'global/steps_done': 14067072, 'global/episodes_done': 3518, 'global/unclipped_grad_norm': 0.7741428428101089, 'global/model_version': 21976, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:52,405] calculate_sps 32000 steps in 10.0309
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:27:52,405] calculate_sps 31360 steps in 10.0309
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:52,405] {'local/mean_episode_return': 27477.777777777777, 'local/mean_episode_step': 3193.4444444444443, 'local/SPS': 3190.1322988465367, 'local/env_act_steps': 14105856, 'local/env_train_steps': 14101760, 'local/optimizer_steps': 22033, 'local/running_reward': 16117.08233173077, 'local/running_step': 1853.090625, 'local/steps_done': 14105856, 'local/episodes_done': 3527, 'local/unclipped_grad_norm': 0.7309621247101803, 'local/model_version': 22033, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:27:52,406] {'global/mean_episode_return': 27087.5, 'global/mean_episode_step': 3164.25, 'global/SPS': 3126.329652869606, 'global/env_act_steps': 14100608, 'global/env_train_steps': 14096000, 'global/optimizer_steps': 22024, 'global/running_reward': 16076.010854007634, 'global/running_step': 1849.3856750954199, 'global/steps_done': 14100608, 'global/episodes_done': 3526, 'global/unclipped_grad_norm': 0.7072349373872081, 'global/model_version': 22024, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:02,437] calculate_sps 34560 steps in 10.0318
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:02,438] calculate_sps 35200 steps in 10.0318
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:02,438] {'local/mean_episode_return': 27844.444444444445, 'local/mean_episode_step': 3197.6666666666665, 'local/SPS': 3445.0371323554577, 'local/env_act_steps': 14138368, 'local/env_train_steps': 14136320, 'local/optimizer_steps': 22088, 'local/running_reward': 16284.344242125984, 'local/running_step': 1867.4297797736222, 'local/steps_done': 14138368, 'local/episodes_done': 3536, 'local/unclipped_grad_norm': 0.7148472487926483, 'local/model_version': 22088, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:02,439] {'global/mean_episode_return': 26525.0, 'global/mean_episode_step': 3095.25, 'global/SPS': 3508.834116287966, 'global/env_act_steps': 14133632, 'global/env_train_steps': 14131200, 'global/optimizer_steps': 22080, 'global/running_reward': 16237.433381782947, 'global/running_step': 1862.7358890503876, 'global/steps_done': 14133632, 'global/episodes_done': 3534, 'global/unclipped_grad_norm': 0.7218136084931237, 'global/model_version': 22080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:12,440] calculate_sps 30720 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:12,440] calculate_sps 30720 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:12,441] {'local/mean_episode_return': 29800.0, 'local/mean_episode_step': 3450.3928571428573, 'local/SPS': 3071.179613676271, 'local/env_act_steps': 14171520, 'local/env_train_steps': 14167040, 'local/optimizer_steps': 22136, 'local/running_reward': 16114.819618725869, 'local/running_step': 1843.326224662162, 'local/steps_done': 14171520, 'local/episodes_done': 3551, 'local/unclipped_grad_norm': 0.7418074359496435, 'local/model_version': 22136, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:12,442] {'global/mean_episode_return': 30387.5, 'global/mean_episode_step': 3484.34375, 'global/SPS': 3071.179613676271, 'global/env_act_steps': 14167040, 'global/env_train_steps': 14161920, 'global/optimizer_steps': 22128, 'global/running_reward': 16220.812380268198, 'global/running_step': 1856.1683429118773, 'global/steps_done': 14167040, 'global/episodes_done': 3551, 'global/unclipped_grad_norm': 0.7256472706794739, 'global/model_version': 22128, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:22,450] calculate_sps 35200 steps in 10.01
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:22,450] calculate_sps 35840 steps in 10.01
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:22,451] {'local/mean_episode_return': 30009.090909090908, 'local/mean_episode_step': 3483.909090909091, 'local/SPS': 3516.492816745994, 'local/env_act_steps': 14203904, 'local/env_train_steps': 14202240, 'local/optimizer_steps': 22191, 'local/running_reward': 15572.838438735178, 'local/running_step': 1779.227087450593, 'local/steps_done': 14203904, 'local/episodes_done': 3563, 'local/unclipped_grad_norm': 0.6849401647394354, 'local/model_version': 22191, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:22,452] {'global/mean_episode_return': 31050.0, 'global/mean_episode_step': 3555.3, 'global/SPS': 3580.429049777739, 'global/env_act_steps': 14199808, 'global/env_train_steps': 14197760, 'global/optimizer_steps': 22184, 'global/running_reward': 15613.6962890625, 'global/running_step': 1784.0164489746094, 'global/steps_done': 14199808, 'global/episodes_done': 3562, 'global/unclipped_grad_norm': 0.7149182739002364, 'global/model_version': 22184, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:32,454] calculate_sps 31360 steps in 10.0041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:32,455] calculate_sps 30720 steps in 10.0041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:32,455] {'local/mean_episode_return': 30525.0, 'local/mean_episode_step': 3492.75, 'local/SPS': 3134.7031610190866, 'local/env_act_steps': 14237312, 'local/env_train_steps': 14233600, 'local/optimizer_steps': 22240, 'local/running_reward': 15593.35787835249, 'local/running_step': 1778.6132064176245, 'local/steps_done': 14237312, 'local/episodes_done': 3571, 'local/unclipped_grad_norm': 0.6574648953213984, 'local/model_version': 22240, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:32,456] {'global/mean_episode_return': 28875.0, 'global/mean_episode_step': 3417.25, 'global/SPS': 3070.729627120738, 'global/env_act_steps': 14233472, 'global/env_train_steps': 14228480, 'global/optimizer_steps': 22232, 'global/running_reward': 15560.004752851712, 'global/running_step': 1775.0874821768061, 'global/steps_done': 14233472, 'global/episodes_done': 3570, 'global/unclipped_grad_norm': 0.6254747727264961, 'global/model_version': 22232, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:42,454] calculate_sps 32640 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:42,454] calculate_sps 35840 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:42,455] {'local/mean_episode_return': 31040.0, 'local/mean_episode_step': 3386.5, 'local/SPS': 3263.906541067223, 'local/env_act_steps': 14269824, 'local/env_train_steps': 14266240, 'local/optimizer_steps': 22290, 'local/running_reward': 15636.217396653543, 'local/running_step': 1783.8932086614172, 'local/steps_done': 14269824, 'local/episodes_done': 3581, 'local/unclipped_grad_norm': 0.8430102974176407, 'local/model_version': 22290, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:42,455] {'global/mean_episode_return': 32000.0, 'global/mean_episode_step': 3438.0, 'global/SPS': 3583.8973784267546, 'global/env_act_steps': 14265600, 'global/env_train_steps': 14264320, 'global/optimizer_steps': 22288, 'global/running_reward': 15647.264068725099, 'global/running_step': 1785.2621700697212, 'global/steps_done': 14265600, 'global/episodes_done': 3579, 'global/unclipped_grad_norm': 0.8230160245937961, 'global/model_version': 22288, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:52,472] calculate_sps 33920 steps in 10.0175
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:28:52,472] calculate_sps 30720 steps in 10.0175
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:52,473] {'local/mean_episode_return': 32262.5, 'local/mean_episode_step': 3658.125, 'local/SPS': 3386.0855169976644, 'local/env_act_steps': 14302592, 'local/env_train_steps': 14300160, 'local/optimizer_steps': 22344, 'local/running_reward': 15651.611328125, 'local/running_step': 1784.8177795410156, 'local/steps_done': 14302592, 'local/episodes_done': 3589, 'local/unclipped_grad_norm': 0.6431626870676324, 'local/model_version': 22344, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:28:52,474] {'global/mean_episode_return': 31330.0, 'global/mean_episode_step': 3556.2, 'global/SPS': 3066.6434870922244, 'global/env_act_steps': 14299264, 'global/env_train_steps': 14295040, 'global/optimizer_steps': 22336, 'global/running_reward': 15646.022457224335, 'global/running_step': 1783.7216017110266, 'global/steps_done': 14299264, 'global/episodes_done': 3589, 'global/unclipped_grad_norm': 0.6724083988616864, 'global/model_version': 22336, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:02,483] calculate_sps 30720 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:02,483] calculate_sps 33920 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:02,483] {'local/mean_episode_return': 31155.555555555555, 'local/mean_episode_step': 3552.0, 'local/SPS': 3068.6344041857396, 'local/env_act_steps': 14335360, 'local/env_train_steps': 14330880, 'local/optimizer_steps': 22392, 'local/running_reward': 15998.992919921875, 'local/running_step': 1824.0513305664062, 'local/steps_done': 14335360, 'local/episodes_done': 3598, 'local/unclipped_grad_norm': 0.6152131582299868, 'local/model_version': 22392, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:02,485] {'global/mean_episode_return': 31685.714285714286, 'global/mean_episode_step': 3590.4285714285716, 'global/SPS': 3388.2838212884208, 'global/env_act_steps': 14331520, 'global/env_train_steps': 14328960, 'global/optimizer_steps': 22388, 'global/running_reward': 15979.60689484127, 'global/running_step': 1822.2916666666667, 'global/steps_done': 14331520, 'global/episodes_done': 3596, 'global/unclipped_grad_norm': 0.6192487180233002, 'global/model_version': 22388, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:12,510] calculate_sps 34560 steps in 10.0278
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:12,510] calculate_sps 32640 steps in 10.0278
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:12,511] {'local/mean_episode_return': 32000.0, 'local/mean_episode_step': 3683.875, 'local/SPS': 3446.4164684879142, 'local/env_act_steps': 14367488, 'local/env_train_steps': 14365440, 'local/optimizer_steps': 22445, 'local/running_reward': 15967.785109561753, 'local/running_step': 1821.5336155378486, 'local/steps_done': 14367488, 'local/episodes_done': 3606, 'local/unclipped_grad_norm': 0.7470301873279068, 'local/model_version': 22445, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:12,512] {'global/mean_episode_return': 32600.0, 'global/mean_episode_step': 3707.5555555555557, 'global/SPS': 3254.948886905252, 'global/env_act_steps': 14364416, 'global/env_train_steps': 14361600, 'global/optimizer_steps': 22440, 'global/running_reward': 15961.119892996108, 'global/running_step': 1820.7304535505837, 'global/steps_done': 14364416, 'global/episodes_done': 3605, 'global/unclipped_grad_norm': 0.7541543944523885, 'global/model_version': 22440, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:22,515] calculate_sps 32000 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:22,515] calculate_sps 32640 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:22,516] {'local/mean_episode_return': 31911.11111111111, 'local/mean_episode_step': 3555.3333333333335, 'local/SPS': 3198.5760733499146, 'local/env_act_steps': 14401024, 'local/env_train_steps': 14397440, 'local/optimizer_steps': 22496, 'local/running_reward': 15852.40338740458, 'local/running_step': 1806.8062678912213, 'local/steps_done': 14401024, 'local/episodes_done': 3615, 'local/unclipped_grad_norm': 0.7238554498728584, 'local/model_version': 22496, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:22,517] {'global/mean_episode_return': 30840.0, 'global/mean_episode_step': 3493.6, 'global/SPS': 3262.5475948169133, 'global/env_act_steps': 14397952, 'global/env_train_steps': 14394240, 'global/optimizer_steps': 22491, 'global/running_reward': 15857.860209923665, 'global/running_step': 1807.3072220896947, 'global/steps_done': 14397952, 'global/episodes_done': 3615, 'global/unclipped_grad_norm': 0.7316209843345717, 'global/model_version': 22491, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:32,550] calculate_sps 33920 steps in 10.0353
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:32,550] calculate_sps 33920 steps in 10.0353
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:32,550] {'local/mean_episode_return': 30666.666666666668, 'local/mean_episode_step': 3453.6666666666665, 'local/SPS': 3380.0824063638993, 'local/env_act_steps': 14433920, 'local/env_train_steps': 14431360, 'local/optimizer_steps': 22548, 'local/running_reward': 15874.580496108949, 'local/running_step': 1808.3473674610896, 'local/steps_done': 14433920, 'local/episodes_done': 3624, 'local/unclipped_grad_norm': 0.7638039491497554, 'local/model_version': 22548, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:32,551] {'global/mean_episode_return': 30666.666666666668, 'global/mean_episode_step': 3453.6666666666665, 'global/SPS': 3380.0824063638993, 'global/env_act_steps': 14431232, 'global/env_train_steps': 14428160, 'global/optimizer_steps': 22544, 'global/running_reward': 15868.695913461539, 'global/running_step': 1807.9841045673077, 'global/steps_done': 14431232, 'global/episodes_done': 3624, 'global/unclipped_grad_norm': 0.7346642928303413, 'global/model_version': 22544, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:42,567] calculate_sps 32640 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:42,567] calculate_sps 33280 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:42,578] {'local/mean_episode_return': 31900.0, 'local/mean_episode_step': 3588.6, 'local/SPS': 3258.661279476154, 'local/env_act_steps': 14467328, 'local/env_train_steps': 14464000, 'local/optimizer_steps': 22600, 'local/running_reward': 15934.464798850575, 'local/running_step': 1818.076089559387, 'local/steps_done': 14467328, 'local/episodes_done': 3634, 'local/unclipped_grad_norm': 0.7579580831986207, 'local/model_version': 22600, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:42,580] {'global/mean_episode_return': 32000.0, 'global/mean_episode_step': 3607.5555555555557, 'global/SPS': 3322.556598681569, 'global/env_act_steps': 14464512, 'global/env_train_steps': 14461440, 'global/optimizer_steps': 22595, 'global/running_reward': 15941.766826923076, 'global/running_step': 1818.4154146634614, 'global/steps_done': 14464512, 'global/episodes_done': 3633, 'global/unclipped_grad_norm': 0.7717909257785946, 'global/model_version': 22595, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:52,602] calculate_sps 32640 steps in 10.0359
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:29:52,602] calculate_sps 33280 steps in 10.0359
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:52,603] {'local/mean_episode_return': 31509.090909090908, 'local/mean_episode_step': 3499.181818181818, 'local/SPS': 3252.3376399662834, 'local/env_act_steps': 14500224, 'local/env_train_steps': 14496640, 'local/optimizer_steps': 22650, 'local/running_reward': 15990.789153696498, 'local/running_step': 1825.5563594357977, 'local/steps_done': 14500224, 'local/episodes_done': 3645, 'local/unclipped_grad_norm': 0.7379087007045746, 'local/model_version': 22650, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:29:52,604] {'global/mean_episode_return': 31688.88888888889, 'global/mean_episode_step': 3481.0, 'global/SPS': 3316.1089662401323, 'global/env_act_steps': 14498048, 'global/env_train_steps': 14494720, 'global/optimizer_steps': 22648, 'global/running_reward': 15994.596851145037, 'global/running_step': 1825.9031488549617, 'global/steps_done': 14498048, 'global/episodes_done': 3642, 'global/unclipped_grad_norm': 0.7139627770432886, 'global/model_version': 22648, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:02,613] calculate_sps 33920 steps in 10.0107
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:02,614] calculate_sps 32000 steps in 10.0107
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:02,614] {'local/mean_episode_return': 29840.0, 'local/mean_episode_step': 3374.8, 'local/SPS': 3388.3801732348848, 'local/env_act_steps': 14532608, 'local/env_train_steps': 14530560, 'local/optimizer_steps': 22704, 'local/running_reward': 16042.8915513834, 'local/running_step': 1832.900413784585, 'local/steps_done': 14532608, 'local/episodes_done': 3650, 'local/unclipped_grad_norm': 0.7563602841562695, 'local/model_version': 22704, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:02,615] {'global/mean_episode_return': 30200.0, 'global/mean_episode_step': 3431.75, 'global/SPS': 3196.5850690895136, 'global/env_act_steps': 14530944, 'global/env_train_steps': 14526720, 'global/optimizer_steps': 22698, 'global/running_reward': 16020.762402723736, 'global/running_step': 1830.4922178988327, 'global/steps_done': 14530944, 'global/episodes_done': 3650, 'global/unclipped_grad_norm': 0.7926641350984573, 'global/model_version': 22698, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:12,653] calculate_sps 30720 steps in 10.0401
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:12,654] calculate_sps 34560 steps in 10.0401
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:12,654] {'local/mean_episode_return': 31740.0, 'local/mean_episode_step': 3707.1, 'local/SPS': 3059.738080151595, 'local/env_act_steps': 14565760, 'local/env_train_steps': 14561280, 'local/optimizer_steps': 22752, 'local/running_reward': 16566.795366795366, 'local/running_step': 1891.2303028474903, 'local/steps_done': 14565760, 'local/episodes_done': 3656, 'local/unclipped_grad_norm': 0.700960616270701, 'local/model_version': 22752, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:12,655] {'global/mean_episode_return': 29325.0, 'global/mean_episode_step': 3572.625, 'global/SPS': 3442.2053401705443, 'global/env_act_steps': 14563456, 'global/env_train_steps': 14561280, 'global/optimizer_steps': 22752, 'global/running_reward': 16537.475393700788, 'global/running_step': 1888.1763041338584, 'global/steps_done': 14563456, 'global/episodes_done': 3655, 'global/unclipped_grad_norm': 0.6926151933493437, 'global/model_version': 22752, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:22,658] calculate_sps 35200 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:22,658] calculate_sps 31360 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:22,658] {'local/mean_episode_return': 29580.0, 'local/mean_episode_step': 3415.0, 'local/SPS': 3518.439130856804, 'local/env_act_steps': 14598144, 'local/env_train_steps': 14596480, 'local/optimizer_steps': 22807, 'local/running_reward': 16661.854619565216, 'local/running_step': 1890.8038537549407, 'local/steps_done': 14598144, 'local/episodes_done': 3666, 'local/unclipped_grad_norm': 0.8517159613696011, 'local/model_version': 22807, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:22,660] {'global/mean_episode_return': 30654.545454545456, 'global/mean_episode_step': 3490.4545454545455, 'global/SPS': 3134.609407490607, 'global/env_act_steps': 14597248, 'global/env_train_steps': 14592640, 'global/optimizer_steps': 22800, 'global/running_reward': 16665.767045454544, 'global/running_step': 1891.817501183712, 'global/steps_done': 14597248, 'global/episodes_done': 3666, 'global/unclipped_grad_norm': 0.8495064725478491, 'global/model_version': 22800, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:32,669] calculate_sps 31360 steps in 10.0108
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:32,669] calculate_sps 35200 steps in 10.0108
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:32,669] {'local/mean_episode_return': 30733.333333333332, 'local/mean_episode_step': 3469.8333333333335, 'local/SPS': 3132.609274662485, 'local/env_act_steps': 14631040, 'local/env_train_steps': 14627840, 'local/optimizer_steps': 22856, 'local/running_reward': 17021.4798151751, 'local/running_step': 1930.1294686284048, 'local/steps_done': 14631040, 'local/episodes_done': 3672, 'local/unclipped_grad_norm': 0.6804337221748975, 'local/model_version': 22856, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:32,675] {'global/mean_episode_return': 30733.333333333332, 'global/mean_episode_step': 3469.8333333333335, 'global/SPS': 3516.1940838048304, 'global/env_act_steps': 14629632, 'global/env_train_steps': 14627840, 'global/optimizer_steps': 22856, 'global/running_reward': 17005.175395256916, 'global/running_step': 1928.4510251976285, 'global/steps_done': 14629632, 'global/episodes_done': 3672, 'global/unclipped_grad_norm': 0.7037378496357373, 'global/model_version': 22856, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:42,671] calculate_sps 31360 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:42,672] calculate_sps 30720 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:42,672] {'local/mean_episode_return': 30885.714285714286, 'local/mean_episode_step': 3496.4285714285716, 'local/SPS': 3135.2701345063847, 'local/env_act_steps': 14663936, 'local/env_train_steps': 14659200, 'local/optimizer_steps': 22905, 'local/running_reward': 17296.087670233464, 'local/running_step': 1958.0753587062256, 'local/steps_done': 14663936, 'local/episodes_done': 3679, 'local/unclipped_grad_norm': 0.6706889724853088, 'local/model_version': 22905, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:42,673] {'global/mean_episode_return': 30885.714285714286, 'global/mean_episode_step': 3496.4285714285716, 'global/SPS': 3071.2850297205405, 'global/env_act_steps': 14663040, 'global/env_train_steps': 14658560, 'global/optimizer_steps': 22904, 'global/running_reward': 17287.871168582376, 'global/running_step': 1957.142331178161, 'global/steps_done': 14663040, 'global/episodes_done': 3679, 'global/unclipped_grad_norm': 0.6775505930806199, 'global/model_version': 22904, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:52,674] calculate_sps 35200 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:30:52,675] calculate_sps 35200 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:52,675] {'local/mean_episode_return': 28675.0, 'local/mean_episode_step': 3264.75, 'local/SPS': 3518.7929250572747, 'local/env_act_steps': 14695936, 'local/env_train_steps': 14694400, 'local/optimizer_steps': 22960, 'local/running_reward': 17521.303125, 'local/running_step': 1980.92559375, 'local/steps_done': 14695936, 'local/episodes_done': 3687, 'local/unclipped_grad_norm': 0.7377732000567696, 'local/model_version': 22960, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:30:52,677] {'global/mean_episode_return': 28675.0, 'global/mean_episode_step': 3264.75, 'global/SPS': 3518.7929250572747, 'global/env_act_steps': 14695296, 'global/env_train_steps': 14693760, 'global/optimizer_steps': 22958, 'global/running_reward': 17515.432787698413, 'global/running_step': 1980.4167906746031, 'global/steps_done': 14695296, 'global/episodes_done': 3687, 'global/unclipped_grad_norm': 0.7394096476060373, 'global/model_version': 22958, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:02,707] calculate_sps 30720 steps in 10.0326
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:02,708] calculate_sps 31360 steps in 10.0326
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:02,708] {'local/mean_episode_return': 33760.0, 'local/mean_episode_step': 3672.4, 'local/SPS': 3062.010640573939, 'local/env_act_steps': 14729216, 'local/env_train_steps': 14725120, 'local/optimizer_steps': 23008, 'local/running_reward': 17693.19110576923, 'local/running_step': 1999.024188701923, 'local/steps_done': 14729216, 'local/episodes_done': 3697, 'local/unclipped_grad_norm': 0.6883032470941544, 'local/model_version': 23008, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:02,709] {'global/mean_episode_return': 33760.0, 'global/mean_episode_step': 3672.4, 'global/SPS': 3125.802528919229, 'global/env_act_steps': 14728832, 'global/env_train_steps': 14725120, 'global/optimizer_steps': 23008, 'global/running_reward': 17695.55403148855, 'global/running_step': 1999.2262344942749, 'global/steps_done': 14728832, 'global/episodes_done': 3697, 'global/unclipped_grad_norm': 0.6805858415365219, 'global/model_version': 23008, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:12,707] calculate_sps 34560 steps in 10
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:12,707] calculate_sps 34560 steps in 10
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:12,707] {'local/mean_episode_return': 27040.0, 'local/mean_episode_step': 3239.4, 'local/SPS': 3455.99225465603, 'local/env_act_steps': 14761728, 'local/env_train_steps': 14759680, 'local/optimizer_steps': 23061, 'local/running_reward': 17926.81779035433, 'local/running_step': 2022.9596764271653, 'local/steps_done': 14761728, 'local/episodes_done': 3702, 'local/unclipped_grad_norm': 0.7165264762797445, 'local/model_version': 23061, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:12,708] {'global/mean_episode_return': 27040.0, 'global/mean_episode_step': 3239.4, 'global/SPS': 3455.99225465603, 'global/env_act_steps': 14761728, 'global/env_train_steps': 14759680, 'global/optimizer_steps': 23061, 'global/running_reward': 17921.221425097276, 'global/running_step': 2022.3863995622569, 'global/steps_done': 14761728, 'global/episodes_done': 3702, 'global/unclipped_grad_norm': 0.7165264762797445, 'global/model_version': 23061, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:22,745] calculate_sps 32000 steps in 10.0375
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:22,745] calculate_sps 26880 steps in 10.0375
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:22,745] {'local/mean_episode_return': 34400.0, 'local/mean_episode_step': 3699.5, 'local/SPS': 3188.055387972505, 'local/env_act_steps': 14794880, 'local/env_train_steps': 14791680, 'local/optimizer_steps': 23112, 'local/running_reward': 18309.287524131276, 'local/running_step': 2061.0874155405404, 'local/steps_done': 14794880, 'local/episodes_done': 3710, 'local/unclipped_grad_norm': 0.7791233959735608, 'local/model_version': 23112, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:22,746] {'global/mean_episode_return': 32114.285714285714, 'global/mean_episode_step': 3497.8571428571427, 'global/SPS': 2677.966525896904, 'global/env_act_steps': 14788224, 'global/env_train_steps': 14786560, 'global/optimizer_steps': 23104, 'global/running_reward': 18289.5946557971, 'global/running_step': 2058.553291062802, 'global/steps_done': 14788224, 'global/episodes_done': 3709, 'global/unclipped_grad_norm': 0.738658071603886, 'global/model_version': 23104, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:32,755] calculate_sps 31360 steps in 10.0103
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:32,755] calculate_sps 30720 steps in 10.0103
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:32,758] {'local/mean_episode_return': 34145.454545454544, 'local/mean_episode_step': 3739.7272727272725, 'local/SPS': 3132.7858035210866, 'local/env_act_steps': 14827776, 'local/env_train_steps': 14823040, 'local/optimizer_steps': 23161, 'local/running_reward': 18302.46534533074, 'local/running_step': 2064.6298942120625, 'local/steps_done': 14827776, 'local/episodes_done': 3721, 'local/unclipped_grad_norm': 0.7165083374295916, 'local/model_version': 23161, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:32,760] {'global/mean_episode_return': 36454.545454545456, 'global/mean_episode_step': 3921.181818181818, 'global/SPS': 3068.851399367595, 'global/env_act_steps': 14821888, 'global/env_train_steps': 14817280, 'global/optimizer_steps': 23152, 'global/running_reward': 18374.780180608366, 'global/running_step': 2071.7975879277565, 'global/steps_done': 14821888, 'global/episodes_done': 3720, 'global/unclipped_grad_norm': 0.7868424175928036, 'global/model_version': 23152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:42,798] calculate_sps 35200 steps in 10.0434
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:42,799] calculate_sps 35200 steps in 10.0434
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:42,799] {'local/mean_episode_return': 38818.181818181816, 'local/mean_episode_step': 4150.272727272727, 'local/SPS': 3504.793940018919, 'local/env_act_steps': 14859648, 'local/env_train_steps': 14858240, 'local/optimizer_steps': 23216, 'local/running_reward': 17705.603664658636, 'local/running_step': 2003.7602597891566, 'local/steps_done': 14859648, 'local/episodes_done': 3732, 'local/unclipped_grad_norm': 0.7209241040728309, 'local/model_version': 23216, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:42,800] {'global/mean_episode_return': 37636.36363636364, 'global/mean_episode_step': 4082.2727272727275, 'global/SPS': 3504.793940018919, 'global/env_act_steps': 14854016, 'global/env_train_steps': 14852480, 'global/optimizer_steps': 23206, 'global/running_reward': 17809.14778386454, 'global/running_step': 2013.8211840139443, 'global/steps_done': 14854016, 'global/episodes_done': 3731, 'global/unclipped_grad_norm': 0.675601936324879, 'global/model_version': 23206, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:52,824] calculate_sps 30720 steps in 10.0255
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:31:52,824] calculate_sps 31360 steps in 10.0255
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:52,824] {'local/mean_episode_return': 34866.666666666664, 'local/mean_episode_step': 3817.5833333333335, 'local/SPS': 3064.197820314975, 'local/env_act_steps': 14893184, 'local/env_train_steps': 14888960, 'local/optimizer_steps': 23264, 'local/running_reward': 17363.272304389313, 'local/running_step': 1966.9212189885495, 'local/steps_done': 14893184, 'local/episodes_done': 3744, 'local/unclipped_grad_norm': 0.8136380823949972, 'local/model_version': 23264, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:31:52,826] {'global/mean_episode_return': 35900.0, 'global/mean_episode_step': 3887.25, 'global/SPS': 3128.0352749048707, 'global/env_act_steps': 14887808, 'global/env_train_steps': 14883840, 'global/optimizer_steps': 23256, 'global/running_reward': 17429.036458333332, 'global/running_step': 1974.7062618371212, 'global/steps_done': 14887808, 'global/episodes_done': 3743, 'global/unclipped_grad_norm': 0.8561678272485733, 'global/model_version': 23256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:02,835] calculate_sps 34560 steps in 10.0121
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:02,836] calculate_sps 34560 steps in 10.0121
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:02,836] {'local/mean_episode_return': 34625.0, 'local/mean_episode_step': 3775.0, 'local/SPS': 3451.833081898625, 'local/env_act_steps': 14925568, 'local/env_train_steps': 14923520, 'local/optimizer_steps': 23317, 'local/running_reward': 17199.31138833992, 'local/running_step': 1945.0663908102767, 'local/steps_done': 14925568, 'local/episodes_done': 3752, 'local/unclipped_grad_norm': 0.7995780014766837, 'local/model_version': 23317, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:02,837] {'global/mean_episode_return': 33622.22222222222, 'global/mean_episode_step': 3691.8888888888887, 'global/SPS': 3451.833081898625, 'global/env_act_steps': 14920448, 'global/env_train_steps': 14918400, 'global/optimizer_steps': 23309, 'global/running_reward': 17187.5, 'global/running_step': 1944.2977634803922, 'global/steps_done': 14920448, 'global/episodes_done': 3752, 'global/unclipped_grad_norm': 0.7756003580003414, 'global/model_version': 23309, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:12,865] calculate_sps 32000 steps in 10.0293
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:12,865] calculate_sps 32000 steps in 10.0293
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:12,866] {'local/mean_episode_return': 30620.0, 'local/mean_episode_step': 3504.5, 'local/SPS': 3190.6662659922017, 'local/env_act_steps': 14958976, 'local/env_train_steps': 14955520, 'local/optimizer_steps': 23368, 'local/running_reward': 17209.213362068964, 'local/running_step': 1946.7136613984674, 'local/steps_done': 14958976, 'local/episodes_done': 3762, 'local/unclipped_grad_norm': 0.6045037613195532, 'local/model_version': 23368, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:12,875] {'global/mean_episode_return': 31875.0, 'global/mean_episode_step': 3647.875, 'global/SPS': 3190.6662659922017, 'global/env_act_steps': 14953984, 'global/env_train_steps': 14950400, 'global/optimizer_steps': 23360, 'global/running_reward': 17199.680939885497, 'global/running_step': 1945.6787333015268, 'global/steps_done': 14953984, 'global/episodes_done': 3760, 'global/unclipped_grad_norm': 0.589435779580883, 'global/model_version': 23360, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:22,867] calculate_sps 32000 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:22,868] calculate_sps 32640 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:22,868] {'local/mean_episode_return': 33973.333333333336, 'local/mean_episode_step': 3718.3333333333335, 'local/SPS': 3199.2547817416757, 'local/env_act_steps': 14991744, 'local/env_train_steps': 14987520, 'local/optimizer_steps': 23418, 'local/running_reward': 17085.382080078125, 'local/running_step': 1934.3997497558594, 'local/steps_done': 14991744, 'local/episodes_done': 3777, 'local/unclipped_grad_norm': 0.829537239074707, 'local/model_version': 23418, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:22,869] {'global/mean_episode_return': 32676.923076923078, 'global/mean_episode_step': 3567.4615384615386, 'global/SPS': 3263.2398773765094, 'global/env_act_steps': 14986752, 'global/env_train_steps': 14983040, 'global/optimizer_steps': 23411, 'global/running_reward': 17169.4580078125, 'global/running_step': 1942.8650512695312, 'global/steps_done': 14986752, 'global/episodes_done': 3773, 'global/unclipped_grad_norm': 0.8101446581821815, 'global/model_version': 23411, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:32,891] calculate_sps 34560 steps in 10.0236
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:32,891] calculate_sps 33920 steps in 10.0236
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:32,892] {'local/mean_episode_return': 29511.11111111111, 'local/mean_episode_step': 3418.3333333333335, 'local/SPS': 3447.862352235384, 'local/env_act_steps': 15024000, 'local/env_train_steps': 15022080, 'local/optimizer_steps': 23472, 'local/running_reward': 16292.491319444445, 'local/running_step': 1849.567150297619, 'local/steps_done': 15024000, 'local/episodes_done': 3786, 'local/unclipped_grad_norm': 0.7240134025061572, 'local/model_version': 23472, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:32,893] {'global/mean_episode_return': 31300.0, 'global/mean_episode_step': 3549.5833333333335, 'global/SPS': 3384.0130494162104, 'global/env_act_steps': 15019520, 'global/env_train_steps': 15016960, 'global/optimizer_steps': 23464, 'global/running_reward': 16336.99951171875, 'global/running_step': 1854.9558715820312, 'global/steps_done': 15019520, 'global/episodes_done': 3785, 'global/unclipped_grad_norm': 0.7367137529939976, 'global/model_version': 23464, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:42,900] calculate_sps 30720 steps in 10.0089
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:42,900] calculate_sps 30720 steps in 10.0089
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:42,900] {'local/mean_episode_return': 36875.0, 'local/mean_episode_step': 3894.0625, 'local/SPS': 3069.261720333698, 'local/env_act_steps': 15057024, 'local/env_train_steps': 15052800, 'local/optimizer_steps': 23520, 'local/running_reward': 16164.901283914729, 'local/running_step': 1838.8082606589148, 'local/steps_done': 15057024, 'local/episodes_done': 3796, 'local/unclipped_grad_norm': 0.7760816067457199, 'local/model_version': 23520, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:42,911] {'global/mean_episode_return': 37528.57142857143, 'global/mean_episode_step': 3984.0, 'global/SPS': 3069.261720333698, 'global/env_act_steps': 15052672, 'global/env_train_steps': 15047680, 'global/optimizer_steps': 23512, 'global/running_reward': 16188.872466216217, 'global/running_step': 1840.8215190637065, 'global/steps_done': 15052672, 'global/episodes_done': 3793, 'global/unclipped_grad_norm': 0.775211081529657, 'global/model_version': 23512, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:52,910] calculate_sps 34560 steps in 10.0106
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:32:52,910] calculate_sps 35840 steps in 10.0106
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:52,910] {'local/mean_episode_return': 32000.0, 'local/mean_episode_step': 3531.9, 'local/SPS': 3452.343530258068, 'local/env_act_steps': 15089408, 'local/env_train_steps': 15087360, 'local/optimizer_steps': 23573, 'local/running_reward': 16073.304718379446, 'local/running_step': 1829.096745306324, 'local/steps_done': 15089408, 'local/episodes_done': 3806, 'local/unclipped_grad_norm': 0.7349370425602175, 'local/model_version': 23573, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:32:52,911] {'global/mean_episode_return': 31809.090909090908, 'global/mean_episode_step': 3526.0454545454545, 'global/SPS': 3580.208105452811, 'global/env_act_steps': 15085184, 'global/env_train_steps': 15083520, 'global/optimizer_steps': 23568, 'global/running_reward': 16088.425812007874, 'global/running_step': 1830.5908280019685, 'global/steps_done': 15085184, 'global/episodes_done': 3805, 'global/unclipped_grad_norm': 0.7494873266134944, 'global/model_version': 23568, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:02,927] calculate_sps 32000 steps in 10.0169
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:02,928] calculate_sps 30720 steps in 10.0169
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:02,928] {'local/mean_episode_return': 30800.0, 'local/mean_episode_step': 3467.777777777778, 'local/SPS': 3194.596237805371, 'local/env_act_steps': 15121920, 'local/env_train_steps': 15119360, 'local/optimizer_steps': 23624, 'local/running_reward': 16041.643085629921, 'local/running_step': 1821.6374569389764, 'local/steps_done': 15121920, 'local/episodes_done': 3815, 'local/unclipped_grad_norm': 0.7252354727071875, 'local/model_version': 23624, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:02,929] {'global/mean_episode_return': 29500.0, 'global/mean_episode_step': 3336.5, 'global/SPS': 3066.812388293156, 'global/env_act_steps': 15118336, 'global/env_train_steps': 15114240, 'global/optimizer_steps': 23616, 'global/running_reward': 16015.974903474904, 'global/running_step': 1819.649523407336, 'global/steps_done': 15118336, 'global/episodes_done': 3813, 'global/unclipped_grad_norm': 0.7537864881257216, 'global/model_version': 23616, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:12,932] calculate_sps 30720 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:12,932] calculate_sps 34560 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:12,942] {'local/mean_episode_return': 34000.0, 'local/mean_episode_step': 3755.181818181818, 'local/SPS': 3070.6431288778635, 'local/env_act_steps': 15155328, 'local/env_train_steps': 15150080, 'local/optimizer_steps': 23672, 'local/running_reward': 16063.781130268198, 'local/running_step': 1820.0866558908046, 'local/steps_done': 15155328, 'local/episodes_done': 3826, 'local/unclipped_grad_norm': 0.7585119598855575, 'local/model_version': 23672, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:12,944] {'global/mean_episode_return': 33672.72727272727, 'global/mean_episode_step': 3720.818181818182, 'global/SPS': 3454.4735199875963, 'global/env_act_steps': 15150848, 'global/env_train_steps': 15148800, 'global/optimizer_steps': 23669, 'global/running_reward': 16098.071481299212, 'global/running_step': 1824.337813730315, 'global/steps_done': 15150848, 'global/episodes_done': 3824, 'global/unclipped_grad_norm': 0.7413215136752939, 'global/model_version': 23669, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:22,948] calculate_sps 35840 steps in 10.0163
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:22,948] calculate_sps 32000 steps in 10.0163
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:22,949] {'local/mean_episode_return': 31060.0, 'local/mean_episode_step': 3548.8, 'local/SPS': 3578.171943795387, 'local/env_act_steps': 15187456, 'local/env_train_steps': 15185920, 'local/optimizer_steps': 23728, 'local/running_reward': 15829.892928286852, 'local/running_step': 1789.1541334661354, 'local/steps_done': 15187456, 'local/episodes_done': 3836, 'local/unclipped_grad_norm': 0.711118576249906, 'local/model_version': 23728, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:22,950] {'global/mean_episode_return': 31400.0, 'global/mean_episode_step': 3594.0, 'global/SPS': 3194.7963783887385, 'global/env_act_steps': 15184256, 'global/env_train_steps': 15180800, 'global/optimizer_steps': 23720, 'global/running_reward': 15854.310344827587, 'global/running_step': 1792.5967432950192, 'global/steps_done': 15184256, 'global/episodes_done': 3835, 'global/unclipped_grad_norm': 0.7197290629732842, 'global/model_version': 23720, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:32,965] calculate_sps 30720 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:32,965] calculate_sps 33280 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:32,965] {'local/mean_episode_return': 34700.0, 'local/mean_episode_step': 3718.75, 'local/SPS': 3066.955830239358, 'local/env_act_steps': 15220736, 'local/env_train_steps': 15216640, 'local/optimizer_steps': 23776, 'local/running_reward': 15723.26923076923, 'local/running_step': 1776.1731069711539, 'local/steps_done': 15220736, 'local/episodes_done': 3844, 'local/unclipped_grad_norm': 0.688392611220479, 'local/model_version': 23776, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:32,975] {'global/mean_episode_return': 36600.0, 'global/mean_episode_step': 3859.0, 'global/SPS': 3322.5354827593046, 'global/env_act_steps': 15217152, 'global/env_train_steps': 15214080, 'global/optimizer_steps': 23771, 'global/running_reward': 15713.37852626459, 'global/running_step': 1774.637737110895, 'global/steps_done': 15217152, 'global/episodes_done': 3843, 'global/unclipped_grad_norm': 0.7098184350658866, 'global/model_version': 23771, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:42,985] calculate_sps 33920 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:42,986] calculate_sps 33280 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:42,986] {'local/mean_episode_return': 34745.454545454544, 'local/mean_episode_step': 3759.0, 'local/SPS': 3384.780868003155, 'local/env_act_steps': 15253120, 'local/env_train_steps': 15250560, 'local/optimizer_steps': 23828, 'local/running_reward': 15618.391798418972, 'local/running_step': 1767.888309041502, 'local/steps_done': 15253120, 'local/episodes_done': 3855, 'local/unclipped_grad_norm': 0.6908198354335932, 'local/model_version': 23828, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:42,987] {'global/mean_episode_return': 33783.333333333336, 'global/mean_episode_step': 3692.0, 'global/SPS': 3320.9170780408313, 'global/env_act_steps': 15249792, 'global/env_train_steps': 15247360, 'global/optimizer_steps': 23824, 'global/running_reward': 15655.45036764706, 'global/running_step': 1771.7224571078432, 'global/steps_done': 15249792, 'global/episodes_done': 3855, 'global/unclipped_grad_norm': 0.6511346574099559, 'global/model_version': 23824, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:52,994] calculate_sps 32640 steps in 10.0081
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:33:52,994] calculate_sps 30720 steps in 10.0081
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:52,995] {'local/mean_episode_return': 26909.090909090908, 'local/mean_episode_step': 3182.2727272727275, 'local/SPS': 3261.344925788975, 'local/env_act_steps': 15285632, 'local/env_train_steps': 15283200, 'local/optimizer_steps': 23880, 'local/running_reward': 15590.886441929133, 'local/running_step': 1766.3156065452756, 'local/steps_done': 15285632, 'local/episodes_done': 3866, 'local/unclipped_grad_norm': 0.6843703615550811, 'local/model_version': 23880, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:33:52,996] {'global/mean_episode_return': 27540.0, 'global/mean_episode_step': 3223.3, 'global/SPS': 3069.5011066249176, 'global/env_act_steps': 15283328, 'global/env_train_steps': 15278080, 'global/optimizer_steps': 23872, 'global/running_reward': 15584.222924618321, 'global/running_step': 1765.6168296755725, 'global/steps_done': 15283328, 'global/episodes_done': 3865, 'global/unclipped_grad_norm': 0.6622849979127446, 'global/model_version': 23872, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:03,019] calculate_sps 30720 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:03,019] calculate_sps 35840 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:03,019] {'local/mean_episode_return': 38000.0, 'local/mean_episode_step': 4155.25, 'local/SPS': 3064.4565328681697, 'local/env_act_steps': 15318784, 'local/env_train_steps': 15313920, 'local/optimizer_steps': 23928, 'local/running_reward': 15697.224903474904, 'local/running_step': 1774.96048503861, 'local/steps_done': 15318784, 'local/episodes_done': 3870, 'local/unclipped_grad_norm': 0.7418168935303887, 'local/model_version': 23928, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:03,021] {'global/mean_episode_return': 34520.0, 'global/mean_episode_step': 3878.6, 'global/SPS': 3575.199288346198, 'global/env_act_steps': 15315456, 'global/env_train_steps': 15313920, 'global/optimizer_steps': 23928, 'global/running_reward': 15655.54656374502, 'global/running_step': 1770.285202938247, 'global/steps_done': 15315456, 'global/episodes_done': 3870, 'global/unclipped_grad_norm': 0.7624908044402089, 'global/model_version': 23928, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:13,037] calculate_sps 35840 steps in 10.0185
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:13,037] calculate_sps 30720 steps in 10.0185
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:13,037] {'local/mean_episode_return': 31775.0, 'local/mean_episode_step': 3588.0, 'local/SPS': 3577.3721063372764, 'local/env_act_steps': 15350784, 'local/env_train_steps': 15349760, 'local/optimizer_steps': 23983, 'local/running_reward': 16233.221875, 'local/running_step': 1833.42071875, 'local/steps_done': 15350784, 'local/episodes_done': 3878, 'local/unclipped_grad_norm': 0.6551524536176161, 'local/model_version': 23983, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:13,038] {'global/mean_episode_return': 31485.714285714286, 'global/mean_episode_step': 3606.4285714285716, 'global/SPS': 3066.318948289094, 'global/env_act_steps': 15349248, 'global/env_train_steps': 15344640, 'global/optimizer_steps': 23976, 'global/running_reward': 16204.006865530304, 'global/running_step': 1830.5666725852273, 'global/steps_done': 15349248, 'global/episodes_done': 3877, 'global/unclipped_grad_norm': 0.6547287808110317, 'global/model_version': 23976, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:23,063] calculate_sps 30720 steps in 10.0259
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:23,063] calculate_sps 35200 steps in 10.0259
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:23,064] {'local/mean_episode_return': 32500.0, 'local/mean_episode_step': 3622.25, 'local/SPS': 3064.0592266588546, 'local/env_act_steps': 15384192, 'local/env_train_steps': 15380480, 'local/optimizer_steps': 24032, 'local/running_reward': 16555.92672413793, 'local/running_step': 1864.315164032567, 'local/steps_done': 15384192, 'local/episodes_done': 3882, 'local/unclipped_grad_norm': 0.8101435388837542, 'local/model_version': 24032, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:23,065] {'global/mean_episode_return': 33300.0, 'global/mean_episode_step': 3624.5, 'global/SPS': 3510.901197213271, 'global/env_act_steps': 15381504, 'global/env_train_steps': 15379840, 'global/optimizer_steps': 24030, 'global/running_reward': 16514.899553571428, 'global/running_step': 1859.954799107143, 'global/steps_done': 15381504, 'global/episodes_done': 3881, 'global/unclipped_grad_norm': 0.794089150097635, 'global/model_version': 24030, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:33,078] calculate_sps 32640 steps in 10.0149
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:33,078] calculate_sps 31360 steps in 10.0149
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:33,079] {'local/mean_episode_return': 37100.0, 'local/mean_episode_step': 4017.875, 'local/SPS': 3259.141713205939, 'local/env_act_steps': 15416832, 'local/env_train_steps': 15413120, 'local/optimizer_steps': 24083, 'local/running_reward': 17264.466911764706, 'local/running_step': 1937.4551776960784, 'local/steps_done': 15416832, 'local/episodes_done': 3890, 'local/unclipped_grad_norm': 0.6474190529655007, 'local/model_version': 24083, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:33,080] {'global/mean_episode_return': 32571.428571428572, 'global/mean_episode_step': 3689.285714285714, 'global/SPS': 3131.332234256686, 'global/env_act_steps': 15415040, 'global/env_train_steps': 15411200, 'global/optimizer_steps': 24080, 'global/running_reward': 17243.174499045803, 'global/running_step': 1935.3877027671756, 'global/steps_done': 15415040, 'global/episodes_done': 3888, 'global/unclipped_grad_norm': 0.6481292086839676, 'global/model_version': 24080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:43,099] calculate_sps 33920 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:43,100] calculate_sps 33280 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:43,110] {'local/mean_episode_return': 39544.444444444445, 'local/mean_episode_step': 4172.111111111111, 'local/SPS': 3384.79391354299, 'local/env_act_steps': 15449472, 'local/env_train_steps': 15447040, 'local/optimizer_steps': 24136, 'local/running_reward': 16694.917279411766, 'local/running_step': 1883.702205882353, 'local/steps_done': 15449472, 'local/episodes_done': 3899, 'local/unclipped_grad_norm': 0.7712246235811485, 'local/model_version': 24136, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:43,112] {'global/mean_episode_return': 41390.90909090909, 'global/mean_episode_step': 4301.545454545455, 'global/SPS': 3320.9298774384056, 'global/env_act_steps': 15447680, 'global/env_train_steps': 15444480, 'global/optimizer_steps': 24132, 'global/running_reward': 16722.94730392157, 'global/running_step': 1886.0149203431372, 'global/steps_done': 15447680, 'global/episodes_done': 3899, 'global/unclipped_grad_norm': 0.7874811469362333, 'global/model_version': 24132, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:53,117] calculate_sps 30720 steps in 10.0175
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:34:53,117] calculate_sps 33280 steps in 10.0175
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:53,117] {'local/mean_episode_return': 33436.36363636364, 'local/mean_episode_step': 3688.5454545454545, 'local/SPS': 3066.6424652746805, 'local/env_act_steps': 15483008, 'local/env_train_steps': 15477760, 'local/optimizer_steps': 24184, 'local/running_reward': 16564.951097328245, 'local/running_step': 1872.681029341603, 'local/steps_done': 15483008, 'local/episodes_done': 3910, 'local/unclipped_grad_norm': 0.6625658714522918, 'local/model_version': 24184, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:34:53,119] {'global/mean_episode_return': 33560.0, 'global/mean_episode_step': 3699.3, 'global/SPS': 3322.1960040475706, 'global/env_act_steps': 15480960, 'global/env_train_steps': 15477760, 'global/optimizer_steps': 24184, 'global/running_reward': 16573.46153846154, 'global/running_step': 1873.611328125, 'global/steps_done': 15480960, 'global/episodes_done': 3909, 'global/unclipped_grad_norm': 0.649299639921922, 'global/model_version': 24184, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:03,128] calculate_sps 35840 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:03,128] calculate_sps 32640 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:03,128] {'local/mean_episode_return': 31690.909090909092, 'local/mean_episode_step': 3484.7272727272725, 'local/SPS': 3580.075688365738, 'local/env_act_steps': 15515264, 'local/env_train_steps': 15513600, 'local/optimizer_steps': 24240, 'local/running_reward': 16238.61607142857, 'local/running_step': 1837.626457093254, 'local/steps_done': 15515264, 'local/episodes_done': 3921, 'local/unclipped_grad_norm': 0.7213499993085861, 'local/model_version': 24240, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:03,130] {'global/mean_episode_return': 31400.0, 'global/mean_episode_step': 3459.2727272727275, 'global/SPS': 3260.426073333083, 'global/env_act_steps': 15514112, 'global/env_train_steps': 15510400, 'global/optimizer_steps': 24235, 'global/running_reward': 16251.592664092665, 'global/running_step': 1839.0516409266409, 'global/steps_done': 15514112, 'global/episodes_done': 3920, 'global/unclipped_grad_norm': 0.7107202737939124, 'global/model_version': 24235, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:13,139] calculate_sps 30720 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:13,140] calculate_sps 33920 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:13,140] {'local/mean_episode_return': 25400.0, 'local/mean_episode_step': 3050.1666666666665, 'local/SPS': 3068.4452801665475, 'local/env_act_steps': 15548672, 'local/env_train_steps': 15544320, 'local/optimizer_steps': 24288, 'local/running_reward': 16393.977490421457, 'local/running_step': 1848.9100215517242, 'local/steps_done': 15548672, 'local/episodes_done': 3927, 'local/unclipped_grad_norm': 0.6460204645991325, 'local/model_version': 24288, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:13,141] {'global/mean_episode_return': 26828.571428571428, 'global/mean_episode_step': 3166.0, 'global/SPS': 3388.074996850563, 'global/env_act_steps': 15547008, 'global/env_train_steps': 15544320, 'global/optimizer_steps': 24288, 'global/running_reward': 16369.066147859921, 'global/running_step': 1846.4921571011673, 'global/steps_done': 15547008, 'global/episodes_done': 3927, 'global/unclipped_grad_norm': 0.6633556282745218, 'global/model_version': 24288, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:23,145] calculate_sps 34560 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:23,158] calculate_sps 32000 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:23,158] {'local/mean_episode_return': 34520.0, 'local/mean_episode_step': 3764.8, 'local/SPS': 3454.098736345148, 'local/env_act_steps': 15581056, 'local/env_train_steps': 15578880, 'local/optimizer_steps': 24342, 'local/running_reward': 17144.750494071148, 'local/running_step': 1928.5916193181818, 'local/steps_done': 15581056, 'local/episodes_done': 3932, 'local/unclipped_grad_norm': 0.7739525045509692, 'local/model_version': 24342, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:23,160] {'global/mean_episode_return': 34520.0, 'global/mean_episode_step': 3764.8, 'global/SPS': 3198.239570689952, 'global/env_act_steps': 15580416, 'global/env_train_steps': 15576320, 'global/optimizer_steps': 24337, 'global/running_reward': 17129.02298850575, 'global/running_step': 1926.885476532567, 'global/steps_done': 15580416, 'global/episodes_done': 3932, 'global/unclipped_grad_norm': 0.78115328051606, 'global/model_version': 24337, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:33,182] calculate_sps 32000 steps in 10.0376
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:33,183] calculate_sps 34560 steps in 10.0376
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:33,183] {'local/mean_episode_return': 29433.333333333332, 'local/mean_episode_step': 3521.1666666666665, 'local/SPS': 3188.0069244245487, 'local/env_act_steps': 15614208, 'local/env_train_steps': 15610880, 'local/optimizer_steps': 24392, 'local/running_reward': 17415.68532818533, 'local/running_step': 1958.882541023166, 'local/steps_done': 15614208, 'local/episodes_done': 3938, 'local/unclipped_grad_norm': 0.6914734309911728, 'local/model_version': 24392, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:33,184] {'global/mean_episode_return': 29433.333333333332, 'global/mean_episode_step': 3521.1666666666665, 'global/SPS': 3443.0474783785126, 'global/env_act_steps': 15612928, 'global/env_train_steps': 15610880, 'global/optimizer_steps': 24392, 'global/running_reward': 17397.625492125986, 'global/running_step': 1957.0036909448818, 'global/steps_done': 15612928, 'global/episodes_done': 3938, 'global/unclipped_grad_norm': 0.6925562918186188, 'global/model_version': 24392, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:43,223] calculate_sps 32000 steps in 10.041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:43,223] calculate_sps 30720 steps in 10.041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:43,223] {'local/mean_episode_return': 29800.0, 'local/mean_episode_step': 3338.125, 'local/SPS': 3186.923997129488, 'local/env_act_steps': 15646976, 'local/env_train_steps': 15642880, 'local/optimizer_steps': 24441, 'local/running_reward': 17703.69873046875, 'local/running_step': 1989.0689086914062, 'local/steps_done': 15646976, 'local/episodes_done': 3946, 'local/unclipped_grad_norm': 0.5944360695323165, 'local/model_version': 24441, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:43,224] {'global/mean_episode_return': 29800.0, 'global/mean_episode_step': 3338.125, 'global/SPS': 3059.4470372443084, 'global/env_act_steps': 15646208, 'global/env_train_steps': 15641600, 'global/optimizer_steps': 24440, 'global/running_reward': 17697.884615384617, 'global/running_step': 1988.4595853365386, 'global/steps_done': 15646208, 'global/episodes_done': 3946, 'global/unclipped_grad_norm': 0.5960244480520487, 'global/model_version': 24440, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 12:35:52,234] saving global stats {'mean_episode_return': 35400.0, 'mean_episode_step': 3537.5, 'SPS': None, 'env_act_steps': 15665920, 'env_train_steps': 15662080, 'optimizer_steps': 24472, 'running_reward': 18068.607954545456, 'running_step': 2028.8985896915585, 'steps_done': 15665920, 'episodes_done': 3948, 'unclipped_grad_norm': 0.6386450547724962, 'model_version': 24472, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 12:35:52,338] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:53,238] calculate_sps 34560 steps in 10.015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:35:53,239] calculate_sps 35200 steps in 10.015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:53,239] {'local/mean_episode_return': 31750.0, 'local/mean_episode_step': 3337.75, 'local/SPS': 3450.8276714510653, 'local/env_act_steps': 15679104, 'local/env_train_steps': 15677440, 'local/optimizer_steps': 24496, 'local/running_reward': 18226.232569721116, 'local/running_step': 2045.7556337151395, 'local/steps_done': 15679104, 'local/episodes_done': 3950, 'local/unclipped_grad_norm': 0.669577792557803, 'local/model_version': 24496, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:35:53,240] {'global/mean_episode_return': 31750.0, 'global/mean_episode_step': 3337.75, 'global/SPS': 3514.731887589048, 'global/env_act_steps': 15678336, 'global/env_train_steps': 15676800, 'global/optimizer_steps': 24494, 'global/running_reward': 18209.910358565736, 'global/running_step': 2044.0023032868526, 'global/steps_done': 15678336, 'global/episodes_done': 3950, 'global/unclipped_grad_norm': 0.6724030231987989, 'global/model_version': 24494, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:03,264] calculate_sps 30720 steps in 10.0259
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:03,265] calculate_sps 31360 steps in 10.0259
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:03,265] {'local/mean_episode_return': 35222.22222222222, 'local/mean_episode_step': 3906.0, 'local/SPS': 3064.053324683688, 'local/env_act_steps': 15712000, 'local/env_train_steps': 15708160, 'local/optimizer_steps': 24544, 'local/running_reward': 18634.678988326847, 'local/running_step': 2088.508086089494, 'local/steps_done': 15712000, 'local/episodes_done': 3959, 'local/unclipped_grad_norm': 0.6494986141721407, 'local/model_version': 24544, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:03,266] {'global/mean_episode_return': 35222.22222222222, 'global/mean_episode_step': 3906.0, 'global/SPS': 3127.8877689479314, 'global/env_act_steps': 15711360, 'global/env_train_steps': 15708160, 'global/optimizer_steps': 24544, 'global/running_reward': 18635.919331395347, 'global/running_step': 2088.7017017926355, 'global/steps_done': 15711360, 'global/episodes_done': 3959, 'global/unclipped_grad_norm': 0.6442228543758393, 'global/model_version': 24544, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:13,273] calculate_sps 33280 steps in 10.0084
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:13,284] calculate_sps 32640 steps in 10.0084
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:13,284] {'local/mean_episode_return': 35846.153846153844, 'local/mean_episode_step': 3819.769230769231, 'local/SPS': 3325.2146804959807, 'local/env_act_steps': 15744640, 'local/env_train_steps': 15741440, 'local/optimizer_steps': 24596, 'local/running_reward': 17928.933823529413, 'local/running_step': 2017.4699142156862, 'local/steps_done': 15744640, 'local/episodes_done': 3972, 'local/unclipped_grad_norm': 0.6784987925336912, 'local/model_version': 24596, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:13,286] {'global/mean_episode_return': 35846.153846153844, 'global/mean_episode_step': 3819.769230769231, 'global/SPS': 3261.268244332596, 'global/env_act_steps': 15744384, 'global/env_train_steps': 15740800, 'global/optimizer_steps': 24594, 'global/running_reward': 17941.478924418603, 'global/running_step': 2018.6164001937984, 'global/steps_done': 15744384, 'global/episodes_done': 3972, 'global/unclipped_grad_norm': 0.6787299305200577, 'global/model_version': 24594, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:23,287] calculate_sps 33280 steps in 10.0139
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:23,288] calculate_sps 33920 steps in 10.0139
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:23,288] {'local/mean_episode_return': 24725.0, 'local/mean_episode_step': 2952.5, 'local/SPS': 3323.373524267472, 'local/env_act_steps': 15777408, 'local/env_train_steps': 15774720, 'local/optimizer_steps': 24648, 'local/running_reward': 17951.287841796875, 'local/running_step': 2026.7323303222656, 'local/steps_done': 15777408, 'local/episodes_done': 3980, 'local/unclipped_grad_norm': 0.645887415856123, 'local/model_version': 24648, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:23,289] {'global/mean_episode_return': 24725.0, 'global/mean_episode_step': 2952.5, 'global/SPS': 3387.284553580308, 'global/env_act_steps': 15777408, 'global/env_train_steps': 15774720, 'global/optimizer_steps': 24648, 'global/running_reward': 17950.16351744186, 'global/running_step': 2026.604378633721, 'global/steps_done': 15777408, 'global/episodes_done': 3980, 'global/unclipped_grad_norm': 0.6468812279679157, 'global/model_version': 24648, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:33,315] calculate_sps 30720 steps in 10.0285
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:33,315] calculate_sps 25600 steps in 10.0285
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:33,316] {'local/mean_episode_return': 35385.71428571428, 'local/mean_episode_step': 3895.0714285714284, 'local/SPS': 3063.2650688766785, 'local/env_act_steps': 15810688, 'local/env_train_steps': 15805440, 'local/optimizer_steps': 24696, 'local/running_reward': 17328.203125, 'local/running_step': 1960.5353665865384, 'local/steps_done': 15810688, 'local/episodes_done': 3994, 'local/unclipped_grad_norm': 0.707589665427804, 'local/model_version': 24696, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:33,317] {'global/mean_episode_return': 35276.92307692308, 'global/mean_episode_step': 3908.846153846154, 'global/SPS': 2552.7208907305653, 'global/env_act_steps': 15804032, 'global/env_train_steps': 15800320, 'global/optimizer_steps': 24688, 'global/running_reward': 17339.54326923077, 'global/running_step': 1961.1028771033655, 'global/steps_done': 15804032, 'global/episodes_done': 3993, 'global/unclipped_grad_norm': 0.6790576063096523, 'global/model_version': 24688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:43,327] calculate_sps 35840 steps in 10.0122
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:43,338] calculate_sps 33280 steps in 10.0122
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:43,338] {'local/mean_episode_return': 28725.0, 'local/mean_episode_step': 3425.875, 'local/SPS': 3579.6244524466397, 'local/env_act_steps': 15842688, 'local/env_train_steps': 15841280, 'local/optimizer_steps': 24752, 'local/running_reward': 17513.81875, 'local/running_step': 1978.9498125, 'local/steps_done': 15842688, 'local/episodes_done': 4002, 'local/unclipped_grad_norm': 0.6859028222305434, 'local/model_version': 24752, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:43,340] {'global/mean_episode_return': 29657.14285714286, 'global/mean_episode_step': 3457.8571428571427, 'global/SPS': 3323.936991557594, 'global/env_act_steps': 15836800, 'global/env_train_steps': 15833600, 'global/optimizer_steps': 24739, 'global/running_reward': 17451.470947265625, 'global/running_step': 1974.3336486816406, 'global/steps_done': 15836800, 'global/episodes_done': 4000, 'global/unclipped_grad_norm': 0.7102370063463846, 'global/model_version': 24739, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:53,345] calculate_sps 30720 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:36:53,346] calculate_sps 33280 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:53,346] {'local/mean_episode_return': 36650.0, 'local/mean_episode_step': 4018.75, 'local/SPS': 3066.4947468176993, 'local/env_act_steps': 15875712, 'local/env_train_steps': 15872000, 'local/optimizer_steps': 24800, 'local/running_reward': 17950.423934108527, 'local/running_step': 2016.7609011627908, 'local/steps_done': 15875712, 'local/episodes_done': 4006, 'local/unclipped_grad_norm': 0.7862141653895378, 'local/model_version': 24800, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:36:53,347] {'global/mean_episode_return': 32320.0, 'global/mean_episode_step': 3657.6, 'global/SPS': 3322.035975719174, 'global/env_act_steps': 15869568, 'global/env_train_steps': 15866880, 'global/optimizer_steps': 24792, 'global/running_reward': 17845.01953125, 'global/running_step': 2005.9879455566406, 'global/steps_done': 15869568, 'global/episodes_done': 4005, 'global/unclipped_grad_norm': 0.7755896668389158, 'global/model_version': 24792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:03,356] calculate_sps 32640 steps in 10.0109
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:03,356] calculate_sps 31360 steps in 10.0109
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:03,356] {'local/mean_episode_return': 34350.0, 'local/mean_episode_step': 3795.25, 'local/SPS': 3260.4318970559416, 'local/env_act_steps': 15908224, 'local/env_train_steps': 15904640, 'local/optimizer_steps': 24850, 'local/running_reward': 18617.759596456694, 'local/running_step': 2087.0908895177167, 'local/steps_done': 15908224, 'local/episodes_done': 4010, 'local/unclipped_grad_norm': 0.7069697314500809, 'local/model_version': 24850, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:03,357] {'global/mean_episode_return': 37650.0, 'global/mean_episode_step': 4078.75, 'global/SPS': 3132.571822661591, 'global/env_act_steps': 15902848, 'global/env_train_steps': 15898240, 'global/optimizer_steps': 24840, 'global/running_reward': 18497.313701923078, 'global/running_step': 2074.284885817308, 'global/steps_done': 15902848, 'global/episodes_done': 4009, 'global/unclipped_grad_norm': 0.702760573476553, 'global/model_version': 24840, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:13,371] calculate_sps 33920 steps in 10.0144
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:13,371] calculate_sps 35200 steps in 10.0144
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:13,371] {'local/mean_episode_return': 30977.777777777777, 'local/mean_episode_step': 3545.3333333333335, 'local/SPS': 3387.1345570105236, 'local/env_act_steps': 15940096, 'local/env_train_steps': 15938560, 'local/optimizer_steps': 24904, 'local/running_reward': 18826.499748995982, 'local/running_step': 2105.3693837851406, 'local/steps_done': 15940096, 'local/episodes_done': 4019, 'local/unclipped_grad_norm': 0.7699756644390248, 'local/model_version': 24904, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:13,372] {'global/mean_episode_return': 29175.0, 'global/mean_episode_step': 3422.5, 'global/SPS': 3514.9509553882795, 'global/env_act_steps': 15934848, 'global/env_train_steps': 15933440, 'global/optimizer_steps': 24896, 'global/running_reward': 18783.4875, 'global/running_step': 2101.8853125, 'global/steps_done': 15934848, 'global/episodes_done': 4017, 'global/unclipped_grad_norm': 0.7604818093989577, 'global/model_version': 24896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:23,380] calculate_sps 30720 steps in 10.0095
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:23,380] calculate_sps 30720 steps in 10.0095
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:23,381] {'local/mean_episode_return': 35555.555555555555, 'local/mean_episode_step': 3884.3333333333335, 'local/SPS': 3069.0754430935485, 'local/env_act_steps': 15974016, 'local/env_train_steps': 15969280, 'local/optimizer_steps': 24952, 'local/running_reward': 18958.71462264151, 'local/running_step': 2117.8267983490564, 'local/steps_done': 15974016, 'local/episodes_done': 4028, 'local/unclipped_grad_norm': 0.7090224505712589, 'local/model_version': 24952, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:23,382] {'global/mean_episode_return': 36018.181818181816, 'global/mean_episode_step': 3914.3636363636365, 'global/SPS': 3069.0754430935485, 'global/env_act_steps': 15968640, 'global/env_train_steps': 15964160, 'global/optimizer_steps': 24944, 'global/running_reward': 19010.973011363636, 'global/running_step': 2123.109463778409, 'global/steps_done': 15968640, 'global/episodes_done': 4028, 'global/unclipped_grad_norm': 0.7120771445333958, 'global/model_version': 24944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:33,385] calculate_sps 35840 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:33,385] calculate_sps 35840 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:33,386] {'local/mean_episode_return': 34025.0, 'local/mean_episode_step': 3756.0, 'local/SPS': 3582.0985679026653, 'local/env_act_steps': 16006144, 'local/env_train_steps': 16005120, 'local/optimizer_steps': 25007, 'local/running_reward': 19075.93376494024, 'local/running_step': 2130.895293824701, 'local/steps_done': 16006144, 'local/episodes_done': 4036, 'local/unclipped_grad_norm': 0.717433698610826, 'local/model_version': 25007, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:33,387] {'global/mean_episode_return': 34333.333333333336, 'global/mean_episode_step': 3784.8333333333335, 'global/SPS': 3582.0985679026653, 'global/env_act_steps': 16001152, 'global/env_train_steps': 16000000, 'global/optimizer_steps': 25000, 'global/running_reward': 19041.89222440945, 'global/running_step': 2127.8054872047246, 'global/steps_done': 16001152, 'global/episodes_done': 4034, 'global/unclipped_grad_norm': 0.72365727648139, 'global/model_version': 25000, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:43,387] calculate_sps 30720 steps in 10.002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:43,388] calculate_sps 30720 steps in 10.002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:43,388] {'local/mean_episode_return': 33307.692307692305, 'local/mean_episode_step': 3676.3076923076924, 'local/SPS': 3071.3934547427743, 'local/env_act_steps': 16039296, 'local/env_train_steps': 16035840, 'local/optimizer_steps': 25056, 'local/running_reward': 18857.462596525096, 'local/running_step': 2101.2855333011585, 'local/steps_done': 16039296, 'local/episodes_done': 4049, 'local/unclipped_grad_norm': 0.766425080445348, 'local/model_version': 25056, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:43,389] {'global/mean_episode_return': 32433.333333333332, 'global/mean_episode_step': 3607.1666666666665, 'global/SPS': 3071.3934547427743, 'global/env_act_steps': 16034688, 'global/env_train_steps': 16030720, 'global/optimizer_steps': 25048, 'global/running_reward': 18881.82251908397, 'global/running_step': 2104.4832120706105, 'global/steps_done': 16034688, 'global/episodes_done': 4046, 'global/unclipped_grad_norm': 0.7620835117995739, 'global/model_version': 25048, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:53,401] calculate_sps 32000 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:37:53,401] calculate_sps 33280 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:53,409] {'local/mean_episode_return': 36746.666666666664, 'local/mean_episode_step': 4053.2, 'local/SPS': 3196.2868148960442, 'local/env_act_steps': 16072064, 'local/env_train_steps': 16067840, 'local/optimizer_steps': 25105, 'local/running_reward': 17929.400634765625, 'local/running_step': 2001.5682373046875, 'local/steps_done': 16072064, 'local/episodes_done': 4064, 'local/unclipped_grad_norm': 0.6909843406506947, 'local/model_version': 25105, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:37:53,411] {'global/mean_episode_return': 38150.0, 'global/mean_episode_step': 4131.625, 'global/SPS': 3324.138287491886, 'global/env_act_steps': 16067200, 'global/env_train_steps': 16064000, 'global/optimizer_steps': 25100, 'global/running_reward': 18115.70497047244, 'global/running_step': 2021.9282726377953, 'global/steps_done': 16067200, 'global/episodes_done': 4062, 'global/unclipped_grad_norm': 0.712546999924458, 'global/model_version': 25100, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:03,407] calculate_sps 34560 steps in 10.0078
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:03,407] calculate_sps 33280 steps in 10.0078
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:03,407] {'local/mean_episode_return': 34033.333333333336, 'local/mean_episode_step': 3827.9166666666665, 'local/SPS': 3453.298487902044, 'local/env_act_steps': 16104320, 'local/env_train_steps': 16102400, 'local/optimizer_steps': 25160, 'local/running_reward': 17362.065972222223, 'local/running_step': 1932.7651909722222, 'local/steps_done': 16104320, 'local/episodes_done': 4076, 'local/unclipped_grad_norm': 0.7209433029998432, 'local/model_version': 25160, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:03,409] {'global/mean_episode_return': 31733.333333333332, 'global/mean_episode_step': 3671.0, 'global/SPS': 3325.3985439056723, 'global/env_act_steps': 16100096, 'global/env_train_steps': 16097280, 'global/optimizer_steps': 25152, 'global/running_reward': 17416.208657587547, 'global/running_step': 1939.4046388618676, 'global/steps_done': 16100096, 'global/episodes_done': 4074, 'global/unclipped_grad_norm': 0.7071152512843792, 'global/model_version': 25152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:13,409] calculate_sps 30720 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:13,409] calculate_sps 31360 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:13,410] {'local/mean_episode_return': 37981.818181818184, 'local/mean_episode_step': 3992.909090909091, 'local/SPS': 3071.4294028781123, 'local/env_act_steps': 16137472, 'local/env_train_steps': 16133120, 'local/optimizer_steps': 25208, 'local/running_reward': 16937.572393822393, 'local/running_step': 1888.4132782335907, 'local/steps_done': 16137472, 'local/episodes_done': 4087, 'local/unclipped_grad_norm': 0.6713089564194282, 'local/model_version': 25208, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:13,419] {'global/mean_episode_return': 38169.230769230766, 'global/mean_episode_step': 4026.3076923076924, 'global/SPS': 3135.4175154380728, 'global/env_act_steps': 16133248, 'global/env_train_steps': 16128640, 'global/optimizer_steps': 25200, 'global/running_reward': 17018.140685328184, 'global/running_step': 1895.785744449807, 'global/steps_done': 16133248, 'global/episodes_done': 4087, 'global/unclipped_grad_norm': 0.6977352006360888, 'global/model_version': 25200, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:23,416] calculate_sps 33920 steps in 10.0073
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:23,416] calculate_sps 35200 steps in 10.0073
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:23,416] {'local/mean_episode_return': 41625.0, 'local/mean_episode_step': 4338.0, 'local/SPS': 3389.53771246526, 'local/env_act_steps': 16169600, 'local/env_train_steps': 16167040, 'local/optimizer_steps': 25260, 'local/running_reward': 16204.121015936254, 'local/running_step': 1825.6850099601593, 'local/steps_done': 16169600, 'local/episodes_done': 4095, 'local/unclipped_grad_norm': 0.7229664841523538, 'local/model_version': 25260, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:23,417] {'global/mean_episode_return': 40342.857142857145, 'global/mean_episode_step': 4235.714285714285, 'global/SPS': 3517.444795954515, 'global/env_act_steps': 16165504, 'global/env_train_steps': 16163840, 'global/optimizer_steps': 25256, 'global/running_reward': 16218.136160714286, 'global/running_step': 1825.5257006448412, 'global/steps_done': 16165504, 'global/episodes_done': 4094, 'global/unclipped_grad_norm': 0.7043206577322313, 'global/model_version': 25256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:33,420] calculate_sps 32640 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:33,421] calculate_sps 30720 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:33,421] {'local/mean_episode_return': 36028.57142857143, 'local/mean_episode_step': 3920.1428571428573, 'local/SPS': 3262.5557586486143, 'local/env_act_steps': 16202496, 'local/env_train_steps': 16199680, 'local/optimizer_steps': 25312, 'local/running_reward': 16627.419747081713, 'local/running_step': 1878.5813168774318, 'local/steps_done': 16202496, 'local/episodes_done': 4102, 'local/unclipped_grad_norm': 0.5870245139186199, 'local/model_version': 25312, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:33,422] {'global/mean_episode_return': 38742.857142857145, 'global/mean_episode_step': 4106.142857142857, 'global/SPS': 3070.640714022225, 'global/env_act_steps': 16199168, 'global/env_train_steps': 16194560, 'global/optimizer_steps': 25304, 'global/running_reward': 16614.585313688214, 'global/running_step': 1876.4784339353612, 'global/steps_done': 16199168, 'global/episodes_done': 4101, 'global/unclipped_grad_norm': 0.5974354638407627, 'global/model_version': 25304, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:43,453] calculate_sps 31360 steps in 10.0332
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:43,453] calculate_sps 35840 steps in 10.0332
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:43,454] {'local/mean_episode_return': 37800.0, 'local/mean_episode_step': 4020.25, 'local/SPS': 3125.6237409189807, 'local/env_act_steps': 16235648, 'local/env_train_steps': 16231040, 'local/optimizer_steps': 25360, 'local/running_reward': 16984.362934362933, 'local/running_step': 1929.480966457529, 'local/steps_done': 16235648, 'local/episodes_done': 4106, 'local/unclipped_grad_norm': 0.7505455389618874, 'local/model_version': 25360, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:43,455] {'global/mean_episode_return': 31600.0, 'global/mean_episode_step': 3752.0, 'global/SPS': 3572.141418193121, 'global/env_act_steps': 16231424, 'global/env_train_steps': 16230400, 'global/optimizer_steps': 25359, 'global/running_reward': 16908.035714285714, 'global/running_step': 1918.7504340277778, 'global/steps_done': 16231424, 'global/episodes_done': 4102, 'global/unclipped_grad_norm': 0.7262094774029472, 'global/model_version': 25359, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:53,457] calculate_sps 35200 steps in 10.0032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:38:53,457] calculate_sps 30720 steps in 10.0032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:53,466] {'local/mean_episode_return': 35614.28571428572, 'local/mean_episode_step': 3850.8571428571427, 'local/SPS': 3518.8840895348812, 'local/env_act_steps': 16267776, 'local/env_train_steps': 16266240, 'local/optimizer_steps': 25416, 'local/running_reward': 17042.274651394422, 'local/running_step': 1945.8691795318725, 'local/steps_done': 16267776, 'local/episodes_done': 4114, 'local/unclipped_grad_norm': 0.7529921888240746, 'local/model_version': 25416, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:38:53,468] {'global/mean_episode_return': 38062.5, 'global/mean_episode_step': 4061.5, 'global/SPS': 3071.026114503169, 'global/env_act_steps': 16264960, 'global/env_train_steps': 16261120, 'global/optimizer_steps': 25408, 'global/running_reward': 17042.51550572519, 'global/running_step': 1946.2404281965648, 'global/steps_done': 16264960, 'global/episodes_done': 4111, 'global/unclipped_grad_norm': 0.768847863284909, 'global/model_version': 25408, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:03,471] calculate_sps 30720 steps in 10.0147
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:03,472] calculate_sps 34560 steps in 10.0147
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:03,472] {'local/mean_episode_return': 36200.0, 'local/mean_episode_step': 3963.6666666666665, 'local/SPS': 3067.5052676501455, 'local/env_act_steps': 16301184, 'local/env_train_steps': 16296960, 'local/optimizer_steps': 25464, 'local/running_reward': 17111.29070881226, 'local/running_step': 1950.3855363984674, 'local/steps_done': 16301184, 'local/episodes_done': 4123, 'local/unclipped_grad_norm': 0.7463415128489336, 'local/model_version': 25464, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:03,473] {'global/mean_episode_return': 34280.0, 'global/mean_episode_step': 3759.0, 'global/SPS': 3450.9434261064134, 'global/env_act_steps': 16297728, 'global/env_train_steps': 16295680, 'global/optimizer_steps': 25461, 'global/running_reward': 17123.8037109375, 'global/running_step': 1951.7279052734375, 'global/steps_done': 16297728, 'global/episodes_done': 4121, 'global/unclipped_grad_norm': 0.74528857559528, 'global/model_version': 25461, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:13,477] calculate_sps 33920 steps in 10.0038
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:13,477] calculate_sps 32000 steps in 10.0038
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:13,477] {'local/mean_episode_return': 34800.0, 'local/mean_episode_step': 3910.222222222222, 'local/SPS': 3390.7046894731657, 'local/env_act_steps': 16333568, 'local/env_train_steps': 16330880, 'local/optimizer_steps': 25516, 'local/running_reward': 17092.514822134388, 'local/running_step': 1946.1427556818182, 'local/steps_done': 16333568, 'local/episodes_done': 4132, 'local/unclipped_grad_norm': 0.7140904925763607, 'local/model_version': 25516, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:13,478] {'global/mean_episode_return': 35460.0, 'global/mean_episode_step': 3950.4, 'global/SPS': 3198.778008936949, 'global/env_act_steps': 16331008, 'global/env_train_steps': 16327680, 'global/optimizer_steps': 25512, 'global/running_reward': 17100.787259615383, 'global/running_step': 1947.5006310096153, 'global/steps_done': 16331008, 'global/episodes_done': 4131, 'global/unclipped_grad_norm': 0.7093097950313606, 'global/model_version': 25512, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:23,510] calculate_sps 32640 steps in 10.0345
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:23,510] calculate_sps 32640 steps in 10.0345
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:23,510] {'local/mean_episode_return': 29514.285714285714, 'local/mean_episode_step': 3482.714285714286, 'local/SPS': 3252.766051960258, 'local/env_act_steps': 16366336, 'local/env_train_steps': 16363520, 'local/optimizer_steps': 25568, 'local/running_reward': 17100.68359375, 'local/running_step': 1942.3260192871094, 'local/steps_done': 16366336, 'local/episodes_done': 4139, 'local/unclipped_grad_norm': 0.6677515930854357, 'local/model_version': 25568, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:23,512] {'global/mean_episode_return': 30525.0, 'global/mean_episode_step': 3586.875, 'global/SPS': 3252.766051960258, 'global/env_act_steps': 16363904, 'global/env_train_steps': 16360320, 'global/optimizer_steps': 25562, 'global/running_reward': 17084.81274319066, 'global/running_step': 1941.2106335116732, 'global/steps_done': 16363904, 'global/episodes_done': 4139, 'global/unclipped_grad_norm': 0.6649614453315735, 'global/model_version': 25562, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:33,558] calculate_sps 31360 steps in 10.0487
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:33,558] calculate_sps 33920 steps in 10.0487
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:33,559] {'local/mean_episode_return': 35700.0, 'local/mean_episode_step': 3890.0, 'local/SPS': 3120.7918925552644, 'local/env_act_steps': 16399488, 'local/env_train_steps': 16394880, 'local/optimizer_steps': 25616, 'local/running_reward': 17109.013030888033, 'local/running_step': 1940.858560569498, 'local/steps_done': 16399488, 'local/episodes_done': 4149, 'local/unclipped_grad_norm': 0.6920010130852461, 'local/model_version': 25616, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:33,559] {'global/mean_episode_return': 34733.333333333336, 'global/mean_episode_step': 3808.777777777778, 'global/SPS': 3375.550414396511, 'global/env_act_steps': 16396416, 'global/env_train_steps': 16394240, 'global/optimizer_steps': 25616, 'global/running_reward': 17124.846210629923, 'global/running_step': 1942.5299889271653, 'global/steps_done': 16396416, 'global/episodes_done': 4148, 'global/unclipped_grad_norm': 0.684519597225719, 'global/model_version': 25616, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:43,578] calculate_sps 35200 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:43,579] calculate_sps 31360 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:43,579] {'local/mean_episode_return': 31133.333333333332, 'local/mean_episode_step': 3484.5, 'local/SPS': 3513.020200124807, 'local/env_act_steps': 16432256, 'local/env_train_steps': 16430080, 'local/optimizer_steps': 25672, 'local/running_reward': 17293.6279296875, 'local/running_step': 1958.6338500976562, 'local/steps_done': 16432256, 'local/episodes_done': 4155, 'local/unclipped_grad_norm': 0.6695189531892538, 'local/model_version': 25672, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:43,591] {'global/mean_episode_return': 33028.57142857143, 'global/mean_episode_step': 3646.8571428571427, 'global/SPS': 3129.7816328384647, 'global/env_act_steps': 16430208, 'global/env_train_steps': 16425600, 'global/optimizer_steps': 25664, 'global/running_reward': 17256.137547348484, 'global/running_step': 1954.9796401515152, 'global/steps_done': 16430208, 'global/episodes_done': 4155, 'global/unclipped_grad_norm': 0.7041488541290164, 'global/model_version': 25664, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:53,592] calculate_sps 30720 steps in 10.0134
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:39:53,592] calculate_sps 35200 steps in 10.0134
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:53,592] {'local/mean_episode_return': 39685.71428571428, 'local/mean_episode_step': 4259.857142857143, 'local/SPS': 3067.875856583176, 'local/env_act_steps': 16465536, 'local/env_train_steps': 16460800, 'local/optimizer_steps': 25720, 'local/running_reward': 17594.849759615383, 'local/running_step': 1983.9506009615384, 'local/steps_done': 16465536, 'local/episodes_done': 4162, 'local/unclipped_grad_norm': 0.5636273010944327, 'local/model_version': 25720, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:39:53,594] {'global/mean_episode_return': 39685.71428571428, 'global/mean_episode_step': 4259.857142857143, 'global/SPS': 3515.274419001556, 'global/env_act_steps': 16462848, 'global/env_train_steps': 16460800, 'global/optimizer_steps': 25720, 'global/running_reward': 17590.63112745098, 'global/running_step': 1983.4358762254901, 'global/steps_done': 16462848, 'global/episodes_done': 4162, 'global/unclipped_grad_norm': 0.5490719077310392, 'global/model_version': 25720, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:03,592] calculate_sps 34560 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:03,592] calculate_sps 30720 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:03,592] {'local/mean_episode_return': 32777.77777777778, 'local/mean_episode_step': 3749.5555555555557, 'local/SPS': 3455.943393871508, 'local/env_act_steps': 16497408, 'local/env_train_steps': 16495360, 'local/optimizer_steps': 25773, 'local/running_reward': 17605.057730923694, 'local/running_step': 1981.1508534136547, 'local/steps_done': 16497408, 'local/episodes_done': 4171, 'local/unclipped_grad_norm': 0.7645748088944633, 'local/model_version': 25773, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:03,593] {'global/mean_episode_return': 32777.77777777778, 'global/mean_episode_step': 3749.5555555555557, 'global/SPS': 3071.9496834413403, 'global/env_act_steps': 16495872, 'global/env_train_steps': 16491520, 'global/optimizer_steps': 25768, 'global/running_reward': 17599.745639534885, 'global/running_step': 1981.2683805717054, 'global/steps_done': 16495872, 'global/episodes_done': 4171, 'global/unclipped_grad_norm': 0.7760514337569475, 'global/model_version': 25768, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:13,627] calculate_sps 32000 steps in 10.0348
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:13,627] calculate_sps 35200 steps in 10.0348
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:13,627] {'local/mean_episode_return': 33900.0, 'local/mean_episode_step': 3885.875, 'local/SPS': 3188.890934282455, 'local/env_act_steps': 16530688, 'local/env_train_steps': 16527360, 'local/optimizer_steps': 25824, 'local/running_reward': 17801.484375, 'local/running_step': 1997.7625901442307, 'local/steps_done': 16530688, 'local/episodes_done': 4179, 'local/unclipped_grad_norm': 0.7982963338202121, 'local/model_version': 25824, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:13,629] {'global/mean_episode_return': 32971.42857142857, 'global/mean_episode_step': 3807.1428571428573, 'global/SPS': 3507.780027710701, 'global/env_act_steps': 16528384, 'global/env_train_steps': 16526720, 'global/optimizer_steps': 25822, 'global/running_reward': 17786.70029527559, 'global/running_step': 1996.4244586614172, 'global/steps_done': 16528384, 'global/episodes_done': 4178, 'global/unclipped_grad_norm': 0.7807142097089026, 'global/model_version': 25822, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:23,631] calculate_sps 32000 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:23,631] calculate_sps 31360 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:23,631] {'local/mean_episode_return': 38500.0, 'local/mean_episode_step': 4066.0, 'local/SPS': 3198.643001233007, 'local/env_act_steps': 16563456, 'local/env_train_steps': 16559360, 'local/optimizer_steps': 25873, 'local/running_reward': 18114.83154296875, 'local/running_step': 2027.4381103515625, 'local/steps_done': 16563456, 'local/episodes_done': 4183, 'local/unclipped_grad_norm': 0.8850074665887016, 'local/model_version': 25873, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:23,632] {'global/mean_episode_return': 39250.0, 'global/mean_episode_step': 4154.75, 'global/SPS': 3134.6701412083466, 'global/env_act_steps': 16561792, 'global/env_train_steps': 16558080, 'global/optimizer_steps': 25872, 'global/running_reward': 18081.806752873563, 'global/running_step': 2024.1083572796936, 'global/steps_done': 16561792, 'global/episodes_done': 4182, 'global/unclipped_grad_norm': 0.8837025207281113, 'global/model_version': 25872, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:33,644] calculate_sps 34560 steps in 10.0134
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:33,645] calculate_sps 33920 steps in 10.0134
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:33,645] {'local/mean_episode_return': 29330.0, 'local/mean_episode_step': 3447.45, 'local/SPS': 3451.3905798263654, 'local/env_act_steps': 16596096, 'local/env_train_steps': 16593920, 'local/optimizer_steps': 25928, 'local/running_reward': 18612.426470588234, 'local/running_step': 2071.6415747549017, 'local/steps_done': 16596096, 'local/episodes_done': 4194, 'local/unclipped_grad_norm': 0.7173186475580389, 'local/model_version': 25928, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:33,655] {'global/mean_episode_return': 30250.0, 'global/mean_episode_step': 3531.75, 'global/SPS': 3387.4759394592106, 'global/env_act_steps': 16594688, 'global/env_train_steps': 16592000, 'global/optimizer_steps': 25924, 'global/running_reward': 18620.4766536965, 'global/running_step': 2073.182453793774, 'global/steps_done': 16594688, 'global/episodes_done': 4193, 'global/unclipped_grad_norm': 0.7384497976073852, 'global/model_version': 25924, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:43,660] calculate_sps 30720 steps in 10.016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:43,661] calculate_sps 32640 steps in 10.016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:43,661] {'local/mean_episode_return': 34657.142857142855, 'local/mean_episode_step': 3820.8571428571427, 'local/SPS': 3067.091327677893, 'local/env_act_steps': 16629376, 'local/env_train_steps': 16624640, 'local/optimizer_steps': 25976, 'local/running_reward': 18459.080528846152, 'local/running_step': 2047.0257211538462, 'local/steps_done': 16629376, 'local/episodes_done': 4201, 'local/unclipped_grad_norm': 0.7639118929704031, 'local/model_version': 25976, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:43,662] {'global/mean_episode_return': 33850.0, 'global/mean_episode_step': 3748.125, 'global/SPS': 3258.7845356577614, 'global/env_act_steps': 16627712, 'global/env_train_steps': 16624640, 'global/optimizer_steps': 25976, 'global/running_reward': 18449.36409883721, 'global/running_step': 2045.8634629360465, 'global/steps_done': 16627712, 'global/episodes_done': 4201, 'global/unclipped_grad_norm': 0.7447632419375273, 'global/model_version': 25976, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:53,682] calculate_sps 35840 steps in 10.0201
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:40:53,682] calculate_sps 32640 steps in 10.0201
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:53,683] {'local/mean_episode_return': 34211.11111111111, 'local/mean_episode_step': 3791.8333333333335, 'local/SPS': 3576.82248398811, 'local/env_act_steps': 16661632, 'local/env_train_steps': 16660480, 'local/optimizer_steps': 26031, 'local/running_reward': 18541.387648809523, 'local/running_step': 2056.92578125, 'local/steps_done': 16661632, 'local/episodes_done': 4212, 'local/unclipped_grad_norm': 0.7957189004529607, 'local/model_version': 26031, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:40:53,684] {'global/mean_episode_return': 34562.5, 'global/mean_episode_step': 3808.1875, 'global/SPS': 3257.463333632029, 'global/env_act_steps': 16660992, 'global/env_train_steps': 16657280, 'global/optimizer_steps': 26027, 'global/running_reward': 18547.01923076923, 'global/running_step': 2057.498076923077, 'global/steps_done': 16660992, 'global/episodes_done': 4211, 'global/unclipped_grad_norm': 0.7944803667419097, 'global/model_version': 26027, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:03,709] calculate_sps 30720 steps in 10.0285
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:03,709] calculate_sps 33920 steps in 10.0285
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:03,710] {'local/mean_episode_return': 34514.28571428572, 'local/mean_episode_step': 3754.0, 'local/SPS': 3063.2706765094017, 'local/env_act_steps': 16695040, 'local/env_train_steps': 16691200, 'local/optimizer_steps': 26080, 'local/running_reward': 18202.873563218393, 'local/running_step': 2022.217822078544, 'local/steps_done': 16695040, 'local/episodes_done': 4219, 'local/unclipped_grad_norm': 0.7547651121810991, 'local/model_version': 26080, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:03,711] {'global/mean_episode_return': 34125.0, 'global/mean_episode_step': 3742.375, 'global/SPS': 3382.361371979131, 'global/env_act_steps': 16693888, 'global/env_train_steps': 16691200, 'global/optimizer_steps': 26080, 'global/running_reward': 18190.235894941634, 'global/running_step': 2020.8471546692606, 'global/steps_done': 16693888, 'global/episodes_done': 4219, 'global/unclipped_grad_norm': 0.7590477607160244, 'global/model_version': 26080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:13,726] calculate_sps 33280 steps in 10.0178
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:13,727] calculate_sps 31360 steps in 10.0178
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:13,727] {'local/mean_episode_return': 30300.0, 'local/mean_episode_step': 3513.1666666666665, 'local/SPS': 3322.08467836097, 'local/env_act_steps': 16727552, 'local/env_train_steps': 16724480, 'local/optimizer_steps': 26131, 'local/running_reward': 18679.798228346455, 'local/running_step': 2075.2046013779527, 'local/steps_done': 16727552, 'local/episodes_done': 4225, 'local/unclipped_grad_norm': 0.6621382701046327, 'local/model_version': 26131, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:13,729] {'global/mean_episode_return': 30300.0, 'global/mean_episode_step': 3513.1666666666665, 'global/SPS': 3130.4259469170674, 'global/env_act_steps': 16727296, 'global/env_train_steps': 16722560, 'global/optimizer_steps': 26129, 'global/running_reward': 18672.485632183907, 'global/running_step': 2074.4744372605364, 'global/steps_done': 16727296, 'global/episodes_done': 4225, 'global/unclipped_grad_norm': 0.6622837839686141, 'global/model_version': 26129, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:23,750] calculate_sps 33280 steps in 10.0233
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:23,751] calculate_sps 35200 steps in 10.0233
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:23,751] {'local/mean_episode_return': 35942.857142857145, 'local/mean_episode_step': 4037.4285714285716, 'local/SPS': 3320.251487342464, 'local/env_act_steps': 16760320, 'local/env_train_steps': 16757760, 'local/optimizer_steps': 26184, 'local/running_reward': 18927.62451171875, 'local/running_step': 2100.2606201171875, 'local/steps_done': 16760320, 'local/episodes_done': 4232, 'local/unclipped_grad_norm': 0.6849453932834122, 'local/model_version': 26184, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:23,752] {'global/mean_episode_return': 35942.857142857145, 'global/mean_episode_step': 4037.4285714285716, 'global/SPS': 3511.8044577660676, 'global/env_act_steps': 16759680, 'global/env_train_steps': 16757760, 'global/optimizer_steps': 26184, 'global/running_reward': 18918.663537549408, 'global/running_step': 2099.453896986166, 'global/steps_done': 16759680, 'global/episodes_done': 4232, 'global/unclipped_grad_norm': 0.683986403725364, 'global/model_version': 26184, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:33,771] calculate_sps 31360 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:33,771] calculate_sps 30720 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:33,772] {'local/mean_episode_return': 32516.666666666668, 'local/mean_episode_step': 3593.0833333333335, 'local/SPS': 3129.3235491009987, 'local/env_act_steps': 16793728, 'local/env_train_steps': 16789120, 'local/optimizer_steps': 26232, 'local/running_reward': 18764.87667624521, 'local/running_step': 2078.4306752873563, 'local/steps_done': 16793728, 'local/episodes_done': 4244, 'local/unclipped_grad_norm': 0.7011034895355502, 'local/model_version': 26232, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:33,773] {'global/mean_episode_return': 32516.666666666668, 'global/mean_episode_step': 3593.0833333333335, 'global/SPS': 3065.459803200978, 'global/env_act_steps': 16793472, 'global/env_train_steps': 16788480, 'global/optimizer_steps': 26232, 'global/running_reward': 18776.379024621212, 'global/running_step': 2079.6058238636365, 'global/steps_done': 16793472, 'global/episodes_done': 4244, 'global/unclipped_grad_norm': 0.7011034895355502, 'global/model_version': 26232, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:43,772] calculate_sps 35200 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:43,772] calculate_sps 35840 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:43,772] {'local/mean_episode_return': 32783.333333333336, 'local/mean_episode_step': 3591.8333333333335, 'local/SPS': 3519.890986957739, 'local/env_act_steps': 16825728, 'local/env_train_steps': 16824320, 'local/optimizer_steps': 26288, 'local/running_reward': 18553.5875, 'local/running_step': 2052.75453125, 'local/steps_done': 16825728, 'local/episodes_done': 4256, 'local/unclipped_grad_norm': 0.6768620620880809, 'local/model_version': 26288, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:43,774] {'global/mean_episode_return': 32783.333333333336, 'global/mean_episode_step': 3591.8333333333335, 'global/SPS': 3583.8890049024258, 'global/env_act_steps': 16825472, 'global/env_train_steps': 16824320, 'global/optimizer_steps': 26288, 'global/running_reward': 18556.84375, 'global/running_step': 2053.10146875, 'global/steps_done': 16825472, 'global/episodes_done': 4256, 'global/unclipped_grad_norm': 0.6768620620880809, 'global/model_version': 26288, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:53,787] calculate_sps 30720 steps in 10.0148
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:41:53,787] calculate_sps 25600 steps in 10.0148
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:53,787] {'local/mean_episode_return': 39600.0, 'local/mean_episode_step': 4072.2, 'local/SPS': 3067.446627272115, 'local/env_act_steps': 16858880, 'local/env_train_steps': 16855040, 'local/optimizer_steps': 26336, 'local/running_reward': 18315.450048262548, 'local/running_step': 2032.622918677606, 'local/steps_done': 16858880, 'local/episodes_done': 4261, 'local/unclipped_grad_norm': 0.6752554904669523, 'local/model_version': 26336, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:41:53,799] {'global/mean_episode_return': 39600.0, 'global/mean_episode_step': 4072.2, 'global/SPS': 2556.2055227267624, 'global/env_act_steps': 16852352, 'global/env_train_steps': 16849920, 'global/optimizer_steps': 26328, 'global/running_reward': 18240.877976190477, 'global/running_step': 2023.9613095238096, 'global/steps_done': 16852352, 'global/episodes_done': 4261, 'global/unclipped_grad_norm': 0.6830798171460628, 'global/model_version': 26328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:03,796] calculate_sps 32000 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:03,796] calculate_sps 30720 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:03,796] {'local/mean_episode_return': 37225.0, 'local/mean_episode_step': 3984.5625, 'local/SPS': 3197.122341093517, 'local/env_act_steps': 16891264, 'local/env_train_steps': 16887040, 'local/optimizer_steps': 26386, 'local/running_reward': 17745.528656126484, 'local/running_step': 1975.7789649209485, 'local/steps_done': 16891264, 'local/episodes_done': 4277, 'local/unclipped_grad_norm': 0.8049329626560211, 'local/model_version': 26386, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:03,798] {'global/mean_episode_return': 37693.333333333336, 'global/mean_episode_step': 4022.0, 'global/SPS': 3069.2374474497765, 'global/env_act_steps': 16885504, 'global/env_train_steps': 16880640, 'global/optimizer_steps': 26376, 'global/running_reward': 17965.866312741313, 'global/running_step': 1998.737693050193, 'global/steps_done': 16885504, 'global/episodes_done': 4276, 'global/unclipped_grad_norm': 0.7493375471482674, 'global/model_version': 26376, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:13,805] calculate_sps 34560 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:13,806] calculate_sps 35200 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:13,806] {'local/mean_episode_return': 40080.0, 'local/mean_episode_step': 4399.4, 'local/SPS': 3452.638983495328, 'local/env_act_steps': 16923392, 'local/env_train_steps': 16921600, 'local/optimizer_steps': 26440, 'local/running_reward': 17547.634462151393, 'local/running_step': 1957.0921314741036, 'local/steps_done': 16923392, 'local/episodes_done': 4282, 'local/unclipped_grad_norm': 0.7421849223750608, 'local/model_version': 26440, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:13,807] {'global/mean_episode_return': 38433.333333333336, 'global/mean_episode_step': 4236.666666666667, 'global/SPS': 3516.5767424489454, 'global/env_act_steps': 16917504, 'global/env_train_steps': 16915840, 'global/optimizer_steps': 26431, 'global/running_reward': 17483.80625, 'global/running_step': 1950.09375, 'global/steps_done': 16917504, 'global/episodes_done': 4282, 'global/unclipped_grad_norm': 0.7914759018204429, 'global/model_version': 26431, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:23,815] calculate_sps 30720 steps in 10.0101
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:23,816] calculate_sps 31360 steps in 10.0101
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:23,816] {'local/mean_episode_return': 40366.666666666664, 'local/mean_episode_step': 4454.0, 'local/SPS': 3068.8970826272953, 'local/env_act_steps': 16956800, 'local/env_train_steps': 16952320, 'local/optimizer_steps': 26488, 'local/running_reward': 18045.38433908046, 'local/running_step': 2008.2822377873563, 'local/steps_done': 16956800, 'local/episodes_done': 4288, 'local/unclipped_grad_norm': 0.7521405834704638, 'local/model_version': 26488, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:23,817] {'global/mean_episode_return': 40366.666666666664, 'global/mean_episode_step': 4454.0, 'global/SPS': 3132.8324385153637, 'global/env_act_steps': 16951168, 'global/env_train_steps': 16947200, 'global/optimizer_steps': 26480, 'global/running_reward': 17995.431321292777, 'global/running_step': 2003.6657259980989, 'global/steps_done': 16951168, 'global/episodes_done': 4288, 'global/unclipped_grad_norm': 0.7666316120600214, 'global/model_version': 26480, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:33,822] calculate_sps 33920 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:33,822] calculate_sps 34560 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:33,823] {'local/mean_episode_return': 40742.857142857145, 'local/mean_episode_step': 4327.857142857143, 'local/SPS': 3389.850260089204, 'local/env_act_steps': 16988928, 'local/env_train_steps': 16986240, 'local/optimizer_steps': 26541, 'local/running_reward': 18246.44546812749, 'local/running_step': 2029.4168637948208, 'local/steps_done': 16988928, 'local/episodes_done': 4295, 'local/unclipped_grad_norm': 0.7295081129051605, 'local/model_version': 26541, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:33,824] {'global/mean_episode_return': 42000.0, 'global/mean_episode_step': 4431.2, 'global/SPS': 3453.8096989588116, 'global/env_act_steps': 16983808, 'global/env_train_steps': 16981760, 'global/optimizer_steps': 26533, 'global/running_reward': 18208.547794117647, 'global/running_step': 2025.1071078431373, 'global/steps_done': 16983808, 'global/episodes_done': 4293, 'global/unclipped_grad_norm': 0.6871871692392061, 'global/model_version': 26533, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:43,839] calculate_sps 32640 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:43,839] calculate_sps 32000 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:43,839] {'local/mean_episode_return': 38133.333333333336, 'local/mean_episode_step': 4094.3333333333335, 'local/SPS': 3258.4272812803247, 'local/env_act_steps': 17022080, 'local/env_train_steps': 17018880, 'local/optimizer_steps': 26592, 'local/running_reward': 18675.47055984556, 'local/running_step': 2072.2676459942086, 'local/steps_done': 17022080, 'local/episodes_done': 4298, 'local/unclipped_grad_norm': 0.6910235875961828, 'local/model_version': 26592, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:43,841] {'global/mean_episode_return': 37920.0, 'global/mean_episode_step': 4084.4, 'global/SPS': 3194.536550274828, 'global/env_act_steps': 17016960, 'global/env_train_steps': 17013760, 'global/optimizer_steps': 26584, 'global/running_reward': 18575.458494208495, 'global/running_step': 2062.410653957529, 'global/steps_done': 17016960, 'global/episodes_done': 4298, 'global/unclipped_grad_norm': 0.7399514183109882, 'global/model_version': 26584, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:53,858] calculate_sps 31360 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:42:53,859] calculate_sps 32000 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:53,859] {'local/mean_episode_return': 30938.46153846154, 'local/mean_episode_step': 3472.769230769231, 'local/SPS': 3129.7753772159435, 'local/env_act_steps': 17054848, 'local/env_train_steps': 17050240, 'local/optimizer_steps': 26640, 'local/running_reward': 18608.233642578125, 'local/running_step': 2059.2042236328125, 'local/steps_done': 17054848, 'local/episodes_done': 4311, 'local/unclipped_grad_norm': 0.7402189249793688, 'local/model_version': 26640, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:42:53,860] {'global/mean_episode_return': 30938.46153846154, 'global/mean_episode_step': 3472.769230769231, 'global/SPS': 3193.6483440979014, 'global/env_act_steps': 17049856, 'global/env_train_steps': 17045760, 'global/optimizer_steps': 26633, 'global/running_reward': 18667.62524319066, 'global/running_step': 2066.2061040856033, 'global/steps_done': 17049856, 'global/episodes_done': 4311, 'global/unclipped_grad_norm': 0.697980419105413, 'global/model_version': 26633, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:03,879] calculate_sps 35200 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:03,879] calculate_sps 34560 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:03,879] {'local/mean_episode_return': 36350.0, 'local/mean_episode_step': 3881.0, 'local/SPS': 3512.975396002228, 'local/env_act_steps': 17087232, 'local/env_train_steps': 17085440, 'local/optimizer_steps': 26696, 'local/running_reward': 18875.99431818182, 'local/running_step': 2088.287240612648, 'local/steps_done': 17087232, 'local/episodes_done': 4316, 'local/unclipped_grad_norm': 0.8499219502721514, 'local/model_version': 26696, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:03,881] {'global/mean_episode_return': 36350.0, 'global/mean_episode_step': 3881.0, 'global/SPS': 3449.103116074915, 'global/env_act_steps': 17082752, 'global/env_train_steps': 17080320, 'global/optimizer_steps': 26688, 'global/running_reward': 18809.308122568094, 'global/running_step': 2081.2936527237352, 'global/steps_done': 17082752, 'global/episodes_done': 4316, 'global/unclipped_grad_norm': 0.859721104665236, 'global/model_version': 26688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:13,895] calculate_sps 30720 steps in 10.0163
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:13,895] calculate_sps 31360 steps in 10.0163
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:13,896] {'local/mean_episode_return': 36290.90909090909, 'local/mean_episode_step': 3965.0, 'local/SPS': 3066.9962738032323, 'local/env_act_steps': 17120640, 'local/env_train_steps': 17116160, 'local/optimizer_steps': 26744, 'local/running_reward': 18843.744013409963, 'local/running_step': 2080.7034841954023, 'local/steps_done': 17120640, 'local/episodes_done': 4328, 'local/unclipped_grad_norm': 0.7438779839624962, 'local/model_version': 26744, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:13,907] {'global/mean_episode_return': 36290.90909090909, 'global/mean_episode_step': 3965.0, 'global/SPS': 3130.8920295074663, 'global/env_act_steps': 17116288, 'global/env_train_steps': 17111680, 'global/optimizer_steps': 26736, 'global/running_reward': 18904.979723282442, 'global/running_step': 2087.781309637405, 'global/steps_done': 17116288, 'global/episodes_done': 4328, 'global/unclipped_grad_norm': 0.7624923450251421, 'global/model_version': 26736, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:23,918] calculate_sps 35200 steps in 10.0226
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:23,918] calculate_sps 35200 steps in 10.0226
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:23,918] {'local/mean_episode_return': 37155.555555555555, 'local/mean_episode_step': 4148.666666666667, 'local/SPS': 3512.0636798007126, 'local/env_act_steps': 17153024, 'local/env_train_steps': 17151360, 'local/optimizer_steps': 26799, 'local/running_reward': 18717.422183794468, 'local/running_step': 2062.357553112648, 'local/steps_done': 17153024, 'local/episodes_done': 4337, 'local/unclipped_grad_norm': 0.7390709308060732, 'local/model_version': 26799, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:23,920] {'global/mean_episode_return': 36800.0, 'global/mean_episode_step': 4180.857142857143, 'global/SPS': 3512.0636798007126, 'global/env_act_steps': 17149184, 'global/env_train_steps': 17146880, 'global/optimizer_steps': 26792, 'global/running_reward': 18705.860894941634, 'global/running_step': 2062.2859922178986, 'global/steps_done': 17149184, 'global/episodes_done': 4335, 'global/unclipped_grad_norm': 0.727396045412336, 'global/model_version': 26792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:33,935] calculate_sps 31360 steps in 10.0173
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:33,935] calculate_sps 30720 steps in 10.0173
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:33,936] {'local/mean_episode_return': 38828.57142857143, 'local/mean_episode_step': 4157.571428571428, 'local/SPS': 3130.5794296146314, 'local/env_act_steps': 17185792, 'local/env_train_steps': 17182720, 'local/optimizer_steps': 26848, 'local/running_reward': 18919.244384765625, 'local/running_step': 2072.4639282226562, 'local/steps_done': 17185792, 'local/episodes_done': 4344, 'local/unclipped_grad_norm': 0.7503570719641082, 'local/model_version': 26848, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:33,937] {'global/mean_episode_return': 38228.57142857143, 'global/mean_episode_step': 4100.714285714285, 'global/SPS': 3066.690053500047, 'global/env_act_steps': 17182464, 'global/env_train_steps': 17177600, 'global/optimizer_steps': 26840, 'global/running_reward': 18894.921875, 'global/running_step': 2070.5581129807692, 'global/steps_done': 17182464, 'global/episodes_done': 4342, 'global/unclipped_grad_norm': 0.7358868060012659, 'global/model_version': 26840, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:43,962] calculate_sps 32640 steps in 10.0277
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:43,963] calculate_sps 35840 steps in 10.0277
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:43,963] {'local/mean_episode_return': 36466.666666666664, 'local/mean_episode_step': 3972.3333333333335, 'local/SPS': 3254.9916834919914, 'local/env_act_steps': 17218944, 'local/env_train_steps': 17215360, 'local/optimizer_steps': 26898, 'local/running_reward': 18712.57842664093, 'local/running_step': 2045.7768762065637, 'local/steps_done': 17218944, 'local/episodes_done': 4353, 'local/unclipped_grad_norm': 0.7301634514331817, 'local/model_version': 26898, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:43,964] {'global/mean_episode_return': 37200.0, 'global/mean_episode_step': 4020.090909090909, 'global/SPS': 3574.1085152068927, 'global/env_act_steps': 17215104, 'global/env_train_steps': 17213440, 'global/optimizer_steps': 26896, 'global/running_reward': 18736.55024509804, 'global/running_step': 2048.879595588235, 'global/steps_done': 17215104, 'global/episodes_done': 4353, 'global/unclipped_grad_norm': 0.7310318771217551, 'global/model_version': 26896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:53,973] calculate_sps 33920 steps in 10.0105
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:43:53,974] calculate_sps 30720 steps in 10.0105
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:53,982] {'local/mean_episode_return': 39466.666666666664, 'local/mean_episode_step': 4128.833333333333, 'local/SPS': 3388.430126694, 'local/env_act_steps': 17251584, 'local/env_train_steps': 17249280, 'local/optimizer_steps': 26952, 'local/running_reward': 18881.07843137255, 'local/running_step': 2064.739950980392, 'local/steps_done': 17251584, 'local/episodes_done': 4359, 'local/unclipped_grad_norm': 0.9122060708425663, 'local/model_version': 26952, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:43:53,983] {'global/mean_episode_return': 43080.0, 'global/mean_episode_step': 4422.8, 'global/SPS': 3068.766907194566, 'global/env_act_steps': 17248640, 'global/env_train_steps': 17244160, 'global/optimizer_steps': 26944, 'global/running_reward': 18841.430104961833, 'global/running_step': 2060.116173664122, 'global/steps_done': 17248640, 'global/episodes_done': 4358, 'global/unclipped_grad_norm': 0.8932862629493078, 'global/model_version': 26944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:04,005] calculate_sps 30720 steps in 10.032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:04,006] calculate_sps 35840 steps in 10.032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:04,006] {'local/mean_episode_return': 39680.0, 'local/mean_episode_step': 4121.6, 'local/SPS': 3062.188856428093, 'local/env_act_steps': 17284992, 'local/env_train_steps': 17280000, 'local/optimizer_steps': 27000, 'local/running_reward': 19055.411877394636, 'local/running_step': 2084.096084770115, 'local/steps_done': 17284992, 'local/episodes_done': 4364, 'local/unclipped_grad_norm': 0.7817774085948864, 'local/model_version': 27000, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:04,007] {'global/mean_episode_return': 37080.0, 'global/mean_episode_step': 3910.0, 'global/SPS': 3572.553665832775, 'global/env_act_steps': 17281152, 'global/env_train_steps': 17280000, 'global/optimizer_steps': 26999, 'global/running_reward': 19014.4500492126, 'global/running_step': 2079.635180856299, 'global/steps_done': 17281152, 'global/episodes_done': 4363, 'global/unclipped_grad_norm': 0.8204810305075212, 'global/model_version': 26999, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:14,014] calculate_sps 35840 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:14,014] calculate_sps 30720 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:14,015] {'local/mean_episode_return': 38000.0, 'local/mean_episode_step': 4058.2, 'local/SPS': 3580.682175825089, 'local/env_act_steps': 17316864, 'local/env_train_steps': 17315840, 'local/optimizer_steps': 27055, 'local/running_reward': 19585.07781124498, 'local/running_step': 2142.249937248996, 'local/steps_done': 17316864, 'local/episodes_done': 4369, 'local/unclipped_grad_norm': 0.7470754683017731, 'local/model_version': 27055, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:14,015] {'global/mean_episode_return': 38160.0, 'global/mean_episode_step': 4083.2, 'global/SPS': 3069.156150707219, 'global/env_act_steps': 17314560, 'global/env_train_steps': 17310720, 'global/optimizer_steps': 27048, 'global/running_reward': 19539.529454022988, 'global/running_step': 2137.19375598659, 'global/steps_done': 17314560, 'global/episodes_done': 4368, 'global/unclipped_grad_norm': 0.721248950277056, 'global/model_version': 27048, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:24,023] calculate_sps 30720 steps in 10.0085
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:24,024] calculate_sps 33280 steps in 10.0085
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:24,024] {'local/mean_episode_return': 36266.666666666664, 'local/mean_episode_step': 3940.8888888888887, 'local/SPS': 3069.399176437126, 'local/env_act_steps': 17349760, 'local/env_train_steps': 17346560, 'local/optimizer_steps': 27104, 'local/running_reward': 19894.69236381323, 'local/running_step': 2174.374331225681, 'local/steps_done': 17349760, 'local/episodes_done': 4378, 'local/unclipped_grad_norm': 0.758370754061913, 'local/model_version': 27104, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:24,025] {'global/mean_episode_return': 36000.0, 'global/mean_episode_step': 3906.0, 'global/SPS': 3325.1824411402195, 'global/env_act_steps': 17347072, 'global/env_train_steps': 17344000, 'global/optimizer_steps': 27099, 'global/running_reward': 19909.44881889764, 'global/running_step': 2176.2100147637793, 'global/steps_done': 17347072, 'global/episodes_done': 4378, 'global/unclipped_grad_norm': 0.8039948057894614, 'global/model_version': 27099, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:34,066] calculate_sps 32000 steps in 10.0434
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:34,066] calculate_sps 33280 steps in 10.0434
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:34,066] {'local/mean_episode_return': 37375.0, 'local/mean_episode_step': 4118.0, 'local/SPS': 3186.167610968379, 'local/env_act_steps': 17382656, 'local/env_train_steps': 17378560, 'local/optimizer_steps': 27153, 'local/running_reward': 19827.02456225681, 'local/running_step': 2164.1079766536964, 'local/steps_done': 17382656, 'local/episodes_done': 4386, 'local/unclipped_grad_norm': 0.6682726436731766, 'local/model_version': 27153, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:34,067] {'global/mean_episode_return': 37375.0, 'global/mean_episode_step': 4118.0, 'global/SPS': 3313.614315407114, 'global/env_act_steps': 17379840, 'global/env_train_steps': 17377280, 'global/optimizer_steps': 27152, 'global/running_reward': 19827.392578125, 'global/running_step': 2164.2081909179688, 'global/steps_done': 17379840, 'global/episodes_done': 4386, 'global/unclipped_grad_norm': 0.6556998980495164, 'global/model_version': 27152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:44,096] calculate_sps 34560 steps in 10.0293
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:44,096] calculate_sps 31360 steps in 10.0293
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:44,096] {'local/mean_episode_return': 35150.0, 'local/mean_episode_step': 3906.0625, 'local/SPS': 3445.9044945194473, 'local/env_act_steps': 17415296, 'local/env_train_steps': 17413120, 'local/optimizer_steps': 27208, 'local/running_reward': 19937.916666666668, 'local/running_step': 2175.1997549019607, 'local/steps_done': 17415296, 'local/episodes_done': 4395, 'local/unclipped_grad_norm': 0.6219706749374216, 'local/model_version': 27208, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:44,098] {'global/mean_episode_return': 35057.142857142855, 'global/mean_episode_step': 3922.785714285714, 'global/SPS': 3126.8392635454243, 'global/env_act_steps': 17413248, 'global/env_train_steps': 17408640, 'global/optimizer_steps': 27200, 'global/running_reward': 19927.963362068964, 'global/running_step': 2174.372066570881, 'global/steps_done': 17413248, 'global/episodes_done': 4394, 'global/unclipped_grad_norm': 0.5887307409817973, 'global/model_version': 27200, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:54,116] calculate_sps 30720 steps in 10.0204
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:44:54,116] calculate_sps 35200 steps in 10.0204
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:54,117] {'local/mean_episode_return': 38640.0, 'local/mean_episode_step': 4209.8, 'local/SPS': 3065.732879910724, 'local/env_act_steps': 17448832, 'local/env_train_steps': 17443840, 'local/optimizer_steps': 27256, 'local/running_reward': 19316.674618320612, 'local/running_step': 2111.5766340648856, 'local/steps_done': 17448832, 'local/episodes_done': 4410, 'local/unclipped_grad_norm': 0.7534913712491592, 'local/model_version': 27256, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:44:54,118] {'global/mean_episode_return': 37706.666666666664, 'global/mean_episode_step': 4107.066666666667, 'global/SPS': 3512.8189248977046, 'global/env_act_steps': 17446016, 'global/env_train_steps': 17443840, 'global/optimizer_steps': 27256, 'global/running_reward': 19399.542236328125, 'global/running_step': 2120.1181030273438, 'global/steps_done': 17446016, 'global/episodes_done': 4409, 'global/unclipped_grad_norm': 0.7619928041739124, 'global/model_version': 27256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:04,116] calculate_sps 35200 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:04,116] calculate_sps 30720 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:04,117] {'local/mean_episode_return': 43191.666666666664, 'local/mean_episode_step': 4444.75, 'local/SPS': 3519.835853602179, 'local/env_act_steps': 17480704, 'local/env_train_steps': 17479040, 'local/optimizer_steps': 27311, 'local/running_reward': 17848.62575301205, 'local/running_step': 1966.0278614457832, 'local/steps_done': 17480704, 'local/episodes_done': 4423, 'local/unclipped_grad_norm': 0.7401065650311384, 'local/model_version': 27311, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:04,117] {'global/mean_episode_return': 43700.0, 'global/mean_episode_step': 4512.846153846154, 'global/SPS': 3071.856744961902, 'global/env_act_steps': 17479552, 'global/env_train_steps': 17474560, 'global/optimizer_steps': 27304, 'global/running_reward': 17930.975667938932, 'global/running_step': 1973.7380427003816, 'global/steps_done': 17479552, 'global/episodes_done': 4423, 'global/unclipped_grad_norm': 0.7552345556517442, 'global/model_version': 27304, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:14,137] calculate_sps 31360 steps in 10.0206
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:14,137] calculate_sps 35840 steps in 10.0206
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:14,138] {'local/mean_episode_return': 34200.0, 'local/mean_episode_step': 3918.8, 'local/SPS': 3129.5612117003807, 'local/env_act_steps': 17514240, 'local/env_train_steps': 17510400, 'local/optimizer_steps': 27360, 'local/running_reward': 17843.4518129771, 'local/running_step': 1969.8133349236641, 'local/steps_done': 17514240, 'local/episodes_done': 4428, 'local/unclipped_grad_norm': 0.7094167705093112, 'local/model_version': 27360, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:14,139] {'global/mean_episode_return': 33800.0, 'global/mean_episode_step': 3878.5, 'global/SPS': 3576.641384800435, 'global/env_act_steps': 17512064, 'global/env_train_steps': 17510400, 'global/optimizer_steps': 27360, 'global/running_reward': 17811.79872047244, 'global/running_step': 1966.5366633858268, 'global/steps_done': 17512064, 'global/episodes_done': 4427, 'global/unclipped_grad_norm': 0.7002861457211631, 'global/model_version': 27360, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:24,143] calculate_sps 32640 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:24,144] calculate_sps 30720 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:24,158] {'local/mean_episode_return': 36300.0, 'local/mean_episode_step': 3862.6666666666665, 'local/SPS': 3262.486328507596, 'local/env_act_steps': 17546752, 'local/env_train_steps': 17543040, 'local/optimizer_steps': 27410, 'local/running_reward': 18134.92249015748, 'local/running_step': 1996.4062192421259, 'local/steps_done': 17546752, 'local/episodes_done': 4434, 'local/unclipped_grad_norm': 0.7773263216018677, 'local/model_version': 27410, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:24,160] {'global/mean_episode_return': 36228.57142857143, 'global/mean_episode_step': 3893.714285714286, 'global/SPS': 3070.5753680071493, 'global/env_act_steps': 17545216, 'global/env_train_steps': 17541120, 'global/optimizer_steps': 27408, 'global/running_reward': 18126.48407335907, 'global/running_step': 1995.7288851351352, 'global/steps_done': 17545216, 'global/episodes_done': 4434, 'global/unclipped_grad_norm': 0.7680076994001865, 'global/model_version': 27408, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:34,144] calculate_sps 33920 steps in 10.0025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:34,145] calculate_sps 34560 steps in 10.0025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:34,154] {'local/mean_episode_return': 36085.71428571428, 'local/mean_episode_step': 3908.4285714285716, 'local/SPS': 3391.1435436354222, 'local/env_act_steps': 17579136, 'local/env_train_steps': 17576960, 'local/optimizer_steps': 27464, 'local/running_reward': 18518.058300395256, 'local/running_step': 2035.0242403656127, 'local/steps_done': 17579136, 'local/episodes_done': 4441, 'local/unclipped_grad_norm': 0.7358697674892567, 'local/model_version': 27464, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:34,156] {'global/mean_episode_return': 36800.0, 'global/mean_episode_step': 3982.3333333333335, 'global/SPS': 3455.1273840813737, 'global/env_act_steps': 17577728, 'global/env_train_steps': 17575680, 'global/optimizer_steps': 27461, 'global/running_reward': 18508.366141732284, 'global/running_step': 2034.1316744586613, 'global/steps_done': 17577728, 'global/episodes_done': 4440, 'global/unclipped_grad_norm': 0.7565754601415599, 'global/model_version': 27461, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:44,149] calculate_sps 30720 steps in 10.0051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:44,150] calculate_sps 32000 steps in 10.0051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:44,162] {'local/mean_episode_return': 35175.0, 'local/mean_episode_step': 3685.5, 'local/SPS': 3070.438684552571, 'local/env_act_steps': 17612416, 'local/env_train_steps': 17607680, 'local/optimizer_steps': 27512, 'local/running_reward': 18621.153846153848, 'local/running_step': 2046.0530949519232, 'local/steps_done': 17612416, 'local/episodes_done': 4449, 'local/unclipped_grad_norm': 0.7237295989568034, 'local/model_version': 27512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:44,164] {'global/mean_episode_return': 34800.0, 'global/mean_episode_step': 3661.0, 'global/SPS': 3198.3736297422615, 'global/env_act_steps': 17611136, 'global/env_train_steps': 17607680, 'global/optimizer_steps': 27512, 'global/running_reward': 18615.87045019157, 'global/running_step': 2045.4470785440612, 'global/steps_done': 17611136, 'global/episodes_done': 4449, 'global/unclipped_grad_norm': 0.7133222610927096, 'global/model_version': 27512, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 12:45:52,280] saving global stats {'mean_episode_return': 43400.0, 'mean_episode_step': 4528.25, 'SPS': None, 'env_act_steps': 17630592, 'env_train_steps': 17628160, 'optimizer_steps': 27544, 'running_reward': 18724.732730263157, 'running_step': 2059.517937911184, 'steps_done': 17630592, 'episodes_done': 4453, 'unclipped_grad_norm': 0.6978500299155712, 'model_version': 27544, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 12:45:52,366] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:54,173] calculate_sps 33920 steps in 10.024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:45:54,173] calculate_sps 32000 steps in 10.024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:54,174] {'local/mean_episode_return': 40200.0, 'local/mean_episode_step': 4295.5, 'local/SPS': 3383.871712802295, 'local/env_act_steps': 17644160, 'local/env_train_steps': 17641600, 'local/optimizer_steps': 27564, 'local/running_reward': 18718.7752016129, 'local/running_step': 2059.9205519153224, 'local/steps_done': 17644160, 'local/episodes_done': 4455, 'local/unclipped_grad_norm': 0.6949565903498576, 'local/model_version': 27564, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:45:54,174] {'global/mean_episode_return': 40200.0, 'global/mean_episode_step': 4295.5, 'global/SPS': 3192.331804530467, 'global/env_act_steps': 17643776, 'global/env_train_steps': 17639680, 'global/optimizer_steps': 27561, 'global/running_reward': 18718.621323529413, 'global/running_step': 2059.7123774509805, 'global/steps_done': 17643776, 'global/episodes_done': 4455, 'global/unclipped_grad_norm': 0.7014559945281671, 'global/model_version': 27561, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:04,179] calculate_sps 32640 steps in 10.0059
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:04,180] calculate_sps 34560 steps in 10.0059
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:04,180] {'local/mean_episode_return': 39550.0, 'local/mean_episode_step': 4186.25, 'local/SPS': 3262.0775047817065, 'local/env_act_steps': 17677312, 'local/env_train_steps': 17674240, 'local/optimizer_steps': 27616, 'local/running_reward': 19394.769546332045, 'local/running_step': 2133.675916988417, 'local/steps_done': 17677312, 'local/episodes_done': 4459, 'local/unclipped_grad_norm': 0.583482237962576, 'local/model_version': 27616, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:04,191] {'global/mean_episode_return': 39550.0, 'global/mean_episode_step': 4186.25, 'global/SPS': 3453.964416827689, 'global/env_act_steps': 17676672, 'global/env_train_steps': 17674240, 'global/optimizer_steps': 27616, 'global/running_reward': 19383.26848249027, 'global/running_step': 2132.449446741245, 'global/steps_done': 17676672, 'global/episodes_done': 4459, 'global/unclipped_grad_norm': 0.5837722789157521, 'global/model_version': 27616, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:14,194] calculate_sps 31360 steps in 10.0127
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:14,194] calculate_sps 30720 steps in 10.0127
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:14,194] {'local/mean_episode_return': 33550.0, 'local/mean_episode_step': 3733.0, 'local/SPS': 3132.0293167379327, 'local/env_act_steps': 17710336, 'local/env_train_steps': 17705600, 'local/optimizer_steps': 27664, 'local/running_reward': 19918.647044573645, 'local/running_step': 2191.6057412790697, 'local/steps_done': 17710336, 'local/episodes_done': 4463, 'local/unclipped_grad_norm': 0.7412321617205938, 'local/model_version': 27664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:14,196] {'global/mean_episode_return': 33550.0, 'global/mean_episode_step': 3733.0, 'global/SPS': 3068.11035109022, 'global/env_act_steps': 17710208, 'global/env_train_steps': 17704960, 'global/optimizer_steps': 27664, 'global/running_reward': 19908.116650763357, 'global/running_step': 2190.528566316794, 'global/steps_done': 17710208, 'global/episodes_done': 4463, 'global/unclipped_grad_norm': 0.7412321617205938, 'global/model_version': 27664, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:24,210] calculate_sps 35200 steps in 10.0175
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:24,211] calculate_sps 35840 steps in 10.0175
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:24,211] {'local/mean_episode_return': 29022.222222222223, 'local/mean_episode_step': 3511.777777777778, 'local/SPS': 3513.8585655721095, 'local/env_act_steps': 17742336, 'local/env_train_steps': 17740800, 'local/optimizer_steps': 27720, 'local/running_reward': 20250.11875, 'local/running_step': 2213.8796875, 'local/steps_done': 17742336, 'local/episodes_done': 4472, 'local/unclipped_grad_norm': 0.7426384123308318, 'local/model_version': 27720, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:24,212] {'global/mean_episode_return': 29022.222222222223, 'global/mean_episode_step': 3511.777777777778, 'global/SPS': 3577.746903127966, 'global/env_act_steps': 17742336, 'global/env_train_steps': 17740800, 'global/optimizer_steps': 27720, 'global/running_reward': 20253.87823705179, 'global/running_step': 2214.2641932270917, 'global/steps_done': 17742336, 'global/episodes_done': 4472, 'global/unclipped_grad_norm': 0.7426384123308318, 'global/model_version': 27720, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:34,212] calculate_sps 30720 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:34,212] calculate_sps 25600 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:34,212] {'local/mean_episode_return': 37962.5, 'local/mean_episode_step': 4116.75, 'local/SPS': 3071.3567021220174, 'local/env_act_steps': 17775488, 'local/env_train_steps': 17771520, 'local/optimizer_steps': 27768, 'local/running_reward': 19934.30863899614, 'local/running_step': 2176.6071730212357, 'local/steps_done': 17775488, 'local/episodes_done': 4488, 'local/unclipped_grad_norm': 0.695044589539369, 'local/model_version': 27768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:34,214] {'global/mean_episode_return': 39442.857142857145, 'global/mean_episode_step': 4217.285714285715, 'global/SPS': 2559.4639184350144, 'global/env_act_steps': 17768704, 'global/env_train_steps': 17766400, 'global/optimizer_steps': 27760, 'global/running_reward': 20131.84921116505, 'global/running_step': 2196.8335861650485, 'global/steps_done': 17768704, 'global/episodes_done': 4486, 'global/unclipped_grad_norm': 0.7078093990683556, 'global/model_version': 27760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:44,213] calculate_sps 32640 steps in 10.0015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:44,213] calculate_sps 30720 steps in 10.0015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:44,213] {'local/mean_episode_return': 42622.22222222222, 'local/mean_episode_step': 4520.666666666667, 'local/SPS': 3263.525601492112, 'local/env_act_steps': 17807744, 'local/env_train_steps': 17804160, 'local/optimizer_steps': 27818, 'local/running_reward': 19027.399553571428, 'local/running_step': 2083.5599268353176, 'local/steps_done': 17807744, 'local/episodes_done': 4497, 'local/unclipped_grad_norm': 0.6832945877313614, 'local/model_version': 27818, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:44,214] {'global/mean_episode_return': 40355.555555555555, 'global/mean_episode_step': 4336.666666666667, 'global/SPS': 3071.5535072866933, 'global/env_act_steps': 17801856, 'global/env_train_steps': 17797120, 'global/optimizer_steps': 27808, 'global/running_reward': 19109.984314671816, 'global/running_step': 2091.5959519787643, 'global/steps_done': 17801856, 'global/episodes_done': 4495, 'global/unclipped_grad_norm': 0.670494024331371, 'global/model_version': 27808, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:54,236] calculate_sps 33920 steps in 10.0226
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:46:54,236] calculate_sps 35840 steps in 10.0226
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:54,236] {'local/mean_episode_return': 39266.666666666664, 'local/mean_episode_step': 4161.0, 'local/SPS': 3384.355413050941, 'local/env_act_steps': 17840512, 'local/env_train_steps': 17838080, 'local/optimizer_steps': 27872, 'local/running_reward': 19276.69677734375, 'local/running_step': 2113.0238342285156, 'local/steps_done': 17840512, 'local/episodes_done': 4500, 'local/unclipped_grad_norm': 0.7115974787760664, 'local/model_version': 27872, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:46:54,238] {'global/mean_episode_return': 32800.0, 'global/mean_episode_step': 3751.3333333333335, 'global/SPS': 3575.9227005821263, 'global/env_act_steps': 17834368, 'global/env_train_steps': 17832960, 'global/optimizer_steps': 27864, 'global/running_reward': 19088.61958661417, 'global/running_step': 2093.5397699311025, 'global/steps_done': 17834368, 'global/episodes_done': 4498, 'global/unclipped_grad_norm': 0.6775595463280167, 'global/model_version': 27864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:04,261] calculate_sps 30720 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:04,261] calculate_sps 30720 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:04,262] {'local/mean_episode_return': 37825.0, 'local/mean_episode_step': 3970.375, 'local/SPS': 3064.264862754967, 'local/env_act_steps': 17874048, 'local/env_train_steps': 17868800, 'local/optimizer_steps': 27920, 'local/running_reward': 19503.828721374044, 'local/running_step': 2138.075560591603, 'local/steps_done': 17874048, 'local/episodes_done': 4508, 'local/unclipped_grad_norm': 0.692833007623752, 'local/model_version': 27920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:04,263] {'global/mean_episode_return': 41425.0, 'global/mean_episode_step': 4290.75, 'global/SPS': 3064.264862754967, 'global/env_act_steps': 17867904, 'global/env_train_steps': 17863680, 'global/optimizer_steps': 27912, 'global/running_reward': 19539.539599236643, 'global/running_step': 2140.729932013359, 'global/steps_done': 17867904, 'global/episodes_done': 4506, 'global/unclipped_grad_norm': 0.7250077916930119, 'global/model_version': 27912, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:14,266] calculate_sps 35840 steps in 10.0048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:14,266] calculate_sps 35840 steps in 10.0048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:14,266] {'local/mean_episode_return': 37257.142857142855, 'local/mean_episode_step': 3994.714285714286, 'local/SPS': 3582.277915248748, 'local/env_act_steps': 17906176, 'local/env_train_steps': 17904640, 'local/optimizer_steps': 27976, 'local/running_reward': 19611.921065737053, 'local/running_step': 2155.0968314243028, 'local/steps_done': 17906176, 'local/episodes_done': 4515, 'local/unclipped_grad_norm': 0.7182411375854697, 'local/model_version': 27976, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:14,268] {'global/mean_episode_return': 36333.333333333336, 'global/mean_episode_step': 3901.222222222222, 'global/SPS': 3582.277915248748, 'global/env_act_steps': 17900544, 'global/env_train_steps': 17899520, 'global/optimizer_steps': 27967, 'global/running_reward': 19606.047794117647, 'global/running_step': 2154.1434742647057, 'global/steps_done': 17900544, 'global/episodes_done': 4515, 'global/unclipped_grad_norm': 0.7035997374491259, 'global/model_version': 27967, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:24,275] calculate_sps 30720 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:24,275] calculate_sps 30720 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:24,276] {'local/mean_episode_return': 39422.22222222222, 'local/mean_episode_step': 4102.555555555556, 'local/SPS': 3069.1581245879024, 'local/env_act_steps': 17939200, 'local/env_train_steps': 17935360, 'local/optimizer_steps': 28024, 'local/running_reward': 19604.54820736434, 'local/running_step': 2153.64183624031, 'local/steps_done': 17939200, 'local/episodes_done': 4524, 'local/unclipped_grad_norm': 0.7806865349411964, 'local/model_version': 28024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:24,277] {'global/mean_episode_return': 38028.57142857143, 'global/mean_episode_step': 4009.0, 'global/SPS': 3069.1581245879024, 'global/env_act_steps': 17934208, 'global/env_train_steps': 17930240, 'global/optimizer_steps': 28016, 'global/running_reward': 19591.718155893537, 'global/running_step': 2152.3044498574145, 'global/steps_done': 17934208, 'global/episodes_done': 4522, 'global/unclipped_grad_norm': 0.7684532987828158, 'global/model_version': 28016, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:34,294] calculate_sps 33280 steps in 10.0187
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:34,294] calculate_sps 33920 steps in 10.0187
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:34,296] {'local/mean_episode_return': 39157.142857142855, 'local/mean_episode_step': 4078.0, 'local/SPS': 3321.783709403639, 'local/env_act_steps': 17971840, 'local/env_train_steps': 17968640, 'local/optimizer_steps': 28076, 'local/running_reward': 18896.274509803923, 'local/running_step': 2088.3836090686273, 'local/steps_done': 17971840, 'local/episodes_done': 4538, 'local/unclipped_grad_norm': 0.7016415532964927, 'local/model_version': 28076, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:34,297] {'global/mean_episode_return': 39973.333333333336, 'global/mean_episode_step': 4118.4, 'global/SPS': 3385.664165353709, 'global/env_act_steps': 17966848, 'global/env_train_steps': 17964160, 'global/optimizer_steps': 28068, 'global/running_reward': 19060.680147058825, 'global/running_step': 2103.7291053921567, 'global/steps_done': 17966848, 'global/episodes_done': 4537, 'global/unclipped_grad_norm': 0.7488537304676496, 'global/model_version': 28068, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:44,314] calculate_sps 33280 steps in 10.0203
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:44,314] calculate_sps 32640 steps in 10.0203
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:44,315] {'local/mean_episode_return': 34580.0, 'local/mean_episode_step': 3847.1, 'local/SPS': 3321.2562163908738, 'local/env_act_steps': 18004864, 'local/env_train_steps': 18001920, 'local/optimizer_steps': 28128, 'local/running_reward': 18530.46875, 'local/running_step': 2052.440437257752, 'local/steps_done': 18004864, 'local/episodes_done': 4544, 'local/unclipped_grad_norm': 0.7087937218065445, 'local/model_version': 28128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:44,316] {'global/mean_episode_return': 35016.666666666664, 'global/mean_episode_step': 3901.9166666666665, 'global/SPS': 3257.3859045372033, 'global/env_act_steps': 18000128, 'global/env_train_steps': 17996800, 'global/optimizer_steps': 28120, 'global/running_reward': 18507.45793269231, 'global/running_step': 2049.7029146634613, 'global/steps_done': 18000128, 'global/episodes_done': 4544, 'global/unclipped_grad_norm': 0.6840922113221425, 'global/model_version': 28120, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:54,331] calculate_sps 31360 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:47:54,332] calculate_sps 33280 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:54,332] {'local/mean_episode_return': 38000.0, 'local/mean_episode_step': 4051.5, 'local/SPS': 3130.629128451443, 'local/env_act_steps': 18037888, 'local/env_train_steps': 18033280, 'local/optimizer_steps': 28176, 'local/running_reward': 19331.24394379845, 'local/running_step': 2140.1494973352715, 'local/steps_done': 18037888, 'local/episodes_done': 4546, 'local/unclipped_grad_norm': 0.6780417859554291, 'local/model_version': 28176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:47:54,334] {'global/mean_episode_return': 46600.0, 'global/mean_episode_step': 4894.0, 'global/SPS': 3322.3002995811235, 'global/env_act_steps': 18033152, 'global/env_train_steps': 18030080, 'global/optimizer_steps': 28171, 'global/running_reward': 19188.202519379844, 'global/running_step': 2125.0943859011627, 'global/steps_done': 18033152, 'global/episodes_done': 4545, 'global/unclipped_grad_norm': 0.709604508152195, 'global/model_version': 28171, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:04,336] calculate_sps 35200 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:04,336] calculate_sps 33280 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:04,336] {'local/mean_episode_return': 39333.333333333336, 'local/mean_episode_step': 4239.0, 'local/SPS': 3518.365177656475, 'local/env_act_steps': 18070528, 'local/env_train_steps': 18068480, 'local/optimizer_steps': 28232, 'local/running_reward': 19455.220588235294, 'local/running_step': 2149.9916973039217, 'local/steps_done': 18070528, 'local/episodes_done': 4555, 'local/unclipped_grad_norm': 0.8472271056047508, 'local/model_version': 28232, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:04,338] {'global/mean_episode_return': 38340.0, 'global/mean_episode_step': 4136.0, 'global/SPS': 3326.454349784304, 'global/env_act_steps': 18066816, 'global/env_train_steps': 18063360, 'global/optimizer_steps': 28224, 'global/running_reward': 19491.272576045627, 'global/running_step': 2154.3716432984793, 'global/steps_done': 18066816, 'global/episodes_done': 4555, 'global/unclipped_grad_norm': 0.8517600258566299, 'global/model_version': 28224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:14,367] calculate_sps 30720 steps in 10.0315
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:14,368] calculate_sps 33920 steps in 10.0315
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:14,368] {'local/mean_episode_return': 39725.0, 'local/mean_episode_step': 4407.625, 'local/SPS': 3062.3528275143553, 'local/env_act_steps': 18103936, 'local/env_train_steps': 18099200, 'local/optimizer_steps': 28280, 'local/running_reward': 19676.903735632182, 'local/running_step': 2170.994492337165, 'local/steps_done': 18103936, 'local/episodes_done': 4563, 'local/unclipped_grad_norm': 0.8774503109355768, 'local/model_version': 28280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:14,369] {'global/mean_episode_return': 38533.333333333336, 'global/mean_episode_step': 4266.666666666667, 'global/SPS': 3381.3479137137674, 'global/env_act_steps': 18099840, 'global/env_train_steps': 18097280, 'global/optimizer_steps': 28276, 'global/running_reward': 19668.74394379845, 'global/running_step': 2170.8351804748063, 'global/steps_done': 18099840, 'global/episodes_done': 4561, 'global/unclipped_grad_norm': 0.8228901670529292, 'global/model_version': 28276, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:24,400] calculate_sps 35200 steps in 10.0328
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:24,400] calculate_sps 32640 steps in 10.0328
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:24,400] {'local/mean_episode_return': 37250.0, 'local/mean_episode_step': 3930.75, 'local/SPS': 3508.5053334142895, 'local/env_act_steps': 18135936, 'local/env_train_steps': 18134400, 'local/optimizer_steps': 28334, 'local/running_reward': 19646.28125, 'local/running_step': 2166.3535625, 'local/steps_done': 18135936, 'local/episodes_done': 4571, 'local/unclipped_grad_norm': 0.7090504221894123, 'local/model_version': 28334, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:24,401] {'global/mean_episode_return': 38711.11111111111, 'global/mean_episode_step': 4131.0, 'global/SPS': 3253.3413091659772, 'global/env_act_steps': 18132736, 'global/env_train_steps': 18129920, 'global/optimizer_steps': 28328, 'global/running_reward': 19640.795233463035, 'global/running_step': 2165.258481274319, 'global/steps_done': 18132736, 'global/episodes_done': 4570, 'global/unclipped_grad_norm': 0.7350492766843393, 'global/model_version': 28328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:34,418] calculate_sps 31360 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:34,418] calculate_sps 32000 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:34,430] {'local/mean_episode_return': 41125.0, 'local/mean_episode_step': 4239.9375, 'local/SPS': 3130.4121640132066, 'local/env_act_steps': 18169472, 'local/env_train_steps': 18165760, 'local/optimizer_steps': 28384, 'local/running_reward': 18735.418654580153, 'local/running_step': 2075.534261688931, 'local/steps_done': 18169472, 'local/episodes_done': 4587, 'local/unclipped_grad_norm': 0.7377073848247528, 'local/model_version': 28384, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:34,432] {'global/mean_episode_return': 40666.666666666664, 'global/mean_episode_step': 4219.333333333333, 'global/SPS': 3194.2981265440885, 'global/env_act_steps': 18166144, 'global/env_train_steps': 18161920, 'global/optimizer_steps': 28378, 'global/running_reward': 18852.496408045976, 'global/running_step': 2086.843151340996, 'global/steps_done': 18166144, 'global/episodes_done': 4585, 'global/unclipped_grad_norm': 0.7264461851119995, 'global/model_version': 28378, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:44,427] calculate_sps 32640 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:44,427] calculate_sps 34560 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:44,427] {'local/mean_episode_return': 34766.666666666664, 'local/mean_episode_step': 3844.3333333333335, 'local/SPS': 3260.8655510801577, 'local/env_act_steps': 18201984, 'local/env_train_steps': 18198400, 'local/optimizer_steps': 28434, 'local/running_reward': 18368.08562992126, 'local/running_step': 2044.5299889271653, 'local/steps_done': 18201984, 'local/episodes_done': 4593, 'local/unclipped_grad_norm': 0.8213201302289963, 'local/model_version': 28434, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:44,428] {'global/mean_episode_return': 38228.57142857143, 'global/mean_episode_step': 4099.571428571428, 'global/SPS': 3452.681171731932, 'global/env_act_steps': 18198656, 'global/env_train_steps': 18196480, 'global/optimizer_steps': 28432, 'global/running_reward': 18356.29306102362, 'global/running_step': 2043.4441129429133, 'global/steps_done': 18198656, 'global/episodes_done': 4592, 'global/unclipped_grad_norm': 0.8211018796320315, 'global/model_version': 28432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:54,449] calculate_sps 33920 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:48:54,449] calculate_sps 30720 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:54,449] {'local/mean_episode_return': 42080.0, 'local/mean_episode_step': 4464.2, 'local/SPS': 3384.80526807618, 'local/env_act_steps': 18234624, 'local/env_train_steps': 18232320, 'local/optimizer_steps': 28488, 'local/running_reward': 18309.33823529412, 'local/running_step': 2034.299662990196, 'local/steps_done': 18234624, 'local/episodes_done': 4603, 'local/unclipped_grad_norm': 0.6933690596509863, 'local/model_version': 28488, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:48:54,451] {'global/mean_episode_return': 39840.0, 'global/mean_episode_step': 4253.4, 'global/SPS': 3065.48401637088, 'global/env_act_steps': 18232192, 'global/env_train_steps': 18227200, 'global/optimizer_steps': 28480, 'global/running_reward': 18348.908635496184, 'global/running_step': 2038.535663167939, 'global/steps_done': 18232192, 'global/episodes_done': 4602, 'global/unclipped_grad_norm': 0.714644675453504, 'global/model_version': 28480, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:04,456] calculate_sps 30720 steps in 10.0077
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:04,457] calculate_sps 35840 steps in 10.0077
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:04,457] {'local/mean_episode_return': 32591.666666666668, 'local/mean_episode_step': 3637.0, 'local/SPS': 3069.6414362295777, 'local/env_act_steps': 18268032, 'local/env_train_steps': 18263040, 'local/optimizer_steps': 28536, 'local/running_reward': 17876.939655172413, 'local/running_step': 1990.3708093869732, 'local/steps_done': 18268032, 'local/episodes_done': 4616, 'local/unclipped_grad_norm': 0.7369669079780579, 'local/model_version': 28536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:04,467] {'global/mean_episode_return': 33746.153846153844, 'global/mean_episode_step': 3738.3076923076924, 'global/SPS': 3581.2483422678406, 'global/env_act_steps': 18264832, 'global/env_train_steps': 18263040, 'global/optimizer_steps': 28536, 'global/running_reward': 17923.210784313724, 'global/running_step': 1995.3304227941176, 'global/steps_done': 18264832, 'global/episodes_done': 4616, 'global/unclipped_grad_norm': 0.7141979656049183, 'global/model_version': 28536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:14,461] calculate_sps 35840 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:14,461] calculate_sps 30720 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:14,462] {'local/mean_episode_return': 37425.0, 'local/mean_episode_step': 4022.625, 'local/SPS': 3582.320513949721, 'local/env_act_steps': 18300288, 'local/env_train_steps': 18298880, 'local/optimizer_steps': 28592, 'local/running_reward': 17625.545634920636, 'local/running_step': 1966.168216765873, 'local/steps_done': 18300288, 'local/episodes_done': 4624, 'local/unclipped_grad_norm': 0.7325090835137027, 'local/model_version': 28592, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:14,463] {'global/mean_episode_return': 37425.0, 'global/mean_episode_step': 4022.625, 'global/SPS': 3070.560440528332, 'global/env_act_steps': 18298496, 'global/env_train_steps': 18293760, 'global/optimizer_steps': 28584, 'global/running_reward': 17626.95461026616, 'global/running_step': 1965.7289389258556, 'global/steps_done': 18298496, 'global/episodes_done': 4624, 'global/unclipped_grad_norm': 0.7489396017044783, 'global/model_version': 28584, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:24,476] calculate_sps 30720 steps in 10.0144
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:24,476] calculate_sps 35840 steps in 10.0144
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:24,476] {'local/mean_episode_return': 40450.0, 'local/mean_episode_step': 4300.375, 'local/SPS': 3067.5783704390137, 'local/env_act_steps': 18333952, 'local/env_train_steps': 18329600, 'local/optimizer_steps': 28640, 'local/running_reward': 17654.88355513308, 'local/running_step': 1976.1850344581749, 'local/steps_done': 18333952, 'local/episodes_done': 4632, 'local/unclipped_grad_norm': 0.6805123385662833, 'local/model_version': 28640, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:24,478] {'global/mean_episode_return': 40142.857142857145, 'global/mean_episode_step': 4252.0, 'global/SPS': 3578.841432178849, 'global/env_act_steps': 18331264, 'global/env_train_steps': 18329600, 'global/optimizer_steps': 28640, 'global/running_reward': 17665.7958984375, 'global/running_step': 1977.0962829589844, 'global/steps_done': 18331264, 'global/episodes_done': 4631, 'global/unclipped_grad_norm': 0.6738571436809642, 'global/model_version': 28640, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:34,494] calculate_sps 33280 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:34,494] calculate_sps 30720 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:34,496] {'local/mean_episode_return': 32160.0, 'local/mean_episode_step': 3629.8, 'local/SPS': 3321.9214985092262, 'local/env_act_steps': 18366080, 'local/env_train_steps': 18362880, 'local/optimizer_steps': 28692, 'local/running_reward': 17617.274651394422, 'local/running_step': 1973.3291521414342, 'local/steps_done': 18366080, 'local/episodes_done': 4637, 'local/unclipped_grad_norm': 0.7769483092885751, 'local/model_version': 28692, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:34,498] {'global/mean_episode_return': 33900.0, 'global/mean_episode_step': 3798.0, 'global/SPS': 3066.389075546978, 'global/env_act_steps': 18364288, 'global/env_train_steps': 18360320, 'global/optimizer_steps': 28688, 'global/running_reward': 17581.492248062015, 'global/running_step': 1969.6960089631782, 'global/steps_done': 18364288, 'global/episodes_done': 4637, 'global/unclipped_grad_norm': 0.7829446252435446, 'global/model_version': 28688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:44,496] calculate_sps 33280 steps in 10.0022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:44,506] calculate_sps 33920 steps in 10.0022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:44,506] {'local/mean_episode_return': 33320.0, 'local/mean_episode_step': 3705.15, 'local/SPS': 3327.259155434308, 'local/env_act_steps': 18398592, 'local/env_train_steps': 18396160, 'local/optimizer_steps': 28744, 'local/running_reward': 17786.029773622045, 'local/running_step': 1983.907880167323, 'local/steps_done': 18398592, 'local/episodes_done': 4648, 'local/unclipped_grad_norm': 0.669972685094063, 'local/model_version': 28744, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:44,508] {'global/mean_episode_return': 33200.0, 'global/mean_episode_step': 3699.9444444444443, 'global/SPS': 3391.2449084234295, 'global/env_act_steps': 18396800, 'global/env_train_steps': 18394240, 'global/optimizer_steps': 28740, 'global/running_reward': 17792.021407480315, 'global/running_step': 1984.9723486712599, 'global/steps_done': 18396800, 'global/episodes_done': 4647, 'global/unclipped_grad_norm': 0.6802585056194892, 'global/model_version': 28740, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:54,498] calculate_sps 30720 steps in 10.0017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:49:54,498] calculate_sps 32640 steps in 10.0017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:54,498] {'local/mean_episode_return': 30600.0, 'local/mean_episode_step': 3417.125, 'local/SPS': 3071.4665965392783, 'local/env_act_steps': 18431616, 'local/env_train_steps': 18426880, 'local/optimizer_steps': 28792, 'local/running_reward': 17871.68120155039, 'local/running_step': 1988.4925205910852, 'local/steps_done': 18431616, 'local/episodes_done': 4656, 'local/unclipped_grad_norm': 0.6718196738511324, 'local/model_version': 28792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:49:54,500] {'global/mean_episode_return': 31022.222222222223, 'global/mean_episode_step': 3454.3333333333335, 'global/SPS': 3263.433258822983, 'global/env_act_steps': 18429440, 'global/env_train_steps': 18426880, 'global/optimizer_steps': 28792, 'global/running_reward': 17861.776960784315, 'global/running_step': 1987.6117034313725, 'global/steps_done': 18429440, 'global/episodes_done': 4656, 'global/unclipped_grad_norm': 0.6640856105547684, 'global/model_version': 28792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:04,533] calculate_sps 35840 steps in 10.0358
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:04,534] calculate_sps 32000 steps in 10.0358
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:04,534] {'local/mean_episode_return': 31480.0, 'local/mean_episode_step': 3563.7, 'local/SPS': 3571.2092031825046, 'local/env_act_steps': 18463744, 'local/env_train_steps': 18462720, 'local/optimizer_steps': 28847, 'local/running_reward': 17968.606822709164, 'local/running_step': 1993.0147534860557, 'local/steps_done': 18463744, 'local/episodes_done': 4666, 'local/unclipped_grad_norm': 0.632892756299539, 'local/model_version': 28847, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:04,535] {'global/mean_episode_return': 31755.555555555555, 'global/mean_episode_step': 3548.0, 'global/SPS': 3188.5796456986645, 'global/env_act_steps': 18462976, 'global/env_train_steps': 18458880, 'global/optimizer_steps': 28841, 'global/running_reward': 17969.215171755724, 'global/running_step': 1993.3775345896947, 'global/steps_done': 18462976, 'global/episodes_done': 4665, 'global/unclipped_grad_norm': 0.6367337804059593, 'global/model_version': 28841, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:14,534] calculate_sps 30720 steps in 10.0004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:14,534] calculate_sps 34560 steps in 10.0004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:14,535] {'local/mean_episode_return': 37563.63636363636, 'local/mean_episode_step': 4109.0, 'local/SPS': 3071.8645811650617, 'local/env_act_steps': 18496768, 'local/env_train_steps': 18493440, 'local/optimizer_steps': 28896, 'local/running_reward': 17665.043604651164, 'local/running_step': 1960.9336543120155, 'local/steps_done': 18496768, 'local/episodes_done': 4677, 'local/unclipped_grad_norm': 0.6599016524091059, 'local/model_version': 28896, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:14,536] {'global/mean_episode_return': 36800.0, 'global/mean_episode_step': 4060.181818181818, 'global/SPS': 3455.8476538106943, 'global/env_act_steps': 18495232, 'global/env_train_steps': 18493440, 'global/optimizer_steps': 28896, 'global/running_reward': 17681.417410714286, 'global/running_step': 1962.731181795635, 'global/steps_done': 18495232, 'global/episodes_done': 4676, 'global/unclipped_grad_norm': 0.6535332240841606, 'global/model_version': 28896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:24,543] calculate_sps 32640 steps in 10.0092
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:24,543] calculate_sps 30720 steps in 10.0092
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:24,543] {'local/mean_episode_return': 32825.0, 'local/mean_episode_step': 3686.375, 'local/SPS': 3260.992003449882, 'local/env_act_steps': 18529664, 'local/env_train_steps': 18526080, 'local/optimizer_steps': 28946, 'local/running_reward': 17647.203307392996, 'local/running_step': 1956.126732733463, 'local/steps_done': 18529664, 'local/episodes_done': 4685, 'local/unclipped_grad_norm': 0.723229473233223, 'local/model_version': 28946, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:24,544] {'global/mean_episode_return': 32575.0, 'global/mean_episode_step': 3676.75, 'global/SPS': 3069.168944423418, 'global/env_act_steps': 18528896, 'global/env_train_steps': 18524160, 'global/optimizer_steps': 28944, 'global/running_reward': 17637.25047528517, 'global/running_step': 1955.130822243346, 'global/steps_done': 18528896, 'global/episodes_done': 4684, 'global/unclipped_grad_norm': 0.7359127420932055, 'global/model_version': 28944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:34,571] calculate_sps 33920 steps in 10.0279
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:34,572] calculate_sps 35840 steps in 10.0279
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:34,572] {'local/mean_episode_return': 38800.0, 'local/mean_episode_step': 4082.5, 'local/SPS': 3382.578902130889, 'local/env_act_steps': 18562048, 'local/env_train_steps': 18560000, 'local/optimizer_steps': 29000, 'local/running_reward': 18114.575098814228, 'local/running_step': 2006.935863389328, 'local/steps_done': 18562048, 'local/episodes_done': 4687, 'local/unclipped_grad_norm': 0.6453458931710985, 'local/model_version': 29000, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:34,573] {'global/mean_episode_return': 39000.0, 'global/mean_episode_step': 4161.333333333333, 'global/SPS': 3574.045632440185, 'global/env_act_steps': 18561024, 'global/env_train_steps': 18560000, 'global/optimizer_steps': 28999, 'global/running_reward': 18095.412101593625, 'global/running_step': 2004.8101967131474, 'global/steps_done': 18561024, 'global/episodes_done': 4687, 'global/unclipped_grad_norm': 0.638936389576305, 'global/model_version': 28999, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:44,578] calculate_sps 30720 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:44,578] calculate_sps 30720 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:44,579] {'local/mean_episode_return': 37933.333333333336, 'local/mean_episode_step': 4112.666666666667, 'local/SPS': 3069.957681913413, 'local/env_act_steps': 18595584, 'local/env_train_steps': 18590720, 'local/optimizer_steps': 29048, 'local/running_reward': 18609.363072519085, 'local/running_step': 2062.2822340171756, 'local/steps_done': 18595584, 'local/episodes_done': 4693, 'local/unclipped_grad_norm': 0.6941187071303526, 'local/model_version': 29048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:44,580] {'global/mean_episode_return': 37933.333333333336, 'global/mean_episode_step': 4112.666666666667, 'global/SPS': 3069.957681913413, 'global/env_act_steps': 18594944, 'global/env_train_steps': 18590720, 'global/optimizer_steps': 29048, 'global/running_reward': 18599.840801886792, 'global/running_step': 2061.264799528302, 'global/steps_done': 18594944, 'global/episodes_done': 4693, 'global/unclipped_grad_norm': 0.6910721793466684, 'global/model_version': 29048, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:54,623] calculate_sps 35840 steps in 10.0456
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:50:54,624] calculate_sps 35200 steps in 10.0456
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:54,624] {'local/mean_episode_return': 31800.0, 'local/mean_episode_step': 3706.25, 'local/SPS': 3567.728966638745, 'local/env_act_steps': 18627968, 'local/env_train_steps': 18626560, 'local/optimizer_steps': 29104, 'local/running_reward': 19077.050395256916, 'local/running_step': 2105.8839859189725, 'local/steps_done': 18627968, 'local/episodes_done': 4697, 'local/unclipped_grad_norm': 0.8249476685055664, 'local/model_version': 29104, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:50:54,625] {'global/mean_episode_return': 31800.0, 'global/mean_episode_step': 3706.25, 'global/SPS': 3504.01952080591, 'global/env_act_steps': 18627456, 'global/env_train_steps': 18625920, 'global/optimizer_steps': 29102, 'global/running_reward': 19065.317421259842, 'global/running_step': 2104.8135457677167, 'global/steps_done': 18627456, 'global/episodes_done': 4697, 'global/unclipped_grad_norm': 0.8238788064983156, 'global/model_version': 29102, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:04,625] calculate_sps 30720 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:04,626] calculate_sps 31360 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:04,626] {'local/mean_episode_return': 39950.0, 'local/mean_episode_step': 4213.25, 'local/SPS': 3071.4028260696746, 'local/env_act_steps': 18661376, 'local/env_train_steps': 18657280, 'local/optimizer_steps': 29152, 'local/running_reward': 19915.51125478927, 'local/running_step': 2189.685165229885, 'local/steps_done': 18661376, 'local/episodes_done': 4701, 'local/unclipped_grad_norm': 0.7593501831094424, 'local/model_version': 29152, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:04,627] {'global/mean_episode_return': 39950.0, 'global/mean_episode_step': 4213.25, 'global/SPS': 3135.3903849461262, 'global/env_act_steps': 18661120, 'global/env_train_steps': 18657280, 'global/optimizer_steps': 29152, 'global/running_reward': 19907.658032319392, 'global/running_step': 2188.858929420152, 'global/steps_done': 18661120, 'global/episodes_done': 4701, 'global/unclipped_grad_norm': 0.7631284534931183, 'global/model_version': 29152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:14,630] calculate_sps 34560 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:14,631] calculate_sps 34560 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:14,631] {'local/mean_episode_return': 42480.0, 'local/mean_episode_step': 4445.4, 'local/SPS': 3454.2997413120415, 'local/env_act_steps': 18693888, 'local/env_train_steps': 18691840, 'local/optimizer_steps': 29205, 'local/running_reward': 20498.591289370077, 'local/running_step': 2247.7978900098424, 'local/steps_done': 18693888, 'local/episodes_done': 4706, 'local/unclipped_grad_norm': 0.6607074040286945, 'local/model_version': 29205, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:14,632] {'global/mean_episode_return': 42480.0, 'global/mean_episode_step': 4445.4, 'global/SPS': 3454.2997413120415, 'global/env_act_steps': 18693888, 'global/env_train_steps': 18691840, 'global/optimizer_steps': 29205, 'global/running_reward': 20495.648193359375, 'global/running_step': 2247.5133056640625, 'global/steps_done': 18693888, 'global/episodes_done': 4706, 'global/unclipped_grad_norm': 0.6607074040286945, 'global/model_version': 29205, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:24,655] calculate_sps 32000 steps in 10.0242
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:24,655] calculate_sps 26880 steps in 10.0242
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:24,655] {'local/mean_episode_return': 43163.63636363636, 'local/mean_episode_step': 4493.636363636364, 'local/SPS': 3192.2716701048425, 'local/env_act_steps': 18726784, 'local/env_train_steps': 18723840, 'local/optimizer_steps': 29256, 'local/running_reward': 20116.129620622567, 'local/running_step': 2212.544929474708, 'local/steps_done': 18726784, 'local/episodes_done': 4718, 'local/unclipped_grad_norm': 0.6906552130685133, 'local/model_version': 29256, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:24,656] {'global/mean_episode_return': 42020.0, 'global/mean_episode_step': 4403.6, 'global/SPS': 2681.508202888068, 'global/env_act_steps': 18720128, 'global/env_train_steps': 18718720, 'global/optimizer_steps': 29248, 'global/running_reward': 20210.807926829268, 'global/running_step': 2221.9025152439026, 'global/steps_done': 18720128, 'global/episodes_done': 4717, 'global/unclipped_grad_norm': 0.6997553266065065, 'global/model_version': 29248, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:34,706] calculate_sps 31360 steps in 10.0523
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:34,707] calculate_sps 30720 steps in 10.0523
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:34,707] {'local/mean_episode_return': 39580.0, 'local/mean_episode_step': 4295.3, 'local/SPS': 3119.6852436197514, 'local/env_act_steps': 18759808, 'local/env_train_steps': 18755200, 'local/optimizer_steps': 29304, 'local/running_reward': 19547.880329457363, 'local/running_step': 2155.4953972868216, 'local/steps_done': 18759808, 'local/episodes_done': 4728, 'local/unclipped_grad_norm': 0.7085138869782289, 'local/model_version': 29304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:34,708] {'global/mean_episode_return': 41020.0, 'global/mean_episode_step': 4410.5, 'global/SPS': 3056.018197831593, 'global/env_act_steps': 18753536, 'global/env_train_steps': 18749440, 'global/optimizer_steps': 29296, 'global/running_reward': 19636.793582375478, 'global/running_step': 2164.4756645114944, 'global/steps_done': 18753536, 'global/episodes_done': 4727, 'global/unclipped_grad_norm': 0.7102688824137052, 'global/model_version': 29296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:44,715] calculate_sps 35200 steps in 10.0083
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:44,715] calculate_sps 34560 steps in 10.0083
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:44,724] {'local/mean_episode_return': 36200.0, 'local/mean_episode_step': 3799.4285714285716, 'local/SPS': 3517.091524135717, 'local/env_act_steps': 18791680, 'local/env_train_steps': 18790400, 'local/optimizer_steps': 29360, 'local/running_reward': 19571.655371485944, 'local/running_step': 2161.8818398594376, 'local/steps_done': 18791680, 'local/episodes_done': 4735, 'local/unclipped_grad_norm': 0.7310236777578082, 'local/model_version': 29360, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:44,725] {'global/mean_episode_return': 36280.0, 'global/mean_episode_step': 3866.8, 'global/SPS': 3453.144405515068, 'global/env_act_steps': 18786048, 'global/env_train_steps': 18784000, 'global/optimizer_steps': 29349, 'global/running_reward': 19509.996309055117, 'global/running_step': 2154.548966535433, 'global/steps_done': 18786048, 'global/episodes_done': 4732, 'global/unclipped_grad_norm': 0.7138548066031258, 'global/model_version': 29349, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:54,743] calculate_sps 30720 steps in 10.0281
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:51:54,743] calculate_sps 32000 steps in 10.0281
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:54,744] {'local/mean_episode_return': 33400.0, 'local/mean_episode_step': 3758.230769230769, 'local/SPS': 3063.391718988813, 'local/env_act_steps': 18824832, 'local/env_train_steps': 18821120, 'local/optimizer_steps': 29408, 'local/running_reward': 19470.45728764479, 'local/running_step': 2154.3695704633205, 'local/steps_done': 18824832, 'local/episodes_done': 4748, 'local/unclipped_grad_norm': 0.6102561000734568, 'local/model_version': 29408, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:51:54,745] {'global/mean_episode_return': 33553.846153846156, 'global/mean_episode_step': 3684.5384615384614, 'global/SPS': 3191.0330406133467, 'global/env_act_steps': 18819328, 'global/env_train_steps': 18816000, 'global/optimizer_steps': 29400, 'global/running_reward': 19579.356971153848, 'global/running_step': 2166.1577223557692, 'global/steps_done': 18819328, 'global/episodes_done': 4745, 'global/unclipped_grad_norm': 0.6380536527025933, 'global/model_version': 29400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:04,746] calculate_sps 32000 steps in 10.0018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:04,747] calculate_sps 32640 steps in 10.0018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:04,747] {'local/mean_episode_return': 40585.71428571428, 'local/mean_episode_step': 4236.357142857143, 'local/SPS': 3199.439108949468, 'local/env_act_steps': 18857344, 'local/env_train_steps': 18853120, 'local/optimizer_steps': 29457, 'local/running_reward': 18240.05905511811, 'local/running_step': 2026.6402251476377, 'local/steps_done': 18857344, 'local/episodes_done': 4762, 'local/unclipped_grad_norm': 0.7034954264455912, 'local/model_version': 29457, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:04,748] {'global/mean_episode_return': 40446.153846153844, 'global/mean_episode_step': 4290.2307692307695, 'global/SPS': 3263.4278911284573, 'global/env_act_steps': 18852224, 'global/env_train_steps': 18848640, 'global/optimizer_steps': 29450, 'global/running_reward': 18397.300583657587, 'global/running_step': 2041.9337609435797, 'global/steps_done': 18852224, 'global/episodes_done': 4758, 'global/unclipped_grad_norm': 0.7106742870807647, 'global/model_version': 29450, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:14,756] calculate_sps 34560 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:14,757] calculate_sps 33920 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:14,757] {'local/mean_episode_return': 33000.0, 'local/mean_episode_step': 3722.5714285714284, 'local/SPS': 3452.180160492695, 'local/env_act_steps': 18889856, 'local/env_train_steps': 18887680, 'local/optimizer_steps': 29512, 'local/running_reward': 17911.571112204725, 'local/running_step': 1998.1428088090552, 'local/steps_done': 18889856, 'local/episodes_done': 4770, 'local/unclipped_grad_norm': 0.6888320930979469, 'local/model_version': 29512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:14,758] {'global/mean_episode_return': 35577.77777777778, 'global/mean_episode_step': 3865.1111111111113, 'global/SPS': 3388.250898261349, 'global/env_act_steps': 18885120, 'global/env_train_steps': 18882560, 'global/optimizer_steps': 29504, 'global/running_reward': 17930.398832684827, 'global/running_step': 1999.5455678501946, 'global/steps_done': 18885120, 'global/episodes_done': 4767, 'global/unclipped_grad_norm': 0.6609363497959243, 'global/model_version': 29504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:24,776] calculate_sps 30720 steps in 10.0202
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:24,777] calculate_sps 32000 steps in 10.0202
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:24,777] {'local/mean_episode_return': 34466.666666666664, 'local/mean_episode_step': 3701.0, 'local/SPS': 3065.8200500542657, 'local/env_act_steps': 18923392, 'local/env_train_steps': 18918400, 'local/optimizer_steps': 29560, 'local/running_reward': 17965.964933206105, 'local/running_step': 2006.2673246660306, 'local/steps_done': 18923392, 'local/episodes_done': 4776, 'local/unclipped_grad_norm': 0.7295221757764617, 'local/model_version': 29560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:24,778] {'global/mean_episode_return': 32514.285714285714, 'global/mean_episode_step': 3630.5714285714284, 'global/SPS': 3193.56255213986, 'global/env_act_steps': 18918784, 'global/env_train_steps': 18914560, 'global/optimizer_steps': 29553, 'global/running_reward': 17914.240731939164, 'global/running_step': 2000.291973621673, 'global/steps_done': 18918784, 'global/episodes_done': 4775, 'global/unclipped_grad_norm': 0.750441701132424, 'global/model_version': 29553, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:34,781] calculate_sps 35840 steps in 10.003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:34,781] calculate_sps 34560 steps in 10.003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:34,781] {'local/mean_episode_return': 31333.333333333332, 'local/mean_episode_step': 3544.5, 'local/SPS': 3582.91862471413, 'local/env_act_steps': 18955392, 'local/env_train_steps': 18954240, 'local/optimizer_steps': 29615, 'local/running_reward': 18466.090625, 'local/running_step': 2061.30678125, 'local/steps_done': 18955392, 'local/episodes_done': 4782, 'local/unclipped_grad_norm': 0.6943061124194753, 'local/model_version': 29615, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:34,783] {'global/mean_episode_return': 30866.666666666668, 'global/mean_episode_step': 3389.0, 'global/SPS': 3454.957245260054, 'global/env_act_steps': 18951552, 'global/env_train_steps': 18949120, 'global/optimizer_steps': 29608, 'global/running_reward': 18413.861083984375, 'global/running_step': 2056.186279296875, 'global/steps_done': 18951552, 'global/episodes_done': 4781, 'global/unclipped_grad_norm': 0.6508397996425629, 'global/model_version': 29608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:44,794] calculate_sps 30720 steps in 10.0145
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:44,794] calculate_sps 30720 steps in 10.0145
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:44,794] {'local/mean_episode_return': 33290.90909090909, 'local/mean_episode_step': 3661.4545454545455, 'local/SPS': 3067.556753267497, 'local/env_act_steps': 18988288, 'local/env_train_steps': 18984960, 'local/optimizer_steps': 29664, 'local/running_reward': 18490.03830252918, 'local/running_step': 2061.8539032101166, 'local/steps_done': 18988288, 'local/episodes_done': 4793, 'local/unclipped_grad_norm': 0.6471098205264734, 'local/model_version': 29664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:44,807] {'global/mean_episode_return': 34300.0, 'global/mean_episode_step': 3772.5833333333335, 'global/SPS': 3067.556753267497, 'global/env_act_steps': 18984448, 'global/env_train_steps': 18979840, 'global/optimizer_steps': 29656, 'global/running_reward': 18527.64165856031, 'global/running_step': 2065.5227383268484, 'global/steps_done': 18984448, 'global/episodes_done': 4793, 'global/unclipped_grad_norm': 0.7083678531150023, 'global/model_version': 29656, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:54,825] calculate_sps 33280 steps in 10.0316
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:52:54,825] calculate_sps 35840 steps in 10.0316
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:54,825] {'local/mean_episode_return': 36480.0, 'local/mean_episode_step': 3855.2, 'local/SPS': 3317.531549974188, 'local/env_act_steps': 19021312, 'local/env_train_steps': 19018240, 'local/optimizer_steps': 29715, 'local/running_reward': 18313.38117732558, 'local/running_step': 2044.7278948643411, 'local/steps_done': 19021312, 'local/episodes_done': 4803, 'local/unclipped_grad_norm': 0.8544454475243887, 'local/model_version': 29715, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:52:54,826] {'global/mean_episode_return': 36488.88888888889, 'global/mean_episode_step': 3834.222222222222, 'global/SPS': 3572.726284587587, 'global/env_act_steps': 19017216, 'global/env_train_steps': 19015680, 'global/optimizer_steps': 29712, 'global/running_reward': 18325.91552734375, 'global/running_step': 2045.8811340332031, 'global/steps_done': 19017216, 'global/episodes_done': 4802, 'global/unclipped_grad_norm': 0.8037374259105751, 'global/model_version': 29712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:04,850] calculate_sps 33280 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:04,850] calculate_sps 30720 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:04,850] {'local/mean_episode_return': 34800.0, 'local/mean_episode_step': 3772.222222222222, 'local/SPS': 3319.8428334538917, 'local/env_act_steps': 19053824, 'local/env_train_steps': 19051520, 'local/optimizer_steps': 29768, 'local/running_reward': 18266.46776574803, 'local/running_step': 2042.1421013779527, 'local/steps_done': 19053824, 'local/episodes_done': 4812, 'local/unclipped_grad_norm': 0.7745937446378311, 'local/model_version': 29768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:04,852] {'global/mean_episode_return': 34875.0, 'global/mean_episode_step': 3833.625, 'global/SPS': 3064.4703078035923, 'global/env_act_steps': 19050624, 'global/env_train_steps': 19046400, 'global/optimizer_steps': 29760, 'global/running_reward': 18255.32507183908, 'global/running_step': 2041.1473299808429, 'global/steps_done': 19050624, 'global/episodes_done': 4810, 'global/unclipped_grad_norm': 0.7851633305350939, 'global/model_version': 29760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:14,868] calculate_sps 30720 steps in 10.0177
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:14,868] calculate_sps 35200 steps in 10.0177
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:14,878] {'local/mean_episode_return': 36210.0, 'local/mean_episode_step': 4034.1, 'local/SPS': 3066.5621087559953, 'local/env_act_steps': 19087232, 'local/env_train_steps': 19082240, 'local/optimizer_steps': 29816, 'local/running_reward': 18155.124521072798, 'local/running_step': 2024.9849437260536, 'local/steps_done': 19087232, 'local/episodes_done': 4822, 'local/unclipped_grad_norm': 0.8066915186742941, 'local/model_version': 29816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:14,879] {'global/mean_episode_return': 36344.444444444445, 'global/mean_episode_step': 3927.5555555555557, 'global/SPS': 3513.7690829495778, 'global/env_act_steps': 19083136, 'global/env_train_steps': 19081600, 'global/optimizer_steps': 29814, 'global/running_reward': 18186.64185531496, 'global/running_step': 2029.046998031496, 'global/steps_done': 19083136, 'global/episodes_done': 4819, 'global/unclipped_grad_norm': 0.8176061726278729, 'global/model_version': 29814, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:24,872] calculate_sps 35840 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:24,872] calculate_sps 31360 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:24,872] {'local/mean_episode_return': 37711.11111111111, 'local/mean_episode_step': 4005.4444444444443, 'local/SPS': 3582.420996261647, 'local/env_act_steps': 19119488, 'local/env_train_steps': 19118080, 'local/optimizer_steps': 29872, 'local/running_reward': 17969.02901785714, 'local/running_step': 2002.4061879960318, 'local/steps_done': 19119488, 'local/episodes_done': 4831, 'local/unclipped_grad_norm': 0.680373238665717, 'local/model_version': 29872, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:24,887] {'global/mean_episode_return': 37083.333333333336, 'global/mean_episode_step': 4030.5833333333335, 'global/SPS': 3134.618371728941, 'global/env_act_steps': 19116800, 'global/env_train_steps': 19112960, 'global/optimizer_steps': 29864, 'global/running_reward': 18002.325926806083, 'global/running_step': 2005.647189876426, 'global/steps_done': 19116800, 'global/episodes_done': 4831, 'global/unclipped_grad_norm': 0.6730982679128646, 'global/model_version': 29864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:34,880] calculate_sps 30720 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:34,880] calculate_sps 33280 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:34,880] {'local/mean_episode_return': 39662.5, 'local/mean_episode_step': 4216.625, 'local/SPS': 3069.576644624866, 'local/env_act_steps': 19152384, 'local/env_train_steps': 19148800, 'local/optimizer_steps': 29920, 'local/running_reward': 17766.995987354087, 'local/running_step': 1982.841530885214, 'local/steps_done': 19152384, 'local/episodes_done': 4839, 'local/unclipped_grad_norm': 0.7029728423804045, 'local/model_version': 29920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:34,891] {'global/mean_episode_return': 39662.5, 'global/mean_episode_step': 4216.625, 'global/SPS': 3325.374698343605, 'global/env_act_steps': 19149440, 'global/env_train_steps': 19146240, 'global/optimizer_steps': 29916, 'global/running_reward': 17766.151960784315, 'global/running_step': 1982.315042892157, 'global/steps_done': 19149440, 'global/episodes_done': 4839, 'global/unclipped_grad_norm': 0.6766993707189193, 'global/model_version': 29916, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:44,904] calculate_sps 32640 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:44,905] calculate_sps 33280 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:44,905] {'local/mean_episode_return': 37066.666666666664, 'local/mean_episode_step': 4057.6666666666665, 'local/SPS': 3255.8829285072734, 'local/env_act_steps': 19185024, 'local/env_train_steps': 19181440, 'local/optimizer_steps': 29970, 'local/running_reward': 17338.00245098039, 'local/running_step': 1942.0372242647059, 'local/steps_done': 19185024, 'local/episodes_done': 4851, 'local/unclipped_grad_norm': 0.720605925321579, 'local/model_version': 29970, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:44,906] {'global/mean_episode_return': 36272.72727272727, 'global/mean_episode_step': 4000.2727272727275, 'global/SPS': 3319.72377024271, 'global/env_act_steps': 19182080, 'global/env_train_steps': 19179520, 'global/optimizer_steps': 29968, 'global/running_reward': 17382.230392156864, 'global/running_step': 1946.4918504901962, 'global/steps_done': 19182080, 'global/episodes_done': 4850, 'global/unclipped_grad_norm': 0.7230110397705665, 'global/model_version': 29968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:54,942] calculate_sps 33920 steps in 10.0374
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:53:54,942] calculate_sps 31360 steps in 10.0374
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:54,943] {'local/mean_episode_return': 37160.0, 'local/mean_episode_step': 4146.35, 'local/SPS': 3379.364718597778, 'local/env_act_steps': 19217664, 'local/env_train_steps': 19215360, 'local/optimizer_steps': 30024, 'local/running_reward': 16907.647058823528, 'local/running_step': 1901.4444240196078, 'local/steps_done': 19217664, 'local/episodes_done': 4862, 'local/unclipped_grad_norm': 0.6759887006547716, 'local/model_version': 30024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:53:54,944] {'global/mean_episode_return': 37945.454545454544, 'global/mean_episode_step': 4195.681818181818, 'global/SPS': 3124.3183247413417, 'global/env_act_steps': 19215616, 'global/env_train_steps': 19210880, 'global/optimizer_steps': 30016, 'global/running_reward': 16952.355677480915, 'global/running_step': 1905.9421815362596, 'global/steps_done': 19215616, 'global/episodes_done': 4862, 'global/unclipped_grad_norm': 0.7197476321210464, 'global/model_version': 30016, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:04,958] calculate_sps 30720 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:04,958] calculate_sps 35200 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:04,959] {'local/mean_episode_return': 32777.77777777778, 'local/mean_episode_step': 3637.0, 'local/SPS': 3067.1214804066694, 'local/env_act_steps': 19251072, 'local/env_train_steps': 19246080, 'local/optimizer_steps': 30072, 'local/running_reward': 16625.909961685822, 'local/running_step': 1873.9255567528735, 'local/steps_done': 19251072, 'local/episodes_done': 4871, 'local/unclipped_grad_norm': 0.7329675996055206, 'local/model_version': 30072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:04,960] {'global/mean_episode_return': 32777.77777777778, 'global/mean_episode_step': 3637.0, 'global/SPS': 3514.410029632642, 'global/env_act_steps': 19248000, 'global/env_train_steps': 19246080, 'global/optimizer_steps': 30072, 'global/running_reward': 16628.21763833992, 'global/running_step': 1874.1152729743083, 'global/steps_done': 19248000, 'global/episodes_done': 4871, 'global/unclipped_grad_norm': 0.7045594432524273, 'global/model_version': 30072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:14,959] calculate_sps 35840 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:14,974] calculate_sps 30720 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:14,974] {'local/mean_episode_return': 35950.0, 'local/mean_episode_step': 3686.25, 'local/SPS': 3583.807920451041, 'local/env_act_steps': 19283200, 'local/env_train_steps': 19281920, 'local/optimizer_steps': 30128, 'local/running_reward': 16942.648157370517, 'local/running_step': 1908.5205117031871, 'local/steps_done': 19283200, 'local/episodes_done': 4875, 'local/unclipped_grad_norm': 0.7614157402089664, 'local/model_version': 30128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:14,976] {'global/mean_episode_return': 35950.0, 'global/mean_episode_step': 3686.25, 'global/SPS': 3071.8353603866067, 'global/env_act_steps': 19281792, 'global/env_train_steps': 19276800, 'global/optimizer_steps': 30120, 'global/running_reward': 16897.531960227272, 'global/running_step': 1903.4634528882575, 'global/steps_done': 19281792, 'global/episodes_done': 4875, 'global/unclipped_grad_norm': 0.7507977696756521, 'global/model_version': 30120, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:24,980] calculate_sps 30720 steps in 10.0215
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:24,980] calculate_sps 35840 steps in 10.0215
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:24,981] {'local/mean_episode_return': 32100.0, 'local/mean_episode_step': 3663.0, 'local/SPS': 3065.3996365885746, 'local/env_act_steps': 19316608, 'local/env_train_steps': 19312640, 'local/optimizer_steps': 30176, 'local/running_reward': 17215.391522988506, 'local/running_step': 1939.8684446839081, 'local/steps_done': 19316608, 'local/episodes_done': 4885, 'local/unclipped_grad_norm': 0.767459100112319, 'local/model_version': 30176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:24,982] {'global/mean_episode_return': 33333.333333333336, 'global/mean_episode_step': 3796.222222222222, 'global/SPS': 3576.2995760200038, 'global/env_act_steps': 19314432, 'global/env_train_steps': 19312640, 'global/optimizer_steps': 30176, 'global/running_reward': 17218.13112745098, 'global/running_step': 1940.3413909313726, 'global/steps_done': 19314432, 'global/episodes_done': 4884, 'global/unclipped_grad_norm': 0.7756968805832523, 'global/model_version': 30176, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:34,989] calculate_sps 33920 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:34,990] calculate_sps 30720 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:34,990] {'local/mean_episode_return': 30911.11111111111, 'local/mean_episode_step': 3544.222222222222, 'local/SPS': 3388.6973502568294, 'local/env_act_steps': 19349120, 'local/env_train_steps': 19346560, 'local/optimizer_steps': 30228, 'local/running_reward': 17082.701771653545, 'local/running_step': 1920.4947711614172, 'local/steps_done': 19349120, 'local/episodes_done': 4894, 'local/unclipped_grad_norm': 0.7643980882488765, 'local/model_version': 30228, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:34,991] {'global/mean_episode_return': 29920.0, 'global/mean_episode_step': 3436.2, 'global/SPS': 3069.008920987317, 'global/env_act_steps': 19347968, 'global/env_train_steps': 19343360, 'global/optimizer_steps': 30224, 'global/running_reward': 17085.203959923663, 'global/running_step': 1920.943970658397, 'global/steps_done': 19347968, 'global/episodes_done': 4894, 'global/unclipped_grad_norm': 0.7668686881661415, 'global/model_version': 30224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:45,011] calculate_sps 32640 steps in 10.0216
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:45,012] calculate_sps 35840 steps in 10.0216
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:45,012] {'local/mean_episode_return': 35288.88888888889, 'local/mean_episode_step': 3899.777777777778, 'local/SPS': 3256.9791328592696, 'local/env_act_steps': 19382144, 'local/env_train_steps': 19379200, 'local/optimizer_steps': 30280, 'local/running_reward': 17266.624273255813, 'local/running_step': 1938.45824249031, 'local/steps_done': 19382144, 'local/episodes_done': 4903, 'local/unclipped_grad_norm': 0.7493008489792163, 'local/model_version': 30280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:45,023] {'global/mean_episode_return': 36350.0, 'global/mean_episode_step': 3999.0, 'global/SPS': 3576.290812551355, 'global/env_act_steps': 19380608, 'global/env_train_steps': 19379200, 'global/optimizer_steps': 30280, 'global/running_reward': 17267.02818627451, 'global/running_step': 1938.6466299019608, 'global/steps_done': 19380608, 'global/episodes_done': 4902, 'global/unclipped_grad_norm': 0.748261566140822, 'global/model_version': 30280, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:55,014] calculate_sps 31360 steps in 10.0007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:54:55,026] calculate_sps 30720 steps in 10.0007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:55,026] {'local/mean_episode_return': 38072.72727272727, 'local/mean_episode_step': 4093.4545454545455, 'local/SPS': 3135.7829633249635, 'local/env_act_steps': 19415296, 'local/env_train_steps': 19410560, 'local/optimizer_steps': 30328, 'local/running_reward': 16922.224903474904, 'local/running_step': 1899.202129584942, 'local/steps_done': 19415296, 'local/episodes_done': 4914, 'local/unclipped_grad_norm': 0.6557480084399382, 'local/model_version': 30328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:54:55,028] {'global/mean_episode_return': 36509.09090909091, 'global/mean_episode_step': 3965.818181818182, 'global/SPS': 3071.787392644862, 'global/env_act_steps': 19414144, 'global/env_train_steps': 19409920, 'global/optimizer_steps': 30328, 'global/running_reward': 16939.30701335878, 'global/running_step': 1901.0548664122136, 'global/steps_done': 19414144, 'global/episodes_done': 4913, 'global/unclipped_grad_norm': 0.6557480084399382, 'global/model_version': 30328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:05,031] calculate_sps 35200 steps in 10.0188
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:05,031] calculate_sps 34560 steps in 10.0188
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:05,032] {'local/mean_episode_return': 40966.666666666664, 'local/mean_episode_step': 4322.25, 'local/SPS': 3513.382436612253, 'local/env_act_steps': 19447296, 'local/env_train_steps': 19445760, 'local/optimizer_steps': 30384, 'local/running_reward': 16994.59375, 'local/running_step': 1910.498125, 'local/steps_done': 19447296, 'local/episodes_done': 4921, 'local/unclipped_grad_norm': 0.7764559989528996, 'local/model_version': 30384, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:05,033] {'global/mean_episode_return': 41400.0, 'global/mean_episode_step': 4349.071428571428, 'global/SPS': 3449.5027559465757, 'global/env_act_steps': 19446656, 'global/env_train_steps': 19444480, 'global/optimizer_steps': 30381, 'global/running_reward': 16993.30708661417, 'global/running_step': 1910.2232714074803, 'global/steps_done': 19446656, 'global/episodes_done': 4921, 'global/unclipped_grad_norm': 0.7930712176943725, 'global/model_version': 30381, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:15,046] calculate_sps 30720 steps in 10.0152
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:15,046] calculate_sps 32000 steps in 10.0152
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:15,047] {'local/mean_episode_return': 37800.0, 'local/mean_episode_step': 4063.285714285714, 'local/SPS': 3067.3504560638517, 'local/env_act_steps': 19480576, 'local/env_train_steps': 19476480, 'local/optimizer_steps': 30432, 'local/running_reward': 16777.665264423078, 'local/running_step': 1888.9612379807693, 'local/steps_done': 19480576, 'local/episodes_done': 4928, 'local/unclipped_grad_norm': 0.7915502109875282, 'local/model_version': 30432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:15,048] {'global/mean_episode_return': 37800.0, 'global/mean_episode_step': 4063.285714285714, 'global/SPS': 3195.156725066512, 'global/env_act_steps': 19479808, 'global/env_train_steps': 19476480, 'global/optimizer_steps': 30432, 'global/running_reward': 16773.365106177607, 'global/running_step': 1888.402388996139, 'global/steps_done': 19479808, 'global/episodes_done': 4928, 'global/unclipped_grad_norm': 0.773395520214941, 'global/model_version': 30432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:25,055] calculate_sps 32640 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:25,056] calculate_sps 32000 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:25,056] {'local/mean_episode_return': 31488.88888888889, 'local/mean_episode_step': 3487.777777777778, 'local/SPS': 3260.857939395412, 'local/env_act_steps': 19512832, 'local/env_train_steps': 19509120, 'local/optimizer_steps': 30483, 'local/running_reward': 16909.40910218254, 'local/running_step': 1903.9219680059523, 'local/steps_done': 19512832, 'local/episodes_done': 4937, 'local/unclipped_grad_norm': 0.7328785564385208, 'local/model_version': 30483, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:25,057] {'global/mean_episode_return': 31575.0, 'global/mean_episode_step': 3522.625, 'global/SPS': 3196.9195484268744, 'global/env_act_steps': 19512576, 'global/env_train_steps': 19508480, 'global/optimizer_steps': 30481, 'global/running_reward': 16907.281494140625, 'global/running_step': 1903.74609375, 'global/steps_done': 19512576, 'global/episodes_done': 4936, 'global/unclipped_grad_norm': 0.74379549525222, 'global/model_version': 30481, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:35,078] calculate_sps 33920 steps in 10.0223
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:35,081] calculate_sps 34560 steps in 10.0223
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:35,081] {'local/mean_episode_return': 34500.0, 'local/mean_episode_step': 3648.5, 'local/SPS': 3384.4617667615207, 'local/env_act_steps': 19545728, 'local/env_train_steps': 19543040, 'local/optimizer_steps': 30536, 'local/running_reward': 17352.769333657587, 'local/running_step': 1949.620956955253, 'local/steps_done': 19545728, 'local/episodes_done': 4939, 'local/unclipped_grad_norm': 0.8104753170935612, 'local/model_version': 30536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:35,082] {'global/mean_episode_return': 33266.666666666664, 'global/mean_episode_step': 3502.0, 'global/SPS': 3448.3195359457004, 'global/env_act_steps': 19545472, 'global/env_train_steps': 19543040, 'global/optimizer_steps': 30536, 'global/running_reward': 17346.33694066148, 'global/running_step': 1948.9403270914397, 'global/steps_done': 19545472, 'global/episodes_done': 4939, 'global/unclipped_grad_norm': 0.7979276166720823, 'global/model_version': 30536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:45,106] calculate_sps 30720 steps in 10.0279
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:45,106] calculate_sps 25600 steps in 10.0279
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:45,106] {'local/mean_episode_return': 32771.42857142857, 'local/mean_episode_step': 3702.8571428571427, 'local/SPS': 3063.449913092224, 'local/env_act_steps': 19579008, 'local/env_train_steps': 19573760, 'local/optimizer_steps': 30584, 'local/running_reward': 17972.80949519231, 'local/running_step': 2011.141376201923, 'local/steps_done': 19579008, 'local/episodes_done': 4946, 'local/unclipped_grad_norm': 0.7808103393763304, 'local/model_version': 30584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:45,108] {'global/mean_episode_return': 32771.42857142857, 'global/mean_episode_step': 3702.8571428571427, 'global/SPS': 2552.8749275768537, 'global/env_act_steps': 19572224, 'global/env_train_steps': 19568640, 'global/optimizer_steps': 30576, 'global/running_reward': 17937.33552631579, 'global/running_step': 2008.2163576555024, 'global/steps_done': 19572224, 'global/episodes_done': 4946, 'global/unclipped_grad_norm': 0.8011830374598503, 'global/model_version': 30576, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 12:55:52,304] saving global stats {'mean_episode_return': 43000.0, 'mean_episode_step': 4920.0, 'SPS': None, 'env_act_steps': 19591808, 'env_train_steps': 19589120, 'optimizer_steps': 30608, 'running_reward': 18300.95486111111, 'running_step': 2041.7458129084966, 'steps_done': 19591808, 'episodes_done': 4948, 'unclipped_grad_norm': 0.635267835110426, 'model_version': 30608, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 12:55:52,404] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:55,122] calculate_sps 35200 steps in 10.016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:55:55,122] calculate_sps 32640 steps in 10.016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:55,123] {'local/mean_episode_return': 39833.333333333336, 'local/mean_episode_step': 4362.5, 'local/SPS': 3514.373388248261, 'local/env_act_steps': 19610624, 'local/env_train_steps': 19608960, 'local/optimizer_steps': 30639, 'local/running_reward': 18323.292004048584, 'local/running_step': 2042.4389233299596, 'local/steps_done': 19610624, 'local/episodes_done': 4952, 'local/unclipped_grad_norm': 0.728762458671223, 'local/model_version': 30639, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:55:55,124] {'global/mean_episode_return': 39833.333333333336, 'global/mean_episode_step': 4362.5, 'global/SPS': 3258.7825963756604, 'global/env_act_steps': 19604864, 'global/env_train_steps': 19601280, 'global/optimizer_steps': 30626, 'global/running_reward': 18272.861519607843, 'global/running_step': 2037.9535232843136, 'global/steps_done': 19604864, 'global/episodes_done': 4952, 'global/unclipped_grad_norm': 0.7365293860435486, 'global/model_version': 30626, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:05,138] calculate_sps 31360 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:05,138] calculate_sps 33920 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:05,138] {'local/mean_episode_return': 33214.28571428572, 'local/mean_episode_step': 3609.714285714286, 'local/SPS': 3131.0952715508597, 'local/env_act_steps': 19643776, 'local/env_train_steps': 19640320, 'local/optimizer_steps': 30688, 'local/running_reward': 18544.202461389963, 'local/running_step': 2064.4946307915056, 'local/steps_done': 19643776, 'local/episodes_done': 4959, 'local/unclipped_grad_norm': 0.7650185388569929, 'local/model_version': 30688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:05,140] {'global/mean_episode_return': 33214.28571428572, 'global/mean_episode_step': 3609.714285714286, 'global/SPS': 3386.6948855550113, 'global/env_act_steps': 19637760, 'global/env_train_steps': 19635200, 'global/optimizer_steps': 30680, 'global/running_reward': 18495.81104085603, 'global/running_step': 2058.898711089494, 'global/steps_done': 19637760, 'global/episodes_done': 4959, 'global/unclipped_grad_norm': 0.7230224595577629, 'global/model_version': 30680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:15,174] calculate_sps 33280 steps in 10.0363
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:15,174] calculate_sps 32000 steps in 10.0363
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:15,174] {'local/mean_episode_return': 38070.0, 'local/mean_episode_step': 4096.2, 'local/SPS': 3315.962284913355, 'local/env_act_steps': 19676672, 'local/env_train_steps': 19673600, 'local/optimizer_steps': 30739, 'local/running_reward': 18492.78635700389, 'local/running_step': 2057.374513618677, 'local/steps_done': 19676672, 'local/episodes_done': 4969, 'local/unclipped_grad_norm': 0.8213684138129739, 'local/model_version': 30739, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:15,175] {'global/mean_episode_return': 38255.555555555555, 'global/mean_episode_step': 4114.666666666667, 'global/SPS': 3188.425273955149, 'global/env_act_steps': 19671296, 'global/env_train_steps': 19667200, 'global/optimizer_steps': 30729, 'global/running_reward': 18513.889551526718, 'global/running_step': 2060.2327051526718, 'global/steps_done': 19671296, 'global/episodes_done': 4968, 'global/unclipped_grad_norm': 0.8578158318996429, 'global/model_version': 30729, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:25,175] calculate_sps 33280 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:25,176] calculate_sps 34560 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:25,176] {'local/mean_episode_return': 31237.5, 'local/mean_episode_step': 3562.375, 'local/SPS': 3327.544538660134, 'local/env_act_steps': 19709056, 'local/env_train_steps': 19706880, 'local/optimizer_steps': 30792, 'local/running_reward': 18524.329916007904, 'local/running_step': 2057.5372097332015, 'local/steps_done': 19709056, 'local/episodes_done': 4977, 'local/unclipped_grad_norm': 0.7533810633533405, 'local/model_version': 30792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:25,178] {'global/mean_episode_return': 31787.5, 'global/mean_episode_step': 3588.375, 'global/SPS': 3455.527020916293, 'global/env_act_steps': 19703808, 'global/env_train_steps': 19701760, 'global/optimizer_steps': 30784, 'global/running_reward': 18517.26131889764, 'global/running_step': 2057.3389517716537, 'global/steps_done': 19703808, 'global/episodes_done': 4976, 'global/unclipped_grad_norm': 0.7640861668369987, 'global/model_version': 30784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:35,177] calculate_sps 30720 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:35,177] calculate_sps 30720 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:35,177] {'local/mean_episode_return': 31175.0, 'local/mean_episode_step': 3540.75, 'local/SPS': 3071.617503685433, 'local/env_act_steps': 19742080, 'local/env_train_steps': 19737600, 'local/optimizer_steps': 30840, 'local/running_reward': 18638.002664728683, 'local/running_step': 2064.6226078003874, 'local/steps_done': 19742080, 'local/episodes_done': 4985, 'local/unclipped_grad_norm': 0.6181224888811508, 'local/model_version': 30840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:35,178] {'global/mean_episode_return': 31266.666666666668, 'global/mean_episode_step': 3560.8888888888887, 'global/SPS': 3071.617503685433, 'global/env_act_steps': 19737216, 'global/env_train_steps': 19732480, 'global/optimizer_steps': 30832, 'global/running_reward': 18604.14870689655, 'global/running_step': 2061.9822497605364, 'global/steps_done': 19737216, 'global/episodes_done': 4985, 'global/unclipped_grad_norm': 0.6283454230676094, 'global/model_version': 30832, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:45,222] calculate_sps 34560 steps in 10.0461
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:45,223] calculate_sps 34560 steps in 10.0461
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:45,223] {'local/mean_episode_return': 30480.0, 'local/mean_episode_step': 3312.1, 'local/SPS': 3440.139841051009, 'local/env_act_steps': 19774208, 'local/env_train_steps': 19772160, 'local/optimizer_steps': 30893, 'local/running_reward': 18842.78510956175, 'local/running_step': 2087.011205179283, 'local/steps_done': 19774208, 'local/episodes_done': 4995, 'local/unclipped_grad_norm': 0.7064510769439194, 'local/model_version': 30893, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:45,224] {'global/mean_episode_return': 30777.777777777777, 'global/mean_episode_step': 3329.777777777778, 'global/SPS': 3440.139841051009, 'global/env_act_steps': 19769088, 'global/env_train_steps': 19767040, 'global/optimizer_steps': 30885, 'global/running_reward': 18844.44967369478, 'global/running_step': 2086.5892633032126, 'global/steps_done': 19769088, 'global/episodes_done': 4994, 'global/unclipped_grad_norm': 0.6617170724104036, 'global/model_version': 30885, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:55,235] calculate_sps 32000 steps in 10.0127
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:56:55,236] calculate_sps 32000 steps in 10.0127
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:55,236] {'local/mean_episode_return': 36200.0, 'local/mean_episode_step': 3899.714285714286, 'local/SPS': 3195.932833984385, 'local/env_act_steps': 19807488, 'local/env_train_steps': 19804160, 'local/optimizer_steps': 30944, 'local/running_reward': 18457.62920673077, 'local/running_step': 2051.323467548077, 'local/steps_done': 19807488, 'local/episodes_done': 5009, 'local/unclipped_grad_norm': 0.7574969743396721, 'local/model_version': 30944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:56:55,237] {'global/mean_episode_return': 36171.42857142857, 'global/mean_episode_step': 3895.5714285714284, 'global/SPS': 3195.932833984385, 'global/env_act_steps': 19802752, 'global/env_train_steps': 19799040, 'global/optimizer_steps': 30936, 'global/running_reward': 18588.554538973385, 'global/running_step': 2064.5051093155894, 'global/steps_done': 19802752, 'global/episodes_done': 5008, 'global/unclipped_grad_norm': 0.7779621876337949, 'global/model_version': 30936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:05,247] calculate_sps 31360 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:05,248] calculate_sps 32640 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:05,248] {'local/mean_episode_return': 33623.07692307692, 'local/mean_episode_step': 3743.3846153846152, 'local/SPS': 3132.3789814163933, 'local/env_act_steps': 19840256, 'local/env_train_steps': 19835520, 'local/optimizer_steps': 30993, 'local/running_reward': 17451.235961914062, 'local/running_step': 1946.4820556640625, 'local/steps_done': 19840256, 'local/episodes_done': 5022, 'local/unclipped_grad_norm': 0.7029060751807933, 'local/model_version': 30993, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:05,249] {'global/mean_episode_return': 33235.71428571428, 'global/mean_episode_step': 3705.3571428571427, 'global/SPS': 3260.2311847395113, 'global/env_act_steps': 19835264, 'global/env_train_steps': 19831680, 'global/optimizer_steps': 30986, 'global/running_reward': 17539.443897637797, 'global/running_step': 1955.8818897637796, 'global/steps_done': 19835264, 'global/episodes_done': 5022, 'global/unclipped_grad_norm': 0.7043712401390075, 'global/model_version': 30986, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:15,289] calculate_sps 35200 steps in 10.0419
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:15,289] calculate_sps 33920 steps in 10.0419
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:15,289] {'local/mean_episode_return': 35675.0, 'local/mean_episode_step': 3809.625, 'local/SPS': 3505.2991189594136, 'local/env_act_steps': 19872128, 'local/env_train_steps': 19870720, 'local/optimizer_steps': 31048, 'local/running_reward': 17689.592745983937, 'local/running_step': 1971.4387863955824, 'local/steps_done': 19872128, 'local/episodes_done': 5030, 'local/unclipped_grad_norm': 0.7644659334963019, 'local/model_version': 31048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:15,291] {'global/mean_episode_return': 35400.0, 'global/mean_episode_step': 3808.1666666666665, 'global/SPS': 3377.8336964517985, 'global/env_act_steps': 19867904, 'global/env_train_steps': 19865600, 'global/optimizer_steps': 31040, 'global/running_reward': 17635.29718137255, 'global/running_step': 1965.6469975490197, 'global/steps_done': 19867904, 'global/episodes_done': 5028, 'global/unclipped_grad_norm': 0.7627611717692128, 'global/model_version': 31040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:25,308] calculate_sps 30720 steps in 10.0192
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:25,308] calculate_sps 30720 steps in 10.0192
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:25,308] {'local/mean_episode_return': 31530.0, 'local/mean_episode_step': 3519.8, 'local/SPS': 3066.1233970221706, 'local/env_act_steps': 19905280, 'local/env_train_steps': 19901440, 'local/optimizer_steps': 31096, 'local/running_reward': 17650.425313706564, 'local/running_step': 1963.9698962355212, 'local/steps_done': 19905280, 'local/episodes_done': 5040, 'local/unclipped_grad_norm': 0.8417786670227846, 'local/model_version': 31096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:25,310] {'global/mean_episode_return': 32680.0, 'global/mean_episode_step': 3548.9, 'global/SPS': 3066.1233970221706, 'global/env_act_steps': 19901184, 'global/env_train_steps': 19896320, 'global/optimizer_steps': 31088, 'global/running_reward': 17666.983173076922, 'global/running_step': 1966.623046875, 'global/steps_done': 19901184, 'global/episodes_done': 5038, 'global/unclipped_grad_norm': 0.8447300363332033, 'global/model_version': 31088, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:35,334] calculate_sps 32640 steps in 10.0267
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:35,334] calculate_sps 35200 steps in 10.0267
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:35,335] {'local/mean_episode_return': 36844.444444444445, 'local/mean_episode_step': 3965.8888888888887, 'local/SPS': 3255.3129646894513, 'local/env_act_steps': 19937664, 'local/env_train_steps': 19934080, 'local/optimizer_steps': 31146, 'local/running_reward': 17341.3290513834, 'local/running_step': 1925.1453186758893, 'local/steps_done': 19937664, 'local/episodes_done': 5049, 'local/unclipped_grad_norm': 0.7197411668300628, 'local/model_version': 31146, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:35,336] {'global/mean_episode_return': 36833.333333333336, 'global/mean_episode_step': 4025.4444444444443, 'global/SPS': 3510.631628586663, 'global/env_act_steps': 19933184, 'global/env_train_steps': 19931520, 'global/optimizer_steps': 31143, 'global/running_reward': 17367.684375, 'global/running_step': 1928.3486875, 'global/steps_done': 19933184, 'global/episodes_done': 5047, 'global/unclipped_grad_norm': 0.7108334324576638, 'global/model_version': 31143, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:45,353] calculate_sps 33920 steps in 10.0187
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:45,354] calculate_sps 31360 steps in 10.0187
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:45,354] {'local/mean_episode_return': 34500.0, 'local/mean_episode_step': 3843.375, 'local/SPS': 3385.685113617815, 'local/env_act_steps': 19970560, 'local/env_train_steps': 19968000, 'local/optimizer_steps': 31200, 'local/running_reward': 17519.938594357976, 'local/running_step': 1942.9199598735408, 'local/steps_done': 19970560, 'local/episodes_done': 5057, 'local/unclipped_grad_norm': 0.8101895876504757, 'local/model_version': 31200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:45,355] {'global/mean_episode_return': 33760.0, 'global/mean_episode_step': 3754.8, 'global/SPS': 3130.1617088164708, 'global/env_act_steps': 19966720, 'global/env_train_steps': 19962880, 'global/optimizer_steps': 31192, 'global/running_reward': 17504.23425572519, 'global/running_step': 1941.7069716125955, 'global/steps_done': 19966720, 'global/episodes_done': 5057, 'global/unclipped_grad_norm': 0.7990018707148883, 'global/model_version': 31192, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:55,366] calculate_sps 30720 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:57:55,367] calculate_sps 33920 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:55,367] {'local/mean_episode_return': 35050.0, 'local/mean_episode_step': 3921.0, 'local/SPS': 3068.042994169888, 'local/env_act_steps': 20003712, 'local/env_train_steps': 19998720, 'local/optimizer_steps': 31248, 'local/running_reward': 17599.086027992278, 'local/running_step': 1945.9502895752896, 'local/steps_done': 20003712, 'local/episodes_done': 5065, 'local/unclipped_grad_norm': 0.7763103016962608, 'local/model_version': 31248, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:57:55,368] {'global/mean_episode_return': 35171.42857142857, 'global/mean_episode_step': 3980.4285714285716, 'global/SPS': 3387.6308060625847, 'global/env_act_steps': 19999360, 'global/env_train_steps': 19996800, 'global/optimizer_steps': 31244, 'global/running_reward': 17581.84129901961, 'global/running_step': 1945.0533700980393, 'global/steps_done': 19999360, 'global/episodes_done': 5064, 'global/unclipped_grad_norm': 0.802947352711971, 'global/model_version': 31244, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:05,404] calculate_sps 35840 steps in 10.0379
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:05,404] calculate_sps 32640 steps in 10.0379
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:05,405] {'local/mean_episode_return': 36800.0, 'local/mean_episode_step': 4020.25, 'local/SPS': 3570.4645446667623, 'local/env_act_steps': 20035968, 'local/env_train_steps': 20034560, 'local/optimizer_steps': 31304, 'local/running_reward': 17816.238839285714, 'local/running_step': 1960.732917906746, 'local/steps_done': 20035968, 'local/episodes_done': 5069, 'local/unclipped_grad_norm': 0.7217674343181508, 'local/model_version': 31304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:05,406] {'global/mean_episode_return': 36280.0, 'global/mean_episode_step': 3917.2, 'global/SPS': 3251.673067464373, 'global/env_act_steps': 20032512, 'global/env_train_steps': 20029440, 'global/optimizer_steps': 31296, 'global/running_reward': 17745.37886100386, 'global/running_step': 1953.8325892857142, 'global/steps_done': 20032512, 'global/episodes_done': 5069, 'global/unclipped_grad_norm': 0.7330644849974376, 'global/model_version': 31296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:15,411] calculate_sps 30720 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:15,411] calculate_sps 32640 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:15,411] {'local/mean_episode_return': 37177.77777777778, 'local/mean_episode_step': 3991.3333333333335, 'local/SPS': 3069.997180632266, 'local/env_act_steps': 20069248, 'local/env_train_steps': 20065280, 'local/optimizer_steps': 31352, 'local/running_reward': 18253.701923076922, 'local/running_step': 2003.1610877403846, 'local/steps_done': 20069248, 'local/episodes_done': 5078, 'local/unclipped_grad_norm': 0.7076027188450098, 'local/model_version': 31352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:15,413] {'global/mean_episode_return': 37177.77777777778, 'global/mean_episode_step': 3991.3333333333335, 'global/SPS': 3261.8720044217825, 'global/env_act_steps': 20065664, 'global/env_train_steps': 20062080, 'global/optimizer_steps': 31346, 'global/running_reward': 18260.635859073358, 'global/running_step': 2004.0817748552124, 'global/steps_done': 20065664, 'global/episodes_done': 5078, 'global/unclipped_grad_norm': 0.6898970156908035, 'global/model_version': 31346, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:25,413] calculate_sps 33280 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:25,413] calculate_sps 33920 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:25,423] {'local/mean_episode_return': 35288.88888888889, 'local/mean_episode_step': 3772.1111111111113, 'local/SPS': 3327.8340964056115, 'local/env_act_steps': 20101760, 'local/env_train_steps': 20098560, 'local/optimizer_steps': 31403, 'local/running_reward': 17947.31791338583, 'local/running_step': 1970.4284264271653, 'local/steps_done': 20101760, 'local/episodes_done': 5087, 'local/unclipped_grad_norm': 0.8730519513289133, 'local/model_version': 31403, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:25,426] {'global/mean_episode_return': 36025.0, 'global/mean_episode_step': 3849.5, 'global/SPS': 3391.8309059518733, 'global/env_act_steps': 20098560, 'global/env_train_steps': 20096000, 'global/optimizer_steps': 31400, 'global/running_reward': 17952.38630836576, 'global/running_step': 1970.730696741245, 'global/steps_done': 20098560, 'global/episodes_done': 5086, 'global/unclipped_grad_norm': 0.8770403696431054, 'global/model_version': 31400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:35,443] calculate_sps 33280 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:35,443] calculate_sps 32000 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:35,443] {'local/mean_episode_return': 36840.0, 'local/mean_episode_step': 3978.4, 'local/SPS': 3317.4920479404213, 'local/env_act_steps': 20134784, 'local/env_train_steps': 20131840, 'local/optimizer_steps': 31456, 'local/running_reward': 17877.585998062015, 'local/running_step': 1965.8385113856589, 'local/steps_done': 20134784, 'local/episodes_done': 5097, 'local/unclipped_grad_norm': 0.8554703497661734, 'local/model_version': 31456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:35,445] {'global/mean_episode_return': 36163.63636363636, 'global/mean_episode_step': 3903.3636363636365, 'global/SPS': 3189.896199942713, 'global/env_act_steps': 20132096, 'global/env_train_steps': 20128000, 'global/optimizer_steps': 31449, 'global/running_reward': 17900.074546755724, 'global/running_step': 1968.477069417939, 'global/steps_done': 20132096, 'global/episodes_done': 5097, 'global/unclipped_grad_norm': 0.8279247569794558, 'global/model_version': 31449, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:45,468] calculate_sps 32000 steps in 10.0251
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:45,468] calculate_sps 34560 steps in 10.0251
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:45,468] {'local/mean_episode_return': 38914.28571428572, 'local/mean_episode_step': 4071.0, 'local/SPS': 3192.0007136580157, 'local/env_act_steps': 20167936, 'local/env_train_steps': 20163840, 'local/optimizer_steps': 31505, 'local/running_reward': 17830.643701737452, 'local/running_step': 1958.8985581563707, 'local/steps_done': 20167936, 'local/episodes_done': 5104, 'local/unclipped_grad_norm': 0.7023342130135517, 'local/model_version': 31505, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:45,469] {'global/mean_episode_return': 38914.28571428572, 'global/mean_episode_step': 4071.0, 'global/SPS': 3447.3607707506567, 'global/env_act_steps': 20164864, 'global/env_train_steps': 20162560, 'global/optimizer_steps': 31504, 'global/running_reward': 17818.106079101562, 'global/running_step': 1957.2677307128906, 'global/steps_done': 20164864, 'global/episodes_done': 5104, 'global/unclipped_grad_norm': 0.7254786811091684, 'global/model_version': 31504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:55,485] calculate_sps 34560 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:58:55,486] calculate_sps 30720 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:55,486] {'local/mean_episode_return': 39336.36363636364, 'local/mean_episode_step': 4223.363636363636, 'local/SPS': 3450.053736100609, 'local/env_act_steps': 20199936, 'local/env_train_steps': 20198400, 'local/optimizer_steps': 31560, 'local/running_reward': 17866.728125, 'local/running_step': 1965.649375, 'local/steps_done': 20199936, 'local/episodes_done': 5115, 'local/unclipped_grad_norm': 0.6978892916982824, 'local/model_version': 31560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:58:55,487] {'global/mean_episode_return': 39750.0, 'global/mean_episode_step': 4249.4, 'global/SPS': 3066.7144320894304, 'global/env_act_steps': 20197888, 'global/env_train_steps': 20193280, 'global/optimizer_steps': 31552, 'global/running_reward': 17895.730377906977, 'global/running_step': 1968.5201671511627, 'global/steps_done': 20197888, 'global/episodes_done': 5114, 'global/unclipped_grad_norm': 0.7045267609258493, 'global/model_version': 31552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:05,490] calculate_sps 30720 steps in 10.0051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:05,491] calculate_sps 35840 steps in 10.0051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:05,502] {'local/mean_episode_return': 34600.0, 'local/mean_episode_step': 3703.1666666666665, 'local/SPS': 3070.442928288348, 'local/env_act_steps': 20233216, 'local/env_train_steps': 20229120, 'local/optimizer_steps': 31608, 'local/running_reward': 17512.818509615383, 'local/running_step': 1932.4774338942307, 'local/steps_done': 20233216, 'local/episodes_done': 5121, 'local/unclipped_grad_norm': 0.7924097888171673, 'local/model_version': 31608, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:05,504] {'global/mean_episode_return': 34685.71428571428, 'global/mean_episode_step': 3740.285714285714, 'global/SPS': 3582.183416336406, 'global/env_act_steps': 20230272, 'global/env_train_steps': 20229120, 'global/optimizer_steps': 31607, 'global/running_reward': 17488.1268527668, 'global/running_step': 1929.7305768280632, 'global/steps_done': 20230272, 'global/episodes_done': 5121, 'global/unclipped_grad_norm': 0.777406186949123, 'global/model_version': 31607, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:15,516] calculate_sps 34560 steps in 10.0255
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:15,516] calculate_sps 30720 steps in 10.0255
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:15,517] {'local/mean_episode_return': 31780.0, 'local/mean_episode_step': 3398.8, 'local/SPS': 3447.218202948926, 'local/env_act_steps': 20265728, 'local/env_train_steps': 20263680, 'local/optimizer_steps': 31661, 'local/running_reward': 18092.977977362203, 'local/running_step': 1989.3558378444882, 'local/steps_done': 20265728, 'local/episodes_done': 5126, 'local/unclipped_grad_norm': 0.807761401500342, 'local/model_version': 31661, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:15,518] {'global/mean_episode_return': 31780.0, 'global/mean_episode_step': 3398.8, 'global/SPS': 3064.193958176823, 'global/env_act_steps': 20264192, 'global/env_train_steps': 20259840, 'global/optimizer_steps': 31656, 'global/running_reward': 18052.01945754717, 'global/running_step': 1985.3535672169812, 'global/steps_done': 20264192, 'global/episodes_done': 5126, 'global/unclipped_grad_norm': 0.8074803291534891, 'global/model_version': 31656, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:25,516] calculate_sps 32000 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:25,517] calculate_sps 35200 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:25,517] {'local/mean_episode_return': 37345.454545454544, 'local/mean_episode_step': 3950.2727272727275, 'local/SPS': 3199.7569459526585, 'local/env_act_steps': 20299008, 'local/env_train_steps': 20295680, 'local/optimizer_steps': 31712, 'local/running_reward': 18456.298076923078, 'local/running_step': 2027.6913161057691, 'local/steps_done': 20299008, 'local/episodes_done': 5137, 'local/unclipped_grad_norm': 0.7353067257825066, 'local/model_version': 31712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:25,527] {'global/mean_episode_return': 37345.454545454544, 'global/mean_episode_step': 3950.2727272727275, 'global/SPS': 3519.7326405479243, 'global/env_act_steps': 20296576, 'global/env_train_steps': 20295040, 'global/optimizer_steps': 31710, 'global/running_reward': 18486.666254940712, 'global/running_step': 2030.8754940711462, 'global/steps_done': 20296576, 'global/episodes_done': 5137, 'global/unclipped_grad_norm': 0.7426692054227546, 'global/model_version': 31710, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:35,528] calculate_sps 32000 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:35,528] calculate_sps 31360 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:35,528] {'local/mean_episode_return': 36855.555555555555, 'local/mean_episode_step': 3916.0, 'local/SPS': 3196.295187786831, 'local/env_act_steps': 20331776, 'local/env_train_steps': 20327680, 'local/optimizer_steps': 31761, 'local/running_reward': 18060.595703125, 'local/running_step': 1989.0897521972656, 'local/steps_done': 20331776, 'local/episodes_done': 5146, 'local/unclipped_grad_norm': 0.7334302651638888, 'local/model_version': 31761, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:35,529] {'global/mean_episode_return': 36855.555555555555, 'global/mean_episode_step': 3916.0, 'global/SPS': 3132.369284031094, 'global/env_act_steps': 20330112, 'global/env_train_steps': 20326400, 'global/optimizer_steps': 31760, 'global/running_reward': 18067.479723282442, 'global/running_step': 1989.3791447996184, 'global/steps_done': 20330112, 'global/episodes_done': 5146, 'global/unclipped_grad_norm': 0.7326826459169388, 'global/model_version': 31760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:45,553] calculate_sps 34560 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:45,566] calculate_sps 33920 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:45,566] {'local/mean_episode_return': 33275.0, 'local/mean_episode_step': 3567.6875, 'local/SPS': 3447.4155382856093, 'local/env_act_steps': 20364288, 'local/env_train_steps': 20362240, 'local/optimizer_steps': 31816, 'local/running_reward': 18054.656742125986, 'local/running_step': 1997.294968011811, 'local/steps_done': 20364288, 'local/episodes_done': 5155, 'local/unclipped_grad_norm': 0.749472270228646, 'local/model_version': 31816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:45,568] {'global/mean_episode_return': 33183.333333333336, 'global/mean_episode_step': 3544.0, 'global/SPS': 3383.574509798839, 'global/env_act_steps': 20362880, 'global/env_train_steps': 20360320, 'global/optimizer_steps': 31812, 'global/running_reward': 18042.27294921875, 'global/running_step': 1995.74560546875, 'global/steps_done': 20362880, 'global/episodes_done': 5152, 'global/unclipped_grad_norm': 0.7376013547182083, 'global/model_version': 31812, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:55,555] calculate_sps 30720 steps in 10.0026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 12:59:55,556] calculate_sps 32640 steps in 10.0026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:55,556] {'local/mean_episode_return': 29471.428571428572, 'local/mean_episode_step': 3369.4285714285716, 'local/SPS': 3071.2146051441487, 'local/env_act_steps': 20397952, 'local/env_train_steps': 20392960, 'local/optimizer_steps': 31864, 'local/running_reward': 18188.63177281369, 'local/running_step': 2011.648110741445, 'local/steps_done': 20397952, 'local/episodes_done': 5162, 'local/unclipped_grad_norm': 0.7973044204215208, 'local/model_version': 31864, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 12:59:55,557] {'global/mean_episode_return': 30377.777777777777, 'global/mean_episode_step': 3429.277777777778, 'global/SPS': 3263.1655179656577, 'global/env_act_steps': 20396544, 'global/env_train_steps': 20392960, 'global/optimizer_steps': 31864, 'global/running_reward': 18183.15411121673, 'global/running_step': 2011.2607830323193, 'global/steps_done': 20396544, 'global/episodes_done': 5162, 'global/unclipped_grad_norm': 0.80408764229371, 'global/model_version': 31864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:05,606] calculate_sps 35840 steps in 10.051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:05,606] calculate_sps 33280 steps in 10.051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:05,606] {'local/mean_episode_return': 36357.142857142855, 'local/mean_episode_step': 3879.714285714286, 'local/SPS': 3565.8225095692032, 'local/env_act_steps': 20429824, 'local/env_train_steps': 20428800, 'local/optimizer_steps': 31919, 'local/running_reward': 18410.924949799195, 'local/running_step': 2037.6566578815261, 'local/steps_done': 20429824, 'local/episodes_done': 5169, 'local/unclipped_grad_norm': 0.79800948175517, 'local/model_version': 31919, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:05,607] {'global/mean_episode_return': 35116.666666666664, 'global/mean_episode_step': 3774.8333333333335, 'global/SPS': 3311.120901742832, 'global/env_act_steps': 20429312, 'global/env_train_steps': 20426240, 'global/optimizer_steps': 31915, 'global/running_reward': 18402.447509765625, 'global/running_step': 2036.527099609375, 'global/steps_done': 20429312, 'global/episodes_done': 5168, 'global/unclipped_grad_norm': 0.814523612167321, 'global/model_version': 31915, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:15,640] calculate_sps 30720 steps in 10.0334
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:15,640] calculate_sps 33280 steps in 10.0334
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:15,640] {'local/mean_episode_return': 38100.0, 'local/mean_episode_step': 4072.8333333333335, 'local/SPS': 3061.777004746135, 'local/env_act_steps': 20463232, 'local/env_train_steps': 20459520, 'local/optimizer_steps': 31968, 'local/running_reward': 18689.137332375478, 'local/running_step': 2067.7261733716473, 'local/steps_done': 20463232, 'local/episodes_done': 5175, 'local/unclipped_grad_norm': 0.7660044243141096, 'local/model_version': 31968, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:15,642] {'global/mean_episode_return': 38914.28571428572, 'global/mean_episode_step': 4135.142857142857, 'global/SPS': 3316.9250884749795, 'global/env_act_steps': 20462464, 'global/env_train_steps': 20459520, 'global/optimizer_steps': 31968, 'global/running_reward': 18685.436776061775, 'global/running_step': 2067.3022140444014, 'global/steps_done': 20462464, 'global/episodes_done': 5175, 'global/unclipped_grad_norm': 0.7525289446677802, 'global/model_version': 31968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:25,666] calculate_sps 33280 steps in 10.0262
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:25,666] calculate_sps 32000 steps in 10.0262
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:25,666] {'local/mean_episode_return': 41391.666666666664, 'local/mean_episode_step': 4372.5, 'local/SPS': 3319.314851577253, 'local/env_act_steps': 20495872, 'local/env_train_steps': 20492800, 'local/optimizer_steps': 32019, 'local/running_reward': 18773.841911764706, 'local/running_step': 2077.5488664215686, 'local/steps_done': 20495872, 'local/episodes_done': 5182, 'local/unclipped_grad_norm': 0.8066130409053728, 'local/model_version': 32019, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:25,667] {'global/mean_episode_return': 41391.666666666664, 'global/mean_episode_step': 4372.5, 'global/SPS': 3191.648895747359, 'global/env_act_steps': 20495616, 'global/env_train_steps': 20491520, 'global/optimizer_steps': 32017, 'global/running_reward': 18771.89913127413, 'global/running_step': 2077.3502654440153, 'global/steps_done': 20495616, 'global/episodes_done': 5182, 'global/unclipped_grad_norm': 0.8128570330386259, 'global/model_version': 32017, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:35,687] calculate_sps 33280 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:35,688] calculate_sps 34560 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:35,688] {'local/mean_episode_return': 33283.333333333336, 'local/mean_episode_step': 3637.6666666666665, 'local/SPS': 3320.9341439261884, 'local/env_act_steps': 20528384, 'local/env_train_steps': 20526080, 'local/optimizer_steps': 32072, 'local/running_reward': 18611.940206692914, 'local/running_step': 2057.3877952755906, 'local/steps_done': 20528384, 'local/episodes_done': 5194, 'local/unclipped_grad_norm': 0.8432213003343006, 'local/model_version': 32072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:35,689] {'global/mean_episode_return': 33283.333333333336, 'global/mean_episode_step': 3637.6666666666665, 'global/SPS': 3448.662380231042, 'global/env_act_steps': 20528000, 'global/env_train_steps': 20526080, 'global/optimizer_steps': 32072, 'global/running_reward': 18609.643651185772, 'global/running_step': 2057.137197381423, 'global/steps_done': 20528000, 'global/episodes_done': 5194, 'global/unclipped_grad_norm': 0.8363272615454413, 'global/model_version': 32072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:45,700] calculate_sps 30720 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:45,700] calculate_sps 30720 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:45,710] {'local/mean_episode_return': 37412.5, 'local/mean_episode_step': 3978.75, 'local/SPS': 3068.4555103903194, 'local/env_act_steps': 20561664, 'local/env_train_steps': 20556800, 'local/optimizer_steps': 32120, 'local/running_reward': 18513.85516826923, 'local/running_step': 2048.888942307692, 'local/steps_done': 20561664, 'local/episodes_done': 5202, 'local/unclipped_grad_norm': 0.7159999882181486, 'local/model_version': 32120, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:45,712] {'global/mean_episode_return': 37412.5, 'global/mean_episode_step': 3978.75, 'global/SPS': 3068.4555103903194, 'global/env_act_steps': 20561664, 'global/env_train_steps': 20556800, 'global/optimizer_steps': 32120, 'global/running_reward': 18518.812381178708, 'global/running_step': 2049.4300142585553, 'global/steps_done': 20561664, 'global/episodes_done': 5202, 'global/unclipped_grad_norm': 0.7159999882181486, 'global/model_version': 32120, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:55,724] calculate_sps 35200 steps in 10.0259
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:00:55,725] calculate_sps 26880 steps in 10.0259
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:55,725] {'local/mean_episode_return': 31618.18181818182, 'local/mean_episode_step': 3622.909090909091, 'local/SPS': 3510.9083773710395, 'local/env_act_steps': 20593536, 'local/env_train_steps': 20592000, 'local/optimizer_steps': 32174, 'local/running_reward': 18297.747238955824, 'local/running_step': 2019.1983559236949, 'local/steps_done': 20593536, 'local/episodes_done': 5213, 'local/unclipped_grad_norm': 0.7975274550694006, 'local/model_version': 32174, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:00:55,726] {'global/mean_episode_return': 31820.0, 'global/mean_episode_step': 3646.5, 'global/SPS': 2681.0573063560664, 'global/env_act_steps': 20587776, 'global/env_train_steps': 20583680, 'global/optimizer_steps': 32161, 'global/running_reward': 18309.30223651961, 'global/running_step': 2020.6425015318628, 'global/steps_done': 20587776, 'global/episodes_done': 5212, 'global/unclipped_grad_norm': 0.8102518327352477, 'global/model_version': 32161, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:05,751] calculate_sps 31360 steps in 10.0257
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:05,751] calculate_sps 34560 steps in 10.0257
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:05,751] {'local/mean_episode_return': 38783.333333333336, 'local/mean_episode_step': 4062.5, 'local/SPS': 3127.948242476096, 'local/env_act_steps': 20626816, 'local/env_train_steps': 20623360, 'local/optimizer_steps': 32224, 'local/running_reward': 18549.15264423077, 'local/running_step': 2047.529266826923, 'local/steps_done': 20626816, 'local/episodes_done': 5219, 'local/unclipped_grad_norm': 0.7190810459852218, 'local/model_version': 32224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:05,753] {'global/mean_episode_return': 40425.0, 'global/mean_episode_step': 4254.5, 'global/SPS': 3447.126634565493, 'global/env_act_steps': 20620544, 'global/env_train_steps': 20618240, 'global/optimizer_steps': 32216, 'global/running_reward': 18460.159301757812, 'global/running_step': 2037.1250610351562, 'global/steps_done': 20620544, 'global/episodes_done': 5216, 'global/unclipped_grad_norm': 0.740642007372596, 'global/model_version': 32216, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:15,799] calculate_sps 33280 steps in 10.0484
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:15,799] calculate_sps 30720 steps in 10.0484
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:15,799] {'local/mean_episode_return': 33383.333333333336, 'local/mean_episode_step': 3713.5, 'local/SPS': 3311.9633313900945, 'local/env_act_steps': 20659712, 'local/env_train_steps': 20656640, 'local/optimizer_steps': 32275, 'local/running_reward': 18737.758390077823, 'local/running_step': 2070.178623540856, 'local/steps_done': 20659712, 'local/episodes_done': 5225, 'local/unclipped_grad_norm': 0.9034317743544485, 'local/model_version': 32275, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:15,800] {'global/mean_episode_return': 33433.333333333336, 'global/mean_episode_step': 3669.4444444444443, 'global/SPS': 3057.196921283164, 'global/env_act_steps': 20654208, 'global/env_train_steps': 20648960, 'global/optimizer_steps': 32264, 'global/running_reward': 18720.50558460076, 'global/running_step': 2068.3133614543726, 'global/steps_done': 20654208, 'global/episodes_done': 5225, 'global/unclipped_grad_norm': 0.8556405045092106, 'global/model_version': 32264, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:25,802] calculate_sps 33280 steps in 10.0033
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:25,803] calculate_sps 35840 steps in 10.0033
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:25,814] {'local/mean_episode_return': 33183.333333333336, 'local/mean_episode_step': 3651.8333333333335, 'local/SPS': 3326.9077682502552, 'local/env_act_steps': 20692224, 'local/env_train_steps': 20689920, 'local/optimizer_steps': 32328, 'local/running_reward': 18475.74126476378, 'local/running_step': 2039.2300996555118, 'local/steps_done': 20692224, 'local/episodes_done': 5239, 'local/unclipped_grad_norm': 0.799374169336175, 'local/model_version': 32328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:25,816] {'global/mean_episode_return': 33183.333333333336, 'global/mean_episode_step': 3651.8333333333335, 'global/SPS': 3582.823750423352, 'global/env_act_steps': 20686208, 'global/env_train_steps': 20684800, 'global/optimizer_steps': 32320, 'global/running_reward': 18587.803125, 'global/running_step': 2052.49178125, 'global/steps_done': 20686208, 'global/episodes_done': 5239, 'global/unclipped_grad_norm': 0.813784451356956, 'global/model_version': 32320, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:35,837] calculate_sps 30720 steps in 10.0352
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:35,838] calculate_sps 30720 steps in 10.0352
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:35,838] {'local/mean_episode_return': 35085.71428571428, 'local/mean_episode_step': 3742.0, 'local/SPS': 3061.222126154578, 'local/env_act_steps': 20725888, 'local/env_train_steps': 20720640, 'local/optimizer_steps': 32376, 'local/running_reward': 18438.120841254753, 'local/running_step': 2037.8040339828897, 'local/steps_done': 20725888, 'local/episodes_done': 5246, 'local/unclipped_grad_norm': 0.7037771015117565, 'local/model_version': 32376, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:35,839] {'global/mean_episode_return': 38650.0, 'global/mean_episode_step': 4004.75, 'global/SPS': 3061.222126154578, 'global/env_act_steps': 20720256, 'global/env_train_steps': 20715520, 'global/optimizer_steps': 32368, 'global/running_reward': 18363.160831766916, 'global/running_step': 2027.8633399906016, 'global/steps_done': 20720256, 'global/episodes_done': 5243, 'global/unclipped_grad_norm': 0.7420877069234848, 'global/model_version': 32368, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:45,842] calculate_sps 35840 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:45,842] calculate_sps 35200 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:45,842] {'local/mean_episode_return': 41311.11111111111, 'local/mean_episode_step': 4314.444444444444, 'local/SPS': 3582.248634564867, 'local/env_act_steps': 20757632, 'local/env_train_steps': 20756480, 'local/optimizer_steps': 32432, 'local/running_reward': 18204.277973790322, 'local/running_step': 2017.872574344758, 'local/steps_done': 20757632, 'local/episodes_done': 5255, 'local/unclipped_grad_norm': 0.7694085368088314, 'local/model_version': 32432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:45,843] {'global/mean_episode_return': 38272.72727272727, 'global/mean_episode_step': 4089.3636363636365, 'global/SPS': 3518.2799089476375, 'global/env_act_steps': 20752256, 'global/env_train_steps': 20750720, 'global/optimizer_steps': 32422, 'global/running_reward': 18280.553125, 'global/running_step': 2025.64284375, 'global/steps_done': 20752256, 'global/episodes_done': 5254, 'global/unclipped_grad_norm': 0.77276969563078, 'global/model_version': 32422, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:55,863] calculate_sps 30720 steps in 10.0205
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:01:55,863] calculate_sps 31360 steps in 10.0205
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:55,863] {'local/mean_episode_return': 43555.555555555555, 'local/mean_episode_step': 4555.111111111111, 'local/SPS': 3065.72449141361, 'local/env_act_steps': 20791424, 'local/env_train_steps': 20787200, 'local/optimizer_steps': 32480, 'local/running_reward': 17787.71306818182, 'local/running_step': 1979.431551846591, 'local/steps_done': 20791424, 'local/episodes_done': 5264, 'local/unclipped_grad_norm': 0.6589302799353997, 'local/model_version': 32480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:01:55,865] {'global/mean_episode_return': 43380.0, 'global/mean_episode_step': 4501.8, 'global/SPS': 3129.5937516513936, 'global/env_act_steps': 20786048, 'global/env_train_steps': 20782080, 'global/optimizer_steps': 32472, 'global/running_reward': 17857.859848484848, 'global/running_step': 1985.6938032670455, 'global/steps_done': 20786048, 'global/episodes_done': 5264, 'global/unclipped_grad_norm': 0.6697458070516586, 'global/model_version': 32472, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:05,872] calculate_sps 33920 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:05,872] calculate_sps 34560 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:05,872] {'local/mean_episode_return': 36890.0, 'local/mean_episode_step': 3974.1, 'local/SPS': 3388.734721332487, 'local/env_act_steps': 20823680, 'local/env_train_steps': 20821120, 'local/optimizer_steps': 32532, 'local/running_reward': 17894.82886904762, 'local/running_step': 1991.9522259424602, 'local/steps_done': 20823680, 'local/episodes_done': 5274, 'local/unclipped_grad_norm': 0.7127234889910772, 'local/model_version': 32532, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:05,873] {'global/mean_episode_return': 34837.5, 'global/mean_episode_step': 3790.625, 'global/SPS': 3452.6731123010245, 'global/env_act_steps': 20818688, 'global/env_train_steps': 20816640, 'global/optimizer_steps': 32525, 'global/running_reward': 17889.583333333332, 'global/running_step': 1992.036550245098, 'global/steps_done': 20818688, 'global/episodes_done': 5272, 'global/unclipped_grad_norm': 0.670648695725315, 'global/model_version': 32525, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:15,906] calculate_sps 32640 steps in 10.0333
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:15,906] calculate_sps 32000 steps in 10.0333
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:15,906] {'local/mean_episode_return': 34200.0, 'local/mean_episode_step': 3682.4444444444443, 'local/SPS': 3253.1597124564228, 'local/env_act_steps': 20857216, 'local/env_train_steps': 20853760, 'local/optimizer_steps': 32584, 'local/running_reward': 17527.987833969466, 'local/running_step': 1953.301496898855, 'local/steps_done': 20857216, 'local/episodes_done': 5283, 'local/unclipped_grad_norm': 0.757436932852635, 'local/model_version': 32584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:15,908] {'global/mean_episode_return': 36181.818181818184, 'global/mean_episode_step': 3868.909090909091, 'global/SPS': 3189.37226711414, 'global/env_act_steps': 20852480, 'global/env_train_steps': 20848640, 'global/optimizer_steps': 32576, 'global/running_reward': 17566.216856060608, 'global/running_step': 1956.9319661458333, 'global/steps_done': 20852480, 'global/episodes_done': 5283, 'global/unclipped_grad_norm': 0.7634081092535281, 'global/model_version': 32576, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:25,949] calculate_sps 32640 steps in 10.0436
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:25,949] calculate_sps 33920 steps in 10.0436
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:25,949] {'local/mean_episode_return': 32555.555555555555, 'local/mean_episode_step': 3572.3333333333335, 'local/SPS': 3249.816130859108, 'local/env_act_steps': 20889984, 'local/env_train_steps': 20886400, 'local/optimizer_steps': 32634, 'local/running_reward': 17738.162231445312, 'local/running_step': 1975.885498046875, 'local/steps_done': 20889984, 'local/episodes_done': 5292, 'local/unclipped_grad_norm': 0.7943370658159256, 'local/model_version': 32634, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:25,950] {'global/mean_episode_return': 33014.28571428572, 'global/mean_episode_step': 3582.5714285714284, 'global/SPS': 3377.2599006967203, 'global/env_act_steps': 20885248, 'global/env_train_steps': 20882560, 'global/optimizer_steps': 32628, 'global/running_reward': 17722.647094726562, 'global/running_step': 1974.6648864746094, 'global/steps_done': 20885248, 'global/episodes_done': 5290, 'global/unclipped_grad_norm': 0.7822703203329673, 'global/model_version': 32628, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:35,979] calculate_sps 33920 steps in 10.0299
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:35,980] calculate_sps 32640 steps in 10.0299
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:35,980] {'local/mean_episode_return': 33109.09090909091, 'local/mean_episode_step': 3567.3636363636365, 'local/SPS': 3381.8870843938366, 'local/env_act_steps': 20922496, 'local/env_train_steps': 20920320, 'local/optimizer_steps': 32688, 'local/running_reward': 17509.110482283464, 'local/running_step': 1953.1361958661416, 'local/steps_done': 20922496, 'local/episodes_done': 5303, 'local/unclipped_grad_norm': 0.6902563952737384, 'local/model_version': 32688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:35,981] {'global/mean_episode_return': 32658.333333333332, 'global/mean_episode_step': 3517.6666666666665, 'global/SPS': 3254.2687038506733, 'global/env_act_steps': 20918400, 'global/env_train_steps': 20915200, 'global/optimizer_steps': 32680, 'global/running_reward': 17540.6340492278, 'global/running_step': 1955.7911136583011, 'global/steps_done': 20918400, 'global/episodes_done': 5302, 'global/unclipped_grad_norm': 0.7171816986340743, 'global/model_version': 32680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:45,998] calculate_sps 30720 steps in 10.019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:45,999] calculate_sps 32640 steps in 10.019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:45,999] {'local/mean_episode_return': 33222.22222222222, 'local/mean_episode_step': 3606.4444444444443, 'local/SPS': 3066.162286387878, 'local/env_act_steps': 20956032, 'local/env_train_steps': 20951040, 'local/optimizer_steps': 32736, 'local/running_reward': 17335.35901717557, 'local/running_step': 1935.8380844465648, 'local/steps_done': 20956032, 'local/episodes_done': 5312, 'local/unclipped_grad_norm': 0.7329960595816374, 'local/model_version': 32736, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:46,000] {'global/mean_episode_return': 33320.0, 'global/mean_episode_step': 3656.0, 'global/SPS': 3257.79742928712, 'global/env_act_steps': 20951424, 'global/env_train_steps': 20947840, 'global/optimizer_steps': 32730, 'global/running_reward': 17345.93628875969, 'global/running_step': 1936.9297480620155, 'global/steps_done': 20951424, 'global/episodes_done': 5312, 'global/unclipped_grad_norm': 0.7281082844734192, 'global/model_version': 32730, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:56,012] calculate_sps 35840 steps in 10.0141
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:02:56,013] calculate_sps 33920 steps in 10.0141
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:56,013] {'local/mean_episode_return': 33850.0, 'local/mean_episode_step': 3844.5, 'local/SPS': 3578.9532225525886, 'local/env_act_steps': 20988288, 'local/env_train_steps': 20986880, 'local/optimizer_steps': 32792, 'local/running_reward': 17289.977058531746, 'local/running_step': 1928.2667720734128, 'local/steps_done': 20988288, 'local/episodes_done': 5322, 'local/unclipped_grad_norm': 0.7033050847905022, 'local/model_version': 32792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:02:56,015] {'global/mean_episode_return': 33850.0, 'global/mean_episode_step': 3844.5, 'global/SPS': 3387.2235856301286, 'global/env_act_steps': 20984576, 'global/env_train_steps': 20981760, 'global/optimizer_steps': 32784, 'global/running_reward': 17303.80369208494, 'global/running_step': 1930.74173503861, 'global/steps_done': 20984576, 'global/episodes_done': 5322, 'global/unclipped_grad_norm': 0.7231242237267671, 'global/model_version': 32784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:06,031] calculate_sps 30720 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:06,031] calculate_sps 32000 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:06,031] {'local/mean_episode_return': 30957.14285714286, 'local/mean_episode_step': 3484.1428571428573, 'local/SPS': 3066.3881998486427, 'local/env_act_steps': 21021568, 'local/env_train_steps': 21017600, 'local/optimizer_steps': 32840, 'local/running_reward': 17393.62079326923, 'local/running_step': 1928.9975961538462, 'local/steps_done': 21021568, 'local/episodes_done': 5329, 'local/unclipped_grad_norm': 0.6479891619334618, 'local/model_version': 32840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:06,043] {'global/mean_episode_return': 30957.14285714286, 'global/mean_episode_step': 3484.1428571428573, 'global/SPS': 3194.1543748423364, 'global/env_act_steps': 21017856, 'global/env_train_steps': 21013760, 'global/optimizer_steps': 32833, 'global/running_reward': 17348.182091346152, 'global/running_step': 1925.1063701923076, 'global/steps_done': 21017856, 'global/episodes_done': 5329, 'global/unclipped_grad_norm': 0.6369484644763324, 'global/model_version': 32833, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:16,061] calculate_sps 33280 steps in 10.0284
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:16,062] calculate_sps 34560 steps in 10.0284
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:16,062] {'local/mean_episode_return': 37800.0, 'local/mean_episode_step': 4098.142857142857, 'local/SPS': 3318.5654026435036, 'local/env_act_steps': 21054080, 'local/env_train_steps': 21050880, 'local/optimizer_steps': 32891, 'local/running_reward': 17762.592273622045, 'local/running_step': 1963.3928088090552, 'local/steps_done': 21054080, 'local/episodes_done': 5336, 'local/unclipped_grad_norm': 0.6900984706247554, 'local/model_version': 32891, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:16,063] {'global/mean_episode_return': 37800.0, 'global/mean_episode_step': 4098.142857142857, 'global/SPS': 3446.2025335144076, 'global/env_act_steps': 21050368, 'global/env_train_steps': 21048320, 'global/optimizer_steps': 32888, 'global/running_reward': 17746.94881889764, 'global/running_step': 1961.7686392716535, 'global/steps_done': 21050368, 'global/episodes_done': 5336, 'global/unclipped_grad_norm': 0.6745198068293659, 'global/model_version': 32888, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:26,093] calculate_sps 33280 steps in 10.0334
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:26,093] calculate_sps 30720 steps in 10.0334
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:26,093] {'local/mean_episode_return': 32880.0, 'local/mean_episode_step': 3612.1, 'local/SPS': 3316.9058568751975, 'local/env_act_steps': 21087232, 'local/env_train_steps': 21084160, 'local/optimizer_steps': 32944, 'local/running_reward': 17964.29777992278, 'local/running_step': 1984.9088742760619, 'local/steps_done': 21087232, 'local/episodes_done': 5346, 'local/unclipped_grad_norm': 0.7546253957838382, 'local/model_version': 32944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:26,095] {'global/mean_episode_return': 32066.666666666668, 'global/mean_episode_step': 3534.0, 'global/SPS': 3061.7592525001824, 'global/env_act_steps': 21084288, 'global/env_train_steps': 21079040, 'global/optimizer_steps': 32936, 'global/running_reward': 17957.146226415094, 'global/running_step': 1984.1627653301887, 'global/steps_done': 21084288, 'global/episodes_done': 5345, 'global/unclipped_grad_norm': 0.7940027316411337, 'global/model_version': 32936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:36,118] calculate_sps 31360 steps in 10.0257
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:36,118] calculate_sps 35840 steps in 10.0257
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:36,118] {'local/mean_episode_return': 38137.5, 'local/mean_episode_step': 4084.5, 'local/SPS': 3127.963565783206, 'local/env_act_steps': 21120128, 'local/env_train_steps': 21115520, 'local/optimizer_steps': 32992, 'local/running_reward': 17469.674124513618, 'local/running_step': 1933.5145306420234, 'local/steps_done': 21120128, 'local/episodes_done': 5354, 'local/unclipped_grad_norm': 0.7443553432822227, 'local/model_version': 32992, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:36,119] {'global/mean_episode_return': 38366.666666666664, 'global/mean_episode_step': 4110.111111111111, 'global/SPS': 3574.815503752235, 'global/env_act_steps': 21116672, 'global/env_train_steps': 21114880, 'global/optimizer_steps': 32992, 'global/running_reward': 17478.128087944664, 'global/running_step': 1934.2248950098815, 'global/steps_done': 21116672, 'global/episodes_done': 5354, 'global/unclipped_grad_norm': 0.7183833792805672, 'global/model_version': 32992, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:46,135] calculate_sps 35200 steps in 10.017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:46,136] calculate_sps 30720 steps in 10.017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:46,136] {'local/mean_episode_return': 37336.36363636364, 'local/mean_episode_step': 3982.181818181818, 'local/SPS': 3514.0365408196685, 'local/env_act_steps': 21152256, 'local/env_train_steps': 21150720, 'local/optimizer_steps': 33048, 'local/running_reward': 17556.819596613546, 'local/running_step': 1946.0034238047808, 'local/steps_done': 21152256, 'local/episodes_done': 5365, 'local/unclipped_grad_norm': 0.7435475436172315, 'local/model_version': 33048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:46,137] {'global/mean_episode_return': 37336.36363636364, 'global/mean_episode_step': 3982.181818181818, 'global/SPS': 3066.795526533529, 'global/env_act_steps': 21150208, 'global/env_train_steps': 21145600, 'global/optimizer_steps': 33040, 'global/running_reward': 17591.483778625956, 'global/running_step': 1949.2596910782443, 'global/steps_done': 21150208, 'global/episodes_done': 5365, 'global/unclipped_grad_norm': 0.7177369616304835, 'global/model_version': 33040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:56,167] calculate_sps 30720 steps in 10.0319
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:03:56,167] calculate_sps 35840 steps in 10.0319
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:56,168] {'local/mean_episode_return': 40233.333333333336, 'local/mean_episode_step': 4233.0, 'local/SPS': 3062.234050433917, 'local/env_act_steps': 21185536, 'local/env_train_steps': 21181440, 'local/optimizer_steps': 33096, 'local/running_reward': 17514.266826923078, 'local/running_step': 1945.5048377403846, 'local/steps_done': 21185536, 'local/episodes_done': 5371, 'local/unclipped_grad_norm': 0.7334915728618702, 'local/model_version': 33096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:03:56,169] {'global/mean_episode_return': 40360.0, 'global/mean_episode_step': 4199.0, 'global/SPS': 3572.6063921729033, 'global/env_act_steps': 21182464, 'global/env_train_steps': 21181440, 'global/optimizer_steps': 33095, 'global/running_reward': 17491.914682539682, 'global/running_step': 1943.070281498016, 'global/steps_done': 21182464, 'global/episodes_done': 5370, 'global/unclipped_grad_norm': 0.7649613179943778, 'global/model_version': 33095, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:06,173] calculate_sps 33920 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:06,173] calculate_sps 30720 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:06,174] {'local/mean_episode_return': 38170.0, 'local/mean_episode_step': 4013.4, 'local/SPS': 3389.799214782292, 'local/env_act_steps': 21217920, 'local/env_train_steps': 21215360, 'local/optimizer_steps': 33148, 'local/running_reward': 17395.48233695652, 'local/running_step': 1934.0578063241107, 'local/steps_done': 21217920, 'local/episodes_done': 5381, 'local/unclipped_grad_norm': 0.8117269558402208, 'local/model_version': 33148, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:06,175] {'global/mean_episode_return': 37510.0, 'global/mean_episode_step': 4005.8, 'global/SPS': 3070.0068360292457, 'global/env_act_steps': 21216000, 'global/env_train_steps': 21212160, 'global/optimizer_steps': 33144, 'global/running_reward': 17415.404341603054, 'global/running_step': 1935.9072936545801, 'global/steps_done': 21216000, 'global/episodes_done': 5380, 'global/unclipped_grad_norm': 0.8000297327430881, 'global/model_version': 33144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:16,176] calculate_sps 32640 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:16,176] calculate_sps 34560 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:16,176] {'local/mean_episode_return': 32283.333333333332, 'local/mean_episode_step': 3552.8333333333335, 'local/SPS': 3263.370325659619, 'local/env_act_steps': 21250816, 'local/env_train_steps': 21248000, 'local/optimizer_steps': 33200, 'local/running_reward': 17506.757660505835, 'local/running_step': 1951.1642752918287, 'local/steps_done': 21250816, 'local/episodes_done': 5388, 'local/unclipped_grad_norm': 0.7629078878806188, 'local/model_version': 33200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:16,177] {'global/mean_episode_return': 35383.333333333336, 'global/mean_episode_step': 3752.0, 'global/SPS': 3455.333285992538, 'global/env_act_steps': 21248768, 'global/env_train_steps': 21246720, 'global/optimizer_steps': 33197, 'global/running_reward': 17491.78466796875, 'global/running_step': 1949.5998229980469, 'global/steps_done': 21248768, 'global/episodes_done': 5387, 'global/unclipped_grad_norm': 0.7645938694477081, 'global/model_version': 33197, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:26,233] calculate_sps 31360 steps in 10.0581
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:26,233] calculate_sps 32000 steps in 10.0581
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:26,234] {'local/mean_episode_return': 36963.63636363636, 'local/mean_episode_step': 3909.5454545454545, 'local/SPS': 3117.8742279945072, 'local/env_act_steps': 21283968, 'local/env_train_steps': 21279360, 'local/optimizer_steps': 33248, 'local/running_reward': 17147.73467664093, 'local/running_step': 1914.0158663127413, 'local/steps_done': 21283968, 'local/episodes_done': 5399, 'local/unclipped_grad_norm': 0.8095501785477003, 'local/model_version': 33248, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:26,235] {'global/mean_episode_return': 37540.0, 'global/mean_episode_step': 3983.3, 'global/SPS': 3181.504314280109, 'global/env_act_steps': 21282048, 'global/env_train_steps': 21278720, 'global/optimizer_steps': 33248, 'global/running_reward': 17169.681490384617, 'global/running_step': 1916.007421875, 'global/steps_done': 21282048, 'global/episodes_done': 5397, 'global/unclipped_grad_norm': 0.8105196029532189, 'global/model_version': 33248, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:36,246] calculate_sps 35200 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:36,246] calculate_sps 32000 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:36,247] {'local/mean_episode_return': 37400.0, 'local/mean_episode_step': 4040.1666666666665, 'local/SPS': 3515.6587192524375, 'local/env_act_steps': 21315968, 'local/env_train_steps': 21314560, 'local/optimizer_steps': 33304, 'local/running_reward': 17191.625, 'local/running_step': 1925.81175, 'local/steps_done': 21315968, 'local/episodes_done': 5405, 'local/unclipped_grad_norm': 0.7777341739939791, 'local/model_version': 33304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:36,248] {'global/mean_episode_return': 35400.0, 'global/mean_episode_step': 3837.125, 'global/SPS': 3196.0533811385794, 'global/env_act_steps': 21314944, 'global/env_train_steps': 21310720, 'global/optimizer_steps': 33297, 'global/running_reward': 17187.594236381323, 'global/running_step': 1925.1846729085603, 'global/steps_done': 21314944, 'global/episodes_done': 5405, 'global/unclipped_grad_norm': 0.7811458186835659, 'global/model_version': 33297, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:46,261] calculate_sps 30720 steps in 10.0152
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:46,262] calculate_sps 34560 steps in 10.0152
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:46,262] {'local/mean_episode_return': 32850.0, 'local/mean_episode_step': 3624.6, 'local/SPS': 3067.3297913597576, 'local/env_act_steps': 21349376, 'local/env_train_steps': 21345280, 'local/optimizer_steps': 33352, 'local/running_reward': 17075.936901340996, 'local/running_step': 1912.9284602490422, 'local/steps_done': 21349376, 'local/episodes_done': 5416, 'local/unclipped_grad_norm': 0.7622765194003781, 'local/model_version': 33352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:46,263] {'global/mean_episode_return': 32850.0, 'global/mean_episode_step': 3624.6, 'global/SPS': 3450.7460152797275, 'global/env_act_steps': 21347584, 'global/env_train_steps': 21345280, 'global/optimizer_steps': 33352, 'global/running_reward': 17084.592524509804, 'global/running_step': 1913.9068321078432, 'global/steps_done': 21347584, 'global/episodes_done': 5416, 'global/unclipped_grad_norm': 0.7612043919888409, 'global/model_version': 33352, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:56,278] calculate_sps 35200 steps in 10.0173
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:04:56,278] calculate_sps 31360 steps in 10.0173
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:56,279] {'local/mean_episode_return': 32260.0, 'local/mean_episode_step': 3522.8, 'local/SPS': 3513.9116719002645, 'local/env_act_steps': 21382016, 'local/env_train_steps': 21380480, 'local/optimizer_steps': 33406, 'local/running_reward': 16862.80637254902, 'local/running_step': 1886.979105392157, 'local/steps_done': 21382016, 'local/episodes_done': 5426, 'local/unclipped_grad_norm': 0.6957449438395323, 'local/model_version': 33406, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:04:56,279] {'global/mean_episode_return': 32260.0, 'global/mean_episode_step': 3522.8, 'global/SPS': 3130.575853147508, 'global/env_act_steps': 21381376, 'global/env_train_steps': 21376640, 'global/optimizer_steps': 33401, 'global/running_reward': 16866.666666666668, 'global/running_step': 1887.4379142992425, 'global/steps_done': 21381376, 'global/episodes_done': 5426, 'global/unclipped_grad_norm': 0.6846702567168644, 'global/model_version': 33401, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:06,280] calculate_sps 31360 steps in 10.0016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:06,281] calculate_sps 35200 steps in 10.0016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:06,281] {'local/mean_episode_return': 32628.571428571428, 'local/mean_episode_step': 3651.5714285714284, 'local/SPS': 3135.492108025982, 'local/env_act_steps': 21415296, 'local/env_train_steps': 21411840, 'local/optimizer_steps': 33456, 'local/running_reward': 17220.540865384617, 'local/running_step': 1922.5143629807692, 'local/steps_done': 21415296, 'local/episodes_done': 5433, 'local/unclipped_grad_norm': 0.6918517327308655, 'local/model_version': 33456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:06,282] {'global/mean_episode_return': 32466.666666666668, 'global/mean_episode_step': 3677.3333333333335, 'global/SPS': 3519.4299171720204, 'global/env_act_steps': 21413760, 'global/env_train_steps': 21411840, 'global/optimizer_steps': 33456, 'global/running_reward': 17210.394021739132, 'global/running_step': 1921.7579360177865, 'global/steps_done': 21413760, 'global/episodes_done': 5432, 'global/unclipped_grad_norm': 0.7020722004500303, 'global/model_version': 33456, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:16,282] calculate_sps 32000 steps in 10.0025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:16,283] calculate_sps 30720 steps in 10.0025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:16,283] {'local/mean_episode_return': 32400.0, 'local/mean_episode_step': 3594.777777777778, 'local/SPS': 3199.210323703735, 'local/env_act_steps': 21447936, 'local/env_train_steps': 21443840, 'local/optimizer_steps': 33505, 'local/running_reward': 17457.19975490196, 'local/running_step': 1940.169699754902, 'local/steps_done': 21447936, 'local/episodes_done': 5442, 'local/unclipped_grad_norm': 0.7274443847792489, 'local/model_version': 33505, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:16,284] {'global/mean_episode_return': 32520.0, 'global/mean_episode_step': 3585.0, 'global/SPS': 3071.241910755585, 'global/env_act_steps': 21447040, 'global/env_train_steps': 21442560, 'global/optimizer_steps': 33504, 'global/running_reward': 17457.247596153848, 'global/running_step': 1940.376953125, 'global/steps_done': 21447040, 'global/episodes_done': 5442, 'global/unclipped_grad_norm': 0.7195652710894743, 'global/model_version': 33504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:26,293] calculate_sps 34560 steps in 10.0102
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:26,293] calculate_sps 35200 steps in 10.0102
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:26,293] {'local/mean_episode_return': 36600.0, 'local/mean_episode_step': 3984.3, 'local/SPS': 3452.4953209571745, 'local/env_act_steps': 21480320, 'local/env_train_steps': 21478400, 'local/optimizer_steps': 33560, 'local/running_reward': 17317.483942687748, 'local/running_step': 1919.362802618577, 'local/steps_done': 21480320, 'local/episodes_done': 5452, 'local/unclipped_grad_norm': 0.7554061954671686, 'local/model_version': 33560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:26,295] {'global/mean_episode_return': 35711.11111111111, 'global/mean_episode_step': 3894.1111111111113, 'global/SPS': 3516.4304194934184, 'global/env_act_steps': 21479424, 'global/env_train_steps': 21477760, 'global/optimizer_steps': 33558, 'global/running_reward': 17317.558053359684, 'global/running_step': 1919.4054162549407, 'global/steps_done': 21479424, 'global/episodes_done': 5451, 'global/unclipped_grad_norm': 0.7677806825549515, 'global/model_version': 33558, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:36,332] calculate_sps 30720 steps in 10.0394
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:36,333] calculate_sps 31360 steps in 10.0394
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:36,333] {'local/mean_episode_return': 32794.444444444445, 'local/mean_episode_step': 3577.8888888888887, 'local/SPS': 3059.9349251258977, 'local/env_act_steps': 21513600, 'local/env_train_steps': 21509120, 'local/optimizer_steps': 33608, 'local/running_reward': 15967.548076923076, 'local/running_step': 1790.9409254807692, 'local/steps_done': 21513600, 'local/episodes_done': 5471, 'local/unclipped_grad_norm': 0.6728906370699406, 'local/model_version': 33608, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:36,334] {'global/mean_episode_return': 33415.78947368421, 'global/mean_episode_step': 3642.0, 'global/SPS': 3123.683569399354, 'global/env_act_steps': 21512576, 'global/env_train_steps': 21509120, 'global/optimizer_steps': 33608, 'global/running_reward': 16014.068532818534, 'global/running_step': 1795.3984073359072, 'global/steps_done': 21512576, 'global/episodes_done': 5471, 'global/unclipped_grad_norm': 0.6698315262794494, 'global/model_version': 33608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:46,363] calculate_sps 35200 steps in 10.031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:46,363] calculate_sps 33280 steps in 10.031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:46,363] {'local/mean_episode_return': 30000.0, 'local/mean_episode_step': 3307.3333333333335, 'local/SPS': 3509.1363540339803, 'local/env_act_steps': 21545856, 'local/env_train_steps': 21544320, 'local/optimizer_steps': 33662, 'local/running_reward': 15863.089037698413, 'local/running_step': 1786.4055989583333, 'local/steps_done': 21545856, 'local/episodes_done': 5477, 'local/unclipped_grad_norm': 0.7223507657095238, 'local/model_version': 33662, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:46,364] {'global/mean_episode_return': 30000.0, 'global/mean_episode_step': 3307.3333333333335, 'global/SPS': 3317.7289165412176, 'global/env_act_steps': 21545600, 'global/env_train_steps': 21542400, 'global/optimizer_steps': 33659, 'global/running_reward': 15854.514898255815, 'global/running_step': 1785.4368338178294, 'global/steps_done': 21545600, 'global/episodes_done': 5477, 'global/unclipped_grad_norm': 0.7284747110862358, 'global/model_version': 33659, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 13:05:52,325] saving global stats {'mean_episode_return': 29400.0, 'mean_episode_step': 3235.0, 'SPS': None, 'env_act_steps': 21558912, 'env_train_steps': 21555200, 'optimizer_steps': 33680, 'running_reward': 16099.729567307691, 'running_step': 1812.610126201923, 'steps_done': 21558912, 'episodes_done': 5481, 'unclipped_grad_norm': 0.7278780681746346, 'model_version': 33680, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 13:05:52,410] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:56,394] calculate_sps 31360 steps in 10.0303
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:05:56,394] calculate_sps 33280 steps in 10.0303
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:56,394] {'local/mean_episode_return': 33780.0, 'local/mean_episode_step': 3628.6, 'local/SPS': 3126.5172909704156, 'local/env_act_steps': 21578880, 'local/env_train_steps': 21575680, 'local/optimizer_steps': 33712, 'local/running_reward': 16165.08902616279, 'local/running_step': 1819.8769379844962, 'local/steps_done': 21578880, 'local/episodes_done': 5488, 'local/unclipped_grad_norm': 0.7314043241739273, 'local/model_version': 33712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:05:56,395] {'global/mean_episode_return': 33780.0, 'global/mean_episode_step': 3628.6, 'global/SPS': 3317.936716948196, 'global/env_act_steps': 21578368, 'global/env_train_steps': 21575680, 'global/optimizer_steps': 33712, 'global/running_reward': 16170.050048828125, 'global/running_step': 1820.3663635253906, 'global/steps_done': 21578368, 'global/episodes_done': 5488, 'global/unclipped_grad_norm': 0.724999005502125, 'global/model_version': 33712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:06,398] calculate_sps 32640 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:06,399] calculate_sps 32640 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:06,414] {'local/mean_episode_return': 26866.666666666668, 'local/mean_episode_step': 3239.5, 'local/SPS': 3262.874491020773, 'local/env_act_steps': 21612032, 'local/env_train_steps': 21608320, 'local/optimizer_steps': 33762, 'local/running_reward': 16115.736607142857, 'local/running_step': 1814.839074565637, 'local/steps_done': 21612032, 'local/episodes_done': 5494, 'local/unclipped_grad_norm': 0.6326595985889435, 'local/model_version': 33762, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:06,416] {'global/mean_episode_return': 26866.666666666668, 'global/mean_episode_step': 3239.5, 'global/SPS': 3262.874491020773, 'global/env_act_steps': 21611904, 'global/env_train_steps': 21608320, 'global/optimizer_steps': 33762, 'global/running_reward': 16110.123449427481, 'global/running_step': 1814.2740338740457, 'global/steps_done': 21611904, 'global/episodes_done': 5494, 'global/unclipped_grad_norm': 0.6326595985889435, 'global/model_version': 33762, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:16,409] calculate_sps 33920 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:16,409] calculate_sps 27520 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:16,409] {'local/mean_episode_return': 31280.0, 'local/mean_episode_step': 3394.4, 'local/SPS': 3388.0540190022407, 'local/env_act_steps': 21644416, 'local/env_train_steps': 21642240, 'local/optimizer_steps': 33816, 'local/running_reward': 16377.91810770751, 'local/running_step': 1843.5000308794467, 'local/steps_done': 21644416, 'local/episodes_done': 5504, 'local/unclipped_grad_norm': 0.7026627510786057, 'local/model_version': 33816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:16,419] {'global/mean_episode_return': 32150.0, 'global/mean_episode_step': 3435.25, 'global/SPS': 2748.798543718799, 'global/env_act_steps': 21638016, 'global/env_train_steps': 21635840, 'global/optimizer_steps': 33806, 'global/running_reward': 16390.45649509804, 'global/running_step': 1844.4988511029412, 'global/steps_done': 21638016, 'global/episodes_done': 5502, 'global/unclipped_grad_norm': 0.7085307484323328, 'global/model_version': 33806, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:26,413] calculate_sps 30720 steps in 10.0048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:26,414] calculate_sps 32000 steps in 10.0048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:26,414] {'local/mean_episode_return': 34622.22222222222, 'local/mean_episode_step': 3697.777777777778, 'local/SPS': 3070.514927248617, 'local/env_act_steps': 21677696, 'local/env_train_steps': 21672960, 'local/optimizer_steps': 33864, 'local/running_reward': 16067.764423076924, 'local/running_step': 1812.7489182692307, 'local/steps_done': 21677696, 'local/episodes_done': 5513, 'local/unclipped_grad_norm': 0.7285296029100815, 'local/model_version': 33864, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:26,425] {'global/mean_episode_return': 33381.818181818184, 'global/mean_episode_step': 3612.909090909091, 'global/SPS': 3198.4530492173094, 'global/env_act_steps': 21671168, 'global/env_train_steps': 21667840, 'global/optimizer_steps': 33856, 'global/running_reward': 16103.954512548262, 'global/running_step': 1816.4839527027027, 'global/steps_done': 21671168, 'global/episodes_done': 5513, 'global/unclipped_grad_norm': 0.6914897203445435, 'global/model_version': 33856, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:36,421] calculate_sps 35840 steps in 10.0081
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:36,421] calculate_sps 33280 steps in 10.0081
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:36,422] {'local/mean_episode_return': 27666.666666666668, 'local/mean_episode_step': 3198.3333333333335, 'local/SPS': 3581.1142273004407, 'local/env_act_steps': 21709824, 'local/env_train_steps': 21708800, 'local/optimizer_steps': 33919, 'local/running_reward': 16519.581050796813, 'local/running_step': 1859.3015438247012, 'local/steps_done': 21709824, 'local/episodes_done': 5519, 'local/unclipped_grad_norm': 0.785988356850364, 'local/model_version': 33919, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:36,422] {'global/mean_episode_return': 32400.0, 'global/mean_episode_step': 3608.25, 'global/SPS': 3325.3203539218375, 'global/env_act_steps': 21704192, 'global/env_train_steps': 21701120, 'global/optimizer_steps': 33907, 'global/running_reward': 16397.283793604653, 'global/running_step': 1847.262203246124, 'global/steps_done': 21704192, 'global/episodes_done': 5517, 'global/unclipped_grad_norm': 0.8170008267842087, 'global/model_version': 33907, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:46,433] calculate_sps 30720 steps in 10.0115
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:46,433] calculate_sps 33280 steps in 10.0115
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:46,434] {'local/mean_episode_return': 32633.333333333332, 'local/mean_episode_step': 3515.5, 'local/SPS': 3068.474948003421, 'local/env_act_steps': 21743104, 'local/env_train_steps': 21739520, 'local/optimizer_steps': 33968, 'local/running_reward': 17199.405048076922, 'local/running_step': 1918.1716947115385, 'local/steps_done': 21743104, 'local/episodes_done': 5525, 'local/unclipped_grad_norm': 0.7320461169797547, 'local/model_version': 33968, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:46,435] {'global/mean_episode_return': 25000.0, 'global/mean_episode_step': 2937.4, 'global/SPS': 3324.1811936703725, 'global/env_act_steps': 21737344, 'global/env_train_steps': 21734400, 'global/optimizer_steps': 33960, 'global/running_reward': 17095.433156370655, 'global/running_step': 1909.3389840733591, 'global/steps_done': 21737344, 'global/episodes_done': 5522, 'global/unclipped_grad_norm': 0.7203813701305749, 'global/model_version': 33960, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:56,434] calculate_sps 32000 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:06:56,434] calculate_sps 32000 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:56,434] {'local/mean_episode_return': 35860.0, 'local/mean_episode_step': 3832.7, 'local/SPS': 3199.597447497119, 'local/env_act_steps': 21775616, 'local/env_train_steps': 21771520, 'local/optimizer_steps': 34017, 'local/running_reward': 17181.794414370077, 'local/running_step': 1914.3064714566929, 'local/steps_done': 21775616, 'local/episodes_done': 5535, 'local/unclipped_grad_norm': 0.6818082460335323, 'local/model_version': 34017, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:06:56,435] {'global/mean_episode_return': 35830.769230769234, 'global/mean_episode_step': 3806.923076923077, 'global/SPS': 3199.597447497119, 'global/env_act_steps': 21770496, 'global/env_train_steps': 21766400, 'global/optimizer_steps': 34009, 'global/running_reward': 17244.030526061775, 'global/running_step': 1920.523980453668, 'global/steps_done': 21770496, 'global/episodes_done': 5535, 'global/unclipped_grad_norm': 0.719214525149793, 'global/model_version': 34009, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:06,436] calculate_sps 34560 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:06,436] calculate_sps 34560 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:06,436] {'local/mean_episode_return': 33560.0, 'local/mean_episode_step': 3665.9, 'local/SPS': 3455.5546991074402, 'local/env_act_steps': 21807616, 'local/env_train_steps': 21806080, 'local/optimizer_steps': 34072, 'local/running_reward': 17115.815625, 'local/running_step': 1905.5210625, 'local/steps_done': 21807616, 'local/episodes_done': 5545, 'local/unclipped_grad_norm': 0.7167468667030334, 'local/model_version': 34072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:06,447] {'global/mean_episode_return': 33560.0, 'global/mean_episode_step': 3665.9, 'global/SPS': 3455.5546991074402, 'global/env_act_steps': 21803008, 'global/env_train_steps': 21800960, 'global/optimizer_steps': 34064, 'global/running_reward': 17130.00430610236, 'global/running_step': 1907.843811515748, 'global/steps_done': 21803008, 'global/episodes_done': 5545, 'global/unclipped_grad_norm': 0.6651169029149142, 'global/model_version': 34064, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:16,448] calculate_sps 30720 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:16,448] calculate_sps 30720 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:16,448] {'local/mean_episode_return': 34875.0, 'local/mean_episode_step': 3751.375, 'local/SPS': 3068.3631485565343, 'local/env_act_steps': 21841024, 'local/env_train_steps': 21836800, 'local/optimizer_steps': 34120, 'local/running_reward': 17222.3748802682, 'local/running_step': 1910.1910021551723, 'local/steps_done': 21841024, 'local/episodes_done': 5553, 'local/unclipped_grad_norm': 0.7529599585880836, 'local/model_version': 34120, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:16,450] {'global/mean_episode_return': 33833.333333333336, 'global/mean_episode_step': 3705.3333333333335, 'global/SPS': 3068.3631485565343, 'global/env_act_steps': 21836416, 'global/env_train_steps': 21831680, 'global/optimizer_steps': 34112, 'global/running_reward': 17182.641882183907, 'global/running_step': 1906.682471264368, 'global/steps_done': 21836416, 'global/episodes_done': 5551, 'global/unclipped_grad_norm': 0.773705147827665, 'global/model_version': 34112, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:26,459] calculate_sps 33280 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:26,459] calculate_sps 35840 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:26,459] {'local/mean_episode_return': 30200.0, 'local/mean_episode_step': 3514.6666666666665, 'local/SPS': 3324.118101388833, 'local/env_act_steps': 21873152, 'local/env_train_steps': 21870080, 'local/optimizer_steps': 34171, 'local/running_reward': 17493.64106075697, 'local/running_step': 1933.3464890438247, 'local/steps_done': 21873152, 'local/episodes_done': 5557, 'local/unclipped_grad_norm': 0.780477047550912, 'local/model_version': 34171, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:26,460] {'global/mean_episode_return': 33320.0, 'global/mean_episode_step': 3664.6, 'global/SPS': 3579.8194938033585, 'global/env_act_steps': 21868544, 'global/env_train_steps': 21867520, 'global/optimizer_steps': 34167, 'global/running_reward': 17404.821339641436, 'global/running_step': 1925.1475659860557, 'global/steps_done': 21868544, 'global/episodes_done': 5557, 'global/unclipped_grad_norm': 0.7777055149728601, 'global/model_version': 34167, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:36,463] calculate_sps 33280 steps in 10.0037
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:36,463] calculate_sps 30720 steps in 10.0037
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:36,474] {'local/mean_episode_return': 30145.454545454544, 'local/mean_episode_step': 3445.909090909091, 'local/SPS': 3326.7598129168805, 'local/env_act_steps': 21905792, 'local/env_train_steps': 21903360, 'local/optimizer_steps': 34224, 'local/running_reward': 17835.18995098039, 'local/running_step': 1959.4582107843137, 'local/steps_done': 21905792, 'local/episodes_done': 5568, 'local/unclipped_grad_norm': 0.6971655032544766, 'local/model_version': 34224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:36,475] {'global/mean_episode_return': 30933.333333333332, 'global/mean_episode_step': 3503.8888888888887, 'global/SPS': 3070.855211923274, 'global/env_act_steps': 21902336, 'global/env_train_steps': 21898240, 'global/optimizer_steps': 34216, 'global/running_reward': 17830.563446969696, 'global/running_step': 1960.1310961174242, 'global/steps_done': 21902336, 'global/episodes_done': 5566, 'global/unclipped_grad_norm': 0.714148286045814, 'global/model_version': 34216, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:46,477] calculate_sps 30720 steps in 10.0138
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:46,477] calculate_sps 34560 steps in 10.0138
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:46,477] {'local/mean_episode_return': 38540.0, 'local/mean_episode_step': 4077.4, 'local/SPS': 3067.779877582151, 'local/env_act_steps': 21938816, 'local/env_train_steps': 21934080, 'local/optimizer_steps': 34272, 'local/running_reward': 17980.68374515504, 'local/running_step': 1968.7499697189924, 'local/steps_done': 21938816, 'local/episodes_done': 5578, 'local/unclipped_grad_norm': 0.8219188321381807, 'local/model_version': 34272, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:46,479] {'global/mean_episode_return': 33044.444444444445, 'global/mean_episode_step': 3642.6666666666665, 'global/SPS': 3451.25236227992, 'global/env_act_steps': 21934848, 'global/env_train_steps': 21932800, 'global/optimizer_steps': 34269, 'global/running_reward': 17988.468873031496, 'global/running_step': 1969.7291461614172, 'global/steps_done': 21934848, 'global/episodes_done': 5575, 'global/unclipped_grad_norm': 0.7692251582190676, 'global/model_version': 34269, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:56,502] calculate_sps 35840 steps in 10.0262
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:07:56,503] calculate_sps 32000 steps in 10.0262
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:56,503] {'local/mean_episode_return': 42633.333333333336, 'local/mean_episode_step': 4290.5, 'local/SPS': 3574.6384328836994, 'local/env_act_steps': 21970944, 'local/env_train_steps': 21969920, 'local/optimizer_steps': 34327, 'local/running_reward': 17718.81536354582, 'local/running_step': 1947.847983067729, 'local/steps_done': 21970944, 'local/episodes_done': 5584, 'local/unclipped_grad_norm': 0.6945938392118974, 'local/model_version': 34327, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:07:56,504] {'global/mean_episode_return': 43725.0, 'global/mean_episode_step': 4420.125, 'global/SPS': 3191.6414579318744, 'global/env_act_steps': 21968512, 'global/env_train_steps': 21964800, 'global/optimizer_steps': 34320, 'global/running_reward': 17727.572480988594, 'global/running_step': 1947.5679657794676, 'global/steps_done': 21968512, 'global/episodes_done': 5583, 'global/unclipped_grad_norm': 0.72614198105008, 'global/model_version': 34320, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:06,519] calculate_sps 30720 steps in 10.0166
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:06,520] calculate_sps 33280 steps in 10.0166
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:06,520] {'local/mean_episode_return': 37566.666666666664, 'local/mean_episode_step': 4089.0, 'local/SPS': 3066.9183077422817, 'local/env_act_steps': 22003968, 'local/env_train_steps': 22000640, 'local/optimizer_steps': 34376, 'local/running_reward': 18029.62390988372, 'local/running_step': 1985.484859496124, 'local/steps_done': 22003968, 'local/episodes_done': 5590, 'local/unclipped_grad_norm': 0.7650443093509091, 'local/model_version': 34376, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:06,531] {'global/mean_episode_return': 40533.333333333336, 'global/mean_episode_step': 4313.666666666667, 'global/SPS': 3322.4948333874718, 'global/env_act_steps': 22001152, 'global/env_train_steps': 21998080, 'global/optimizer_steps': 34371, 'global/running_reward': 18006.436887254902, 'global/running_step': 1983.5681066176471, 'global/steps_done': 22001152, 'global/episodes_done': 5589, 'global/unclipped_grad_norm': 0.7711401470735961, 'global/model_version': 34371, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:16,526] calculate_sps 32640 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:16,526] calculate_sps 33280 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:16,526] {'local/mean_episode_return': 31366.666666666668, 'local/mean_episode_step': 3455.6666666666665, 'local/SPS': 3261.806178276797, 'local/env_act_steps': 22036864, 'local/env_train_steps': 22033280, 'local/optimizer_steps': 34426, 'local/running_reward': 18310.770306420232, 'local/running_step': 2005.2726775291828, 'local/steps_done': 22036864, 'local/episodes_done': 5596, 'local/unclipped_grad_norm': 0.7811623799800873, 'local/model_version': 34426, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:16,527] {'global/mean_episode_return': 31085.714285714286, 'global/mean_episode_step': 3446.8571428571427, 'global/SPS': 3325.763162164577, 'global/env_act_steps': 22034304, 'global/env_train_steps': 22031360, 'global/optimizer_steps': 34424, 'global/running_reward': 18276.206563706564, 'global/running_step': 2002.1460545366795, 'global/steps_done': 22034304, 'global/episodes_done': 5596, 'global/unclipped_grad_norm': 0.7555750746209666, 'global/model_version': 34424, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:26,545] calculate_sps 33920 steps in 10.0191
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:26,546] calculate_sps 33280 steps in 10.0191
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:26,554] {'local/mean_episode_return': 30550.0, 'local/mean_episode_step': 3355.5, 'local/SPS': 3385.520273899369, 'local/env_act_steps': 22070144, 'local/env_train_steps': 22067200, 'local/optimizer_steps': 34480, 'local/running_reward': 18894.561298076922, 'local/running_step': 2060.815625, 'local/steps_done': 22070144, 'local/episodes_done': 5600, 'local/unclipped_grad_norm': 0.8280676691620438, 'local/model_version': 34480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:26,556] {'global/mean_episode_return': 30550.0, 'global/mean_episode_step': 3355.5, 'global/SPS': 3321.6425328823993, 'global/env_act_steps': 22067712, 'global/env_train_steps': 22064640, 'global/optimizer_steps': 34475, 'global/running_reward': 18834.72820881226, 'global/running_step': 2055.110003591954, 'global/steps_done': 22067712, 'global/episodes_done': 5600, 'global/unclipped_grad_norm': 0.8627688569181106, 'global/model_version': 34475, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:36,558] calculate_sps 31360 steps in 10.0109
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:36,558] calculate_sps 33280 steps in 10.0109
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:36,565] {'local/mean_episode_return': 37433.333333333336, 'local/mean_episode_step': 3971.6666666666665, 'local/SPS': 3132.586594459377, 'local/env_act_steps': 22103296, 'local/env_train_steps': 22098560, 'local/optimizer_steps': 34528, 'local/running_reward': 19384.046211389963, 'local/running_step': 2106.425464527027, 'local/steps_done': 22103296, 'local/episodes_done': 5606, 'local/unclipped_grad_norm': 0.7591270540530483, 'local/model_version': 34528, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:36,566] {'global/mean_episode_return': 37433.333333333336, 'global/mean_episode_step': 3971.6666666666665, 'global/SPS': 3324.3776104466856, 'global/env_act_steps': 22100736, 'global/env_train_steps': 22097920, 'global/optimizer_steps': 34528, 'global/running_reward': 19352.58296996124, 'global/running_step': 2103.538214631783, 'global/steps_done': 22100736, 'global/episodes_done': 5606, 'global/unclipped_grad_norm': 0.746991198861374, 'global/model_version': 34528, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:46,577] calculate_sps 35200 steps in 10.0207
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:46,577] calculate_sps 32640 steps in 10.0207
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:46,577] {'local/mean_episode_return': 36290.90909090909, 'local/mean_episode_step': 3960.818181818182, 'local/SPS': 3512.733841226939, 'local/env_act_steps': 22135680, 'local/env_train_steps': 22133760, 'local/optimizer_steps': 34584, 'local/running_reward': 19576.92996541502, 'local/running_step': 2117.786221590909, 'local/steps_done': 22135680, 'local/episodes_done': 5617, 'local/unclipped_grad_norm': 0.7978216651827097, 'local/model_version': 34584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:46,579] {'global/mean_episode_return': 36290.90909090909, 'global/mean_episode_step': 3960.818181818182, 'global/SPS': 3257.262289137707, 'global/env_act_steps': 22134144, 'global/env_train_steps': 22130560, 'global/optimizer_steps': 34578, 'global/running_reward': 19594.615062260535, 'global/running_step': 2120.2730783045977, 'global/steps_done': 22134144, 'global/episodes_done': 5617, 'global/unclipped_grad_norm': 0.8225154015421867, 'global/model_version': 34578, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:56,581] calculate_sps 30720 steps in 10.0041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:08:56,582] calculate_sps 33920 steps in 10.0041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:56,582] {'local/mean_episode_return': 27200.0, 'local/mean_episode_step': 3121.5, 'local/SPS': 3070.7416289539706, 'local/env_act_steps': 22168832, 'local/env_train_steps': 22164480, 'local/optimizer_steps': 34632, 'local/running_reward': 19844.965612934364, 'local/running_step': 2137.929385859073, 'local/steps_done': 22168832, 'local/episodes_done': 5621, 'local/unclipped_grad_norm': 0.754773523658514, 'local/model_version': 34632, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:08:56,583] {'global/mean_episode_return': 28800.0, 'global/mean_episode_step': 3270.0, 'global/SPS': 3390.6105486366755, 'global/env_act_steps': 22166912, 'global/env_train_steps': 22164480, 'global/optimizer_steps': 34632, 'global/running_reward': 19803.497314453125, 'global/running_step': 2134.1099853515625, 'global/steps_done': 22166912, 'global/episodes_done': 5620, 'global/unclipped_grad_norm': 0.7366920797913162, 'global/model_version': 34632, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:06,591] calculate_sps 34560 steps in 10.0105
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:06,591] calculate_sps 31360 steps in 10.0105
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:06,591] {'local/mean_episode_return': 33583.333333333336, 'local/mean_episode_step': 3618.8333333333335, 'local/SPS': 3452.374528682462, 'local/env_act_steps': 22201088, 'local/env_train_steps': 22199040, 'local/optimizer_steps': 34685, 'local/running_reward': 20159.300595238095, 'local/running_step': 2162.620535714286, 'local/steps_done': 22201088, 'local/episodes_done': 5633, 'local/unclipped_grad_norm': 0.6520821401533091, 'local/model_version': 34685, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:06,592] {'global/mean_episode_return': 32723.076923076922, 'global/mean_episode_step': 3546.3076923076924, 'global/SPS': 3132.7102204711227, 'global/env_act_steps': 22200448, 'global/env_train_steps': 22195840, 'global/optimizer_steps': 34680, 'global/running_reward': 20171.084804389313, 'global/running_step': 2164.093928912214, 'global/steps_done': 22200448, 'global/episodes_done': 5633, 'global/unclipped_grad_norm': 0.6291650993128618, 'global/model_version': 34680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:16,611] calculate_sps 32000 steps in 10.0196
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:16,611] calculate_sps 35200 steps in 10.0196
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:16,612] {'local/mean_episode_return': 37916.666666666664, 'local/mean_episode_step': 3995.75, 'local/SPS': 3193.7365725220216, 'local/env_act_steps': 22234112, 'local/env_train_steps': 22231040, 'local/optimizer_steps': 34736, 'local/running_reward': 19740.69464631783, 'local/running_step': 2115.216660610465, 'local/steps_done': 22234112, 'local/episodes_done': 5645, 'local/unclipped_grad_norm': 0.7924785429940504, 'local/model_version': 34736, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:16,613] {'global/mean_episode_return': 38780.0, 'global/mean_episode_step': 4086.1, 'global/SPS': 3513.1102297742236, 'global/env_act_steps': 22232832, 'global/env_train_steps': 22231040, 'global/optimizer_steps': 34736, 'global/running_reward': 19743.972332015812, 'global/running_step': 2115.635715167984, 'global/steps_done': 22232832, 'global/episodes_done': 5643, 'global/unclipped_grad_norm': 0.7995863277465105, 'global/model_version': 34736, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:26,618] calculate_sps 30720 steps in 10.0074
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:26,619] calculate_sps 30720 steps in 10.0074
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:26,619] {'local/mean_episode_return': 37433.333333333336, 'local/mean_episode_step': 3988.4444444444443, 'local/SPS': 3069.7294138589964, 'local/env_act_steps': 22266880, 'local/env_train_steps': 22261760, 'local/optimizer_steps': 34784, 'local/running_reward': 19348.98681640625, 'local/running_step': 2069.626434326172, 'local/steps_done': 22266880, 'local/episodes_done': 5654, 'local/unclipped_grad_norm': 0.7569617331027985, 'local/model_version': 34784, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:26,620] {'global/mean_episode_return': 36736.36363636364, 'global/mean_episode_step': 3907.6363636363635, 'global/SPS': 3069.7294138589964, 'global/env_act_steps': 22266240, 'global/env_train_steps': 22261760, 'global/optimizer_steps': 34784, 'global/running_reward': 19366.31046455939, 'global/running_step': 2071.6615481321837, 'global/steps_done': 22266240, 'global/episodes_done': 5654, 'global/unclipped_grad_norm': 0.7569617331027985, 'global/model_version': 34784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:36,626] calculate_sps 35840 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:36,626] calculate_sps 35200 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:36,638] {'local/mean_episode_return': 41485.71428571428, 'local/mean_episode_step': 4347.428571428572, 'local/SPS': 3582.13501638525, 'local/env_act_steps': 22298752, 'local/env_train_steps': 22297600, 'local/optimizer_steps': 34839, 'local/running_reward': 19367.5891064257, 'local/running_step': 2065.1810366465866, 'local/steps_done': 22298752, 'local/episodes_done': 5661, 'local/unclipped_grad_norm': 0.6584077734838832, 'local/model_version': 34839, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:36,642] {'global/mean_episode_return': 41485.71428571428, 'global/mean_episode_step': 4347.428571428572, 'global/SPS': 3518.1683196640847, 'global/env_act_steps': 22298496, 'global/env_train_steps': 22296960, 'global/optimizer_steps': 34838, 'global/running_reward': 19359.021577380954, 'global/running_step': 2064.2765066964284, 'global/steps_done': 22298496, 'global/episodes_done': 5661, 'global/unclipped_grad_norm': 0.6517512365071861, 'global/model_version': 34838, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:46,638] calculate_sps 30720 steps in 10.0132
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:46,638] calculate_sps 31360 steps in 10.0132
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:46,638] {'local/mean_episode_return': 34166.666666666664, 'local/mean_episode_step': 3750.6666666666665, 'local/SPS': 3067.937143120417, 'local/env_act_steps': 22332160, 'local/env_train_steps': 22328320, 'local/optimizer_steps': 34888, 'local/running_reward': 19666.666666666668, 'local/running_step': 2094.713272270115, 'local/steps_done': 22332160, 'local/episodes_done': 5667, 'local/unclipped_grad_norm': 0.6574191977174915, 'local/model_version': 34888, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:46,640] {'global/mean_episode_return': 34166.666666666664, 'global/mean_episode_step': 3750.6666666666665, 'global/SPS': 3131.852500268759, 'global/env_act_steps': 22332160, 'global/env_train_steps': 22328320, 'global/optimizer_steps': 34888, 'global/running_reward': 19664.769486692014, 'global/running_step': 2094.520704610266, 'global/steps_done': 22332160, 'global/episodes_done': 5667, 'global/unclipped_grad_norm': 0.6646280291676522, 'global/model_version': 34888, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:56,657] calculate_sps 33920 steps in 10.0201
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:09:56,657] calculate_sps 25600 steps in 10.0201
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:56,657] {'local/mean_episode_return': 45420.0, 'local/mean_episode_step': 4460.7, 'local/SPS': 3385.2007915905483, 'local/env_act_steps': 22364800, 'local/env_train_steps': 22362240, 'local/optimizer_steps': 34940, 'local/running_reward': 20293.382352941175, 'local/running_step': 2160.8322610294117, 'local/steps_done': 22364800, 'local/episodes_done': 5673, 'local/unclipped_grad_norm': 0.5934352141160232, 'local/model_version': 34940, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:09:56,658] {'global/mean_episode_return': 46200.0, 'global/mean_episode_step': 4455.0, 'global/SPS': 2554.8685219551307, 'global/env_act_steps': 22359040, 'global/env_train_steps': 22353920, 'global/optimizer_steps': 34928, 'global/running_reward': 20311.331845238095, 'global/running_step': 2161.5560267857145, 'global/steps_done': 22359040, 'global/episodes_done': 5669, 'global/unclipped_grad_norm': 0.5768762260675431, 'global/model_version': 34928, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:06,658] calculate_sps 32640 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:06,658] calculate_sps 35840 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:06,658] {'local/mean_episode_return': 40525.0, 'local/mean_episode_step': 4241.125, 'local/SPS': 3263.727886762142, 'local/env_act_steps': 22397568, 'local/env_train_steps': 22394880, 'local/optimizer_steps': 34992, 'local/running_reward': 19876.715087890625, 'local/running_step': 2126.03369140625, 'local/steps_done': 22397568, 'local/episodes_done': 5681, 'local/unclipped_grad_norm': 0.7038987046824052, 'local/model_version': 34992, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:06,660] {'global/mean_episode_return': 42370.0, 'global/mean_episode_step': 4378.95, 'global/SPS': 3583.701208993725, 'global/env_act_steps': 22391168, 'global/env_train_steps': 22389760, 'global/optimizer_steps': 34984, 'global/running_reward': 19939.18077689243, 'global/running_step': 2131.2790400896415, 'global/steps_done': 22391168, 'global/episodes_done': 5680, 'global/unclipped_grad_norm': 0.6994061020335981, 'global/model_version': 34984, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:16,681] calculate_sps 30720 steps in 10.0233
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:16,681] calculate_sps 30720 steps in 10.0233
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:16,690] {'local/mean_episode_return': 30725.0, 'local/mean_episode_step': 3521.875, 'local/SPS': 3064.867429024052, 'local/env_act_steps': 22430848, 'local/env_train_steps': 22425600, 'local/optimizer_steps': 35040, 'local/running_reward': 19814.69951923077, 'local/running_step': 2120.386748798077, 'local/steps_done': 22430848, 'local/episodes_done': 5689, 'local/unclipped_grad_norm': 0.7776656597852707, 'local/model_version': 35040, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:16,692] {'global/mean_episode_return': 31025.0, 'global/mean_episode_step': 3499.875, 'global/SPS': 3064.867429024052, 'global/env_act_steps': 22424704, 'global/env_train_steps': 22420480, 'global/optimizer_steps': 35032, 'global/running_reward': 19785.8241889313, 'global/running_step': 2117.986104484733, 'global/steps_done': 22424704, 'global/episodes_done': 5688, 'global/unclipped_grad_norm': 0.7709170840680599, 'global/model_version': 35032, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:26,686] calculate_sps 35840 steps in 10.0051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:26,687] calculate_sps 34560 steps in 10.0051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:26,687] {'local/mean_episode_return': 35966.666666666664, 'local/mean_episode_step': 3882.9444444444443, 'local/SPS': 3582.1683072165283, 'local/env_act_steps': 22462592, 'local/env_train_steps': 22461440, 'local/optimizer_steps': 35096, 'local/running_reward': 20180.40259576613, 'local/running_step': 2155.2847782258063, 'local/steps_done': 22462592, 'local/episodes_done': 5699, 'local/unclipped_grad_norm': 0.7349022288939783, 'local/model_version': 35096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:26,688] {'global/mean_episode_return': 34987.5, 'global/mean_episode_step': 3804.1875, 'global/SPS': 3454.233724815938, 'global/env_act_steps': 22457088, 'global/env_train_steps': 22455040, 'global/optimizer_steps': 35085, 'global/running_reward': 20175.9788784585, 'global/running_step': 2155.172461709486, 'global/steps_done': 22457088, 'global/episodes_done': 5697, 'global/unclipped_grad_norm': 0.7225486942619648, 'global/model_version': 35085, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:36,691] calculate_sps 30720 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:36,691] calculate_sps 32000 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:36,692] {'local/mean_episode_return': 35514.28571428572, 'local/mean_episode_step': 3803.1428571428573, 'local/SPS': 3070.499780845431, 'local/env_act_steps': 22496128, 'local/env_train_steps': 22492160, 'local/optimizer_steps': 35144, 'local/running_reward': 20137.479126908398, 'local/running_step': 2151.4553614026718, 'local/steps_done': 22496128, 'local/episodes_done': 5706, 'local/unclipped_grad_norm': 0.7476455507179102, 'local/model_version': 35144, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:36,703] {'global/mean_episode_return': 36714.28571428572, 'global/mean_episode_step': 3925.4285714285716, 'global/SPS': 3198.4372717139904, 'global/env_act_steps': 22490880, 'global/env_train_steps': 22487040, 'global/optimizer_steps': 35136, 'global/running_reward': 20117.83262310606, 'global/running_step': 2149.232658617424, 'global/steps_done': 22490880, 'global/episodes_done': 5704, 'global/unclipped_grad_norm': 0.7412306210573982, 'global/model_version': 35136, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:46,714] calculate_sps 33280 steps in 10.0236
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:46,714] calculate_sps 33920 steps in 10.0236
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:46,715] {'local/mean_episode_return': 43125.0, 'local/mean_episode_step': 4394.375, 'local/SPS': 3320.17109105405, 'local/env_act_steps': 22528512, 'local/env_train_steps': 22525440, 'local/optimizer_steps': 35195, 'local/running_reward': 20267.47776679842, 'local/running_step': 2166.06654520751, 'local/steps_done': 22528512, 'local/episodes_done': 5714, 'local/unclipped_grad_norm': 0.7313122465914371, 'local/model_version': 35195, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:46,715] {'global/mean_episode_return': 39000.0, 'global/mean_episode_step': 4073.0, 'global/SPS': 3384.020535112782, 'global/env_act_steps': 22523648, 'global/env_train_steps': 22520960, 'global/optimizer_steps': 35189, 'global/running_reward': 20270.05615234375, 'global/running_step': 2165.9518127441406, 'global/steps_done': 22523648, 'global/episodes_done': 5712, 'global/unclipped_grad_norm': 0.7545869805902805, 'global/model_version': 35189, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:56,717] calculate_sps 33280 steps in 10.0022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:10:56,717] calculate_sps 32640 steps in 10.0022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:56,717] {'local/mean_episode_return': 39640.0, 'local/mean_episode_step': 4082.8, 'local/SPS': 3327.2612968159688, 'local/env_act_steps': 22561280, 'local/env_train_steps': 22558720, 'local/optimizer_steps': 35248, 'local/running_reward': 20153.656005859375, 'local/running_step': 2160.4747924804688, 'local/steps_done': 22561280, 'local/episodes_done': 5719, 'local/unclipped_grad_norm': 0.7362313754153702, 'local/model_version': 35248, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:10:56,727] {'global/mean_episode_return': 42771.42857142857, 'global/mean_episode_step': 4335.857142857143, 'global/SPS': 3263.275502646431, 'global/env_act_steps': 22556800, 'global/env_train_steps': 22553600, 'global/optimizer_steps': 35240, 'global/running_reward': 20118.074324324323, 'global/running_step': 2156.323389237452, 'global/steps_done': 22556800, 'global/episodes_done': 5719, 'global/unclipped_grad_norm': 0.7266756304923225, 'global/model_version': 35240, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:06,736] calculate_sps 30720 steps in 10.0191
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:06,736] calculate_sps 31360 steps in 10.0191
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:06,737] {'local/mean_episode_return': 44320.0, 'local/mean_episode_step': 4481.4, 'local/SPS': 3066.1306203006757, 'local/env_act_steps': 22594048, 'local/env_train_steps': 22589440, 'local/optimizer_steps': 35296, 'local/running_reward': 20581.48193359375, 'local/running_step': 2208.4842224121094, 'local/steps_done': 22594048, 'local/episodes_done': 5724, 'local/unclipped_grad_norm': 0.6399827922383944, 'local/model_version': 35296, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:06,738] {'global/mean_episode_return': 44320.0, 'global/mean_episode_step': 4481.4, 'global/SPS': 3130.0083415569397, 'global/env_act_steps': 22589696, 'global/env_train_steps': 22584960, 'global/optimizer_steps': 35288, 'global/running_reward': 20542.637402723736, 'global/running_step': 2203.606061527237, 'global/steps_done': 22589696, 'global/episodes_done': 5724, 'global/unclipped_grad_norm': 0.6474719823648533, 'global/model_version': 35288, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:16,765] calculate_sps 35840 steps in 10.0293
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:16,765] calculate_sps 35200 steps in 10.0293
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:16,765] {'local/mean_episode_return': 43333.333333333336, 'local/mean_episode_step': 4330.333333333333, 'local/SPS': 3573.5432446122704, 'local/env_act_steps': 22626304, 'local/env_train_steps': 22625280, 'local/optimizer_steps': 35351, 'local/running_reward': 21137.667410714286, 'local/running_step': 2269.969680059524, 'local/steps_done': 22626304, 'local/episodes_done': 5727, 'local/unclipped_grad_norm': 0.6751555207100781, 'local/model_version': 35351, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:16,766] {'global/mean_episode_return': 43333.333333333336, 'global/mean_episode_step': 4330.333333333333, 'global/SPS': 3509.7299723870515, 'global/env_act_steps': 22622080, 'global/env_train_steps': 22620160, 'global/optimizer_steps': 35344, 'global/running_reward': 21037.114006916996, 'global/running_step': 2259.2781311758895, 'global/steps_done': 22622080, 'global/episodes_done': 5727, 'global/unclipped_grad_norm': 0.6861915745373283, 'global/model_version': 35344, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:26,790] calculate_sps 30720 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:26,791] calculate_sps 30720 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:26,791] {'local/mean_episode_return': 36236.36363636364, 'local/mean_episode_step': 3841.5454545454545, 'local/SPS': 3064.3788416360003, 'local/env_act_steps': 22659840, 'local/env_train_steps': 22656000, 'local/optimizer_steps': 35400, 'local/running_reward': 21461.101502862595, 'local/running_step': 2303.712279341603, 'local/steps_done': 22659840, 'local/episodes_done': 5738, 'local/unclipped_grad_norm': 0.8062235463638695, 'local/model_version': 35400, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:26,792] {'global/mean_episode_return': 36333.333333333336, 'global/mean_episode_step': 3831.777777777778, 'global/SPS': 3064.3788416360003, 'global/env_act_steps': 22655872, 'global/env_train_steps': 22650880, 'global/optimizer_steps': 35392, 'global/running_reward': 21486.38731060606, 'global/running_step': 2307.0337357954545, 'global/steps_done': 22655872, 'global/episodes_done': 5736, 'global/unclipped_grad_norm': 0.762465326115489, 'global/model_version': 35392, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:36,796] calculate_sps 33280 steps in 10.0062
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:36,796] calculate_sps 35840 steps in 10.0062
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:36,796] {'local/mean_episode_return': 40400.0, 'local/mean_episode_step': 4311.0, 'local/SPS': 3325.9340896406793, 'local/env_act_steps': 22692352, 'local/env_train_steps': 22689280, 'local/optimizer_steps': 35451, 'local/running_reward': 21373.4344242126, 'local/running_step': 2286.723825049213, 'local/steps_done': 22692352, 'local/episodes_done': 5743, 'local/unclipped_grad_norm': 0.8026368892660328, 'local/model_version': 35451, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:36,797] {'global/mean_episode_return': 39085.71428571428, 'global/mean_episode_step': 4189.428571428572, 'global/SPS': 3581.775173459193, 'global/env_act_steps': 22688256, 'global/env_train_steps': 22686720, 'global/optimizer_steps': 35448, 'global/running_reward': 21329.668972332016, 'global/running_step': 2282.6707942193675, 'global/steps_done': 22688256, 'global/episodes_done': 5743, 'global/unclipped_grad_norm': 0.8180968154753957, 'global/model_version': 35448, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:46,803] calculate_sps 33280 steps in 10.0062
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:46,803] calculate_sps 30720 steps in 10.0062
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:46,803] {'local/mean_episode_return': 45000.0, 'local/mean_episode_step': 4544.5, 'local/SPS': 3325.932187708405, 'local/env_act_steps': 22725248, 'local/env_train_steps': 22722560, 'local/optimizer_steps': 35504, 'local/running_reward': 21984.007174124512, 'local/running_step': 2348.3896522373543, 'local/steps_done': 22725248, 'local/episodes_done': 5747, 'local/unclipped_grad_norm': 0.7138750749938892, 'local/model_version': 35504, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:46,804] {'global/mean_episode_return': 45000.0, 'global/mean_episode_step': 4544.5, 'global/SPS': 3070.0912501923735, 'global/env_act_steps': 22722304, 'global/env_train_steps': 22717440, 'global/optimizer_steps': 35496, 'global/running_reward': 21931.047344924813, 'global/running_step': 2342.4852854793235, 'global/steps_done': 22722304, 'global/episodes_done': 5747, 'global/unclipped_grad_norm': 0.6929739937186241, 'global/model_version': 35496, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:56,812] calculate_sps 31360 steps in 10.0095
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:11:56,812] calculate_sps 35840 steps in 10.0095
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:56,826] {'local/mean_episode_return': 39400.0, 'local/mean_episode_step': 4259.111111111111, 'local/SPS': 3133.026753499596, 'local/env_act_steps': 22758656, 'local/env_train_steps': 22753920, 'local/optimizer_steps': 35553, 'local/running_reward': 22253.4063697318, 'local/running_step': 2376.871408045977, 'local/steps_done': 22758656, 'local/episodes_done': 5756, 'local/unclipped_grad_norm': 0.7523984927303937, 'local/model_version': 35553, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:11:56,827] {'global/mean_episode_return': 38800.0, 'global/mean_episode_step': 4284.142857142857, 'global/SPS': 3580.6020039995383, 'global/env_act_steps': 22754944, 'global/env_train_steps': 22753280, 'global/optimizer_steps': 35552, 'global/running_reward': 22220.61274509804, 'global/running_step': 2374.7066789215687, 'global/steps_done': 22754944, 'global/episodes_done': 5754, 'global/unclipped_grad_norm': 0.754220785839217, 'global/model_version': 35552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:06,838] calculate_sps 35200 steps in 10.026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:06,838] calculate_sps 30720 steps in 10.026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:06,839] {'local/mean_episode_return': 43257.142857142855, 'local/mean_episode_step': 4415.285714285715, 'local/SPS': 3510.8557792213087, 'local/env_act_steps': 22790656, 'local/env_train_steps': 22789120, 'local/optimizer_steps': 35608, 'local/running_reward': 22250.834375, 'local/running_step': 2370.30846875, 'local/steps_done': 22790656, 'local/episodes_done': 5763, 'local/unclipped_grad_norm': 0.7339574328877709, 'local/model_version': 35608, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:06,840] {'global/mean_episode_return': 41100.0, 'global/mean_episode_step': 4231.5, 'global/SPS': 3064.019589138597, 'global/env_act_steps': 22788608, 'global/env_train_steps': 22784000, 'global/optimizer_steps': 35600, 'global/running_reward': 22267.148883079848, 'global/running_step': 2371.8264020912547, 'global/steps_done': 22788608, 'global/episodes_done': 5762, 'global/unclipped_grad_norm': 0.724762755446136, 'global/model_version': 35600, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:16,870] calculate_sps 30720 steps in 10.0319
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:16,870] calculate_sps 35200 steps in 10.0319
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:16,871] {'local/mean_episode_return': 43000.0, 'local/mean_episode_step': 4402.75, 'local/SPS': 3062.2234249921494, 'local/env_act_steps': 22824064, 'local/env_train_steps': 22819840, 'local/optimizer_steps': 35656, 'local/running_reward': 22154.18163314176, 'local/running_step': 2360.918103448276, 'local/steps_done': 22824064, 'local/episodes_done': 5771, 'local/unclipped_grad_norm': 0.7228884538635612, 'local/model_version': 35656, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:16,872] {'global/mean_episode_return': 44555.555555555555, 'global/mean_episode_step': 4513.333333333333, 'global/SPS': 3508.7976744701714, 'global/env_act_steps': 22820864, 'global/env_train_steps': 22819200, 'global/optimizer_steps': 35654, 'global/running_reward': 22183.723958333332, 'global/running_step': 2363.749007936508, 'global/steps_done': 22820864, 'global/episodes_done': 5771, 'global/unclipped_grad_norm': 0.7335499914156066, 'global/model_version': 35654, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:26,874] calculate_sps 34560 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:26,874] calculate_sps 31360 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:26,890] {'local/mean_episode_return': 41440.0, 'local/mean_episode_step': 4355.8, 'local/SPS': 3455.1940112541647, 'local/env_act_steps': 22856576, 'local/env_train_steps': 22854400, 'local/optimizer_steps': 35709, 'local/running_reward': 21396.89037893701, 'local/running_step': 2284.262087844488, 'local/steps_done': 22856576, 'local/episodes_done': 5781, 'local/unclipped_grad_norm': 0.7351220379460532, 'local/model_version': 35709, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:26,892] {'global/mean_episode_return': 41440.0, 'global/mean_episode_step': 4355.8, 'global/SPS': 3135.2686398417422, 'global/env_act_steps': 22854400, 'global/env_train_steps': 22850560, 'global/optimizer_steps': 35704, 'global/running_reward': 21434.992247137405, 'global/running_step': 2288.257096851145, 'global/steps_done': 22854400, 'global/episodes_done': 5781, 'global/unclipped_grad_norm': 0.7084545075893403, 'global/model_version': 35704, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:36,883] calculate_sps 32000 steps in 10.0104
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:36,883] calculate_sps 33920 steps in 10.0104
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:36,883] {'local/mean_episode_return': 43566.666666666664, 'local/mean_episode_step': 4532.333333333333, 'local/SPS': 3196.6884585970392, 'local/env_act_steps': 22889344, 'local/env_train_steps': 22886400, 'local/optimizer_steps': 35760, 'local/running_reward': 21515.44189453125, 'local/running_step': 2299.8276977539062, 'local/steps_done': 22889344, 'local/episodes_done': 5787, 'local/unclipped_grad_norm': 0.6689905816433477, 'local/model_version': 35760, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:36,885] {'global/mean_episode_return': 45200.0, 'global/mean_episode_step': 4653.8, 'global/SPS': 3388.4897661128616, 'global/env_act_steps': 22887040, 'global/env_train_steps': 22884480, 'global/optimizer_steps': 35756, 'global/running_reward': 21490.992647058825, 'global/running_step': 2296.9091605392155, 'global/steps_done': 22887040, 'global/episodes_done': 5786, 'global/unclipped_grad_norm': 0.7117649225088266, 'global/model_version': 35756, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:46,890] calculate_sps 32000 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:46,890] calculate_sps 32640 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:46,890] {'local/mean_episode_return': 45654.545454545456, 'local/mean_episode_step': 4622.636363636364, 'local/SPS': 3197.856280206905, 'local/env_act_steps': 22922496, 'local/env_train_steps': 22918400, 'local/optimizer_steps': 35809, 'local/running_reward': 21246.546211389963, 'local/running_step': 2278.8046875, 'local/steps_done': 22922496, 'local/episodes_done': 5798, 'local/unclipped_grad_norm': 0.6734449434645322, 'local/model_version': 35809, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:46,892] {'global/mean_episode_return': 44800.0, 'global/mean_episode_step': 4564.5, 'global/SPS': 3261.813405811043, 'global/env_act_steps': 22920448, 'global/env_train_steps': 22917120, 'global/optimizer_steps': 35808, 'global/running_reward': 21303.735632183907, 'global/running_step': 2284.286129070881, 'global/steps_done': 22920448, 'global/episodes_done': 5798, 'global/unclipped_grad_norm': 0.6695745120254847, 'global/model_version': 35808, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:56,890] calculate_sps 34560 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:12:56,890] calculate_sps 32640 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:56,890] {'local/mean_episode_return': 43500.0, 'local/mean_episode_step': 4505.6, 'local/SPS': 3455.89939562888, 'local/env_act_steps': 22954880, 'local/env_train_steps': 22952960, 'local/optimizer_steps': 35864, 'local/running_reward': 21263.407855731224, 'local/running_step': 2285.181231472332, 'local/steps_done': 22954880, 'local/episodes_done': 5803, 'local/unclipped_grad_norm': 0.7570459506728432, 'local/model_version': 35864, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:12:56,892] {'global/mean_episode_return': 43500.0, 'global/mean_episode_step': 4505.6, 'global/SPS': 3263.904984760609, 'global/env_act_steps': 22953472, 'global/env_train_steps': 22949760, 'global/optimizer_steps': 35859, 'global/running_reward': 21248.837209302324, 'global/running_step': 2283.518077761628, 'global/steps_done': 22953472, 'global/episodes_done': 5803, 'global/unclipped_grad_norm': 0.7367786198270088, 'global/model_version': 35859, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:06,896] calculate_sps 30720 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:06,896] calculate_sps 33920 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:06,896] {'local/mean_episode_return': 40680.0, 'local/mean_episode_step': 4322.1, 'local/SPS': 3070.1598675510795, 'local/env_act_steps': 22987776, 'local/env_train_steps': 22983680, 'local/optimizer_steps': 35912, 'local/running_reward': 21197.11819066148, 'local/running_step': 2273.3844236381324, 'local/steps_done': 22987776, 'local/episodes_done': 5813, 'local/unclipped_grad_norm': 0.7485335391635696, 'local/model_version': 35912, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:06,898] {'global/mean_episode_return': 40222.22222222222, 'global/mean_episode_step': 4298.555555555556, 'global/SPS': 3389.96818708765, 'global/env_act_steps': 22985856, 'global/env_train_steps': 22983680, 'global/optimizer_steps': 35912, 'global/running_reward': 21202.050395256916, 'global/running_step': 2274.2569787549405, 'global/steps_done': 22985856, 'global/episodes_done': 5812, 'global/unclipped_grad_norm': 0.7700648985381396, 'global/model_version': 35912, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:16,902] calculate_sps 33280 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:16,918] calculate_sps 30720 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:16,918] {'local/mean_episode_return': 45488.88888888889, 'local/mean_episode_step': 4642.444444444444, 'local/SPS': 3326.3736528277745, 'local/env_act_steps': 23020160, 'local/env_train_steps': 23016960, 'local/optimizer_steps': 35963, 'local/running_reward': 20518.064476284584, 'local/running_step': 2205.3903162055335, 'local/steps_done': 23020160, 'local/episodes_done': 5823, 'local/unclipped_grad_norm': 0.6090972408944485, 'local/model_version': 35963, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:16,920] {'global/mean_episode_return': 44400.0, 'global/mean_episode_step': 4546.222222222223, 'global/SPS': 3070.498756456407, 'global/env_act_steps': 23019136, 'global/env_train_steps': 23014400, 'global/optimizer_steps': 35960, 'global/running_reward': 20550.91346153846, 'global/running_step': 2208.4109375, 'global/steps_done': 23019136, 'global/episodes_done': 5822, 'global/unclipped_grad_norm': 0.5944981273884574, 'global/model_version': 35960, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:26,909] calculate_sps 33280 steps in 10.0081
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:26,909] calculate_sps 35840 steps in 10.0081
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:26,918] {'local/mean_episode_return': 41600.0, 'local/mean_episode_step': 4397.714285714285, 'local/SPS': 3325.301737800972, 'local/env_act_steps': 23052800, 'local/env_train_steps': 23050240, 'local/optimizer_steps': 36016, 'local/running_reward': 20576.648284313724, 'local/running_step': 2218.047487745098, 'local/steps_done': 23052800, 'local/episodes_done': 5830, 'local/unclipped_grad_norm': 0.7627644701948706, 'local/model_version': 36016, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:26,920] {'global/mean_episode_return': 44257.142857142855, 'global/mean_episode_step': 4565.428571428572, 'global/SPS': 3581.0941791702776, 'global/env_act_steps': 23051392, 'global/env_train_steps': 23050240, 'global/optimizer_steps': 36016, 'global/running_reward': 20576.32068452381, 'global/running_step': 2217.9792906746034, 'global/steps_done': 23051392, 'global/episodes_done': 5829, 'global/unclipped_grad_norm': 0.7670458230589118, 'global/model_version': 36016, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:36,916] calculate_sps 30720 steps in 10.0075
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:36,916] calculate_sps 30720 steps in 10.0075
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:36,917] {'local/mean_episode_return': 36200.0, 'local/mean_episode_step': 3968.75, 'local/SPS': 3069.689044445338, 'local/env_act_steps': 23086080, 'local/env_train_steps': 23080960, 'local/optimizer_steps': 36064, 'local/running_reward': 20471.29206730769, 'local/running_step': 2201.7049278846152, 'local/steps_done': 23086080, 'local/episodes_done': 5838, 'local/unclipped_grad_norm': 0.7588224212328593, 'local/model_version': 36064, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:36,918] {'global/mean_episode_return': 36177.77777777778, 'global/mean_episode_step': 3997.3333333333335, 'global/SPS': 3069.689044445338, 'global/env_act_steps': 23085184, 'global/env_train_steps': 23080960, 'global/optimizer_steps': 36064, 'global/running_reward': 20472.099905303032, 'global/running_step': 2202.0465198863635, 'global/steps_done': 23085184, 'global/episodes_done': 5838, 'global/unclipped_grad_norm': 0.7588224212328593, 'global/model_version': 36064, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:46,933] calculate_sps 35840 steps in 10.0165
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:46,933] calculate_sps 35840 steps in 10.0165
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:46,934] {'local/mean_episode_return': 39571.42857142857, 'local/mean_episode_step': 4169.857142857143, 'local/SPS': 3578.091458499262, 'local/env_act_steps': 23118336, 'local/env_train_steps': 23116800, 'local/optimizer_steps': 36120, 'local/running_reward': 20578.472222222223, 'local/running_step': 2211.088882688492, 'local/steps_done': 23118336, 'local/episodes_done': 5845, 'local/unclipped_grad_norm': 0.7662630746407169, 'local/model_version': 36120, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:46,935] {'global/mean_episode_return': 39571.42857142857, 'global/mean_episode_step': 4169.857142857143, 'global/SPS': 3578.091458499262, 'global/env_act_steps': 23117824, 'global/env_train_steps': 23116800, 'global/optimizer_steps': 36119, 'global/running_reward': 20576.21323529412, 'global/running_step': 2210.8355085784315, 'global/steps_done': 23117824, 'global/episodes_done': 5845, 'global/unclipped_grad_norm': 0.7595964848995209, 'global/model_version': 36119, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:56,937] calculate_sps 30720 steps in 10.0037
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:13:56,938] calculate_sps 30720 steps in 10.0037
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:56,938] {'local/mean_episode_return': 37857.142857142855, 'local/mean_episode_step': 3967.0, 'local/SPS': 3070.875777779393, 'local/env_act_steps': 23151616, 'local/env_train_steps': 23147520, 'local/optimizer_steps': 36168, 'local/running_reward': 21197.09735576923, 'local/running_step': 2273.653094951923, 'local/steps_done': 23151616, 'local/episodes_done': 5852, 'local/unclipped_grad_norm': 0.6809392909829816, 'local/model_version': 36168, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:13:56,939] {'global/mean_episode_return': 37857.142857142855, 'global/mean_episode_step': 3967.0, 'global/SPS': 3070.875777779393, 'global/env_act_steps': 23151616, 'global/env_train_steps': 23147520, 'global/optimizer_steps': 36168, 'global/running_reward': 21190.68418560606, 'global/running_step': 2272.990204782197, 'global/steps_done': 23151616, 'global/episodes_done': 5852, 'global/unclipped_grad_norm': 0.690163499542645, 'global/model_version': 36168, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:06,938] calculate_sps 33920 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:06,938] calculate_sps 26240 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:06,939] {'local/mean_episode_return': 40785.71428571428, 'local/mean_episode_step': 4225.142857142857, 'local/SPS': 3391.905544622514, 'local/env_act_steps': 23184128, 'local/env_train_steps': 23181440, 'local/optimizer_steps': 36220, 'local/running_reward': 20725.89812992126, 'local/running_step': 2225.908987450787, 'local/steps_done': 23184128, 'local/episodes_done': 5866, 'local/unclipped_grad_norm': 0.7293571397089041, 'local/model_version': 36220, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:06,940] {'global/mean_episode_return': 41200.0, 'global/mean_episode_step': 4228.777777777777, 'global/SPS': 2623.9269307457184, 'global/env_act_steps': 23178368, 'global/env_train_steps': 23173760, 'global/optimizer_steps': 36208, 'global/running_reward': 20820.671351674642, 'global/running_step': 2235.6446994617227, 'global/steps_done': 23178368, 'global/episodes_done': 5861, 'global/unclipped_grad_norm': 0.7357464853674174, 'global/model_version': 36208, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:16,949] calculate_sps 32640 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:16,949] calculate_sps 35200 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:16,949] {'local/mean_episode_return': 40575.0, 'local/mean_episode_step': 4271.75, 'local/SPS': 3260.1257527346775, 'local/env_act_steps': 23216640, 'local/env_train_steps': 23214080, 'local/optimizer_steps': 36272, 'local/running_reward': 20070.23252952756, 'local/running_step': 2157.447219488189, 'local/steps_done': 23216640, 'local/episodes_done': 5874, 'local/unclipped_grad_norm': 0.7916592107369349, 'local/model_version': 36272, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:16,950] {'global/mean_episode_return': 40220.0, 'global/mean_episode_step': 4199.1, 'global/SPS': 3515.821890204064, 'global/env_act_steps': 23210496, 'global/env_train_steps': 23208960, 'global/optimizer_steps': 36264, 'global/running_reward': 20095.094621513945, 'global/running_step': 2160.386640936255, 'global/steps_done': 23210496, 'global/episodes_done': 5871, 'global/unclipped_grad_norm': 0.7720415624124664, 'global/model_version': 36264, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:26,968] calculate_sps 30720 steps in 10.0197
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:26,969] calculate_sps 30720 steps in 10.0197
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:26,969] {'local/mean_episode_return': 41555.555555555555, 'local/mean_episode_step': 4365.222222222223, 'local/SPS': 3065.9485165145834, 'local/env_act_steps': 23249664, 'local/env_train_steps': 23244800, 'local/optimizer_steps': 36320, 'local/running_reward': 19818.671269379844, 'local/running_step': 2129.5893289728683, 'local/steps_done': 23249664, 'local/episodes_done': 5883, 'local/unclipped_grad_norm': 0.6358588971197605, 'local/model_version': 36320, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:26,970] {'global/mean_episode_return': 41383.333333333336, 'global/mean_episode_step': 4380.25, 'global/SPS': 3065.9485165145834, 'global/env_act_steps': 23243648, 'global/env_train_steps': 23239680, 'global/optimizer_steps': 36312, 'global/running_reward': 19922.948841698842, 'global/running_step': 2140.6632179054054, 'global/steps_done': 23243648, 'global/episodes_done': 5883, 'global/unclipped_grad_norm': 0.6551083053151766, 'global/model_version': 36312, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:36,970] calculate_sps 35200 steps in 10.0018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:36,985] calculate_sps 34560 steps in 10.0018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:36,985] {'local/mean_episode_return': 30100.0, 'local/mean_episode_step': 3482.0, 'local/SPS': 3519.363304883064, 'local/env_act_steps': 23281664, 'local/env_train_steps': 23280000, 'local/optimizer_steps': 36375, 'local/running_reward': 20174.5, 'local/running_step': 2163.10084375, 'local/steps_done': 23281664, 'local/episodes_done': 5887, 'local/unclipped_grad_norm': 0.7264166403900493, 'local/model_version': 36375, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:36,987] {'global/mean_episode_return': 28700.0, 'global/mean_episode_step': 3325.0, 'global/SPS': 3455.3748811579176, 'global/env_act_steps': 23276416, 'global/env_train_steps': 23274240, 'global/optimizer_steps': 36366, 'global/running_reward': 20015.63720703125, 'global/running_step': 2147.5601196289062, 'global/steps_done': 23276416, 'global/episodes_done': 5885, 'global/unclipped_grad_norm': 0.742388877051848, 'global/model_version': 36366, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:46,992] calculate_sps 31360 steps in 10.022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:46,992] calculate_sps 32000 steps in 10.022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:46,993] {'local/mean_episode_return': 40900.0, 'local/mean_episode_step': 4382.5, 'local/SPS': 3129.1127952118973, 'local/env_act_steps': 23314944, 'local/env_train_steps': 23311360, 'local/optimizer_steps': 36424, 'local/running_reward': 20061.298076923078, 'local/running_step': 2143.1469651442308, 'local/steps_done': 23314944, 'local/episodes_done': 5899, 'local/unclipped_grad_norm': 0.7699484648753185, 'local/model_version': 36424, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:46,994] {'global/mean_episode_return': 39457.142857142855, 'global/mean_episode_step': 4265.071428571428, 'global/SPS': 3192.9722400121404, 'global/env_act_steps': 23309568, 'global/env_train_steps': 23306240, 'global/optimizer_steps': 36416, 'global/running_reward': 20184.549951737452, 'global/running_step': 2157.4251628861, 'global/steps_done': 23309568, 'global/episodes_done': 5899, 'global/unclipped_grad_norm': 0.7510603743791581, 'global/model_version': 36416, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:57,022] calculate_sps 33280 steps in 10.0298
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:14:57,022] calculate_sps 33280 steps in 10.0298
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:57,023] {'local/mean_episode_return': 39700.0, 'local/mean_episode_step': 4136.166666666667, 'local/SPS': 3318.1116522319144, 'local/env_act_steps': 23347712, 'local/env_train_steps': 23344640, 'local/optimizer_steps': 36475, 'local/running_reward': 19859.5703125, 'local/running_step': 2120.8758239746094, 'local/steps_done': 23347712, 'local/episodes_done': 5905, 'local/unclipped_grad_norm': 0.7580399831720427, 'local/model_version': 36475, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:14:57,024] {'global/mean_episode_return': 39700.0, 'global/mean_episode_step': 4136.166666666667, 'global/SPS': 3318.1116522319144, 'global/env_act_steps': 23342592, 'global/env_train_steps': 23339520, 'global/optimizer_steps': 36467, 'global/running_reward': 19815.570494186046, 'global/running_step': 2115.842023982558, 'global/steps_done': 23342592, 'global/episodes_done': 5905, 'global/unclipped_grad_norm': 0.7107934288534463, 'global/model_version': 36467, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:07,027] calculate_sps 33280 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:07,027] calculate_sps 33280 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:07,027] {'local/mean_episode_return': 40600.0, 'local/mean_episode_step': 4339.5, 'local/SPS': 3326.3555797828008, 'local/env_act_steps': 23379968, 'local/env_train_steps': 23377920, 'local/optimizer_steps': 36528, 'local/running_reward': 20328.968253968254, 'local/running_step': 2166.8330853174602, 'local/steps_done': 23379968, 'local/episodes_done': 5909, 'local/unclipped_grad_norm': 0.7890959578864979, 'local/model_version': 36528, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:07,029] {'global/mean_episode_return': 37933.333333333336, 'global/mean_episode_step': 4099.333333333333, 'global/SPS': 3326.3555797828008, 'global/env_act_steps': 23375488, 'global/env_train_steps': 23372800, 'global/optimizer_steps': 36520, 'global/running_reward': 20220.184824902724, 'global/running_step': 2156.0993129863814, 'global/steps_done': 23375488, 'global/episodes_done': 5908, 'global/unclipped_grad_norm': 0.8103561052736247, 'global/model_version': 36520, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:17,032] calculate_sps 30720 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:17,033] calculate_sps 31360 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:17,033] {'local/mean_episode_return': 45218.181818181816, 'local/mean_episode_step': 4595.0, 'local/SPS': 3070.3223522265357, 'local/env_act_steps': 23413248, 'local/env_train_steps': 23408640, 'local/optimizer_steps': 36576, 'local/running_reward': 20239.6875, 'local/running_step': 2161.8083533653844, 'local/steps_done': 23413248, 'local/episodes_done': 5920, 'local/unclipped_grad_norm': 0.667686952278018, 'local/model_version': 36576, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:17,035] {'global/mean_episode_return': 46700.0, 'global/mean_episode_step': 4731.4, 'global/SPS': 3134.287401231255, 'global/env_act_steps': 23408896, 'global/env_train_steps': 23404160, 'global/optimizer_steps': 36568, 'global/running_reward': 20332.004310344826, 'global/running_step': 2170.561182950192, 'global/steps_done': 23408896, 'global/episodes_done': 5918, 'global/unclipped_grad_norm': 0.7319998902579149, 'global/model_version': 36568, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:27,039] calculate_sps 35200 steps in 10.0066
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:27,039] calculate_sps 35200 steps in 10.0066
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:27,039] {'local/mean_episode_return': 37733.333333333336, 'local/mean_episode_step': 4033.3333333333335, 'local/SPS': 3517.6751814834897, 'local/env_act_steps': 23445376, 'local/env_train_steps': 23443840, 'local/optimizer_steps': 36630, 'local/running_reward': 20062.30702191235, 'local/running_step': 2142.960844123506, 'local/steps_done': 23445376, 'local/episodes_done': 5926, 'local/unclipped_grad_norm': 0.7565744425411578, 'local/model_version': 36630, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:27,040] {'global/mean_episode_return': 38175.0, 'global/mean_episode_step': 4061.375, 'global/SPS': 3517.6751814834897, 'global/env_act_steps': 23441536, 'global/env_train_steps': 23439360, 'global/optimizer_steps': 36624, 'global/running_reward': 20039.39338235294, 'global/running_step': 2141.086550245098, 'global/steps_done': 23441536, 'global/episodes_done': 5926, 'global/unclipped_grad_norm': 0.7507223816854613, 'global/model_version': 36624, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:37,075] calculate_sps 31360 steps in 10.0356
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:37,075] calculate_sps 30720 steps in 10.0356
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:37,075] {'local/mean_episode_return': 37633.333333333336, 'local/mean_episode_step': 4004.0, 'local/SPS': 3124.8842943442446, 'local/env_act_steps': 23478400, 'local/env_train_steps': 23475200, 'local/optimizer_steps': 36680, 'local/running_reward': 20639.20784883721, 'local/running_step': 2198.0036942829456, 'local/steps_done': 23478400, 'local/episodes_done': 5932, 'local/unclipped_grad_norm': 0.759426608979702, 'local/model_version': 36680, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:37,076] {'global/mean_episode_return': 38280.0, 'global/mean_episode_step': 4054.0, 'global/SPS': 3061.111145480076, 'global/env_act_steps': 23474816, 'global/env_train_steps': 23470080, 'global/optimizer_steps': 36672, 'global/running_reward': 20590.655048076922, 'global/running_step': 2193.6340745192306, 'global/steps_done': 23474816, 'global/episodes_done': 5931, 'global/unclipped_grad_norm': 0.7169314495598277, 'global/model_version': 36672, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:47,080] calculate_sps 32000 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:47,080] calculate_sps 35840 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:47,080] {'local/mean_episode_return': 42422.22222222222, 'local/mean_episode_step': 4468.888888888889, 'local/SPS': 3198.3448964124527, 'local/env_act_steps': 23511424, 'local/env_train_steps': 23507200, 'local/optimizer_steps': 36730, 'local/running_reward': 20617.97480620155, 'local/running_step': 2192.3454154554265, 'local/steps_done': 23511424, 'local/episodes_done': 5941, 'local/unclipped_grad_norm': 0.7826840054988861, 'local/model_version': 36730, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:47,082] {'global/mean_episode_return': 41575.0, 'global/mean_episode_step': 4443.625, 'global/SPS': 3582.1462839819474, 'global/env_act_steps': 23506944, 'global/env_train_steps': 23505920, 'global/optimizer_steps': 36727, 'global/running_reward': 20625.572709163345, 'global/running_step': 2193.4715201693225, 'global/steps_done': 23506944, 'global/episodes_done': 5939, 'global/unclipped_grad_norm': 0.7812233502214605, 'global/model_version': 36727, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 13:15:52,126] saving global stats {'mean_episode_return': 47720.0, 'mean_episode_step': 4778.2, 'SPS': None, 'env_act_steps': 23521024, 'env_train_steps': 23516160, 'optimizer_steps': 36744, 'running_reward': 20336.548295454544, 'running_step': 2161.8458096590907, 'steps_done': 23521024, 'episodes_done': 5944, 'unclipped_grad_norm': 0.7424091258469749, 'model_version': 36744, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 13:15:52,209] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint_v36758.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 13:15:52,331] saving global stats {'mean_episode_return': 47720.0, 'mean_episode_step': 4778.2, 'SPS': None, 'env_act_steps': 23521024, 'env_train_steps': 23516160, 'optimizer_steps': 36744, 'running_reward': 20336.548295454544, 'running_step': 2161.8458096590907, 'steps_done': 23521024, 'episodes_done': 5944, 'unclipped_grad_norm': 0.7424091258469749, 'model_version': 36744, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 13:15:52,499] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:57,101] calculate_sps 34560 steps in 10.0221
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:15:57,102] calculate_sps 30720 steps in 10.0221
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:57,102] {'local/mean_episode_return': 47333.333333333336, 'local/mean_episode_step': 4799.888888888889, 'local/SPS': 3448.3960731597344, 'local/env_act_steps': 23542784, 'local/env_train_steps': 23541760, 'local/optimizer_steps': 36783, 'local/running_reward': 20122.32780612245, 'local/running_step': 2142.4544642857145, 'local/steps_done': 23542784, 'local/episodes_done': 5950, 'local/unclipped_grad_norm': 0.6904512615698688, 'local/model_version': 36783, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:15:57,103] {'global/mean_episode_return': 46327.27272727273, 'global/mean_episode_step': 4693.090909090909, 'global/SPS': 3065.2409539197643, 'global/env_act_steps': 23539840, 'global/env_train_steps': 23536640, 'global/optimizer_steps': 36776, 'global/running_reward': 20210.992217898834, 'global/running_step': 2150.781645184825, 'global/steps_done': 23539840, 'global/episodes_done': 5950, 'global/unclipped_grad_norm': 0.7031779128069781, 'global/model_version': 36776, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:07,122] calculate_sps 30720 steps in 10.0201
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:07,122] calculate_sps 32640 steps in 10.0201
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:07,122] {'local/mean_episode_return': 47450.0, 'local/mean_episode_step': 4764.125, 'local/SPS': 3065.8364633973456, 'local/env_act_steps': 23576192, 'local/env_train_steps': 23572480, 'local/optimizer_steps': 36832, 'local/running_reward': 19818.055555555555, 'local/running_step': 2111.9349257662834, 'local/steps_done': 23576192, 'local/episodes_done': 5958, 'local/unclipped_grad_norm': 0.7227680157033765, 'local/model_version': 36832, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:07,124] {'global/mean_episode_return': 45885.71428571428, 'global/mean_episode_step': 4673.571428571428, 'global/SPS': 3257.45124235968, 'global/env_act_steps': 23572864, 'global/env_train_steps': 23569280, 'global/optimizer_steps': 36826, 'global/running_reward': 19821.505571705427, 'global/running_step': 2112.3218568313955, 'global/steps_done': 23572864, 'global/episodes_done': 5957, 'global/unclipped_grad_norm': 0.7197893410921097, 'global/model_version': 36826, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:17,126] calculate_sps 33920 steps in 10.0026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:17,126] calculate_sps 33920 steps in 10.0026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:17,142] {'local/mean_episode_return': 46900.0, 'local/mean_episode_step': 4774.0, 'local/SPS': 3391.1051494647436, 'local/env_act_steps': 23609088, 'local/env_train_steps': 23606400, 'local/optimizer_steps': 36884, 'local/running_reward': 20169.260700389106, 'local/running_step': 2148.222610651751, 'local/steps_done': 23609088, 'local/episodes_done': 5960, 'local/unclipped_grad_norm': 0.7489188089966774, 'local/model_version': 36884, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:17,144] {'global/mean_episode_return': 50733.333333333336, 'global/mean_episode_step': 4982.0, 'global/SPS': 3391.1051494647436, 'global/env_act_steps': 23606016, 'global/env_train_steps': 23603200, 'global/optimizer_steps': 36880, 'global/running_reward': 20089.85883204633, 'global/running_step': 2140.5070282335905, 'global/steps_done': 23606016, 'global/episodes_done': 5960, 'global/unclipped_grad_norm': 0.7378088004059262, 'global/model_version': 36880, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:27,147] calculate_sps 32640 steps in 10.0222
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:27,147] calculate_sps 32640 steps in 10.0222
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:27,147] {'local/mean_episode_return': 42040.0, 'local/mean_episode_step': 4445.4, 'local/SPS': 3256.7814795911268, 'local/env_act_steps': 23642496, 'local/env_train_steps': 23639040, 'local/optimizer_steps': 36936, 'local/running_reward': 20974.413314176247, 'local/running_step': 2225.996258381226, 'local/steps_done': 23642496, 'local/episodes_done': 5965, 'local/unclipped_grad_norm': 0.7164621103841525, 'local/model_version': 36936, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:27,159] {'global/mean_episode_return': 42040.0, 'global/mean_episode_step': 4445.4, 'global/SPS': 3256.7814795911268, 'global/env_act_steps': 23639552, 'global/env_train_steps': 23635840, 'global/optimizer_steps': 36930, 'global/running_reward': 20932.36521946565, 'global/running_step': 2221.987327051527, 'global/steps_done': 23639552, 'global/episodes_done': 5965, 'global/unclipped_grad_norm': 0.7021279969811439, 'global/model_version': 36930, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:37,150] calculate_sps 32640 steps in 10.0017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:37,150] calculate_sps 33920 steps in 10.0017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:37,150] {'local/mean_episode_return': 46700.0, 'local/mean_episode_step': 4687.0, 'local/SPS': 3263.4491286318134, 'local/env_act_steps': 23675392, 'local/env_train_steps': 23671680, 'local/optimizer_steps': 36986, 'local/running_reward': 21654.17071984436, 'local/running_step': 2290.8902906128405, 'local/steps_done': 23675392, 'local/episodes_done': 5967, 'local/unclipped_grad_norm': 0.7536678797006607, 'local/model_version': 36986, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:37,167] {'global/mean_episode_return': 46700.0, 'global/mean_episode_step': 4687.0, 'global/SPS': 3391.427525833061, 'global/env_act_steps': 23672704, 'global/env_train_steps': 23669760, 'global/optimizer_steps': 36984, 'global/running_reward': 21570.409025096524, 'global/running_step': 2282.9053149131273, 'global/steps_done': 23672704, 'global/episodes_done': 5967, 'global/unclipped_grad_norm': 0.7307852766028157, 'global/model_version': 36984, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:47,173] calculate_sps 33920 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:47,173] calculate_sps 32640 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:47,173] {'local/mean_episode_return': 36840.0, 'local/mean_episode_step': 4041.8, 'local/SPS': 3383.665282757566, 'local/env_act_steps': 23708288, 'local/env_train_steps': 23705600, 'local/optimizer_steps': 37040, 'local/running_reward': 22252.88788910506, 'local/running_step': 2344.399015077821, 'local/steps_done': 23708288, 'local/episodes_done': 5972, 'local/unclipped_grad_norm': 0.7545325620858757, 'local/model_version': 37040, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:47,184] {'global/mean_episode_return': 37200.0, 'global/mean_episode_step': 4150.75, 'global/SPS': 3255.979800389356, 'global/env_act_steps': 23705984, 'global/env_train_steps': 23702400, 'global/optimizer_steps': 37034, 'global/running_reward': 22204.915865384617, 'global/running_step': 2340.1018028846156, 'global/steps_done': 23705984, 'global/episodes_done': 5971, 'global/unclipped_grad_norm': 0.7881007465720177, 'global/model_version': 37034, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:57,187] calculate_sps 30720 steps in 10.0145
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:16:57,188] calculate_sps 33920 steps in 10.0145
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:57,188] {'local/mean_episode_return': 42680.0, 'local/mean_episode_step': 4456.2, 'local/SPS': 3067.5628148085016, 'local/env_act_steps': 23741568, 'local/env_train_steps': 23736320, 'local/optimizer_steps': 37088, 'local/running_reward': 22778.743990384617, 'local/running_step': 2393.6847355769232, 'local/steps_done': 23741568, 'local/episodes_done': 5977, 'local/unclipped_grad_norm': 0.7398578360055884, 'local/model_version': 37088, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:16:57,189] {'global/mean_episode_return': 41466.666666666664, 'global/mean_episode_step': 4314.5, 'global/SPS': 3387.1006080177203, 'global/env_act_steps': 23739008, 'global/env_train_steps': 23736320, 'global/optimizer_steps': 37088, 'global/running_reward': 22754.38468992248, 'global/running_step': 2391.2616884689924, 'global/steps_done': 23739008, 'global/episodes_done': 5977, 'global/unclipped_grad_norm': 0.7438688198173488, 'global/model_version': 37088, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:07,212] calculate_sps 35200 steps in 10.0254
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:07,213] calculate_sps 30720 steps in 10.0254
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:07,213] {'local/mean_episode_return': 41133.333333333336, 'local/mean_episode_step': 4302.444444444444, 'local/SPS': 3511.0972427638726, 'local/env_act_steps': 23773056, 'local/env_train_steps': 23771520, 'local/optimizer_steps': 37142, 'local/running_reward': 23050.71773373984, 'local/running_step': 2416.090701219512, 'local/steps_done': 23773056, 'local/episodes_done': 5986, 'local/unclipped_grad_norm': 0.8317804893961659, 'local/model_version': 37142, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:07,214] {'global/mean_episode_return': 41133.333333333336, 'global/mean_episode_step': 4302.444444444444, 'global/SPS': 3064.2303209575616, 'global/env_act_steps': 23772160, 'global/env_train_steps': 23767040, 'global/optimizer_steps': 37136, 'global/running_reward': 23057.444498069497, 'global/running_step': 2417.1464165057914, 'global/steps_done': 23772160, 'global/episodes_done': 5986, 'global/unclipped_grad_norm': 0.8462812025099993, 'global/model_version': 37136, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:17,229] calculate_sps 31360 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:17,229] calculate_sps 35840 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:17,232] {'local/mean_episode_return': 47750.0, 'local/mean_episode_step': 4818.125, 'local/SPS': 3130.8666167918022, 'local/env_act_steps': 23806336, 'local/env_train_steps': 23802880, 'local/optimizer_steps': 37192, 'local/running_reward': 22725.88341346154, 'local/running_step': 2388.5368990384613, 'local/steps_done': 23806336, 'local/episodes_done': 5994, 'local/unclipped_grad_norm': 0.8422115567326546, 'local/model_version': 37192, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:17,233] {'global/mean_episode_return': 47750.0, 'global/mean_episode_step': 4818.125, 'global/SPS': 3578.133276333488, 'global/env_act_steps': 23804032, 'global/env_train_steps': 23802880, 'global/optimizer_steps': 37191, 'global/running_reward': 22739.91591365462, 'global/running_step': 2389.7677585341366, 'global/steps_done': 23804032, 'global/episodes_done': 5994, 'global/unclipped_grad_norm': 0.8249592816287821, 'global/model_version': 37191, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:27,255] calculate_sps 32640 steps in 10.026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:27,255] calculate_sps 30720 steps in 10.026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:27,255] {'local/mean_episode_return': 44485.71428571428, 'local/mean_episode_step': 4570.0, 'local/SPS': 3255.549844729994, 'local/env_act_steps': 23839104, 'local/env_train_steps': 23835520, 'local/optimizer_steps': 37242, 'local/running_reward': 22498.40087890625, 'local/running_step': 2366.6685791015625, 'local/steps_done': 23839104, 'local/episodes_done': 6001, 'local/unclipped_grad_norm': 0.7049176368117333, 'local/model_version': 37242, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:27,256] {'global/mean_episode_return': 44485.71428571428, 'global/mean_episode_step': 4570.0, 'global/SPS': 3064.0469126870535, 'global/env_act_steps': 23837824, 'global/env_train_steps': 23833600, 'global/optimizer_steps': 37240, 'global/running_reward': 22498.780776515152, 'global/running_step': 2366.7105232007575, 'global/steps_done': 23837824, 'global/episodes_done': 6001, 'global/unclipped_grad_norm': 0.7136006850977333, 'global/model_version': 37240, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:37,273] calculate_sps 33920 steps in 10.0176
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:37,273] calculate_sps 33920 steps in 10.0176
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:37,273] {'local/mean_episode_return': 44142.857142857145, 'local/mean_episode_step': 4494.714285714285, 'local/SPS': 3386.054812561001, 'local/env_act_steps': 23871360, 'local/env_train_steps': 23869440, 'local/optimizer_steps': 37296, 'local/running_reward': 22696.26736111111, 'local/running_step': 2385.3971354166665, 'local/steps_done': 23871360, 'local/episodes_done': 6008, 'local/unclipped_grad_norm': 0.7649045365828054, 'local/model_version': 37296, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:37,283] {'global/mean_episode_return': 44142.857142857145, 'global/mean_episode_step': 4494.714285714285, 'global/SPS': 3386.054812561001, 'global/env_act_steps': 23870080, 'global/env_train_steps': 23867520, 'global/optimizer_steps': 37292, 'global/running_reward': 22694.717261904763, 'global/running_step': 2385.2742125496034, 'global/steps_done': 23870080, 'global/episodes_done': 6008, 'global/unclipped_grad_norm': 0.7532277393799561, 'global/model_version': 37292, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:47,279] calculate_sps 30720 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:47,280] calculate_sps 32640 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:47,280] {'local/mean_episode_return': 45733.333333333336, 'local/mean_episode_step': 4761.0, 'local/SPS': 3070.0689392386676, 'local/env_act_steps': 23904512, 'local/env_train_steps': 23900160, 'local/optimizer_steps': 37344, 'local/running_reward': 23056.50337837838, 'local/running_step': 2422.839285714286, 'local/steps_done': 23904512, 'local/episodes_done': 6011, 'local/unclipped_grad_norm': 0.7950857200970253, 'local/model_version': 37344, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:47,282] {'global/mean_episode_return': 45733.333333333336, 'global/mean_episode_step': 4761.0, 'global/SPS': 3261.9482479410844, 'global/env_act_steps': 23903104, 'global/env_train_steps': 23900160, 'global/optimizer_steps': 37344, 'global/running_reward': 23023.982558139534, 'global/running_step': 2419.572008236434, 'global/steps_done': 23903104, 'global/episodes_done': 6011, 'global/unclipped_grad_norm': 0.8002506041756043, 'global/model_version': 37344, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:57,292] calculate_sps 34560 steps in 10.0139
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:17:57,293] calculate_sps 32640 steps in 10.0139
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:57,293] {'local/mean_episode_return': 45600.0, 'local/mean_episode_step': 4661.714285714285, 'local/SPS': 3451.2065113419358, 'local/env_act_steps': 23936768, 'local/env_train_steps': 23934720, 'local/optimizer_steps': 37397, 'local/running_reward': 23460.15625, 'local/running_step': 2463.737847222222, 'local/steps_done': 23936768, 'local/episodes_done': 6018, 'local/unclipped_grad_norm': 0.5944883980841007, 'local/model_version': 37397, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:17:57,294] {'global/mean_episode_return': 45600.0, 'global/mean_episode_step': 4661.714285714285, 'global/SPS': 3259.4728162673837, 'global/env_act_steps': 23936384, 'global/env_train_steps': 23932800, 'global/optimizer_steps': 37394, 'global/running_reward': 23457.217548076922, 'global/running_step': 2463.4017427884614, 'global/steps_done': 23936384, 'global/episodes_done': 6018, 'global/unclipped_grad_norm': 0.5865008747577667, 'global/model_version': 37394, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:07,331] calculate_sps 32000 steps in 10.0385
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:07,332] calculate_sps 33920 steps in 10.0385
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:07,332] {'local/mean_episode_return': 47680.0, 'local/mean_episode_step': 4773.0, 'local/SPS': 3187.7151898553793, 'local/env_act_steps': 23969792, 'local/env_train_steps': 23966720, 'local/optimizer_steps': 37448, 'local/running_reward': 23590.207122093023, 'local/running_step': 2482.023558624031, 'local/steps_done': 23969792, 'local/episodes_done': 6023, 'local/unclipped_grad_norm': 0.7578513441132564, 'local/model_version': 37448, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:07,333] {'global/mean_episode_return': 47680.0, 'global/mean_episode_step': 4773.0, 'global/SPS': 3378.9781012467024, 'global/env_act_steps': 23969024, 'global/env_train_steps': 23966720, 'global/optimizer_steps': 37448, 'global/running_reward': 23590.337009803923, 'global/running_step': 2481.887132352941, 'global/steps_done': 23969024, 'global/episodes_done': 6023, 'global/unclipped_grad_norm': 0.7561714798212051, 'global/model_version': 37448, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:17,342] calculate_sps 31360 steps in 10.0103
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:17,342] calculate_sps 30720 steps in 10.0103
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:17,342] {'local/mean_episode_return': 36775.0, 'local/mean_episode_step': 4020.75, 'local/SPS': 3132.776103616705, 'local/env_act_steps': 24002816, 'local/env_train_steps': 23998080, 'local/optimizer_steps': 37497, 'local/running_reward': 23806.225775193798, 'local/running_step': 2502.430414244186, 'local/steps_done': 24002816, 'local/episodes_done': 6031, 'local/unclipped_grad_norm': 0.6107029793213825, 'local/model_version': 37497, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:17,344] {'global/mean_episode_return': 36775.0, 'global/mean_episode_step': 4020.75, 'global/SPS': 3068.8418974204455, 'global/env_act_steps': 24002432, 'global/env_train_steps': 23997440, 'global/optimizer_steps': 37496, 'global/running_reward': 23798.479406130267, 'global/running_step': 2501.8826029693487, 'global/steps_done': 24002432, 'global/episodes_done': 6031, 'global/unclipped_grad_norm': 0.6166427241017421, 'global/model_version': 37496, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:27,367] calculate_sps 35200 steps in 10.0254
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:27,367] calculate_sps 35840 steps in 10.0254
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:27,368] {'local/mean_episode_return': 43733.333333333336, 'local/mean_episode_step': 4573.166666666667, 'local/SPS': 3511.091063822096, 'local/env_act_steps': 24035328, 'local/env_train_steps': 24033280, 'local/optimizer_steps': 37552, 'local/running_reward': 23887.40157480315, 'local/running_step': 2501.2262241633857, 'local/steps_done': 24035328, 'local/episodes_done': 6037, 'local/unclipped_grad_norm': 0.793049830198288, 'local/model_version': 37552, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:27,369] {'global/mean_episode_return': 43733.333333333336, 'global/mean_episode_step': 4573.166666666667, 'global/SPS': 3574.929083164316, 'global/env_act_steps': 24034944, 'global/env_train_steps': 24033280, 'global/optimizer_steps': 37552, 'global/running_reward': 23883.72908464567, 'global/running_step': 2500.878383366142, 'global/steps_done': 24034944, 'global/episodes_done': 6037, 'global/unclipped_grad_norm': 0.7847024266208921, 'global/model_version': 37552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:37,377] calculate_sps 30720 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:37,377] calculate_sps 25600 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:37,377] {'local/mean_episode_return': 38200.0, 'local/mean_episode_step': 4120.333333333333, 'local/SPS': 3069.0127952726602, 'local/env_act_steps': 24068352, 'local/env_train_steps': 24064000, 'local/optimizer_steps': 37600, 'local/running_reward': 23912.39098837209, 'local/running_step': 2498.499878875969, 'local/steps_done': 24068352, 'local/episodes_done': 6046, 'local/unclipped_grad_norm': 0.6122552963594595, 'local/model_version': 37600, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:37,379] {'global/mean_episode_return': 37750.0, 'global/mean_episode_step': 4102.875, 'global/SPS': 2557.5106627272166, 'global/env_act_steps': 24061440, 'global/env_train_steps': 24058880, 'global/optimizer_steps': 37592, 'global/running_reward': 23910.612922705313, 'global/running_step': 2498.546837258454, 'global/steps_done': 24061440, 'global/episodes_done': 6045, 'global/unclipped_grad_norm': 0.6082331590354443, 'global/model_version': 37592, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:47,391] calculate_sps 35200 steps in 10.0141
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:47,391] calculate_sps 32000 steps in 10.0141
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:47,391] {'local/mean_episode_return': 41800.0, 'local/mean_episode_step': 4350.4, 'local/SPS': 3515.0271920318414, 'local/env_act_steps': 24100864, 'local/env_train_steps': 24099200, 'local/optimizer_steps': 37655, 'local/running_reward': 23653.125, 'local/running_step': 2471.5399544783463, 'local/steps_done': 24100864, 'local/episodes_done': 6056, 'local/unclipped_grad_norm': 0.6458305778828535, 'local/model_version': 37655, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:47,392] {'global/mean_episode_return': 41800.0, 'global/mean_episode_step': 4344.555555555556, 'global/SPS': 3195.4792654834923, 'global/env_act_steps': 24095104, 'global/env_train_steps': 24090880, 'global/optimizer_steps': 37642, 'global/running_reward': 23726.681321292777, 'global/running_step': 2478.4690767585553, 'global/steps_done': 24095104, 'global/episodes_done': 6054, 'global/unclipped_grad_norm': 0.6560174819827079, 'global/model_version': 37642, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:57,412] calculate_sps 31360 steps in 10.0211
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:18:57,412] calculate_sps 34560 steps in 10.0211
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:57,413] {'local/mean_episode_return': 40400.0, 'local/mean_episode_step': 4346.5, 'local/SPS': 3129.3840781602216, 'local/env_act_steps': 24134144, 'local/env_train_steps': 24130560, 'local/optimizer_steps': 37704, 'local/running_reward': 23545.943509615383, 'local/running_step': 2467.2649939903845, 'local/steps_done': 24134144, 'local/episodes_done': 6061, 'local/unclipped_grad_norm': 0.797083665217672, 'local/model_version': 37704, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:18:57,414] {'global/mean_episode_return': 40866.666666666664, 'global/mean_episode_step': 4341.5, 'global/SPS': 3448.708984094938, 'global/env_act_steps': 24128000, 'global/env_train_steps': 24125440, 'global/optimizer_steps': 37696, 'global/running_reward': 23514.22057392996, 'global/running_step': 2463.039457684825, 'global/steps_done': 24128000, 'global/episodes_done': 6061, 'global/unclipped_grad_norm': 0.7416809819362782, 'global/model_version': 37696, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:07,417] calculate_sps 33280 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:07,417] calculate_sps 32000 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:07,418] {'local/mean_episode_return': 48200.0, 'local/mean_episode_step': 4863.888888888889, 'local/SPS': 3326.249444240757, 'local/env_act_steps': 24166912, 'local/env_train_steps': 24163840, 'local/optimizer_steps': 37755, 'local/running_reward': 23673.638916015625, 'local/running_step': 2484.6542053222656, 'local/steps_done': 24166912, 'local/episodes_done': 6070, 'local/unclipped_grad_norm': 0.6975142850595362, 'local/model_version': 37755, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:07,419] {'global/mean_episode_return': 47200.0, 'global/mean_episode_step': 4797.125, 'global/SPS': 3198.31677330842, 'global/env_act_steps': 24161536, 'global/env_train_steps': 24157440, 'global/optimizer_steps': 37745, 'global/running_reward': 23730.635734732823, 'global/running_step': 2489.813513835878, 'global/steps_done': 24161536, 'global/episodes_done': 6069, 'global/unclipped_grad_norm': 0.7106196859053203, 'global/model_version': 37745, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:17,444] calculate_sps 33280 steps in 10.0266
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:17,444] calculate_sps 34560 steps in 10.0266
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:17,445] {'local/mean_episode_return': 43920.0, 'local/mean_episode_step': 4469.1, 'local/SPS': 3319.177594325462, 'local/env_act_steps': 24199680, 'local/env_train_steps': 24197120, 'local/optimizer_steps': 37808, 'local/running_reward': 23105.35888671875, 'local/running_step': 2430.464385986328, 'local/steps_done': 24199680, 'local/episodes_done': 6080, 'local/unclipped_grad_norm': 0.7954282310773741, 'local/model_version': 37808, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:17,446] {'global/mean_episode_return': 46888.88888888889, 'global/mean_episode_step': 4715.444444444444, 'global/SPS': 3446.8382710302876, 'global/env_act_steps': 24194432, 'global/env_train_steps': 24192000, 'global/optimizer_steps': 37800, 'global/running_reward': 23157.502431906614, 'global/running_step': 2435.330921692607, 'global/steps_done': 24194432, 'global/episodes_done': 6078, 'global/unclipped_grad_norm': 0.7590474768118425, 'global/model_version': 37800, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:27,501] calculate_sps 31360 steps in 10.0577
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:27,501] calculate_sps 30720 steps in 10.0577
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:27,502] {'local/mean_episode_return': 51142.857142857145, 'local/mean_episode_step': 5086.571428571428, 'local/SPS': 3117.997878071133, 'local/env_act_steps': 24233088, 'local/env_train_steps': 24228480, 'local/optimizer_steps': 37856, 'local/running_reward': 22851.556513409963, 'local/running_step': 2407.6252095306513, 'local/steps_done': 24233088, 'local/episodes_done': 6087, 'local/unclipped_grad_norm': 0.6435720461110274, 'local/model_version': 37856, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:27,503] {'global/mean_episode_return': 48400.0, 'global/mean_episode_step': 4840.428571428572, 'global/SPS': 3054.365268314579, 'global/env_act_steps': 24227968, 'global/env_train_steps': 24222720, 'global/optimizer_steps': 37848, 'global/running_reward': 22862.792223282442, 'global/running_step': 2408.387195849237, 'global/steps_done': 24227968, 'global/episodes_done': 6085, 'global/unclipped_grad_norm': 0.6887157255162796, 'global/model_version': 37848, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:37,537] calculate_sps 34560 steps in 10.0359
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:37,537] calculate_sps 35840 steps in 10.0359
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:37,538] {'local/mean_episode_return': 47885.71428571428, 'local/mean_episode_step': 4882.857142857143, 'local/SPS': 3443.625276267175, 'local/env_act_steps': 24264576, 'local/env_train_steps': 24263040, 'local/optimizer_steps': 37910, 'local/running_reward': 22736.97281504065, 'local/running_step': 2398.7740409044713, 'local/steps_done': 24264576, 'local/episodes_done': 6094, 'local/unclipped_grad_norm': 0.7433687738246388, 'local/model_version': 37910, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:37,539] {'global/mean_episode_return': 49628.57142857143, 'global/mean_episode_step': 5000.142857142857, 'global/SPS': 3571.1669531659595, 'global/env_act_steps': 24259584, 'global/env_train_steps': 24258560, 'global/optimizer_steps': 37903, 'global/running_reward': 22772.229251012144, 'global/running_step': 2401.7133097165993, 'global/steps_done': 24259584, 'global/episodes_done': 6092, 'global/unclipped_grad_norm': 0.7545253057371486, 'global/model_version': 37903, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:47,572] calculate_sps 31360 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:47,572] calculate_sps 30720 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:47,573] {'local/mean_episode_return': 41675.0, 'local/mean_episode_step': 4388.375, 'local/SPS': 3125.1971686767715, 'local/env_act_steps': 24297856, 'local/env_train_steps': 24294400, 'local/optimizer_steps': 37960, 'local/running_reward': 22654.140625, 'local/running_step': 2387.4754807692307, 'local/steps_done': 24297856, 'local/episodes_done': 6102, 'local/unclipped_grad_norm': 0.7426992240548134, 'local/model_version': 37960, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:47,574] {'global/mean_episode_return': 41422.22222222222, 'global/mean_episode_step': 4372.888888888889, 'global/SPS': 3061.4176346221434, 'global/env_act_steps': 24292992, 'global/env_train_steps': 24289280, 'global/optimizer_steps': 37952, 'global/running_reward': 22670.34243295019, 'global/running_step': 2389.6650203544064, 'global/steps_done': 24292992, 'global/episodes_done': 6101, 'global/unclipped_grad_norm': 0.7500328935530721, 'global/model_version': 37952, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:57,615] calculate_sps 32640 steps in 10.0432
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:19:57,615] calculate_sps 33280 steps in 10.0432
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:57,615] {'local/mean_episode_return': 42285.71428571428, 'local/mean_episode_step': 4453.47619047619, 'local/SPS': 3249.9467425156454, 'local/env_act_steps': 24330624, 'local/env_train_steps': 24327040, 'local/optimizer_steps': 38010, 'local/running_reward': 22689.697265625, 'local/running_step': 2392.323272705078, 'local/steps_done': 24330624, 'local/episodes_done': 6111, 'local/unclipped_grad_norm': 0.6841978362202644, 'local/model_version': 38010, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:19:57,616] {'global/mean_episode_return': 42080.0, 'global/mean_episode_step': 4381.666666666666, 'global/SPS': 3313.6711884473248, 'global/env_act_steps': 24325632, 'global/env_train_steps': 24322560, 'global/optimizer_steps': 38003, 'global/running_reward': 22739.05024509804, 'global/running_step': 2396.9140625, 'global/steps_done': 24325632, 'global/episodes_done': 6108, 'global/unclipped_grad_norm': 0.6822950673453948, 'global/model_version': 38003, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:07,643] calculate_sps 33920 steps in 10.0273
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:07,643] calculate_sps 33280 steps in 10.0273
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:07,643] {'local/mean_episode_return': 44257.142857142855, 'local/mean_episode_step': 4589.428571428572, 'local/SPS': 3382.7685501333044, 'local/env_act_steps': 24363136, 'local/env_train_steps': 24360960, 'local/optimizer_steps': 38064, 'local/running_reward': 22614.49311023622, 'local/running_step': 2386.2145054133857, 'local/steps_done': 24363136, 'local/episodes_done': 6118, 'local/unclipped_grad_norm': 0.7593751204786477, 'local/model_version': 38064, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:07,644] {'global/mean_episode_return': 41950.0, 'global/mean_episode_step': 4446.375, 'global/SPS': 3318.942728432676, 'global/env_act_steps': 24358784, 'global/env_train_steps': 24355840, 'global/optimizer_steps': 38056, 'global/running_reward': 22599.300193050192, 'global/running_step': 2384.8373552123553, 'global/steps_done': 24358784, 'global/episodes_done': 6116, 'global/unclipped_grad_norm': 0.7003975209762465, 'global/model_version': 38056, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:17,651] calculate_sps 30720 steps in 10.0082
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:17,651] calculate_sps 32000 steps in 10.0082
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:17,652] {'local/mean_episode_return': 52050.0, 'local/mean_episode_step': 5191.5, 'local/SPS': 3069.4690059287536, 'local/env_act_steps': 24396672, 'local/env_train_steps': 24391680, 'local/optimizer_steps': 38112, 'local/running_reward': 22337.070610687024, 'local/running_step': 2355.219227099237, 'local/steps_done': 24396672, 'local/episodes_done': 6123, 'local/unclipped_grad_norm': 0.8149739485234022, 'local/model_version': 38112, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:17,653] {'global/mean_episode_return': 51500.0, 'global/mean_episode_step': 5148.333333333333, 'global/SPS': 3197.3635478424517, 'global/env_act_steps': 24392064, 'global/env_train_steps': 24387840, 'global/optimizer_steps': 38105, 'global/running_reward': 22319.759615384617, 'global/running_step': 2353.7704927884615, 'global/steps_done': 24392064, 'global/episodes_done': 6123, 'global/unclipped_grad_norm': 0.857137818117531, 'global/model_version': 38105, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:27,651] calculate_sps 35200 steps in 10.0001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:27,651] calculate_sps 34560 steps in 10.0001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:27,651] {'local/mean_episode_return': 44533.333333333336, 'local/mean_episode_step': 4607.666666666667, 'local/SPS': 3519.9569478532253, 'local/env_act_steps': 24428416, 'local/env_train_steps': 24426880, 'local/optimizer_steps': 38166, 'local/running_reward': 22737.676411290322, 'local/running_step': 2394.3404737903224, 'local/steps_done': 24428416, 'local/episodes_done': 6129, 'local/unclipped_grad_norm': 0.7948064638508691, 'local/model_version': 38166, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:27,652] {'global/mean_episode_return': 43080.0, 'global/mean_episode_step': 4462.0, 'global/SPS': 3455.9577306195306, 'global/env_act_steps': 24424448, 'global/env_train_steps': 24422400, 'global/optimizer_steps': 38160, 'global/running_reward': 22682.065217391304, 'global/running_step': 2388.8727458003955, 'global/steps_done': 24424448, 'global/episodes_done': 6128, 'global/unclipped_grad_norm': 0.7637532142075625, 'global/model_version': 38160, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:37,686] calculate_sps 31360 steps in 10.0347
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:37,686] calculate_sps 30720 steps in 10.0347
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:37,686] {'local/mean_episode_return': 48857.142857142855, 'local/mean_episode_step': 4839.571428571428, 'local/SPS': 3125.1502409580385, 'local/env_act_steps': 24461440, 'local/env_train_steps': 24458240, 'local/optimizer_steps': 38216, 'local/running_reward': 22937.748304263565, 'local/running_step': 2415.4944585755816, 'local/steps_done': 24461440, 'local/episodes_done': 6136, 'local/unclipped_grad_norm': 0.7267310810089112, 'local/model_version': 38216, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:37,688] {'global/mean_episode_return': 49514.28571428572, 'global/mean_episode_step': 4957.0, 'global/SPS': 3061.371664611956, 'global/env_act_steps': 24457856, 'global/env_train_steps': 24453120, 'global/optimizer_steps': 38208, 'global/running_reward': 22955.872844827587, 'global/running_step': 2417.1275143678163, 'global/steps_done': 24457856, 'global/episodes_done': 6135, 'global/unclipped_grad_norm': 0.7990842980022231, 'global/model_version': 38208, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:47,716] calculate_sps 32640 steps in 10.0304
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:47,716] calculate_sps 35840 steps in 10.0304
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:47,716] {'local/mean_episode_return': 45054.545454545456, 'local/mean_episode_step': 4768.545454545455, 'local/SPS': 3254.1135341277036, 'local/env_act_steps': 24494592, 'local/env_train_steps': 24490880, 'local/optimizer_steps': 38267, 'local/running_reward': 22544.980694980695, 'local/running_step': 2374.701888272201, 'local/steps_done': 24494592, 'local/episodes_done': 6147, 'local/unclipped_grad_norm': 0.7252358621826359, 'local/model_version': 38267, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:47,717] {'global/mean_episode_return': 46581.818181818184, 'global/mean_episode_step': 4843.363636363636, 'global/SPS': 3573.1442727676745, 'global/env_act_steps': 24490496, 'global/env_train_steps': 24488960, 'global/optimizer_steps': 38264, 'global/running_reward': 22643.345588235294, 'global/running_step': 2384.710386029412, 'global/steps_done': 24490496, 'global/episodes_done': 6146, 'global/unclipped_grad_norm': 0.6797269939311913, 'global/model_version': 38264, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:57,740] calculate_sps 33920 steps in 10.0234
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:20:57,740] calculate_sps 30720 steps in 10.0234
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:57,740] {'local/mean_episode_return': 36650.0, 'local/mean_episode_step': 4030.5, 'local/SPS': 3384.0945084541477, 'local/env_act_steps': 24526976, 'local/env_train_steps': 24524800, 'local/optimizer_steps': 38320, 'local/running_reward': 22128.69318181818, 'local/running_step': 2329.9798666007905, 'local/steps_done': 24526976, 'local/episodes_done': 6155, 'local/unclipped_grad_norm': 0.6045851027065853, 'local/model_version': 38320, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:20:57,741] {'global/mean_episode_return': 33925.0, 'global/mean_episode_step': 3850.75, 'global/SPS': 3064.8403095433787, 'global/env_act_steps': 24523776, 'global/env_train_steps': 24519680, 'global/optimizer_steps': 38312, 'global/running_reward': 22107.31971153846, 'global/running_step': 2328.2892427884617, 'global/steps_done': 24523776, 'global/episodes_done': 6154, 'global/unclipped_grad_norm': 0.6471470755835375, 'global/model_version': 38312, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:07,765] calculate_sps 30720 steps in 10.0251
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:07,765] calculate_sps 33920 steps in 10.0251
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:07,765] {'local/mean_episode_return': 43325.0, 'local/mean_episode_step': 4447.125, 'local/SPS': 3064.308733417736, 'local/env_act_steps': 24560000, 'local/env_train_steps': 24555520, 'local/optimizer_steps': 38368, 'local/running_reward': 22005.595930232557, 'local/running_step': 2319.1651828972867, 'local/steps_done': 24560000, 'local/episodes_done': 6163, 'local/unclipped_grad_norm': 0.7019492179776231, 'local/model_version': 38368, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:07,767] {'global/mean_episode_return': 44175.0, 'global/mean_episode_step': 4520.25, 'global/SPS': 3383.507559815417, 'global/env_act_steps': 24556160, 'global/env_train_steps': 24553600, 'global/optimizer_steps': 38364, 'global/running_reward': 22026.414278656128, 'global/running_step': 2321.200901679842, 'global/steps_done': 24556160, 'global/episodes_done': 6162, 'global/unclipped_grad_norm': 0.6551892078266695, 'global/model_version': 38364, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:17,807] calculate_sps 34560 steps in 10.0431
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:17,808] calculate_sps 32640 steps in 10.0431
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:17,808] {'local/mean_episode_return': 46383.333333333336, 'local/mean_episode_step': 4784.166666666667, 'local/SPS': 3441.165745323985, 'local/env_act_steps': 24592128, 'local/env_train_steps': 24590080, 'local/optimizer_steps': 38421, 'local/running_reward': 21196.551294820718, 'local/running_step': 2235.9677539840636, 'local/steps_done': 24592128, 'local/episodes_done': 6175, 'local/unclipped_grad_norm': 0.8712673018563468, 'local/model_version': 38421, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:17,809] {'global/mean_episode_return': 46307.692307692305, 'global/mean_episode_step': 4765.692307692308, 'global/SPS': 3249.9898705837636, 'global/env_act_steps': 24588928, 'global/env_train_steps': 24586240, 'global/optimizer_steps': 38416, 'global/running_reward': 21316.39404296875, 'global/running_step': 2248.0975646972656, 'global/steps_done': 24588928, 'global/episodes_done': 6175, 'global/unclipped_grad_norm': 0.8354252244417484, 'global/model_version': 38416, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:27,825] calculate_sps 32000 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:27,825] calculate_sps 32000 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:27,826] {'local/mean_episode_return': 55400.0, 'local/mean_episode_step': 5282.0, 'local/SPS': 3194.4317033125735, 'local/env_act_steps': 24625536, 'local/env_train_steps': 24622080, 'local/optimizer_steps': 38472, 'local/running_reward': 21241.58285440613, 'local/running_step': 2242.280920737548, 'local/steps_done': 24625536, 'local/episodes_done': 6178, 'local/unclipped_grad_norm': 0.8381041177347595, 'local/model_version': 38472, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:27,827] {'global/mean_episode_return': 55400.0, 'global/mean_episode_step': 5282.0, 'global/SPS': 3194.4317033125735, 'global/env_act_steps': 24622336, 'global/env_train_steps': 24618240, 'global/optimizer_steps': 38465, 'global/running_reward': 21179.891044061304, 'global/running_step': 2235.595007183908, 'global/steps_done': 24622336, 'global/episodes_done': 6178, 'global/unclipped_grad_norm': 0.9181192961274361, 'global/model_version': 38465, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:37,855] calculate_sps 33280 steps in 10.0307
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:37,856] calculate_sps 34560 steps in 10.0307
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:37,856] {'local/mean_episode_return': 46033.333333333336, 'local/mean_episode_step': 4790.0, 'local/SPS': 3317.8148725661786, 'local/env_act_steps': 24658432, 'local/env_train_steps': 24655360, 'local/optimizer_steps': 38523, 'local/running_reward': 21893.33049610895, 'local/running_step': 2310.7575997081713, 'local/steps_done': 24658432, 'local/episodes_done': 6184, 'local/unclipped_grad_norm': 0.650212409157379, 'local/model_version': 38523, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:37,857] {'global/mean_episode_return': 47300.0, 'global/mean_episode_step': 4871.75, 'global/SPS': 3445.4231368956466, 'global/env_act_steps': 24655488, 'global/env_train_steps': 24652800, 'global/optimizer_steps': 38520, 'global/running_reward': 21869.35328185328, 'global/running_step': 2308.4663067084944, 'global/steps_done': 24655488, 'global/episodes_done': 6182, 'global/unclipped_grad_norm': 0.652359310334379, 'global/model_version': 38520, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:47,872] calculate_sps 33280 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:47,872] calculate_sps 31360 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:47,873] {'local/mean_episode_return': 48400.0, 'local/mean_episode_step': 4856.1, 'local/SPS': 3322.6079265180992, 'local/env_act_steps': 24691328, 'local/env_train_steps': 24688640, 'local/optimizer_steps': 38576, 'local/running_reward': 21578.14931906615, 'local/running_step': 2279.564810311284, 'local/steps_done': 24691328, 'local/episodes_done': 6194, 'local/unclipped_grad_norm': 0.7299440497497343, 'local/model_version': 38576, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:47,874] {'global/mean_episode_return': 47583.333333333336, 'global/mean_episode_step': 4817.833333333333, 'global/SPS': 3130.9190076805166, 'global/env_act_steps': 24688768, 'global/env_train_steps': 24684160, 'global/optimizer_steps': 38568, 'global/running_reward': 21634.59735576923, 'global/running_step': 2284.9640024038463, 'global/steps_done': 24688768, 'global/episodes_done': 6194, 'global/unclipped_grad_norm': 0.71487528582414, 'global/model_version': 38568, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:57,890] calculate_sps 30720 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:21:57,890] calculate_sps 35200 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:57,891] {'local/mean_episode_return': 50280.0, 'local/mean_episode_step': 5015.0, 'local/SPS': 3066.4803698424817, 'local/env_act_steps': 24724608, 'local/env_train_steps': 24719360, 'local/optimizer_steps': 38624, 'local/running_reward': 21351.634615384617, 'local/running_step': 2261.580498798077, 'local/steps_done': 24724608, 'local/episodes_done': 6199, 'local/unclipped_grad_norm': 0.7072984144712487, 'local/model_version': 38624, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:21:57,892] {'global/mean_episode_return': 50280.0, 'global/mean_episode_step': 5015.0, 'global/SPS': 3513.6754237778437, 'global/env_act_steps': 24721280, 'global/env_train_steps': 24719360, 'global/optimizer_steps': 38624, 'global/running_reward': 21330.124261811023, 'global/running_step': 2259.0853838582675, 'global/steps_done': 24721280, 'global/episodes_done': 6199, 'global/unclipped_grad_norm': 0.7096262640718903, 'global/model_version': 38624, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:07,890] calculate_sps 35840 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:07,890] calculate_sps 30720 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:07,890] {'local/mean_episode_return': 37633.333333333336, 'local/mean_episode_step': 3999.1666666666665, 'local/SPS': 3583.895071431453, 'local/env_act_steps': 24756224, 'local/env_train_steps': 24755200, 'local/optimizer_steps': 38679, 'local/running_reward': 21755.60475708502, 'local/running_step': 2303.4211791497974, 'local/steps_done': 24756224, 'local/episodes_done': 6205, 'local/unclipped_grad_norm': 0.7861891215497797, 'local/model_version': 38679, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:07,891] {'global/mean_episode_return': 40280.0, 'global/mean_episode_step': 4201.4, 'global/SPS': 3071.9100612269594, 'global/env_act_steps': 24754560, 'global/env_train_steps': 24750080, 'global/optimizer_steps': 38672, 'global/running_reward': 21716.13581730769, 'global/running_step': 2299.353936298077, 'global/steps_done': 24754560, 'global/episodes_done': 6204, 'global/unclipped_grad_norm': 0.7559537639220556, 'global/model_version': 38672, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:17,900] calculate_sps 30720 steps in 10.0094
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:17,900] calculate_sps 35840 steps in 10.0094
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:17,900] {'local/mean_episode_return': 38480.0, 'local/mean_episode_step': 4187.6, 'local/SPS': 3069.1182819323762, 'local/env_act_steps': 24789504, 'local/env_train_steps': 24785920, 'local/optimizer_steps': 38728, 'local/running_reward': 22177.35576923077, 'local/running_step': 2343.4459435096155, 'local/steps_done': 24789504, 'local/episodes_done': 6210, 'local/unclipped_grad_norm': 0.8309052516611255, 'local/model_version': 38728, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:17,902] {'global/mean_episode_return': 35240.0, 'global/mean_episode_step': 3946.8, 'global/SPS': 3580.6379955877724, 'global/env_act_steps': 24786944, 'global/env_train_steps': 24785920, 'global/optimizer_steps': 38727, 'global/running_reward': 22144.799901185772, 'global/running_step': 2340.641582262846, 'global/steps_done': 24786944, 'global/episodes_done': 6209, 'global/unclipped_grad_norm': 0.860721345110373, 'global/model_version': 38727, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:27,901] calculate_sps 32640 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:27,902] calculate_sps 30720 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:27,902] {'local/mean_episode_return': 43800.0, 'local/mean_episode_step': 4600.090909090909, 'local/SPS': 3263.9176687027575, 'local/env_act_steps': 24822272, 'local/env_train_steps': 24818560, 'local/optimizer_steps': 38778, 'local/running_reward': 21782.391357421875, 'local/running_step': 2303.2472534179688, 'local/steps_done': 24822272, 'local/episodes_done': 6221, 'local/unclipped_grad_norm': 0.7826315784454345, 'local/model_version': 38778, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:27,903] {'global/mean_episode_return': 43533.333333333336, 'global/mean_episode_step': 4566.083333333333, 'global/SPS': 3071.9225117202427, 'global/env_act_steps': 24820608, 'global/env_train_steps': 24816640, 'global/optimizer_steps': 38776, 'global/running_reward': 21838.68821292776, 'global/running_step': 2308.7673776140687, 'global/steps_done': 24820608, 'global/episodes_done': 6221, 'global/unclipped_grad_norm': 0.7716138077025511, 'global/model_version': 38776, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:37,924] calculate_sps 33920 steps in 10.0235
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:37,924] calculate_sps 34560 steps in 10.0235
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:37,924] {'local/mean_episode_return': 45280.0, 'local/mean_episode_step': 4757.4, 'local/SPS': 3384.0414630423556, 'local/env_act_steps': 24854656, 'local/env_train_steps': 24852480, 'local/optimizer_steps': 38832, 'local/running_reward': 21646.535326086956, 'local/running_step': 2285.083003952569, 'local/steps_done': 24854656, 'local/episodes_done': 6226, 'local/unclipped_grad_norm': 0.7344322094210872, 'local/model_version': 38832, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:37,925] {'global/mean_episode_return': 45280.0, 'global/mean_episode_step': 4757.4, 'global/SPS': 3447.891301967683, 'global/env_act_steps': 24853248, 'global/env_train_steps': 24851200, 'global/optimizer_steps': 38829, 'global/running_reward': 21627.401960784315, 'global/running_step': 2283.3875612745096, 'global/steps_done': 24853248, 'global/episodes_done': 6226, 'global/unclipped_grad_norm': 0.7493701610925063, 'global/model_version': 38829, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:47,927] calculate_sps 30720 steps in 10.0036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:47,927] calculate_sps 32000 steps in 10.0036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:47,928] {'local/mean_episode_return': 51375.0, 'local/mean_episode_step': 5061.5, 'local/SPS': 3070.891952543025, 'local/env_act_steps': 24888064, 'local/env_train_steps': 24883200, 'local/optimizer_steps': 38880, 'local/running_reward': 21797.44372605364, 'local/running_step': 2303.6521192528735, 'local/steps_done': 24888064, 'local/episodes_done': 6234, 'local/unclipped_grad_norm': 0.8655627090483904, 'local/model_version': 38880, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:47,939] {'global/mean_episode_return': 51375.0, 'global/mean_episode_step': 5061.5, 'global/SPS': 3198.845783898985, 'global/env_act_steps': 24886656, 'global/env_train_steps': 24883200, 'global/optimizer_steps': 38880, 'global/running_reward': 21813.368055555555, 'global/running_step': 2304.938757183908, 'global/steps_done': 24886656, 'global/episodes_done': 6234, 'global/unclipped_grad_norm': 0.8459125003393959, 'global/model_version': 38880, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:57,960] calculate_sps 35840 steps in 10.0331
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:22:57,960] calculate_sps 33280 steps in 10.0331
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:57,960] {'local/mean_episode_return': 40412.5, 'local/mean_episode_step': 4340.1875, 'local/SPS': 3572.1738444401913, 'local/env_act_steps': 24920064, 'local/env_train_steps': 24919040, 'local/optimizer_steps': 38935, 'local/running_reward': 21660.8625, 'local/running_step': 2285.4364375, 'local/steps_done': 24920064, 'local/episodes_done': 6243, 'local/unclipped_grad_norm': 0.6806732627478513, 'local/model_version': 38935, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:22:57,961] {'global/mean_episode_return': 40412.5, 'global/mean_episode_step': 4340.1875, 'global/SPS': 3317.0185698373207, 'global/env_act_steps': 24919680, 'global/env_train_steps': 24916480, 'global/optimizer_steps': 38931, 'global/running_reward': 21660.44694767442, 'global/running_step': 2285.6711179748063, 'global/steps_done': 24919680, 'global/episodes_done': 6243, 'global/unclipped_grad_norm': 0.6803396624677321, 'global/model_version': 38931, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:07,967] calculate_sps 30720 steps in 10.0069
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:07,968] calculate_sps 33280 steps in 10.0069
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:07,968] {'local/mean_episode_return': 40371.42857142857, 'local/mean_episode_step': 4338.571428571428, 'local/SPS': 3069.8690329338583, 'local/env_act_steps': 24953728, 'local/env_train_steps': 24949760, 'local/optimizer_steps': 38984, 'local/running_reward': 21580.465779467682, 'local/running_step': 2272.4036953422055, 'local/steps_done': 24953728, 'local/episodes_done': 6250, 'local/unclipped_grad_norm': 0.7588957423458293, 'local/model_version': 38984, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:07,969] {'global/mean_episode_return': 40371.42857142857, 'global/mean_episode_step': 4338.571428571428, 'global/SPS': 3325.691452345013, 'global/env_act_steps': 24952832, 'global/env_train_steps': 24949760, 'global/optimizer_steps': 38984, 'global/running_reward': 21574.553571428572, 'global/running_step': 2271.950138754826, 'global/steps_done': 24952832, 'global/episodes_done': 6250, 'global/unclipped_grad_norm': 0.7533131705702476, 'global/model_version': 38984, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:17,990] calculate_sps 33280 steps in 10.0235
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:17,991] calculate_sps 32000 steps in 10.0235
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:17,991] {'local/mean_episode_return': 33666.666666666664, 'local/mean_episode_step': 3695.6666666666665, 'local/SPS': 3320.2021276666596, 'local/env_act_steps': 24986112, 'local/env_train_steps': 24983040, 'local/optimizer_steps': 39035, 'local/running_reward': 21914.729496047432, 'local/running_step': 2305.875247035573, 'local/steps_done': 24986112, 'local/episodes_done': 6253, 'local/unclipped_grad_norm': 0.756812600236313, 'local/model_version': 39035, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:17,992] {'global/mean_episode_return': 33666.666666666664, 'global/mean_episode_step': 3695.6666666666665, 'global/SPS': 3192.5020458333265, 'global/env_act_steps': 24985856, 'global/env_train_steps': 24981760, 'global/optimizer_steps': 39033, 'global/running_reward': 21904.263565891473, 'global/running_step': 2304.747910610465, 'global/steps_done': 24985856, 'global/episodes_done': 6253, 'global/unclipped_grad_norm': 0.7412443522896085, 'global/model_version': 39033, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:28,024] calculate_sps 33280 steps in 10.033
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:28,024] calculate_sps 34560 steps in 10.033
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:28,034] {'local/mean_episode_return': 48925.0, 'local/mean_episode_step': 5015.25, 'local/SPS': 3317.037250977332, 'local/env_act_steps': 25018880, 'local/env_train_steps': 25016320, 'local/optimizer_steps': 39088, 'local/running_reward': 22548.49853515625, 'local/running_step': 2369.161895751953, 'local/steps_done': 25018880, 'local/episodes_done': 6258, 'local/unclipped_grad_norm': 0.7504816606359662, 'local/model_version': 39088, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:28,036] {'global/mean_episode_return': 48925.0, 'global/mean_episode_step': 5015.25, 'global/SPS': 3444.6156067841525, 'global/env_act_steps': 25018624, 'global/env_train_steps': 25016320, 'global/optimizer_steps': 39088, 'global/running_reward': 22545.66650390625, 'global/running_step': 2368.9059448242188, 'global/steps_done': 25018624, 'global/episodes_done': 6258, 'global/unclipped_grad_norm': 0.7645817702466792, 'global/model_version': 39088, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:38,034] calculate_sps 30720 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:38,035] calculate_sps 30720 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:38,035] {'local/mean_episode_return': 45200.0, 'local/mean_episode_step': 4584.666666666667, 'local/SPS': 3069.0462753534985, 'local/env_act_steps': 25052288, 'local/env_train_steps': 25047040, 'local/optimizer_steps': 39136, 'local/running_reward': 22893.630268199235, 'local/running_step': 2402.580429837165, 'local/steps_done': 25052288, 'local/episodes_done': 6265, 'local/unclipped_grad_norm': 0.8344878274947405, 'local/model_version': 39136, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:38,036] {'global/mean_episode_return': 45200.0, 'global/mean_episode_step': 4584.666666666667, 'global/SPS': 3069.0462753534985, 'global/env_act_steps': 25052288, 'global/env_train_steps': 25047040, 'global/optimizer_steps': 39136, 'global/running_reward': 22892.223146387834, 'global/running_step': 2402.4397576045626, 'global/steps_done': 25052288, 'global/episodes_done': 6265, 'global/unclipped_grad_norm': 0.8344878274947405, 'global/model_version': 39136, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:48,045] calculate_sps 35840 steps in 10.0125
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:48,046] calculate_sps 27520 steps in 10.0125
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:48,046] {'local/mean_episode_return': 45975.0, 'local/mean_episode_step': 4706.625, 'local/SPS': 3579.5313720185695, 'local/env_act_steps': 25083904, 'local/env_train_steps': 25082880, 'local/optimizer_steps': 39191, 'local/running_reward': 22729.927884615383, 'local/running_step': 2392.235640182186, 'local/steps_done': 25083904, 'local/episodes_done': 6273, 'local/unclipped_grad_norm': 0.6286973514340141, 'local/model_version': 39191, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:48,047] {'global/mean_episode_return': 43160.0, 'global/mean_episode_step': 4537.8, 'global/SPS': 2748.5687320856873, 'global/env_act_steps': 25078144, 'global/env_train_steps': 25074560, 'global/optimizer_steps': 39178, 'global/running_reward': 22731.868811881188, 'global/running_step': 2392.203318378713, 'global/steps_done': 25078144, 'global/episodes_done': 6270, 'global/unclipped_grad_norm': 0.6731755492233095, 'global/model_version': 39178, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:58,073] calculate_sps 30720 steps in 10.0276
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:23:58,074] calculate_sps 33920 steps in 10.0276
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:58,074] {'local/mean_episode_return': 48633.333333333336, 'local/mean_episode_step': 4881.333333333333, 'local/SPS': 3063.5393571511363, 'local/env_act_steps': 25117440, 'local/env_train_steps': 25113600, 'local/optimizer_steps': 39240, 'local/running_reward': 22468.320610687024, 'local/running_step': 2370.5983122614502, 'local/steps_done': 25117440, 'local/episodes_done': 6279, 'local/unclipped_grad_norm': 0.8173578162582553, 'local/model_version': 39240, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:23:58,075] {'global/mean_episode_return': 49311.11111111111, 'global/mean_episode_step': 4916.888888888889, 'global/SPS': 3382.658040187713, 'global/env_act_steps': 25111296, 'global/env_train_steps': 25108480, 'global/optimizer_steps': 39232, 'global/running_reward': 22509.917953667955, 'global/running_step': 2374.026846042471, 'global/steps_done': 25111296, 'global/episodes_done': 6279, 'global/unclipped_grad_norm': 0.7581645294472024, 'global/model_version': 39232, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:08,119] calculate_sps 33920 steps in 10.0455
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:08,119] calculate_sps 32000 steps in 10.0455
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:08,119] {'local/mean_episode_return': 48440.0, 'local/mean_episode_step': 4981.8, 'local/SPS': 3376.631482917774, 'local/env_act_steps': 25150080, 'local/env_train_steps': 25147520, 'local/optimizer_steps': 39292, 'local/running_reward': 22915.17156862745, 'local/running_step': 2417.469791666667, 'local/steps_done': 25150080, 'local/episodes_done': 6284, 'local/unclipped_grad_norm': 0.7278675078772582, 'local/model_version': 39292, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:08,120] {'global/mean_episode_return': 47100.0, 'global/mean_episode_step': 4882.25, 'global/SPS': 3185.5013989790323, 'global/env_act_steps': 25144704, 'global/env_train_steps': 25140480, 'global/optimizer_steps': 39282, 'global/running_reward': 22845.013170498085, 'global/running_step': 2410.369193007663, 'global/steps_done': 25144704, 'global/episodes_done': 6283, 'global/unclipped_grad_norm': 0.6919971361756325, 'global/model_version': 39282, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:18,131] calculate_sps 32640 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:18,132] calculate_sps 34560 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:18,132] {'local/mean_episode_return': 44860.0, 'local/mean_episode_step': 4645.8, 'local/SPS': 3259.994476905648, 'local/env_act_steps': 25182976, 'local/env_train_steps': 25180160, 'local/optimizer_steps': 39344, 'local/running_reward': 22685.663910505835, 'local/running_step': 2394.7444674124513, 'local/steps_done': 25182976, 'local/episodes_done': 6294, 'local/unclipped_grad_norm': 0.8018143113989097, 'local/model_version': 39344, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:18,133] {'global/mean_episode_return': 46825.0, 'global/mean_episode_step': 4811.375, 'global/SPS': 3451.7588579000976, 'global/env_act_steps': 25177088, 'global/env_train_steps': 25175040, 'global/optimizer_steps': 39336, 'global/running_reward': 22761.6415513834, 'global/running_step': 2402.1921010375495, 'global/steps_done': 25177088, 'global/episodes_done': 6291, 'global/unclipped_grad_norm': 0.8209347106792309, 'global/model_version': 39336, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:28,160] calculate_sps 30720 steps in 10.0284
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:28,160] calculate_sps 30720 steps in 10.0284
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:28,160] {'local/mean_episode_return': 39644.444444444445, 'local/mean_episode_step': 4241.555555555556, 'local/SPS': 3063.2853147123474, 'local/env_act_steps': 25216128, 'local/env_train_steps': 25210880, 'local/optimizer_steps': 39392, 'local/running_reward': 22201.610762548262, 'local/running_step': 2340.816511824324, 'local/steps_done': 25216128, 'local/episodes_done': 6303, 'local/unclipped_grad_norm': 0.8739961888641119, 'local/model_version': 39392, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:28,162] {'global/mean_episode_return': 40383.333333333336, 'global/mean_episode_step': 4293.416666666667, 'global/SPS': 3063.2853147123474, 'global/env_act_steps': 25210624, 'global/env_train_steps': 25205760, 'global/optimizer_steps': 39384, 'global/running_reward': 22253.32776717557, 'global/running_step': 2347.2901061545804, 'global/steps_done': 25210624, 'global/episodes_done': 6303, 'global/unclipped_grad_norm': 0.865316458667318, 'global/model_version': 39384, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:38,193] calculate_sps 35840 steps in 10.0338
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:38,193] calculate_sps 35840 steps in 10.0338
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:38,194] {'local/mean_episode_return': 47742.857142857145, 'local/mean_episode_step': 4656.857142857143, 'local/SPS': 3571.932953553516, 'local/env_act_steps': 25247744, 'local/env_train_steps': 25246720, 'local/optimizer_steps': 39447, 'local/running_reward': 22356.389170040486, 'local/running_step': 2357.4245951417006, 'local/steps_done': 25247744, 'local/episodes_done': 6310, 'local/unclipped_grad_norm': 0.8064864440397783, 'local/model_version': 39447, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:38,195] {'global/mean_episode_return': 47360.0, 'global/mean_episode_step': 4590.8, 'global/SPS': 3571.932953553516, 'global/env_act_steps': 25243008, 'global/env_train_steps': 25241600, 'global/optimizer_steps': 39440, 'global/running_reward': 22337.061511857708, 'global/running_step': 2354.502840909091, 'global/steps_done': 25243008, 'global/episodes_done': 6308, 'global/unclipped_grad_norm': 0.8102032483688423, 'global/model_version': 39440, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:48,223] calculate_sps 30720 steps in 10.0296
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:48,223] calculate_sps 30720 steps in 10.0296
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:48,224] {'local/mean_episode_return': 47400.0, 'local/mean_episode_step': 4657.0, 'local/SPS': 3062.9413175197988, 'local/env_act_steps': 25281280, 'local/env_train_steps': 25277440, 'local/optimizer_steps': 39496, 'local/running_reward': 22561.796278625956, 'local/running_step': 2379.7104902194656, 'local/steps_done': 25281280, 'local/episodes_done': 6314, 'local/unclipped_grad_norm': 0.7322593684099159, 'local/model_version': 39496, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:48,225] {'global/mean_episode_return': 47680.0, 'global/mean_episode_step': 4679.8, 'global/SPS': 3062.9413175197988, 'global/env_act_steps': 25276544, 'global/env_train_steps': 25272320, 'global/optimizer_steps': 39488, 'global/running_reward': 22493.565124045803, 'global/running_step': 2373.0645873091603, 'global/steps_done': 25276544, 'global/episodes_done': 6313, 'global/unclipped_grad_norm': 0.7577218959728876, 'global/model_version': 39488, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:58,245] calculate_sps 33920 steps in 10.0221
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:24:58,245] calculate_sps 35200 steps in 10.0221
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:58,245] {'local/mean_episode_return': 41955.555555555555, 'local/mean_episode_step': 4339.333333333333, 'local/SPS': 3384.530928438492, 'local/env_act_steps': 25313920, 'local/env_train_steps': 25311360, 'local/optimizer_steps': 39548, 'local/running_reward': 22472.549019607843, 'local/running_step': 2368.3039828431374, 'local/steps_done': 25313920, 'local/episodes_done': 6323, 'local/unclipped_grad_norm': 0.6400474258340322, 'local/model_version': 39548, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:24:58,246] {'global/mean_episode_return': 42977.77777777778, 'global/mean_episode_step': 4415.666666666667, 'global/SPS': 3512.249076681454, 'global/env_act_steps': 25309184, 'global/env_train_steps': 25307520, 'global/optimizer_steps': 39542, 'global/running_reward': 22498.92769607843, 'global/running_step': 2371.130024509804, 'global/steps_done': 25309184, 'global/episodes_done': 6322, 'global/unclipped_grad_norm': 0.6387547072437074, 'global/model_version': 39542, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:08,246] calculate_sps 32640 steps in 10.0009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:08,246] calculate_sps 31360 steps in 10.0009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:08,247] {'local/mean_episode_return': 39828.57142857143, 'local/mean_episode_step': 4212.857142857143, 'local/SPS': 3263.691473562892, 'local/env_act_steps': 25346688, 'local/env_train_steps': 25344000, 'local/optimizer_steps': 39600, 'local/running_reward': 22687.82958984375, 'local/running_step': 2388.7259521484375, 'local/steps_done': 25346688, 'local/episodes_done': 6330, 'local/unclipped_grad_norm': 0.6897730239881918, 'local/model_version': 39600, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:08,248] {'global/mean_episode_return': 40228.57142857143, 'global/mean_episode_step': 4238.428571428572, 'global/SPS': 3135.703572638857, 'global/env_act_steps': 25342720, 'global/env_train_steps': 25338880, 'global/optimizer_steps': 39592, 'global/running_reward': 22663.054627862595, 'global/running_step': 2386.96341245229, 'global/steps_done': 25342720, 'global/episodes_done': 6329, 'global/unclipped_grad_norm': 0.693279295861721, 'global/model_version': 39592, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:18,256] calculate_sps 30720 steps in 10.0103
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:18,266] calculate_sps 33920 steps in 10.0103
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:18,266] {'local/mean_episode_return': 43375.0, 'local/mean_episode_step': 4536.75, 'local/SPS': 3068.8315184377207, 'local/env_act_steps': 25379968, 'local/env_train_steps': 25374720, 'local/optimizer_steps': 39648, 'local/running_reward': 22492.061298076922, 'local/running_step': 2365.7231670673077, 'local/steps_done': 25379968, 'local/episodes_done': 6338, 'local/unclipped_grad_norm': 0.652192926655213, 'local/model_version': 39648, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:18,268] {'global/mean_episode_return': 43857.142857142855, 'global/mean_episode_step': 4557.285714285715, 'global/SPS': 3388.5014682749834, 'global/env_act_steps': 25375360, 'global/env_train_steps': 25372800, 'global/optimizer_steps': 39644, 'global/running_reward': 22484.969362745098, 'global/running_step': 2364.875919117647, 'global/steps_done': 25375360, 'global/episodes_done': 6336, 'global/unclipped_grad_norm': 0.6281247500043649, 'global/model_version': 39644, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:28,271] calculate_sps 35840 steps in 10.015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:28,272] calculate_sps 32640 steps in 10.015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:28,272] {'local/mean_episode_return': 40342.857142857145, 'local/mean_episode_step': 4278.714285714285, 'local/SPS': 3578.61949104442, 'local/env_act_steps': 25412224, 'local/env_train_steps': 25410560, 'local/optimizer_steps': 39704, 'local/running_reward': 22882.118055555555, 'local/running_step': 2397.8827194940477, 'local/steps_done': 25412224, 'local/episodes_done': 6345, 'local/unclipped_grad_norm': 0.7275081412600619, 'local/model_version': 39704, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:28,273] {'global/mean_episode_return': 35600.0, 'global/mean_episode_step': 3916.3333333333335, 'global/SPS': 3259.0998936297397, 'global/env_act_steps': 25408896, 'global/env_train_steps': 25405440, 'global/optimizer_steps': 39696, 'global/running_reward': 22841.15577290076, 'global/running_step': 2395.251013835878, 'global/steps_done': 25408896, 'global/episodes_done': 6342, 'global/unclipped_grad_norm': 0.7412484686535138, 'global/model_version': 39696, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:38,295] calculate_sps 30720 steps in 10.0235
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:38,306] calculate_sps 32000 steps in 10.0235
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:38,306] {'local/mean_episode_return': 45666.666666666664, 'local/mean_episode_step': 4626.0, 'local/SPS': 3064.811513845977, 'local/env_act_steps': 25445120, 'local/env_train_steps': 25441280, 'local/optimizer_steps': 39752, 'local/running_reward': 22894.272859922177, 'local/running_step': 2395.5220087548637, 'local/steps_done': 25445120, 'local/episodes_done': 6351, 'local/unclipped_grad_norm': 0.7221206395576397, 'local/model_version': 39752, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:38,308] {'global/mean_episode_return': 46600.0, 'global/mean_episode_step': 4734.333333333333, 'global/SPS': 3192.5119935895596, 'global/env_act_steps': 25441664, 'global/env_train_steps': 25437440, 'global/optimizer_steps': 39745, 'global/running_reward': 22912.90283203125, 'global/running_step': 2397.2418212890625, 'global/steps_done': 25441664, 'global/episodes_done': 6351, 'global/unclipped_grad_norm': 0.7620596374784198, 'global/model_version': 39745, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:48,299] calculate_sps 32640 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:48,299] calculate_sps 34560 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:48,300] {'local/mean_episode_return': 42228.57142857143, 'local/mean_episode_step': 4422.571428571428, 'local/SPS': 3262.5133071699156, 'local/env_act_steps': 25477504, 'local/env_train_steps': 25473920, 'local/optimizer_steps': 39802, 'local/running_reward': 23172.455533596836, 'local/running_step': 2419.8496479743085, 'local/steps_done': 25477504, 'local/episodes_done': 6358, 'local/unclipped_grad_norm': 0.8026295360922814, 'local/model_version': 39802, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:48,301] {'global/mean_episode_return': 37200.0, 'global/mean_episode_step': 4097.4, 'global/SPS': 3454.425854650499, 'global/env_act_steps': 25473792, 'global/env_train_steps': 25472000, 'global/optimizer_steps': 39800, 'global/running_reward': 23114.54183266932, 'global/running_step': 2414.693974103586, 'global/steps_done': 25473792, 'global/episodes_done': 6356, 'global/unclipped_grad_norm': 0.7569089583375237, 'global/model_version': 39800, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 13:25:52,347] saving global stats {'mean_episode_return': 49000.0, 'mean_episode_step': 4856.25, 'SPS': None, 'env_act_steps': 25480704, 'env_train_steps': 25477120, 'optimizer_steps': 39808, 'running_reward': 23212.32638888889, 'running_step': 2423.9991319444443, 'steps_done': 25480704, 'episodes_done': 6360, 'unclipped_grad_norm': 1.0374816320836544, 'model_version': 39808, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 13:25:52,483] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:58,328] calculate_sps 33920 steps in 10.0289
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:25:58,329] calculate_sps 30720 steps in 10.0289
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:58,329] {'local/mean_episode_return': 43160.0, 'local/mean_episode_step': 4472.2, 'local/SPS': 3382.2189672082063, 'local/env_act_steps': 25509248, 'local/env_train_steps': 25507840, 'local/optimizer_steps': 39856, 'local/running_reward': 22658.845766129034, 'local/running_step': 2368.1994392641127, 'local/steps_done': 25509248, 'local/episodes_done': 6373, 'local/unclipped_grad_norm': 0.8302753777415665, 'local/model_version': 39856, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:25:58,330] {'global/mean_episode_return': 43969.230769230766, 'global/mean_episode_step': 4476.384615384615, 'global/SPS': 3063.141706150828, 'global/env_act_steps': 25506560, 'global/env_train_steps': 25502720, 'global/optimizer_steps': 39848, 'global/running_reward': 22796.39892578125, 'global/running_step': 2381.9730834960938, 'global/steps_done': 25506560, 'global/episodes_done': 6369, 'global/unclipped_grad_norm': 0.8517888604352871, 'global/model_version': 39848, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:08,356] calculate_sps 30720 steps in 10.0273
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:08,356] calculate_sps 33920 steps in 10.0273
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:08,356] {'local/mean_episode_return': 40911.11111111111, 'local/mean_episode_step': 4356.777777777777, 'local/SPS': 3063.6383489695395, 'local/env_act_steps': 25542784, 'local/env_train_steps': 25538560, 'local/optimizer_steps': 39904, 'local/running_reward': 21367.867366412214, 'local/running_step': 2233.1554448950383, 'local/steps_done': 25542784, 'local/episodes_done': 6382, 'local/unclipped_grad_norm': 0.7681486544509729, 'local/model_version': 39904, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:08,357] {'global/mean_episode_return': 42584.61538461538, 'global/mean_episode_step': 4505.538461538462, 'global/SPS': 3382.7673436538666, 'global/env_act_steps': 25539200, 'global/env_train_steps': 25536640, 'global/optimizer_steps': 39900, 'global/running_reward': 21410.81495098039, 'global/running_step': 2238.0052083333335, 'global/steps_done': 25539200, 'global/episodes_done': 6382, 'global/unclipped_grad_norm': 0.7636082086425561, 'global/model_version': 39900, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:18,384] calculate_sps 34560 steps in 10.0291
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:18,385] calculate_sps 32640 steps in 10.0291
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:18,385] {'local/mean_episode_return': 42755.555555555555, 'local/mean_episode_step': 4361.888888888889, 'local/SPS': 3445.9683088672327, 'local/env_act_steps': 25575296, 'local/env_train_steps': 25573120, 'local/optimizer_steps': 39958, 'local/running_reward': 21277.38681102362, 'local/running_step': 2224.226654773622, 'local/steps_done': 25575296, 'local/episodes_done': 6391, 'local/unclipped_grad_norm': 0.7508957579180047, 'local/model_version': 39958, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:18,386] {'global/mean_episode_return': 43850.0, 'global/mean_episode_step': 4464.375, 'global/SPS': 3254.5256250412754, 'global/env_act_steps': 25572480, 'global/env_train_steps': 25569280, 'global/optimizer_steps': 39952, 'global/running_reward': 21291.580528846152, 'global/running_step': 2225.6274939903847, 'global/steps_done': 25572480, 'global/episodes_done': 6390, 'global/unclipped_grad_norm': 0.7310571578832773, 'global/model_version': 39952, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:28,409] calculate_sps 32000 steps in 10.0239
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:28,409] calculate_sps 32000 steps in 10.0239
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:28,409] {'local/mean_episode_return': 45560.0, 'local/mean_episode_step': 4576.2, 'local/SPS': 3192.3674914350245, 'local/env_act_steps': 25608064, 'local/env_train_steps': 25605120, 'local/optimizer_steps': 40008, 'local/running_reward': 21625.494384765625, 'local/running_step': 2255.5811462402344, 'local/steps_done': 25608064, 'local/episodes_done': 6396, 'local/unclipped_grad_norm': 0.8395163884758949, 'local/model_version': 40008, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:28,411] {'global/mean_episode_return': 43633.333333333336, 'global/mean_episode_step': 4403.833333333333, 'global/SPS': 3192.3674914350245, 'global/env_act_steps': 25605376, 'global/env_train_steps': 25601280, 'global/optimizer_steps': 40001, 'global/running_reward': 21602.596060311284, 'global/running_step': 2253.1907526750974, 'global/steps_done': 25605376, 'global/episodes_done': 6396, 'global/unclipped_grad_norm': 0.8586391061544418, 'global/model_version': 40001, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:38,411] calculate_sps 31360 steps in 10.0026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:38,412] calculate_sps 34560 steps in 10.0026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:38,412] {'local/mean_episode_return': 44685.71428571428, 'local/mean_episode_step': 4568.0, 'local/SPS': 3135.175300858155, 'local/env_act_steps': 25641088, 'local/env_train_steps': 25636480, 'local/optimizer_steps': 40056, 'local/running_reward': 21428.43386627907, 'local/running_step': 2238.5839389534885, 'local/steps_done': 25641088, 'local/episodes_done': 6403, 'local/unclipped_grad_norm': 0.7199801200379928, 'local/model_version': 40056, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:38,413] {'global/mean_episode_return': 44685.71428571428, 'global/mean_episode_step': 4568.0, 'global/SPS': 3455.0911478844973, 'global/env_act_steps': 25638144, 'global/env_train_steps': 25635840, 'global/optimizer_steps': 40056, 'global/running_reward': 21425.0, 'global/running_step': 2238.1661682128906, 'global/steps_done': 25638144, 'global/episodes_done': 6403, 'global/unclipped_grad_norm': 0.7218523280187087, 'global/model_version': 40056, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:48,431] calculate_sps 35200 steps in 10.0194
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:48,431] calculate_sps 31360 steps in 10.0194
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:48,431] {'local/mean_episode_return': 49750.0, 'local/mean_episode_step': 5092.5, 'local/SPS': 3513.201267231497, 'local/env_act_steps': 25673600, 'local/env_train_steps': 25671680, 'local/optimizer_steps': 40112, 'local/running_reward': 21799.17568897638, 'local/running_step': 2275.688145915354, 'local/steps_done': 25673600, 'local/episodes_done': 6407, 'local/unclipped_grad_norm': 0.7254472659634692, 'local/model_version': 40112, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:48,433] {'global/mean_episode_return': 49750.0, 'global/mean_episode_step': 5092.5, 'global/SPS': 3129.942947169879, 'global/env_act_steps': 25671808, 'global/env_train_steps': 25667200, 'global/optimizer_steps': 40104, 'global/running_reward': 21767.846958174905, 'global/running_step': 2272.5289032794676, 'global/steps_done': 25671808, 'global/episodes_done': 6407, 'global/unclipped_grad_norm': 0.7200291097785035, 'global/model_version': 40104, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:58,464] calculate_sps 30720 steps in 10.0336
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:26:58,465] calculate_sps 35200 steps in 10.0336
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:58,465] {'local/mean_episode_return': 42800.0, 'local/mean_episode_step': 4496.0, 'local/SPS': 3061.7119626856565, 'local/env_act_steps': 25707008, 'local/env_train_steps': 25702400, 'local/optimizer_steps': 40160, 'local/running_reward': 22240.098180076628, 'local/running_step': 2319.106681034483, 'local/steps_done': 25707008, 'local/episodes_done': 6412, 'local/unclipped_grad_norm': 0.6455139753719171, 'local/model_version': 40160, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:26:58,466] {'global/mean_episode_return': 42800.0, 'global/mean_episode_step': 4496.0, 'global/SPS': 3508.2116239106485, 'global/env_act_steps': 25704320, 'global/env_train_steps': 25702400, 'global/optimizer_steps': 40160, 'global/running_reward': 22216.080216535433, 'global/running_step': 2316.555856299213, 'global/steps_done': 25704320, 'global/episodes_done': 6412, 'global/unclipped_grad_norm': 0.6615771507578236, 'global/model_version': 40160, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:08,470] calculate_sps 34560 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:08,470] calculate_sps 30720 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:08,470] {'local/mean_episode_return': 50180.0, 'local/mean_episode_step': 4975.7, 'local/SPS': 3454.088448022473, 'local/env_act_steps': 25739136, 'local/env_train_steps': 25736960, 'local/optimizer_steps': 40214, 'local/running_reward': 22367.834910358564, 'local/running_step': 2333.8075199203186, 'local/steps_done': 25739136, 'local/episodes_done': 6422, 'local/unclipped_grad_norm': 0.7489938531760816, 'local/model_version': 40214, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:08,472] {'global/mean_episode_return': 49600.0, 'global/mean_episode_step': 4929.111111111111, 'global/SPS': 3070.3008426866427, 'global/env_act_steps': 25737984, 'global/env_train_steps': 25733120, 'global/optimizer_steps': 40208, 'global/running_reward': 22385.117633079848, 'global/running_step': 2335.5739068441067, 'global/steps_done': 25737984, 'global/episodes_done': 6421, 'global/unclipped_grad_norm': 0.7345569084088007, 'global/model_version': 40208, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:18,487] calculate_sps 32000 steps in 10.0168
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:18,487] calculate_sps 35840 steps in 10.0168
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:18,487] {'local/mean_episode_return': 42644.444444444445, 'local/mean_episode_step': 4353.444444444444, 'local/SPS': 3194.6314430888624, 'local/env_act_steps': 25772544, 'local/env_train_steps': 25768960, 'local/optimizer_steps': 40264, 'local/running_reward': 21958.26748084291, 'local/running_step': 2293.519636015326, 'local/steps_done': 25772544, 'local/episodes_done': 6431, 'local/unclipped_grad_norm': 0.7259401538968087, 'local/model_version': 40264, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:18,489] {'global/mean_episode_return': 43488.88888888889, 'global/mean_episode_step': 4421.333333333333, 'global/SPS': 3577.987216259526, 'global/env_act_steps': 25770496, 'global/env_train_steps': 25768960, 'global/optimizer_steps': 40264, 'global/running_reward': 21976.254921259842, 'global/running_step': 2295.300412155512, 'global/steps_done': 25770496, 'global/episodes_done': 6430, 'global/unclipped_grad_norm': 0.7407847171915429, 'global/model_version': 40264, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:28,533] calculate_sps 32640 steps in 10.0469
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:28,533] calculate_sps 30720 steps in 10.0469
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:28,533] {'local/mean_episode_return': 44462.5, 'local/mean_episode_step': 4615.625, 'local/SPS': 3248.7753931005886, 'local/env_act_steps': 25805184, 'local/env_train_steps': 25801600, 'local/optimizer_steps': 40314, 'local/running_reward': 21574.491421568626, 'local/running_step': 2256.0726102941176, 'local/steps_done': 25805184, 'local/episodes_done': 6440, 'local/unclipped_grad_norm': 0.7839314764738083, 'local/model_version': 40314, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:28,534] {'global/mean_episode_return': 43700.0, 'global/mean_episode_step': 4562.625, 'global/SPS': 3057.670958212319, 'global/env_act_steps': 25803904, 'global/env_train_steps': 25799680, 'global/optimizer_steps': 40312, 'global/running_reward': 21580.304118773947, 'global/running_step': 2256.6375718390805, 'global/steps_done': 25803904, 'global/episodes_done': 6438, 'global/unclipped_grad_norm': 0.7815288087973992, 'global/model_version': 40312, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:38,553] calculate_sps 33920 steps in 10.0194
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:38,553] calculate_sps 35200 steps in 10.0194
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:38,553] {'local/mean_episode_return': 39150.0, 'local/mean_episode_step': 4150.125, 'local/SPS': 3385.425292905357, 'local/env_act_steps': 25837824, 'local/env_train_steps': 25835520, 'local/optimizer_steps': 40368, 'local/running_reward': 21077.432598039217, 'local/running_step': 2208.537714460784, 'local/steps_done': 25837824, 'local/episodes_done': 6448, 'local/unclipped_grad_norm': 0.7357717054309668, 'local/model_version': 40368, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:38,566] {'global/mean_episode_return': 40788.88888888889, 'global/mean_episode_step': 4267.666666666667, 'global/SPS': 3513.177190750842, 'global/env_act_steps': 25836416, 'global/env_train_steps': 25834880, 'global/optimizer_steps': 40366, 'global/running_reward': 21100.885826771653, 'global/running_step': 2210.7797736220473, 'global/steps_done': 25836416, 'global/episodes_done': 6448, 'global/unclipped_grad_norm': 0.7380629587504599, 'global/model_version': 40366, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:48,571] calculate_sps 30720 steps in 10.0176
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:48,571] calculate_sps 31360 steps in 10.0176
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:48,571] {'local/mean_episode_return': 49233.333333333336, 'local/mean_episode_step': 4874.166666666667, 'local/SPS': 3066.5937837564397, 'local/env_act_steps': 25870976, 'local/env_train_steps': 25866240, 'local/optimizer_steps': 40416, 'local/running_reward': 21501.5625, 'local/running_step': 2249.170547779923, 'local/steps_done': 25870976, 'local/episodes_done': 6454, 'local/unclipped_grad_norm': 0.7388193557659785, 'local/model_version': 40416, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:48,572] {'global/mean_episode_return': 48360.0, 'global/mean_episode_step': 4770.0, 'global/SPS': 3130.4811542513653, 'global/env_act_steps': 25869568, 'global/env_train_steps': 25866240, 'global/optimizer_steps': 40416, 'global/running_reward': 21482.197152509652, 'global/running_step': 2247.360641891892, 'global/steps_done': 25869568, 'global/episodes_done': 6453, 'global/unclipped_grad_norm': 0.7404558479785919, 'global/model_version': 40416, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:58,576] calculate_sps 35200 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:27:58,576] calculate_sps 33280 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:58,576] {'local/mean_episode_return': 51160.0, 'local/mean_episode_step': 5164.2, 'local/SPS': 3518.162283480912, 'local/env_act_steps': 25903104, 'local/env_train_steps': 25901440, 'local/optimizer_steps': 40471, 'local/running_reward': 21568.87450199203, 'local/running_step': 2254.464423555777, 'local/steps_done': 25903104, 'local/episodes_done': 6459, 'local/unclipped_grad_norm': 0.8155314938588576, 'local/model_version': 40471, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:27:58,578] {'global/mean_episode_return': 51566.666666666664, 'global/mean_episode_step': 5202.666666666667, 'global/SPS': 3326.262522563771, 'global/env_act_steps': 25902720, 'global/env_train_steps': 25899520, 'global/optimizer_steps': 40467, 'global/running_reward': 21567.193532818532, 'global/running_step': 2254.306014720077, 'global/steps_done': 25902720, 'global/episodes_done': 6459, 'global/unclipped_grad_norm': 0.8433768562242097, 'global/model_version': 40467, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:08,588] calculate_sps 31360 steps in 10.0125
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:08,589] calculate_sps 33280 steps in 10.0125
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:08,589] {'local/mean_episode_return': 42266.666666666664, 'local/mean_episode_step': 4535.666666666667, 'local/SPS': 3132.071081450476, 'local/env_act_steps': 25935872, 'local/env_train_steps': 25932800, 'local/optimizer_steps': 40520, 'local/running_reward': 21745.806884765625, 'local/running_step': 2262.4673461914062, 'local/steps_done': 25935872, 'local/episodes_done': 6465, 'local/unclipped_grad_norm': 0.7013301019157682, 'local/model_version': 40520, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:08,590] {'global/mean_episode_return': 42266.666666666664, 'global/mean_episode_step': 4535.666666666667, 'global/SPS': 3323.8305354168315, 'global/env_act_steps': 25935232, 'global/env_train_steps': 25932800, 'global/optimizer_steps': 40520, 'global/running_reward': 21741.03100393701, 'global/running_step': 2262.218996062992, 'global/steps_done': 25935232, 'global/episodes_done': 6465, 'global/unclipped_grad_norm': 0.6831544809183985, 'global/model_version': 40520, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:18,617] calculate_sps 32640 steps in 10.0294
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:18,618] calculate_sps 31360 steps in 10.0294
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:18,618] {'local/mean_episode_return': 46933.333333333336, 'local/mean_episode_step': 4643.666666666667, 'local/SPS': 3254.440599054239, 'local/env_act_steps': 25969024, 'local/env_train_steps': 25965440, 'local/optimizer_steps': 40570, 'local/running_reward': 22081.992036679538, 'local/running_step': 2290.728734314672, 'local/steps_done': 25969024, 'local/episodes_done': 6471, 'local/unclipped_grad_norm': 0.6606675520539284, 'local/model_version': 40570, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:18,619] {'global/mean_episode_return': 46933.333333333336, 'global/mean_episode_step': 4643.666666666667, 'global/SPS': 3126.8154775227003, 'global/env_act_steps': 25968896, 'global/env_train_steps': 25964160, 'global/optimizer_steps': 40569, 'global/running_reward': 22073.027566539924, 'global/running_step': 2289.804954847909, 'global/steps_done': 25968896, 'global/episodes_done': 6471, 'global/unclipped_grad_norm': 0.6698465097923668, 'global/model_version': 40569, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:28,644] calculate_sps 33920 steps in 10.0254
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:28,654] calculate_sps 35200 steps in 10.0254
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:28,654] {'local/mean_episode_return': 44100.0, 'local/mean_episode_step': 4456.75, 'local/SPS': 3383.398852204914, 'local/env_act_steps': 26001664, 'local/env_train_steps': 25999360, 'local/optimizer_steps': 40624, 'local/running_reward': 22566.844362745098, 'local/running_step': 2336.325398284314, 'local/steps_done': 26001664, 'local/episodes_done': 6475, 'local/unclipped_grad_norm': 0.7706331268504814, 'local/model_version': 40624, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:28,656] {'global/mean_episode_return': 44100.0, 'global/mean_episode_step': 4456.75, 'global/SPS': 3511.074280590005, 'global/env_act_steps': 26001664, 'global/env_train_steps': 25999360, 'global/optimizer_steps': 40624, 'global/running_reward': 22569.71435546875, 'global/running_step': 2336.6224060058594, 'global/steps_done': 26001664, 'global/episodes_done': 6475, 'global/unclipped_grad_norm': 0.7604561358690262, 'global/model_version': 40624, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:38,657] calculate_sps 30720 steps in 10.0137
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:38,657] calculate_sps 25600 steps in 10.0137
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:38,657] {'local/mean_episode_return': 43371.42857142857, 'local/mean_episode_step': 4511.428571428572, 'local/SPS': 3067.7924407018704, 'local/env_act_steps': 26035072, 'local/env_train_steps': 26030080, 'local/optimizer_steps': 40672, 'local/running_reward': 22861.518199233717, 'local/running_step': 2363.0252634099616, 'local/steps_done': 26035072, 'local/episodes_done': 6482, 'local/unclipped_grad_norm': 0.7164936472351352, 'local/model_version': 40672, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:38,659] {'global/mean_episode_return': 45120.0, 'global/mean_episode_step': 4698.8, 'global/SPS': 2556.493700584892, 'global/env_act_steps': 26028544, 'global/env_train_steps': 26024960, 'global/optimizer_steps': 40664, 'global/running_reward': 22803.697916666668, 'global/running_step': 2357.57578125, 'global/steps_done': 26028544, 'global/episodes_done': 6480, 'global/unclipped_grad_norm': 0.7137190815061331, 'global/model_version': 40664, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:48,697] calculate_sps 35840 steps in 10.0407
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:48,698] calculate_sps 33920 steps in 10.0407
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:48,698] {'local/mean_episode_return': 44966.666666666664, 'local/mean_episode_step': 4567.166666666667, 'local/SPS': 3569.48633246158, 'local/env_act_steps': 26067328, 'local/env_train_steps': 26065920, 'local/optimizer_steps': 40728, 'local/running_reward': 23014.124503968254, 'local/running_step': 2375.3396267361113, 'local/steps_done': 26067328, 'local/episodes_done': 6488, 'local/unclipped_grad_norm': 0.7332781814038754, 'local/model_version': 40728, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:48,699] {'global/mean_episode_return': 43475.0, 'global/mean_episode_step': 4436.125, 'global/SPS': 3378.263850365424, 'global/env_act_steps': 26061440, 'global/env_train_steps': 26058880, 'global/optimizer_steps': 40716, 'global/running_reward': 23027.9608463035, 'global/running_step': 2376.969813959144, 'global/steps_done': 26061440, 'global/episodes_done': 6488, 'global/unclipped_grad_norm': 0.7445930403012496, 'global/model_version': 40716, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:58,738] calculate_sps 30720 steps in 10.0404
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:28:58,739] calculate_sps 32640 steps in 10.0404
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:58,739] {'local/mean_episode_return': 45600.0, 'local/mean_episode_step': 4665.625, 'local/SPS': 3059.6305491132384, 'local/env_act_steps': 26100608, 'local/env_train_steps': 26096640, 'local/optimizer_steps': 40776, 'local/running_reward': 23174.50721153846, 'local/running_step': 2389.752283653846, 'local/steps_done': 26100608, 'local/episodes_done': 6496, 'local/unclipped_grad_norm': 0.8582081273198128, 'local/model_version': 40776, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:28:58,741] {'global/mean_episode_return': 46742.857142857145, 'global/mean_episode_step': 4744.571428571428, 'global/SPS': 3250.8574584328157, 'global/env_act_steps': 26094976, 'global/env_train_steps': 26091520, 'global/optimizer_steps': 40768, 'global/running_reward': 23166.573234732823, 'global/running_step': 2389.5298485209923, 'global/steps_done': 26094976, 'global/episodes_done': 6495, 'global/unclipped_grad_norm': 0.8571162455930159, 'global/model_version': 40768, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:08,755] calculate_sps 34560 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:08,755] calculate_sps 33920 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:08,755] {'local/mean_episode_return': 50500.0, 'local/mean_episode_step': 5149.25, 'local/SPS': 3450.0885528578833, 'local/env_act_steps': 26133248, 'local/env_train_steps': 26131200, 'local/optimizer_steps': 40829, 'local/running_reward': 23417.212009803923, 'local/running_step': 2414.385324754902, 'local/steps_done': 26133248, 'local/episodes_done': 6500, 'local/unclipped_grad_norm': 0.7516502327514145, 'local/model_version': 40829, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:08,756] {'global/mean_episode_return': 48400.0, 'global/mean_episode_step': 4951.0, 'global/SPS': 3386.1980241012557, 'global/env_act_steps': 26128000, 'global/env_train_steps': 26125440, 'global/optimizer_steps': 40820, 'global/running_reward': 23346.063468992248, 'global/running_step': 2407.0276768410854, 'global/steps_done': 26128000, 'global/episodes_done': 6498, 'global/unclipped_grad_norm': 0.7106889300048351, 'global/model_version': 40820, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:18,778] calculate_sps 32000 steps in 10.0234
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:18,779] calculate_sps 32640 steps in 10.0234
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:18,779] {'local/mean_episode_return': 46854.545454545456, 'local/mean_episode_step': 4772.454545454545, 'local/SPS': 3192.5253586115596, 'local/env_act_steps': 26166272, 'local/env_train_steps': 26163200, 'local/optimizer_steps': 40880, 'local/running_reward': 23106.122819767443, 'local/running_step': 2380.769894622093, 'local/steps_done': 26166272, 'local/episodes_done': 6511, 'local/unclipped_grad_norm': 0.7036404840502084, 'local/model_version': 40880, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:18,780] {'global/mean_episode_return': 46907.692307692305, 'global/mean_episode_step': 4796.461538461538, 'global/SPS': 3256.3758657837907, 'global/env_act_steps': 26161024, 'global/env_train_steps': 26158080, 'global/optimizer_steps': 40872, 'global/running_reward': 23238.43871124031, 'global/running_step': 2394.4896438953488, 'global/steps_done': 26161024, 'global/episodes_done': 6511, 'global/unclipped_grad_norm': 0.7090467097094426, 'global/model_version': 40872, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:28,815] calculate_sps 31360 steps in 10.0367
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:28,816] calculate_sps 31360 steps in 10.0367
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:28,816] {'local/mean_episode_return': 44550.0, 'local/mean_episode_step': 4539.583333333333, 'local/SPS': 3124.544910647624, 'local/env_act_steps': 26199168, 'local/env_train_steps': 26194560, 'local/optimizer_steps': 40928, 'local/running_reward': 22252.900048638134, 'local/running_step': 2291.7790916828794, 'local/steps_done': 26199168, 'local/episodes_done': 6523, 'local/unclipped_grad_norm': 0.7938272580504417, 'local/model_version': 40928, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:28,818] {'global/mean_episode_return': 43563.63636363636, 'global/mean_episode_step': 4461.909090909091, 'global/SPS': 3124.544910647624, 'global/env_act_steps': 26194176, 'global/env_train_steps': 26189440, 'global/optimizer_steps': 40921, 'global/running_reward': 22364.159025096524, 'global/running_step': 2303.456805019305, 'global/steps_done': 26194176, 'global/episodes_done': 6522, 'global/unclipped_grad_norm': 0.79362026100256, 'global/model_version': 40921, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:38,837] calculate_sps 35200 steps in 10.0218
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:38,837] calculate_sps 35200 steps in 10.0218
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:38,846] {'local/mean_episode_return': 38175.0, 'local/mean_episode_step': 4008.875, 'local/SPS': 3512.3282878057776, 'local/env_act_steps': 26231424, 'local/env_train_steps': 26229760, 'local/optimizer_steps': 40984, 'local/running_reward': 21940.39558531746, 'local/running_step': 2259.6349206349205, 'local/steps_done': 26231424, 'local/episodes_done': 6531, 'local/unclipped_grad_norm': 0.7289575809346778, 'local/model_version': 40984, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:38,848] {'global/mean_episode_return': 39114.28571428572, 'global/mean_episode_step': 4092.1428571428573, 'global/SPS': 3512.3282878057776, 'global/env_act_steps': 26226688, 'global/env_train_steps': 26224640, 'global/optimizer_steps': 40976, 'global/running_reward': 21937.1062992126, 'global/running_step': 2259.3883489173227, 'global/steps_done': 26226688, 'global/episodes_done': 6529, 'global/unclipped_grad_norm': 0.7348205265673724, 'global/model_version': 40976, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:48,861] calculate_sps 30720 steps in 10.0238
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:48,861] calculate_sps 30720 steps in 10.0238
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:48,861] {'local/mean_episode_return': 52533.333333333336, 'local/mean_episode_step': 5314.0, 'local/SPS': 3064.697794354572, 'local/env_act_steps': 26264960, 'local/env_train_steps': 26260480, 'local/optimizer_steps': 41032, 'local/running_reward': 22266.98473282443, 'local/running_step': 2292.5025047709923, 'local/steps_done': 26264960, 'local/episodes_done': 6534, 'local/unclipped_grad_norm': 0.695275206429263, 'local/model_version': 41032, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:48,863] {'global/mean_episode_return': 47900.0, 'global/mean_episode_step': 4841.5, 'global/SPS': 3064.697794354572, 'global/env_act_steps': 26260224, 'global/env_train_steps': 26255360, 'global/optimizer_steps': 41024, 'global/running_reward': 22183.856154580153, 'global/running_step': 2283.930164599237, 'global/steps_done': 26260224, 'global/episodes_done': 6533, 'global/unclipped_grad_norm': 0.6994728138670325, 'global/model_version': 41024, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:58,897] calculate_sps 35200 steps in 10.0363
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:29:58,897] calculate_sps 35840 steps in 10.0363
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:58,897] {'local/mean_episode_return': 47100.0, 'local/mean_episode_step': 4617.0, 'local/SPS': 3507.2596362723802, 'local/env_act_steps': 26297216, 'local/env_train_steps': 26295680, 'local/optimizer_steps': 41086, 'local/running_reward': 23114.267113095237, 'local/running_step': 2382.1716579861113, 'local/steps_done': 26297216, 'local/episodes_done': 6536, 'local/unclipped_grad_norm': 0.672177192237642, 'local/model_version': 41086, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:29:58,898] {'global/mean_episode_return': 48000.0, 'global/mean_episode_step': 4794.5, 'global/SPS': 3571.0279932955145, 'global/env_act_steps': 26292992, 'global/env_train_steps': 26291200, 'global/optimizer_steps': 41080, 'global/running_reward': 22997.55859375, 'global/running_step': 2369.4881591796875, 'global/steps_done': 26292992, 'global/episodes_done': 6535, 'global/unclipped_grad_norm': 0.7053404665951218, 'global/model_version': 41080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:08,911] calculate_sps 31360 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:08,911] calculate_sps 30720 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:08,911] {'local/mean_episode_return': 43750.0, 'local/mean_episode_step': 4487.875, 'local/SPS': 3131.7413942713197, 'local/env_act_steps': 26330368, 'local/env_train_steps': 26327040, 'local/optimizer_steps': 41136, 'local/running_reward': 23485.907335907337, 'local/running_step': 2423.8523467664095, 'local/steps_done': 26330368, 'local/episodes_done': 6545, 'local/unclipped_grad_norm': 0.7612636339664459, 'local/model_version': 41136, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:08,913] {'global/mean_episode_return': 43428.57142857143, 'global/mean_episode_step': 4443.714285714285, 'global/SPS': 3067.828304592313, 'global/env_act_steps': 26326656, 'global/env_train_steps': 26321920, 'global/optimizer_steps': 41128, 'global/running_reward': 23486.745484790874, 'global/running_step': 2423.678499287072, 'global/steps_done': 26326656, 'global/episodes_done': 6543, 'global/unclipped_grad_norm': 0.7586716658746203, 'global/model_version': 41128, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:18,950] calculate_sps 31360 steps in 10.04
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:18,951] calculate_sps 35200 steps in 10.04
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:18,951] {'local/mean_episode_return': 47360.0, 'local/mean_episode_step': 4761.0, 'local/SPS': 3123.4921917547526, 'local/env_act_steps': 26363008, 'local/env_train_steps': 26358400, 'local/optimizer_steps': 41184, 'local/running_reward': 23360.968137254902, 'local/running_step': 2413.6876225490196, 'local/steps_done': 26363008, 'local/episodes_done': 6550, 'local/unclipped_grad_norm': 0.6701995615536968, 'local/model_version': 41184, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:18,952] {'global/mean_episode_return': 47366.666666666664, 'global/mean_episode_step': 4828.5, 'global/SPS': 3505.9606233981917, 'global/env_act_steps': 26358656, 'global/env_train_steps': 26357120, 'global/optimizer_steps': 41182, 'global/running_reward': 23358.7375, 'global/running_step': 2412.857625, 'global/steps_done': 26358656, 'global/episodes_done': 6549, 'global/unclipped_grad_norm': 0.6526837561417509, 'global/model_version': 41182, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:28,986] calculate_sps 35200 steps in 10.0355
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:28,987] calculate_sps 31360 steps in 10.0355
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:28,987] {'local/mean_episode_return': 43040.0, 'local/mean_episode_step': 4361.7, 'local/SPS': 3507.5344370415514, 'local/env_act_steps': 26395520, 'local/env_train_steps': 26393600, 'local/optimizer_steps': 41240, 'local/running_reward': 23024.132627952757, 'local/running_step': 2383.8832431102364, 'local/steps_done': 26395520, 'local/episodes_done': 6560, 'local/unclipped_grad_norm': 0.7633745947054454, 'local/model_version': 41240, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:28,988] {'global/mean_episode_return': 43654.545454545456, 'global/mean_episode_step': 4389.909090909091, 'global/SPS': 3124.8943166370186, 'global/env_act_steps': 26392064, 'global/env_train_steps': 26388480, 'global/optimizer_steps': 41232, 'global/running_reward': 23082.23778735632, 'global/running_step': 2389.7466475095785, 'global/steps_done': 26392064, 'global/episodes_done': 6560, 'global/unclipped_grad_norm': 0.7293741846084595, 'global/model_version': 41232, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:39,008] calculate_sps 30720 steps in 10.022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:39,009] calculate_sps 33920 steps in 10.022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:39,018] {'local/mean_episode_return': 30000.0, 'local/mean_episode_step': 3270.5, 'local/SPS': 3065.2527670450822, 'local/env_act_steps': 26428928, 'local/env_train_steps': 26424320, 'local/optimizer_steps': 41288, 'local/running_reward': 23471.605603448275, 'local/running_step': 2428.8042983716473, 'local/steps_done': 26428928, 'local/episodes_done': 6562, 'local/unclipped_grad_norm': 0.8442404204979539, 'local/model_version': 41288, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:39,020] {'global/mean_episode_return': 30000.0, 'global/mean_episode_step': 3270.5, 'global/SPS': 3384.549930278945, 'global/env_act_steps': 26424960, 'global/env_train_steps': 26422400, 'global/optimizer_steps': 41284, 'global/running_reward': 23351.3983463035, 'global/running_step': 2416.6853416828794, 'global/steps_done': 26424960, 'global/episodes_done': 6562, 'global/unclipped_grad_norm': 0.8870869298967031, 'global/model_version': 41284, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:49,014] calculate_sps 34560 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:49,014] calculate_sps 32640 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:49,014] {'local/mean_episode_return': 41600.0, 'local/mean_episode_step': 4401.5, 'local/SPS': 3454.1893585387033, 'local/env_act_steps': 26461056, 'local/env_train_steps': 26458880, 'local/optimizer_steps': 41342, 'local/running_reward': 24208.90189243028, 'local/running_step': 2500.9396476593624, 'local/steps_done': 26461056, 'local/episodes_done': 6568, 'local/unclipped_grad_norm': 0.6818831596109602, 'local/model_version': 41342, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:49,016] {'global/mean_episode_return': 39680.0, 'global/mean_episode_step': 4295.0, 'global/SPS': 3262.2899497309973, 'global/env_act_steps': 26458240, 'global/env_train_steps': 26455040, 'global/optimizer_steps': 41336, 'global/running_reward': 24175.618990384617, 'global/running_step': 2497.9649939903848, 'global/steps_done': 26458240, 'global/episodes_done': 6567, 'global/unclipped_grad_norm': 0.6769335565085595, 'global/model_version': 41336, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:59,026] calculate_sps 32000 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:30:59,027] calculate_sps 32000 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:59,027] {'local/mean_episode_return': 41250.0, 'local/mean_episode_step': 4228.75, 'local/SPS': 3195.8865657745996, 'local/env_act_steps': 26493952, 'local/env_train_steps': 26490880, 'local/optimizer_steps': 41392, 'local/running_reward': 24358.000972762646, 'local/running_step': 2514.535384241245, 'local/steps_done': 26493952, 'local/episodes_done': 6576, 'local/unclipped_grad_norm': 0.5937284836173058, 'local/model_version': 41392, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:30:59,028] {'global/mean_episode_return': 42355.555555555555, 'global/mean_episode_step': 4307.111111111111, 'global/SPS': 3195.8865657745996, 'global/env_act_steps': 26491264, 'global/env_train_steps': 26487040, 'global/optimizer_steps': 41385, 'global/running_reward': 24362.300145348836, 'global/running_step': 2515.063953488372, 'global/steps_done': 26491264, 'global/episodes_done': 6576, 'global/unclipped_grad_norm': 0.6166535774055792, 'global/model_version': 41385, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:09,046] calculate_sps 31360 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:09,046] calculate_sps 34560 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:09,046] {'local/mean_episode_return': 45925.0, 'local/mean_episode_step': 4710.625, 'local/SPS': 3129.733599235292, 'local/env_act_steps': 26526848, 'local/env_train_steps': 26522240, 'local/optimizer_steps': 41440, 'local/running_reward': 24336.369163424126, 'local/running_step': 2509.9758633268484, 'local/steps_done': 26526848, 'local/episodes_done': 6584, 'local/unclipped_grad_norm': 0.8427258941034476, 'local/model_version': 41440, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:09,047] {'global/mean_episode_return': 45925.0, 'global/mean_episode_step': 4710.625, 'global/SPS': 3449.0941705858318, 'global/env_act_steps': 26523776, 'global/env_train_steps': 26521600, 'global/optimizer_steps': 41440, 'global/running_reward': 24353.881643700788, 'global/running_step': 2511.9329170767714, 'global/steps_done': 26523776, 'global/episodes_done': 6584, 'global/unclipped_grad_norm': 0.7948653177781538, 'global/model_version': 41440, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:19,061] calculate_sps 35200 steps in 10.0146
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:19,061] calculate_sps 30720 steps in 10.0146
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:19,062] {'local/mean_episode_return': 48488.88888888889, 'local/mean_episode_step': 4816.444444444444, 'local/SPS': 3514.8578189495474, 'local/env_act_steps': 26558976, 'local/env_train_steps': 26557440, 'local/optimizer_steps': 41496, 'local/running_reward': 23681.187749003984, 'local/running_step': 2446.1617592131474, 'local/steps_done': 26558976, 'local/episodes_done': 6594, 'local/unclipped_grad_norm': 0.7681851041104112, 'local/model_version': 41496, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:19,063] {'global/mean_episode_return': 47350.0, 'global/mean_episode_step': 4744.25, 'global/SPS': 3067.5122783559686, 'global/env_act_steps': 26557056, 'global/env_train_steps': 26552320, 'global/optimizer_steps': 41488, 'global/running_reward': 23727.99278846154, 'global/running_step': 2450.4070612980768, 'global/steps_done': 26557056, 'global/episodes_done': 6593, 'global/unclipped_grad_norm': 0.7710171788930893, 'global/model_version': 41488, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:29,098] calculate_sps 30720 steps in 10.0372
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:29,099] calculate_sps 35200 steps in 10.0372
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:29,099] {'local/mean_episode_return': 47114.28571428572, 'local/mean_episode_step': 4822.0, 'local/SPS': 3060.625863205206, 'local/env_act_steps': 26592000, 'local/env_train_steps': 26588160, 'local/optimizer_steps': 41544, 'local/running_reward': 23603.500484496122, 'local/running_step': 2439.4841024709303, 'local/steps_done': 26592000, 'local/episodes_done': 6601, 'local/unclipped_grad_norm': 0.7811476544787487, 'local/model_version': 41544, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:29,100] {'global/mean_episode_return': 48166.666666666664, 'global/mean_episode_step': 4919.666666666667, 'global/SPS': 3506.967134922632, 'global/env_act_steps': 26589056, 'global/env_train_steps': 26587520, 'global/optimizer_steps': 41542, 'global/running_reward': 23597.9, 'global/running_step': 2439.039375, 'global/steps_done': 26589056, 'global/episodes_done': 6599, 'global/unclipped_grad_norm': 0.7611400308432402, 'global/model_version': 41542, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:39,145] calculate_sps 33280 steps in 10.0469
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:39,145] calculate_sps 31360 steps in 10.0469
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:39,145] {'local/mean_episode_return': 45450.0, 'local/mean_episode_step': 4635.75, 'local/SPS': 3312.4650017476374, 'local/env_act_steps': 26624512, 'local/env_train_steps': 26621440, 'local/optimizer_steps': 41595, 'local/running_reward': 23707.48031496063, 'local/running_step': 2452.363927165354, 'local/steps_done': 26624512, 'local/episodes_done': 6605, 'local/unclipped_grad_norm': 0.8099333941936493, 'local/model_version': 41595, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:39,146] {'global/mean_episode_return': 47520.0, 'global/mean_episode_step': 4738.8, 'global/SPS': 3121.3612516468124, 'global/env_act_steps': 26622592, 'global/env_train_steps': 26618880, 'global/optimizer_steps': 41592, 'global/running_reward': 23675.268368320612, 'global/running_step': 2448.973550811069, 'global/steps_done': 26622592, 'global/episodes_done': 6604, 'global/unclipped_grad_norm': 0.859184099137783, 'global/model_version': 41592, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:49,163] calculate_sps 33280 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:49,164] calculate_sps 34560 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:49,174] {'local/mean_episode_return': 48350.0, 'local/mean_episode_step': 4808.875, 'local/SPS': 3321.91438347346, 'local/env_act_steps': 26657536, 'local/env_train_steps': 26654720, 'local/optimizer_steps': 41648, 'local/running_reward': 23780.16593992248, 'local/running_step': 2458.4599079457366, 'local/steps_done': 26657536, 'local/episodes_done': 6613, 'local/unclipped_grad_norm': 0.860523242995424, 'local/model_version': 41648, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:49,176] {'global/mean_episode_return': 48050.0, 'global/mean_episode_step': 4797.875, 'global/SPS': 3449.6803212993623, 'global/env_act_steps': 26655488, 'global/env_train_steps': 26653440, 'global/optimizer_steps': 41645, 'global/running_reward': 23795.11186770428, 'global/running_step': 2460.0158377918287, 'global/steps_done': 26655488, 'global/episodes_done': 6612, 'global/unclipped_grad_norm': 0.8413279250545321, 'global/model_version': 41645, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:59,201] calculate_sps 31360 steps in 10.0381
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:31:59,201] calculate_sps 32000 steps in 10.0381
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:59,202] {'local/mean_episode_return': 47420.0, 'local/mean_episode_step': 4713.9, 'local/SPS': 3124.09473975127, 'local/env_act_steps': 26690688, 'local/env_train_steps': 26686080, 'local/optimizer_steps': 41696, 'local/running_reward': 23431.599903474904, 'local/running_step': 2424.090884411197, 'local/steps_done': 26690688, 'local/episodes_done': 6623, 'local/unclipped_grad_norm': 0.7452218001708388, 'local/model_version': 41696, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:31:59,203] {'global/mean_episode_return': 47700.0, 'global/mean_episode_step': 4723.4, 'global/SPS': 3187.851775256398, 'global/env_act_steps': 26689152, 'global/env_train_steps': 26685440, 'global/optimizer_steps': 41696, 'global/running_reward': 23464.032794676805, 'global/running_step': 2427.0787191064637, 'global/steps_done': 26689152, 'global/episodes_done': 6622, 'global/unclipped_grad_norm': 0.7360483019375333, 'global/model_version': 41696, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:09,225] calculate_sps 35200 steps in 10.0228
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:09,225] calculate_sps 32640 steps in 10.0228
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:09,225] {'local/mean_episode_return': 54000.0, 'local/mean_episode_step': 5395.0, 'local/SPS': 3512.0071205209833, 'local/env_act_steps': 26722688, 'local/env_train_steps': 26721280, 'local/optimizer_steps': 41752, 'local/running_reward': 23689.50625, 'local/running_step': 2451.04315625, 'local/steps_done': 26722688, 'local/episodes_done': 6625, 'local/unclipped_grad_norm': 0.7614091320761612, 'local/model_version': 41752, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:09,227] {'global/mean_episode_return': 50066.666666666664, 'global/mean_episode_step': 5087.333333333333, 'global/SPS': 3256.58842084673, 'global/env_act_steps': 26721664, 'global/env_train_steps': 26718080, 'global/optimizer_steps': 41746, 'global/running_reward': 23659.14124015748, 'global/running_step': 2448.0907664862207, 'global/steps_done': 26721664, 'global/episodes_done': 6625, 'global/unclipped_grad_norm': 0.7580309435725212, 'global/model_version': 41746, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:19,262] calculate_sps 30720 steps in 10.0373
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:19,262] calculate_sps 33920 steps in 10.0373
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:19,262] {'local/mean_episode_return': 39857.142857142855, 'local/mean_episode_step': 4161.714285714285, 'local/SPS': 3060.5984552375694, 'local/env_act_steps': 26756096, 'local/env_train_steps': 26752000, 'local/optimizer_steps': 41800, 'local/running_reward': 23910.895593869733, 'local/running_step': 2470.741858237548, 'local/steps_done': 26756096, 'local/episodes_done': 6632, 'local/unclipped_grad_norm': 0.7207853632668654, 'local/model_version': 41800, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:19,263] {'global/mean_episode_return': 39857.142857142855, 'global/mean_episode_step': 4161.714285714285, 'global/SPS': 3379.4107943248164, 'global/env_act_steps': 26754816, 'global/env_train_steps': 26752000, 'global/optimizer_steps': 41800, 'global/running_reward': 23902.56998069498, 'global/running_step': 2470.0433458011585, 'global/steps_done': 26754816, 'global/episodes_done': 6632, 'global/unclipped_grad_norm': 0.7284270676749723, 'global/model_version': 41800, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:29,266] calculate_sps 33280 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:29,266] calculate_sps 31360 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:29,266] {'local/mean_episode_return': 45950.0, 'local/mean_episode_step': 4626.5, 'local/SPS': 3326.5513022878745, 'local/env_act_steps': 26788352, 'local/env_train_steps': 26785280, 'local/optimizer_steps': 41851, 'local/running_reward': 24298.877728174604, 'local/running_step': 2506.439515128968, 'local/steps_done': 26788352, 'local/episodes_done': 6640, 'local/unclipped_grad_norm': 0.6953326676990471, 'local/model_version': 41851, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:29,267] {'global/mean_episode_return': 45950.0, 'global/mean_episode_step': 4626.5, 'global/SPS': 3134.6348810020354, 'global/env_act_steps': 26787968, 'global/env_train_steps': 26783360, 'global/optimizer_steps': 41848, 'global/running_reward': 24294.105936293436, 'global/running_step': 2506.0355031370655, 'global/steps_done': 26787968, 'global/episodes_done': 6640, 'global/unclipped_grad_norm': 0.6887406554693977, 'global/model_version': 41848, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:39,277] calculate_sps 33280 steps in 10.0113
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:39,278] calculate_sps 35200 steps in 10.0113
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:39,278] {'local/mean_episode_return': 43900.0, 'local/mean_episode_step': 4544.0, 'local/SPS': 3324.248167520664, 'local/env_act_steps': 26821248, 'local/env_train_steps': 26818560, 'local/optimizer_steps': 41904, 'local/running_reward': 24210.074173151752, 'local/running_step': 2495.1236928501944, 'local/steps_done': 26821248, 'local/episodes_done': 6646, 'local/unclipped_grad_norm': 0.7600553018866845, 'local/model_version': 41904, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:39,279] {'global/mean_episode_return': 43900.0, 'global/mean_episode_step': 4544.0, 'global/SPS': 3516.031715646856, 'global/env_act_steps': 26820736, 'global/env_train_steps': 26818560, 'global/optimizer_steps': 41904, 'global/running_reward': 24210.58349609375, 'global/running_step': 2495.1757202148438, 'global/steps_done': 26820736, 'global/episodes_done': 6646, 'global/unclipped_grad_norm': 0.7622383141091892, 'global/model_version': 41904, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:49,279] calculate_sps 31360 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:49,279] calculate_sps 31360 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:49,280] {'local/mean_episode_return': 48100.0, 'local/mean_episode_step': 4902.5, 'local/SPS': 3135.418786023585, 'local/env_act_steps': 26854528, 'local/env_train_steps': 26849920, 'local/optimizer_steps': 41952, 'local/running_reward': 24172.61418269231, 'local/running_step': 2491.1111177884613, 'local/steps_done': 26854528, 'local/episodes_done': 6654, 'local/unclipped_grad_norm': 0.7632777749871215, 'local/model_version': 41952, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:49,280] {'global/mean_episode_return': 48100.0, 'global/mean_episode_step': 4902.5, 'global/SPS': 3135.418786023585, 'global/env_act_steps': 26854528, 'global/env_train_steps': 26849920, 'global/optimizer_steps': 41952, 'global/running_reward': 24173.940577651516, 'global/running_step': 2491.265625, 'global/steps_done': 26854528, 'global/episodes_done': 6654, 'global/unclipped_grad_norm': 0.7632777749871215, 'global/model_version': 41952, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:59,303] calculate_sps 35200 steps in 10.0241
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:32:59,303] calculate_sps 28160 steps in 10.0241
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:59,304] {'local/mean_episode_return': 49307.692307692305, 'local/mean_episode_step': 4936.461538461538, 'local/SPS': 3511.5338316997772, 'local/env_act_steps': 26887040, 'local/env_train_steps': 26885120, 'local/optimizer_steps': 42008, 'local/running_reward': 23367.962598425198, 'local/running_step': 2414.9580155019685, 'local/steps_done': 26887040, 'local/episodes_done': 6667, 'local/unclipped_grad_norm': 0.6586487828088659, 'local/model_version': 42008, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:32:59,305] {'global/mean_episode_return': 48600.0, 'global/mean_episode_step': 4898.166666666667, 'global/SPS': 2809.2270653598216, 'global/env_act_steps': 26880768, 'global/env_train_steps': 26878080, 'global/optimizer_steps': 41997, 'global/running_reward': 23536.150914634145, 'global/running_step': 2430.5927210365853, 'global/steps_done': 26880768, 'global/episodes_done': 6666, 'global/unclipped_grad_norm': 0.684093596206771, 'global/model_version': 41997, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:09,317] calculate_sps 30720 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:09,317] calculate_sps 32640 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:09,317] {'local/mean_episode_return': 48210.0, 'local/mean_episode_step': 4812.45, 'local/SPS': 3067.833198507962, 'local/env_act_steps': 26920192, 'local/env_train_steps': 26915840, 'local/optimizer_steps': 42056, 'local/running_reward': 22097.049951737452, 'local/running_step': 2295.8648950289576, 'local/steps_done': 26920192, 'local/episodes_done': 6678, 'local/unclipped_grad_norm': 0.6510710055008531, 'local/model_version': 42056, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:09,319] {'global/mean_episode_return': 49081.818181818184, 'global/mean_episode_step': 4865.5, 'global/SPS': 3259.57277341471, 'global/env_act_steps': 26913408, 'global/env_train_steps': 26910720, 'global/optimizer_steps': 42048, 'global/running_reward': 22281.170343137255, 'global/running_step': 2313.325337009804, 'global/steps_done': 26913408, 'global/episodes_done': 6678, 'global/unclipped_grad_norm': 0.6440397725970137, 'global/model_version': 42048, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:19,344] calculate_sps 35200 steps in 10.028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:19,344] calculate_sps 32000 steps in 10.028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:19,345] {'local/mean_episode_return': 47320.0, 'local/mean_episode_step': 4859.2, 'local/SPS': 3510.1866679549757, 'local/env_act_steps': 26952576, 'local/env_train_steps': 26951040, 'local/optimizer_steps': 42110, 'local/running_reward': 21957.824851778656, 'local/running_step': 2286.55845479249, 'local/steps_done': 26952576, 'local/episodes_done': 6683, 'local/unclipped_grad_norm': 0.729509732513516, 'local/model_version': 42110, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:19,346] {'global/mean_episode_return': 48300.0, 'global/mean_episode_step': 4953.75, 'global/SPS': 3191.078789049978, 'global/env_act_steps': 26946816, 'global/env_train_steps': 26942720, 'global/optimizer_steps': 42097, 'global/running_reward': 21882.674808429118, 'global/running_step': 2278.5218211206898, 'global/steps_done': 26946816, 'global/episodes_done': 6682, 'global/unclipped_grad_norm': 0.6710247436956484, 'global/model_version': 42097, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:29,365] calculate_sps 31360 steps in 10.0203
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:29,365] calculate_sps 34560 steps in 10.0203
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:29,366] {'local/mean_episode_return': 47700.0, 'local/mean_episode_step': 4736.625, 'local/SPS': 3129.660993099028, 'local/env_act_steps': 26985984, 'local/env_train_steps': 26982400, 'local/optimizer_steps': 42160, 'local/running_reward': 22110.69204980843, 'local/running_step': 2301.5775562739464, 'local/steps_done': 26985984, 'local/episodes_done': 6691, 'local/unclipped_grad_norm': 0.7672319236397743, 'local/model_version': 42160, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:29,367] {'global/mean_episode_return': 46200.0, 'global/mean_episode_step': 4669.375, 'global/SPS': 3449.0141556601534, 'global/env_act_steps': 26979456, 'global/env_train_steps': 26977280, 'global/optimizer_steps': 42152, 'global/running_reward': 22151.72181372549, 'global/running_step': 2305.636550245098, 'global/steps_done': 26979456, 'global/episodes_done': 6690, 'global/unclipped_grad_norm': 0.8019120760939338, 'global/model_version': 42152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:39,382] calculate_sps 32640 steps in 10.0175
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:39,382] calculate_sps 30720 steps in 10.0175
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:39,382] {'local/mean_episode_return': 43742.857142857145, 'local/mean_episode_step': 4515.714285714285, 'local/SPS': 3258.311962083251, 'local/env_act_steps': 27018624, 'local/env_train_steps': 27015040, 'local/optimizer_steps': 42210, 'local/running_reward': 21958.100490196077, 'local/running_step': 2286.3635416666666, 'local/steps_done': 27018624, 'local/episodes_done': 6698, 'local/unclipped_grad_norm': 0.7093465435504913, 'local/model_version': 42210, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:39,383] {'global/mean_episode_return': 45200.0, 'global/mean_episode_step': 4578.625, 'global/SPS': 3066.6465525489416, 'global/env_act_steps': 27013248, 'global/env_train_steps': 27008000, 'global/optimizer_steps': 42200, 'global/running_reward': 21952.574573863636, 'global/running_step': 2286.0580018939395, 'global/steps_done': 27013248, 'global/episodes_done': 6698, 'global/unclipped_grad_norm': 0.7567119002342224, 'global/model_version': 42200, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:49,419] calculate_sps 33920 steps in 10.0363
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:49,419] calculate_sps 35840 steps in 10.0363
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:49,419] {'local/mean_episode_return': 45742.857142857145, 'local/mean_episode_step': 4485.142857142857, 'local/SPS': 3379.727177454383, 'local/env_act_steps': 27051648, 'local/env_train_steps': 27048960, 'local/optimizer_steps': 42264, 'local/running_reward': 21842.19355620155, 'local/running_step': 2279.6517986918607, 'local/steps_done': 27051648, 'local/episodes_done': 6705, 'local/unclipped_grad_norm': 0.712648161859424, 'local/model_version': 42264, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:49,421] {'global/mean_episode_return': 48800.0, 'global/mean_episode_step': 4697.0, 'global/SPS': 3571.032489385763, 'global/env_act_steps': 27045760, 'global/env_train_steps': 27043840, 'global/optimizer_steps': 42256, 'global/running_reward': 21834.78100393701, 'global/running_step': 2277.124723179134, 'global/steps_done': 27045760, 'global/episodes_done': 6704, 'global/unclipped_grad_norm': 0.6795300407601255, 'global/model_version': 42256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:59,421] calculate_sps 30720 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:33:59,422] calculate_sps 30720 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:59,422] {'local/mean_episode_return': 41314.28571428572, 'local/mean_episode_step': 4416.571428571428, 'local/SPS': 3071.1688528621476, 'local/env_act_steps': 27084672, 'local/env_train_steps': 27079680, 'local/optimizer_steps': 42312, 'local/running_reward': 21935.47117248062, 'local/running_step': 2289.684320494186, 'local/steps_done': 27084672, 'local/episodes_done': 6712, 'local/unclipped_grad_norm': 0.7382315751165152, 'local/model_version': 42312, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:33:59,435] {'global/mean_episode_return': 40285.71428571428, 'global/mean_episode_step': 4360.142857142857, 'global/SPS': 3071.1688528621476, 'global/env_act_steps': 27079040, 'global/env_train_steps': 27074560, 'global/optimizer_steps': 42304, 'global/running_reward': 21921.97716346154, 'global/running_step': 2289.3295072115384, 'global/steps_done': 27079040, 'global/episodes_done': 6711, 'global/unclipped_grad_norm': 0.7309458249559005, 'global/model_version': 42304, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:09,442] calculate_sps 35840 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:09,443] calculate_sps 35840 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:09,443] {'local/mean_episode_return': 51075.0, 'local/mean_episode_step': 5113.25, 'local/SPS': 3576.3457763754445, 'local/env_act_steps': 27116544, 'local/env_train_steps': 27115520, 'local/optimizer_steps': 42367, 'local/running_reward': 22247.163654618475, 'local/running_step': 2317.020205823293, 'local/steps_done': 27116544, 'local/episodes_done': 6720, 'local/unclipped_grad_norm': 0.7295551191676747, 'local/model_version': 42367, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:09,444] {'global/mean_episode_return': 46133.333333333336, 'global/mean_episode_step': 4730.5, 'global/SPS': 3576.3457763754445, 'global/env_act_steps': 27111424, 'global/env_train_steps': 27110400, 'global/optimizer_steps': 42359, 'global/running_reward': 22233.89945652174, 'global/running_step': 2316.0004631916995, 'global/steps_done': 27111424, 'global/episodes_done': 6717, 'global/unclipped_grad_norm': 0.7258012370629744, 'global/model_version': 42359, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:19,460] calculate_sps 30720 steps in 10.0173
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:19,461] calculate_sps 30720 steps in 10.0173
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:19,461] {'local/mean_episode_return': 42750.0, 'local/mean_episode_step': 4431.625, 'local/SPS': 3066.6893965973127, 'local/env_act_steps': 27149824, 'local/env_train_steps': 27146240, 'local/optimizer_steps': 42416, 'local/running_reward': 21857.271634615383, 'local/running_step': 2277.978485576923, 'local/steps_done': 27149824, 'local/episodes_done': 6728, 'local/unclipped_grad_norm': 0.7519444923619835, 'local/model_version': 42416, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:19,462] {'global/mean_episode_return': 47760.0, 'global/mean_episode_step': 4797.2, 'global/SPS': 3066.6893965973127, 'global/env_act_steps': 27144832, 'global/env_train_steps': 27141120, 'global/optimizer_steps': 42408, 'global/running_reward': 21921.77322796935, 'global/running_step': 2283.8705699233715, 'global/steps_done': 27144832, 'global/episodes_done': 6727, 'global/unclipped_grad_norm': 0.7618316335945713, 'global/model_version': 42408, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:29,484] calculate_sps 32000 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:29,485] calculate_sps 33280 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:29,485] {'local/mean_episode_return': 49333.333333333336, 'local/mean_episode_step': 4988.444444444444, 'local/SPS': 3192.1309856590697, 'local/env_act_steps': 27182464, 'local/env_train_steps': 27178240, 'local/optimizer_steps': 42466, 'local/running_reward': 21311.72181372549, 'local/running_step': 2229.3730085784314, 'local/steps_done': 27182464, 'local/episodes_done': 6737, 'local/unclipped_grad_norm': 0.7960641357302666, 'local/model_version': 42466, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:29,486] {'global/mean_episode_return': 47480.0, 'global/mean_episode_step': 4850.9, 'global/SPS': 3319.8162250854325, 'global/env_act_steps': 27177472, 'global/env_train_steps': 27174400, 'global/optimizer_steps': 42459, 'global/running_reward': 21401.23161764706, 'global/running_step': 2237.769148284314, 'global/steps_done': 27177472, 'global/episodes_done': 6737, 'global/unclipped_grad_norm': 0.7829054494698843, 'global/model_version': 42459, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:39,492] calculate_sps 34560 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:39,492] calculate_sps 33280 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:39,492] {'local/mean_episode_return': 44171.42857142857, 'local/mean_episode_step': 4648.857142857143, 'local/SPS': 3453.6893907071917, 'local/env_act_steps': 27215360, 'local/env_train_steps': 27212800, 'local/optimizer_steps': 42520, 'local/running_reward': 21245.464494163425, 'local/running_step': 2226.9491427529183, 'local/steps_done': 27215360, 'local/episodes_done': 6744, 'local/unclipped_grad_norm': 0.7075367183597, 'local/model_version': 42520, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:39,494] {'global/mean_episode_return': 45500.0, 'global/mean_episode_step': 4682.0, 'global/SPS': 3325.7749688291474, 'global/env_act_steps': 27211136, 'global/env_train_steps': 27207680, 'global/optimizer_steps': 42512, 'global/running_reward': 21232.901615969582, 'global/running_step': 2225.231255941065, 'global/steps_done': 27211136, 'global/episodes_done': 6743, 'global/unclipped_grad_norm': 0.7435430600395743, 'global/model_version': 42512, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:49,522] calculate_sps 31360 steps in 10.0306
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:49,522] calculate_sps 33280 steps in 10.0306
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:49,522] {'local/mean_episode_return': 40700.0, 'local/mean_episode_step': 4281.0, 'local/SPS': 3126.441712836337, 'local/env_act_steps': 27248768, 'local/env_train_steps': 27244160, 'local/optimizer_steps': 42568, 'local/running_reward': 21446.48587164751, 'local/running_step': 2245.351083572797, 'local/steps_done': 27248768, 'local/episodes_done': 6748, 'local/unclipped_grad_norm': 0.7501745773479342, 'local/model_version': 42568, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:49,523] {'global/mean_episode_return': 37850.0, 'global/mean_episode_step': 4115.25, 'global/SPS': 3317.856511581419, 'global/env_act_steps': 27244032, 'global/env_train_steps': 27240960, 'global/optimizer_steps': 42563, 'global/running_reward': 21344.1451848249, 'global/running_step': 2235.1038424124513, 'global/steps_done': 27244032, 'global/episodes_done': 6747, 'global/unclipped_grad_norm': 0.7005506254294339, 'global/model_version': 42563, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:59,531] calculate_sps 35200 steps in 10.0086
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:34:59,531] calculate_sps 33280 steps in 10.0086
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:59,531] {'local/mean_episode_return': 46466.666666666664, 'local/mean_episode_step': 4759.333333333333, 'local/SPS': 3516.98972865918, 'local/env_act_steps': 27281152, 'local/env_train_steps': 27279360, 'local/optimizer_steps': 42624, 'local/running_reward': 22185.857213438736, 'local/running_step': 2322.544466403162, 'local/steps_done': 27281152, 'local/episodes_done': 6751, 'local/unclipped_grad_norm': 0.710525602634464, 'local/model_version': 42624, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:34:59,532] {'global/mean_episode_return': 46750.0, 'global/mean_episode_step': 4847.75, 'global/SPS': 3325.15392527777, 'global/env_act_steps': 27277440, 'global/env_train_steps': 27274240, 'global/optimizer_steps': 42616, 'global/running_reward': 22125.6405651341, 'global/running_step': 2316.3781429597702, 'global/steps_done': 27277440, 'global/episodes_done': 6751, 'global/unclipped_grad_norm': 0.7255034143070005, 'global/model_version': 42616, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:09,557] calculate_sps 30720 steps in 10.026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:09,557] calculate_sps 32640 steps in 10.026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:09,557] {'local/mean_episode_return': 45700.0, 'local/mean_episode_step': 4896.5, 'local/SPS': 3064.0374404684026, 'local/env_act_steps': 27314432, 'local/env_train_steps': 27310080, 'local/optimizer_steps': 42672, 'local/running_reward': 22664.44110576923, 'local/running_step': 2369.038641826923, 'local/steps_done': 27314432, 'local/episodes_done': 6755, 'local/unclipped_grad_norm': 0.6373300567890207, 'local/model_version': 42672, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:09,559] {'global/mean_episode_return': 45700.0, 'global/mean_episode_step': 4896.5, 'global/SPS': 3255.539780497678, 'global/env_act_steps': 27310464, 'global/env_train_steps': 27306880, 'global/optimizer_steps': 42666, 'global/running_reward': 22600.708575581397, 'global/running_step': 2362.69140625, 'global/steps_done': 27310464, 'global/episodes_done': 6755, 'global/unclipped_grad_norm': 0.6503777369856835, 'global/model_version': 42666, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:19,603] calculate_sps 34560 steps in 10.0466
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:19,603] calculate_sps 33920 steps in 10.0466
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:19,603] {'local/mean_episode_return': 46955.555555555555, 'local/mean_episode_step': 4714.555555555556, 'local/SPS': 3439.9803181732373, 'local/env_act_steps': 27346688, 'local/env_train_steps': 27344640, 'local/optimizer_steps': 42725, 'local/running_reward': 22808.29613095238, 'local/running_step': 2389.162047371032, 'local/steps_done': 27346688, 'local/episodes_done': 6764, 'local/unclipped_grad_norm': 0.6967551134667307, 'local/model_version': 42725, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:19,604] {'global/mean_episode_return': 47750.0, 'global/mean_episode_step': 4740.625, 'global/SPS': 3376.276978947807, 'global/env_act_steps': 27343104, 'global/env_train_steps': 27340800, 'global/optimizer_steps': 42720, 'global/running_reward': 22846.678921568626, 'global/running_step': 2392.2488357843135, 'global/steps_done': 27343104, 'global/episodes_done': 6763, 'global/unclipped_grad_norm': 0.6826977983668998, 'global/model_version': 42720, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:29,634] calculate_sps 32000 steps in 10.0312
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:29,635] calculate_sps 30720 steps in 10.0312
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:29,635] {'local/mean_episode_return': 45000.0, 'local/mean_episode_step': 4666.2, 'local/SPS': 3190.0328206741965, 'local/env_act_steps': 27379840, 'local/env_train_steps': 27376640, 'local/optimizer_steps': 42776, 'local/running_reward': 22701.170366795366, 'local/running_step': 2380.4345439189187, 'local/steps_done': 27379840, 'local/episodes_done': 6769, 'local/unclipped_grad_norm': 0.6420209288012748, 'local/model_version': 42776, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:29,636] {'global/mean_episode_return': 44266.666666666664, 'global/mean_episode_step': 4639.5, 'global/SPS': 3062.4315078472287, 'global/env_act_steps': 27376768, 'global/env_train_steps': 27371520, 'global/optimizer_steps': 42768, 'global/running_reward': 22674.51283269962, 'global/running_step': 2377.739900190114, 'global/steps_done': 27376768, 'global/episodes_done': 6769, 'global/unclipped_grad_norm': 0.6083639422431588, 'global/model_version': 42768, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:39,643] calculate_sps 32000 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:39,644] calculate_sps 35840 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:39,644] {'local/mean_episode_return': 43285.71428571428, 'local/mean_episode_step': 4444.0, 'local/SPS': 3197.203907096, 'local/env_act_steps': 27412864, 'local/env_train_steps': 27408640, 'local/optimizer_steps': 42826, 'local/running_reward': 22870.391230620156, 'local/running_step': 2397.747789486434, 'local/steps_done': 27412864, 'local/episodes_done': 6776, 'local/unclipped_grad_norm': 0.7087921345233917, 'local/model_version': 42826, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:39,645] {'global/mean_episode_return': 43285.71428571428, 'global/mean_episode_step': 4444.0, 'global/SPS': 3580.86837594752, 'global/env_act_steps': 27409280, 'global/env_train_steps': 27407360, 'global/optimizer_steps': 42824, 'global/running_reward': 22863.98252952756, 'global/running_step': 2397.0038447342517, 'global/steps_done': 27409280, 'global/episodes_done': 6776, 'global/unclipped_grad_norm': 0.7355525781001363, 'global/model_version': 42824, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:49,670] calculate_sps 34560 steps in 10.0264
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:49,670] calculate_sps 30720 steps in 10.0264
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:49,670] {'local/mean_episode_return': 43933.333333333336, 'local/mean_episode_step': 4596.75, 'local/SPS': 3446.8907269803967, 'local/env_act_steps': 27444864, 'local/env_train_steps': 27443200, 'local/optimizer_steps': 42880, 'local/running_reward': 22304.275, 'local/running_step': 2346.1615625, 'local/steps_done': 27444864, 'local/episodes_done': 6788, 'local/unclipped_grad_norm': 0.761943534568504, 'local/model_version': 42880, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:49,683] {'global/mean_episode_return': 43933.333333333336, 'global/mean_episode_step': 4596.75, 'global/SPS': 3063.9028684270193, 'global/env_act_steps': 27442560, 'global/env_train_steps': 27438080, 'global/optimizer_steps': 42872, 'global/running_reward': 22397.415865384617, 'global/running_step': 2354.556610576923, 'global/steps_done': 27442560, 'global/episodes_done': 6788, 'global/unclipped_grad_norm': 0.771083909397324, 'global/model_version': 42872, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 13:35:52,386] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 27444864, 'env_train_steps': 27443200, 'optimizer_steps': 42880, 'running_reward': 21971.180555555555, 'running_step': 2318.109375, 'steps_done': 27444864, 'episodes_done': 6788, 'unclipped_grad_norm': 0.6590235717594624, 'model_version': 42880, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 13:35:52,467] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:59,672] calculate_sps 30720 steps in 10.0022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:35:59,672] calculate_sps 35200 steps in 10.0022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:59,672] {'local/mean_episode_return': 39966.666666666664, 'local/mean_episode_step': 4037.8333333333335, 'local/SPS': 3071.327564215131, 'local/env_act_steps': 27477760, 'local/env_train_steps': 27473920, 'local/optimizer_steps': 42928, 'local/running_reward': 22052.480544747083, 'local/running_step': 2333.616093142023, 'local/steps_done': 27477760, 'local/episodes_done': 6794, 'local/unclipped_grad_norm': 0.7218618762368957, 'local/model_version': 42928, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:35:59,674] {'global/mean_episode_return': 39966.666666666664, 'global/mean_episode_step': 4037.8333333333335, 'global/SPS': 3519.229500663171, 'global/env_act_steps': 27474816, 'global/env_train_steps': 27473280, 'global/optimizer_steps': 42926, 'global/running_reward': 22029.842509920636, 'global/running_step': 2330.5861235119046, 'global/steps_done': 27474816, 'global/episodes_done': 6794, 'global/unclipped_grad_norm': 0.7271709709807679, 'global/model_version': 42926, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:09,674] calculate_sps 33280 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:09,675] calculate_sps 31360 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:09,690] {'local/mean_episode_return': 44800.0, 'local/mean_episode_step': 4709.833333333333, 'local/SPS': 3327.5950688068583, 'local/env_act_steps': 27510400, 'local/env_train_steps': 27507200, 'local/optimizer_steps': 42979, 'local/running_reward': 22230.992647058825, 'local/running_step': 2353.6146446078433, 'local/steps_done': 27510400, 'local/episodes_done': 6800, 'local/unclipped_grad_norm': 0.8098599621478249, 'local/model_version': 42979, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:09,692] {'global/mean_episode_return': 44800.0, 'global/mean_episode_step': 4709.833333333333, 'global/SPS': 3135.618430221847, 'global/env_act_steps': 27508352, 'global/env_train_steps': 27504640, 'global/optimizer_steps': 42976, 'global/running_reward': 22221.147423664122, 'global/running_step': 2352.7326753339694, 'global/steps_done': 27508352, 'global/episodes_done': 6800, 'global/unclipped_grad_norm': 0.7907600620388985, 'global/model_version': 42976, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:19,676] calculate_sps 33280 steps in 10.0028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:19,676] calculate_sps 32640 steps in 10.0028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:19,676] {'local/mean_episode_return': 38575.0, 'local/mean_episode_step': 4108.125, 'local/SPS': 3327.07381739874, 'local/env_act_steps': 27542656, 'local/env_train_steps': 27540480, 'local/optimizer_steps': 43032, 'local/running_reward': 22315.91021825397, 'local/running_step': 2359.0197792658732, 'local/steps_done': 27542656, 'local/episodes_done': 6808, 'local/unclipped_grad_norm': 0.7772028041335771, 'local/model_version': 43032, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:19,678] {'global/mean_episode_return': 38575.0, 'global/mean_episode_step': 4108.125, 'global/SPS': 3263.0916286026104, 'global/env_act_steps': 27540992, 'global/env_train_steps': 27537280, 'global/optimizer_steps': 43027, 'global/running_reward': 22318.033088235294, 'global/running_step': 2359.4928921568626, 'global/steps_done': 27540992, 'global/episodes_done': 6808, 'global/unclipped_grad_norm': 0.7838959144610985, 'global/model_version': 43027, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:29,682] calculate_sps 30720 steps in 10.0066
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:29,683] calculate_sps 33920 steps in 10.0066
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:29,683] {'local/mean_episode_return': 48900.0, 'local/mean_episode_step': 4902.75, 'local/SPS': 3069.9650695594814, 'local/env_act_steps': 27576064, 'local/env_train_steps': 27571200, 'local/optimizer_steps': 43080, 'local/running_reward': 22351.394875478927, 'local/running_step': 2363.43286039272, 'local/steps_done': 27576064, 'local/episodes_done': 6816, 'local/unclipped_grad_norm': 0.7223860453814268, 'local/model_version': 43080, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:29,695] {'global/mean_episode_return': 48900.0, 'global/mean_episode_step': 4902.75, 'global/SPS': 3389.7530976385938, 'global/env_act_steps': 27574144, 'global/env_train_steps': 27571200, 'global/optimizer_steps': 43080, 'global/running_reward': 22363.109314671816, 'global/running_step': 2364.2371802606176, 'global/steps_done': 27574144, 'global/episodes_done': 6816, 'global/unclipped_grad_norm': 0.7227692137349326, 'global/model_version': 43080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:39,685] calculate_sps 35200 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:39,686] calculate_sps 32000 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:39,686] {'local/mean_episode_return': 37400.0, 'local/mean_episode_step': 3917.0, 'local/SPS': 3518.8202655178616, 'local/env_act_steps': 27607936, 'local/env_train_steps': 27606400, 'local/optimizer_steps': 43134, 'local/running_reward': 22381.76455823293, 'local/running_step': 2372.8485190763054, 'local/steps_done': 27607936, 'local/episodes_done': 6820, 'local/unclipped_grad_norm': 0.835235433170089, 'local/model_version': 43134, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:39,687] {'global/mean_episode_return': 37400.0, 'global/mean_episode_step': 3917.0, 'global/SPS': 3198.927514107147, 'global/env_act_steps': 27607296, 'global/env_train_steps': 27603200, 'global/optimizer_steps': 43129, 'global/running_reward': 22364.82866795367, 'global/running_step': 2370.935448841699, 'global/steps_done': 27607296, 'global/episodes_done': 6820, 'global/unclipped_grad_norm': 0.8215085410950135, 'global/model_version': 43129, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:49,686] calculate_sps 31360 steps in 10.0007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:49,687] calculate_sps 34560 steps in 10.0007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:49,687] {'local/mean_episode_return': 40920.0, 'local/mean_episode_step': 4275.6, 'local/SPS': 3135.7917847604617, 'local/env_act_steps': 27641216, 'local/env_train_steps': 27637760, 'local/optimizer_steps': 43184, 'local/running_reward': 23028.07091346154, 'local/running_step': 2438.259645432692, 'local/steps_done': 27641216, 'local/episodes_done': 6825, 'local/unclipped_grad_norm': 0.6683317598700523, 'local/model_version': 43184, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:49,689] {'global/mean_episode_return': 40920.0, 'global/mean_episode_step': 4275.6, 'global/SPS': 3455.7705383074476, 'global/env_act_steps': 27640192, 'global/env_train_steps': 27637760, 'global/optimizer_steps': 43184, 'global/running_reward': 23014.725194552528, 'global/running_step': 2436.958931177043, 'global/steps_done': 27640192, 'global/episodes_done': 6825, 'global/unclipped_grad_norm': 0.6957342340187593, 'global/model_version': 43184, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:59,706] calculate_sps 33280 steps in 10.0195
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:36:59,706] calculate_sps 31360 steps in 10.0195
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:59,706] {'local/mean_episode_return': 42685.71428571428, 'local/mean_episode_step': 4499.571428571428, 'local/SPS': 3321.5183612149067, 'local/env_act_steps': 27674112, 'local/env_train_steps': 27671040, 'local/optimizer_steps': 43235, 'local/running_reward': 23314.731274319067, 'local/running_step': 2460.90670598249, 'local/steps_done': 27674112, 'local/episodes_done': 6832, 'local/unclipped_grad_norm': 0.7422854251721326, 'local/model_version': 43235, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:36:59,707] {'global/mean_episode_return': 42685.71428571428, 'global/mean_episode_step': 4499.571428571428, 'global/SPS': 3129.8923019140466, 'global/env_act_steps': 27673728, 'global/env_train_steps': 27669120, 'global/optimizer_steps': 43232, 'global/running_reward': 23307.48449427481, 'global/running_step': 2460.428345658397, 'global/steps_done': 27673728, 'global/episodes_done': 6832, 'global/unclipped_grad_norm': 0.7589974769701561, 'global/model_version': 43232, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:09,716] calculate_sps 33280 steps in 10.01
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:09,716] calculate_sps 35200 steps in 10.01
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:09,717] {'local/mean_episode_return': 38700.0, 'local/mean_episode_step': 4138.8, 'local/SPS': 3324.6671715761163, 'local/env_act_steps': 27706752, 'local/env_train_steps': 27704320, 'local/optimizer_steps': 43288, 'local/running_reward': 23108.817401960783, 'local/running_step': 2436.0905024509802, 'local/steps_done': 27706752, 'local/episodes_done': 6842, 'local/unclipped_grad_norm': 0.7142176150151018, 'local/model_version': 43288, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:09,718] {'global/mean_episode_return': 38700.0, 'global/mean_episode_step': 4138.8, 'global/SPS': 3516.4748930132, 'global/env_act_steps': 27706240, 'global/env_train_steps': 27704320, 'global/optimizer_steps': 43288, 'global/running_reward': 23115.69881889764, 'global/running_step': 2436.849778543307, 'global/steps_done': 27706240, 'global/episodes_done': 6842, 'global/unclipped_grad_norm': 0.7013966318752084, 'global/model_version': 43288, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:19,746] calculate_sps 30720 steps in 10.0302
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:19,747] calculate_sps 30720 steps in 10.0302
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:19,747] {'local/mean_episode_return': 40800.0, 'local/mean_episode_step': 4329.857142857143, 'local/SPS': 3062.73811585572, 'local/env_act_steps': 27739904, 'local/env_train_steps': 27735040, 'local/optimizer_steps': 43336, 'local/running_reward': 23531.52750965251, 'local/running_step': 2469.9070945945946, 'local/steps_done': 27739904, 'local/episodes_done': 6849, 'local/unclipped_grad_norm': 0.7183463747302691, 'local/model_version': 43336, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:19,759] {'global/mean_episode_return': 40800.0, 'global/mean_episode_step': 4329.857142857143, 'global/SPS': 3062.73811585572, 'global/env_act_steps': 27739648, 'global/env_train_steps': 27735040, 'global/optimizer_steps': 43336, 'global/running_reward': 23526.610392720308, 'global/running_step': 2469.5014667145592, 'global/steps_done': 27739648, 'global/episodes_done': 6849, 'global/unclipped_grad_norm': 0.7183463747302691, 'global/model_version': 43336, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:29,757] calculate_sps 35200 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:29,757] calculate_sps 26240 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:29,757] {'local/mean_episode_return': 47960.0, 'local/mean_episode_step': 4785.15, 'local/SPS': 3518.3398565268394, 'local/env_act_steps': 27771904, 'local/env_train_steps': 27770240, 'local/optimizer_steps': 43390, 'local/running_reward': 22653.4875, 'local/running_step': 2380.4363125, 'local/steps_done': 27771904, 'local/episodes_done': 6860, 'local/unclipped_grad_norm': 0.7433233873711692, 'local/model_version': 43390, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:29,759] {'global/mean_episode_return': 47960.0, 'global/mean_episode_step': 4785.15, 'global/SPS': 2622.7624385018257, 'global/env_act_steps': 27765888, 'global/env_train_steps': 27761280, 'global/optimizer_steps': 43376, 'global/running_reward': 22736.72256097561, 'global/running_step': 2388.3298780487803, 'global/steps_done': 27765888, 'global/episodes_done': 6860, 'global/unclipped_grad_norm': 0.74647815823555, 'global/model_version': 43376, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:39,753] calculate_sps 31360 steps in 10.0025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:39,754] calculate_sps 35200 steps in 10.0025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:39,754] {'local/mean_episode_return': 38533.333333333336, 'local/mean_episode_step': 4068.5833333333335, 'local/SPS': 3135.222679599639, 'local/env_act_steps': 27804544, 'local/env_train_steps': 27801600, 'local/optimizer_steps': 43440, 'local/running_reward': 22495.091911764706, 'local/running_step': 2365.4110600490194, 'local/steps_done': 27804544, 'local/episodes_done': 6867, 'local/unclipped_grad_norm': 0.675355059504509, 'local/model_version': 43440, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:39,755] {'global/mean_episode_return': 40360.0, 'global/mean_episode_step': 4197.9, 'global/SPS': 3519.127497509799, 'global/env_act_steps': 27798016, 'global/env_train_steps': 27796480, 'global/optimizer_steps': 43432, 'global/running_reward': 22469.64641434263, 'global/running_step': 2363.3199389940237, 'global/steps_done': 27798016, 'global/episodes_done': 6866, 'global/unclipped_grad_norm': 0.7198754386710269, 'global/model_version': 43432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:49,771] calculate_sps 31360 steps in 10.0178
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:49,771] calculate_sps 30720 steps in 10.0178
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:49,771] {'local/mean_episode_return': 49714.28571428572, 'local/mean_episode_step': 4922.0, 'local/SPS': 3130.4304170741143, 'local/env_act_steps': 27837568, 'local/env_train_steps': 27832960, 'local/optimizer_steps': 43488, 'local/running_reward': 22575.14534883721, 'local/running_step': 2369.982043362403, 'local/steps_done': 27837568, 'local/episodes_done': 6874, 'local/unclipped_grad_norm': 0.7311275598282615, 'local/model_version': 43488, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:49,772] {'global/mean_episode_return': 47175.0, 'global/mean_episode_step': 4734.5, 'global/SPS': 3066.5440820317854, 'global/env_act_steps': 27831424, 'global/env_train_steps': 27827200, 'global/optimizer_steps': 43480, 'global/running_reward': 22587.82327586207, 'global/running_step': 2371.2864583333335, 'global/steps_done': 27831424, 'global/episodes_done': 6874, 'global/unclipped_grad_norm': 0.6713161040097475, 'global/model_version': 43480, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:59,772] calculate_sps 35200 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:37:59,773] calculate_sps 34560 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:59,782] {'local/mean_episode_return': 49680.0, 'local/mean_episode_step': 5034.2, 'local/SPS': 3519.6338805527485, 'local/env_act_steps': 27869696, 'local/env_train_steps': 27868160, 'local/optimizer_steps': 43544, 'local/running_reward': 22564.436005976095, 'local/running_step': 2373.4821650896415, 'local/steps_done': 27869696, 'local/episodes_done': 6879, 'local/unclipped_grad_norm': 0.7631053727652345, 'local/model_version': 43544, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:37:59,784] {'global/mean_episode_return': 49680.0, 'global/mean_episode_step': 5034.2, 'global/SPS': 3455.640537269971, 'global/env_act_steps': 27863808, 'global/env_train_steps': 27861760, 'global/optimizer_steps': 43533, 'global/running_reward': 22516.39081027668, 'global/running_step': 2368.283998270751, 'global/steps_done': 27863808, 'global/episodes_done': 6879, 'global/unclipped_grad_norm': 0.727617251985478, 'global/model_version': 43533, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:09,781] calculate_sps 30720 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:09,782] calculate_sps 32000 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:09,782] {'local/mean_episode_return': 45571.42857142857, 'local/mean_episode_step': 4756.428571428572, 'local/SPS': 3069.2497300659466, 'local/env_act_steps': 27903104, 'local/env_train_steps': 27898880, 'local/optimizer_steps': 43592, 'local/running_reward': 22915.84051724138, 'local/running_step': 2408.09686302682, 'local/steps_done': 27903104, 'local/episodes_done': 6886, 'local/unclipped_grad_norm': 0.6327878832817078, 'local/model_version': 43592, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:09,783] {'global/mean_episode_return': 45320.0, 'global/mean_episode_step': 4733.4, 'global/SPS': 3197.135135485361, 'global/env_act_steps': 27897600, 'global/env_train_steps': 27893760, 'global/optimizer_steps': 43584, 'global/running_reward': 22850.278172348484, 'global/running_step': 2402.111298532197, 'global/steps_done': 27897600, 'global/episodes_done': 6884, 'global/unclipped_grad_norm': 0.6944915295815935, 'global/model_version': 43584, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:19,783] calculate_sps 34560 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:19,783] calculate_sps 33920 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:19,798] {'local/mean_episode_return': 46925.0, 'local/mean_episode_step': 4830.75, 'local/SPS': 3455.9363903309504, 'local/env_act_steps': 27935616, 'local/env_train_steps': 27933440, 'local/optimizer_steps': 43645, 'local/running_reward': 22439.991387795275, 'local/running_step': 2357.562899852362, 'local/steps_done': 27935616, 'local/episodes_done': 6894, 'local/unclipped_grad_norm': 0.7582476063157028, 'local/model_version': 43645, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:19,800] {'global/mean_episode_return': 46780.0, 'global/mean_episode_step': 4827.4, 'global/SPS': 3391.9375682877844, 'global/env_act_steps': 27930240, 'global/env_train_steps': 27927680, 'global/optimizer_steps': 43636, 'global/running_reward': 22536.985294117647, 'global/running_step': 2367.2283394607844, 'global/steps_done': 27930240, 'global/episodes_done': 6894, 'global/unclipped_grad_norm': 0.7448784872316397, 'global/model_version': 43636, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:29,811] calculate_sps 32000 steps in 10.0294
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:29,811] calculate_sps 32640 steps in 10.0294
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:29,811] {'local/mean_episode_return': 45160.0, 'local/mean_episode_step': 4577.0, 'local/SPS': 3190.6171162556516, 'local/env_act_steps': 27968640, 'local/env_train_steps': 27965440, 'local/optimizer_steps': 43696, 'local/running_reward': 21843.392684108527, 'local/running_step': 2300.2759508236436, 'local/steps_done': 27968640, 'local/episodes_done': 6904, 'local/unclipped_grad_norm': 0.7479479920630362, 'local/model_version': 43696, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:29,813] {'global/mean_episode_return': 45160.0, 'global/mean_episode_step': 4577.0, 'global/SPS': 3254.4294585807647, 'global/env_act_steps': 27963648, 'global/env_train_steps': 27960320, 'global/optimizer_steps': 43688, 'global/running_reward': 21923.347701149425, 'global/running_step': 2307.832465277778, 'global/steps_done': 27963648, 'global/episodes_done': 6904, 'global/unclipped_grad_norm': 0.716362415597989, 'global/model_version': 43688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:39,817] calculate_sps 31360 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:39,817] calculate_sps 32640 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:39,817] {'local/mean_episode_return': 40600.0, 'local/mean_episode_step': 4287.888888888889, 'local/SPS': 3134.130268869694, 'local/env_act_steps': 28001536, 'local/env_train_steps': 27996800, 'local/optimizer_steps': 43745, 'local/running_reward': 21802.857490272374, 'local/running_step': 2294.1060311284045, 'local/steps_done': 28001536, 'local/episodes_done': 6913, 'local/unclipped_grad_norm': 0.7751693135621597, 'local/model_version': 43745, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:39,819] {'global/mean_episode_return': 44085.71428571428, 'global/mean_episode_step': 4575.857142857143, 'global/SPS': 3262.053953313355, 'global/env_act_steps': 27996544, 'global/env_train_steps': 27992960, 'global/optimizer_steps': 43738, 'global/running_reward': 21823.948200389106, 'global/running_step': 2297.107368677043, 'global/steps_done': 27996544, 'global/episodes_done': 6911, 'global/unclipped_grad_norm': 0.7712898099422455, 'global/model_version': 43738, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:49,848] calculate_sps 35200 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:49,849] calculate_sps 33920 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:49,849] {'local/mean_episode_return': 40300.0, 'local/mean_episode_step': 4173.333333333333, 'local/SPS': 3508.8700585018837, 'local/env_act_steps': 28033920, 'local/env_train_steps': 28032000, 'local/optimizer_steps': 43800, 'local/running_reward': 22092.644515810276, 'local/running_step': 2320.062932312253, 'local/steps_done': 28033920, 'local/episodes_done': 6919, 'local/unclipped_grad_norm': 0.6768305748701096, 'local/model_version': 43800, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:49,851] {'global/mean_episode_return': 37325.0, 'global/mean_episode_step': 3950.0, 'global/SPS': 3381.27478364727, 'global/env_act_steps': 28029312, 'global/env_train_steps': 28026880, 'global/optimizer_steps': 43792, 'global/running_reward': 22057.58056640625, 'global/running_step': 2316.342559814453, 'global/steps_done': 28029312, 'global/episodes_done': 6919, 'global/unclipped_grad_norm': 0.7113840041889085, 'global/model_version': 43792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:59,862] calculate_sps 30720 steps in 10.0133
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:38:59,862] calculate_sps 31360 steps in 10.0133
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:59,862] {'local/mean_episode_return': 45266.666666666664, 'local/mean_episode_step': 4670.444444444444, 'local/SPS': 3067.913548609407, 'local/env_act_steps': 28067200, 'local/env_train_steps': 28062720, 'local/optimizer_steps': 43848, 'local/running_reward': 21771.61658653846, 'local/running_step': 2289.4943209134617, 'local/steps_done': 28067200, 'local/episodes_done': 6928, 'local/unclipped_grad_norm': 0.8242625712106625, 'local/model_version': 43848, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:38:59,875] {'global/mean_episode_return': 45266.666666666664, 'global/mean_episode_step': 4670.444444444444, 'global/SPS': 3131.828414205436, 'global/env_act_steps': 28062848, 'global/env_train_steps': 28058240, 'global/optimizer_steps': 43840, 'global/running_reward': 21819.62666984733, 'global/running_step': 2294.067539360687, 'global/steps_done': 28062848, 'global/episodes_done': 6928, 'global/unclipped_grad_norm': 0.8079721971104542, 'global/model_version': 43840, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:09,874] calculate_sps 34560 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:09,874] calculate_sps 35200 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:09,875] {'local/mean_episode_return': 43320.0, 'local/mean_episode_step': 4479.7, 'local/SPS': 3451.878456280457, 'local/env_act_steps': 28099456, 'local/env_train_steps': 28097280, 'local/optimizer_steps': 43902, 'local/running_reward': 21869.69246031746, 'local/running_step': 2296.6768353174602, 'local/steps_done': 28099456, 'local/episodes_done': 6938, 'local/unclipped_grad_norm': 0.7588220528430409, 'local/model_version': 43902, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:09,876] {'global/mean_episode_return': 41750.0, 'global/mean_episode_step': 4376.875, 'global/SPS': 3515.802131396762, 'global/env_act_steps': 28095488, 'global/env_train_steps': 28093440, 'global/optimizer_steps': 43896, 'global/running_reward': 21894.644607843136, 'global/running_step': 2299.8923100490197, 'global/steps_done': 28095488, 'global/episodes_done': 6936, 'global/unclipped_grad_norm': 0.7431587441159146, 'global/model_version': 43896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:19,887] calculate_sps 32000 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:19,888] calculate_sps 30720 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:19,888] {'local/mean_episode_return': 47685.71428571428, 'local/mean_episode_step': 4783.714285714285, 'local/SPS': 3195.6458861565097, 'local/env_act_steps': 28132352, 'local/env_train_steps': 28129280, 'local/optimizer_steps': 43952, 'local/running_reward': 21359.29596303502, 'local/running_step': 2246.7501215953307, 'local/steps_done': 28132352, 'local/episodes_done': 6945, 'local/unclipped_grad_norm': 0.6987212836742401, 'local/model_version': 43952, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:19,890] {'global/mean_episode_return': 48125.0, 'global/mean_episode_step': 4830.875, 'global/SPS': 3067.8200507102492, 'global/env_act_steps': 28128640, 'global/env_train_steps': 28124160, 'global/optimizer_steps': 43944, 'global/running_reward': 21372.249034749035, 'global/running_step': 2247.7472550675675, 'global/steps_done': 28128640, 'global/episodes_done': 6944, 'global/unclipped_grad_norm': 0.7126324403410157, 'global/model_version': 43944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:29,895] calculate_sps 31360 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:29,896] calculate_sps 35840 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:29,896] {'local/mean_episode_return': 48200.0, 'local/mean_episode_step': 4867.6, 'local/SPS': 3133.955977923106, 'local/env_act_steps': 28165376, 'local/env_train_steps': 28160640, 'local/optimizer_steps': 44000, 'local/running_reward': 21547.444282945737, 'local/running_step': 2267.7665637112405, 'local/steps_done': 28165376, 'local/episodes_done': 6950, 'local/unclipped_grad_norm': 0.8185962537924448, 'local/model_version': 44000, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:29,897] {'global/mean_episode_return': 49840.0, 'global/mean_episode_step': 4910.2, 'global/SPS': 3581.6639747692634, 'global/env_act_steps': 28161024, 'global/env_train_steps': 28160000, 'global/optimizer_steps': 43999, 'global/running_reward': 21525.981966403164, 'global/running_step': 2265.525506422925, 'global/steps_done': 28161024, 'global/episodes_done': 6949, 'global/unclipped_grad_norm': 0.8204059711911461, 'global/model_version': 43999, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:39,936] calculate_sps 35200 steps in 10.0421
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:39,936] calculate_sps 30720 steps in 10.0421
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:39,937] {'local/mean_episode_return': 44111.11111111111, 'local/mean_episode_step': 4606.888888888889, 'local/SPS': 3505.231292865866, 'local/env_act_steps': 28197248, 'local/env_train_steps': 28195840, 'local/optimizer_steps': 44056, 'local/running_reward': 21225.238453815262, 'local/running_step': 2232.125847138554, 'local/steps_done': 28197248, 'local/episodes_done': 6959, 'local/unclipped_grad_norm': 0.8137440692101207, 'local/model_version': 44056, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:39,938] {'global/mean_episode_return': 42022.22222222222, 'global/mean_episode_step': 4497.0, 'global/SPS': 3059.1109465011195, 'global/env_act_steps': 28194304, 'global/env_train_steps': 28190720, 'global/optimizer_steps': 44048, 'global/running_reward': 21257.415865384617, 'global/running_step': 2235.457782451923, 'global/steps_done': 28194304, 'global/episodes_done': 6958, 'global/unclipped_grad_norm': 0.8443382996685651, 'global/model_version': 44048, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:49,949] calculate_sps 30720 steps in 10.0126
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:49,949] calculate_sps 32640 steps in 10.0126
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:49,949] {'local/mean_episode_return': 46900.0, 'local/mean_episode_step': 4800.5, 'local/SPS': 3068.1222594000565, 'local/env_act_steps': 28230272, 'local/env_train_steps': 28226560, 'local/optimizer_steps': 44104, 'local/running_reward': 21367.81128875969, 'local/running_step': 2245.8016593992247, 'local/steps_done': 28230272, 'local/episodes_done': 6965, 'local/unclipped_grad_norm': 0.7459417677794894, 'local/model_version': 44104, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:49,951] {'global/mean_episode_return': 47833.333333333336, 'global/mean_episode_step': 4835.333333333333, 'global/SPS': 3259.87990061256, 'global/env_act_steps': 28227072, 'global/env_train_steps': 28223360, 'global/optimizer_steps': 44099, 'global/running_reward': 21347.283935546875, 'global/running_step': 2244.2456665039062, 'global/steps_done': 28227072, 'global/episodes_done': 6964, 'global/unclipped_grad_norm': 0.7371449616609835, 'global/model_version': 44099, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:59,994] calculate_sps 33920 steps in 10.046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:39:59,994] calculate_sps 33920 steps in 10.046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:59,995] {'local/mean_episode_return': 46400.0, 'local/mean_episode_step': 4782.857142857143, 'local/SPS': 3376.478822330991, 'local/env_act_steps': 28263040, 'local/env_train_steps': 28260480, 'local/optimizer_steps': 44156, 'local/running_reward': 21591.241455078125, 'local/running_step': 2263.9048767089844, 'local/steps_done': 28263040, 'local/episodes_done': 6972, 'local/unclipped_grad_norm': 0.62800054366772, 'local/model_version': 44156, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:39:59,995] {'global/mean_episode_return': 47225.0, 'global/mean_episode_step': 4833.5, 'global/SPS': 3376.478822330991, 'global/env_act_steps': 28260096, 'global/env_train_steps': 28257280, 'global/optimizer_steps': 44152, 'global/running_reward': 21608.89050387597, 'global/running_step': 2265.7265927810076, 'global/steps_done': 28260096, 'global/episodes_done': 6972, 'global/unclipped_grad_norm': 0.6302857806660095, 'global/model_version': 44152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:40:10,023] calculate_sps 32640 steps in 10.0288
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:40:10,024] calculate_sps 31360 steps in 10.0288
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:40:10,024] {'local/mean_episode_return': 45250.0, 'local/mean_episode_step': 4702.75, 'local/SPS': 3254.639825259168, 'local/env_act_steps': 28295680, 'local/env_train_steps': 28293120, 'local/optimizer_steps': 44208, 'local/running_reward': 21404.479166666668, 'local/running_step': 2247.079381127451, 'local/steps_done': 28295680, 'local/episodes_done': 6980, 'local/unclipped_grad_norm': 0.7004529593082575, 'local/model_version': 44208, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:40:10,025] {'global/mean_episode_return': 44171.42857142857, 'global/mean_episode_step': 4613.857142857143, 'global/SPS': 3127.006890935279, 'global/env_act_steps': 28293248, 'global/env_train_steps': 28288640, 'global/optimizer_steps': 44200, 'global/running_reward': 21407.613416988417, 'global/running_step': 2247.267314189189, 'global/steps_done': 28293248, 'global/episodes_done': 6979, 'global/unclipped_grad_norm': 0.7114799922953049, 'global/model_version': 44200, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:40:20,053] calculate_sps 30720 steps in 10.0298
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:40:20,053] calculate_sps 35200 steps in 10.0298
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:40:20,054] {'local/mean_episode_return': 40955.555555555555, 'local/mean_episode_step': 4203.888888888889, 'local/SPS': 3062.859407478502, 'local/env_act_steps': 28328704, 'local/env_train_steps': 28323840, 'local/optimizer_steps': 44256, 'local/running_reward': 21329.83890503876, 'local/running_step': 2238.8313650678297, 'local/steps_done': 28328704, 'local/episodes_done': 6989, 'local/unclipped_grad_norm': 0.7078033362825712, 'local/model_version': 44256, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:40:20,055] {'global/mean_episode_return': 40577.77777777778, 'global/mean_episode_step': 4195.777777777777, 'global/SPS': 3509.52640440245, 'global/env_act_steps': 28325504, 'global/env_train_steps': 28323840, 'global/optimizer_steps': 44256, 'global/running_reward': 21351.80431547619, 'global/running_step': 2241.1800595238096, 'global/steps_done': 28325504, 'global/episodes_done': 6988, 'global/unclipped_grad_norm': 0.7009990013071469, 'global/model_version': 44256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:40:30,075] calculate_sps 35840 steps in 10.0223
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:40:30,075] calculate_sps 30720 steps in 10.0223
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:40:30,076] {'local/mean_episode_return': 40100.0, 'local/mean_episode_step': 4191.333333333333, 'local/SPS': 3576.011595191406, 'local/env_act_steps': 28360704, 'local/env_train_steps': 28359680, 'local/optimizer_steps': 44311, 'local/running_reward': 21144.95625, 'local/running_step': 2219.22203125, 'local/steps_done': 28360704, 'local/episodes_done': 6995, 'local/unclipped_grad_norm': 0.7390398553826593, 'local/model_version': 44311, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:40:30,077] {'global/mean_episode_return': 41400.0, 'global/mean_episode_step': 4302.666666666667, 'global/SPS': 3065.152795878348, 'global/env_act_steps': 28359040, 'global/env_train_steps': 28354560, 'global/optimizer_steps': 44304, 'global/running_reward': 21125.69179389313, 'global/running_step': 2217.192300811069, 'global/steps_done': 28359040, 'global/episodes_done': 6994, 'global/unclipped_grad_norm': 0.6969719091430306, 'global/model_version': 44304, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:40:40,100] calculate_sps 30720 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:40:40,101] calculate_sps 35840 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:40:40,101] {'local/mean_episode_return': 43966.666666666664, 'local/mean_episode_step': 4540.833333333333, 'local/SPS': 3064.4375834239136, 'local/env_act_steps': 28394496, 'local/env_train_steps': 28390400, 'local/optimizer_steps': 44360, 'local/running_reward': 21509.339488636364, 'local/running_step': 2256.9456972064395, 'local/steps_done': 28394496, 'local/episodes_done': 7001, 'local/unclipped_grad_norm': 0.7644290188137366, 'local/model_version': 44360, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:40:40,102] {'global/mean_episode_return': 44600.0, 'global/mean_episode_step': 4567.857142857143, 'global/SPS': 3575.1771806612323, 'global/env_act_steps': 28391552, 'global/env_train_steps': 28390400, 'global/optimizer_steps': 44359, 'global/running_reward': 21504.33070866142, 'global/running_step': 2256.5111651082675, 'global/steps_done': 28391552, 'global/episodes_done': 7001, 'global/unclipped_grad_norm': 0.8070906313982877, 'global/model_version': 44359, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:40:50,142] calculate_sps 34560 steps in 10.0424
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:40:50,143] calculate_sps 30720 steps in 10.0424
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:40:50,143] {'local/mean_episode_return': 50233.333333333336, 'local/mean_episode_step': 4980.666666666667, 'local/SPS': 3441.392372820494, 'local/env_act_steps': 28427008, 'local/env_train_steps': 28424960, 'local/optimizer_steps': 44413, 'local/running_reward': 21621.967273622045, 'local/running_step': 2271.943590059055, 'local/steps_done': 28427008, 'local/episodes_done': 7007, 'local/unclipped_grad_norm': 0.6984193344723504, 'local/model_version': 44413, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:40:50,144] {'global/mean_episode_return': 50233.333333333336, 'global/mean_episode_step': 4980.666666666667, 'global/SPS': 3059.015442507106, 'global/env_act_steps': 28425216, 'global/env_train_steps': 28421120, 'global/optimizer_steps': 44408, 'global/running_reward': 21614.06844106464, 'global/running_step': 2270.6517050855514, 'global/steps_done': 28425216, 'global/episodes_done': 7007, 'global/unclipped_grad_norm': 0.6621690012362539, 'global/model_version': 44408, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:00,154] calculate_sps 32000 steps in 10.0112
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:00,154] calculate_sps 35200 steps in 10.0112
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:00,154] {'local/mean_episode_return': 41550.0, 'local/mean_episode_step': 4238.75, 'local/SPS': 3196.43098697705, 'local/env_act_steps': 28459904, 'local/env_train_steps': 28456960, 'local/optimizer_steps': 44464, 'local/running_reward': 22017.862354085602, 'local/running_step': 2313.7703064202333, 'local/steps_done': 28459904, 'local/episodes_done': 7011, 'local/unclipped_grad_norm': 0.60261698271714, 'local/model_version': 44464, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:00,156] {'global/mean_episode_return': 38066.666666666664, 'global/mean_episode_step': 4020.0, 'global/SPS': 3516.074085674755, 'global/env_act_steps': 28457856, 'global/env_train_steps': 28456320, 'global/optimizer_steps': 44462, 'global/running_reward': 21972.058823529413, 'global/running_step': 2309.335661764706, 'global/steps_done': 28457856, 'global/episodes_done': 7010, 'global/unclipped_grad_norm': 0.6249323509357594, 'global/model_version': 44462, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:10,168] calculate_sps 31360 steps in 10.0145
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:10,168] calculate_sps 31360 steps in 10.0145
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:10,168] {'local/mean_episode_return': 41520.0, 'local/mean_episode_step': 4417.4, 'local/SPS': 3131.4455477535816, 'local/env_act_steps': 28492928, 'local/env_train_steps': 28488320, 'local/optimizer_steps': 44512, 'local/running_reward': 22578.76090116279, 'local/running_step': 2367.9349563953488, 'local/steps_done': 28492928, 'local/episodes_done': 7016, 'local/unclipped_grad_norm': 0.8229451347142458, 'local/model_version': 44512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:10,169] {'global/mean_episode_return': 43266.666666666664, 'global/mean_episode_step': 4497.0, 'global/SPS': 3131.4455477535816, 'global/env_act_steps': 28491264, 'global/env_train_steps': 28487680, 'global/optimizer_steps': 44512, 'global/running_reward': 22556.36374521073, 'global/running_step': 2365.776430795019, 'global/steps_done': 28491264, 'global/episodes_done': 7016, 'global/unclipped_grad_norm': 0.8263601380586624, 'global/model_version': 44512, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:20,173] calculate_sps 35200 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:20,173] calculate_sps 33280 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:20,174] {'local/mean_episode_return': 41880.0, 'local/mean_episode_step': 4430.6, 'local/SPS': 3518.40760394226, 'local/env_act_steps': 28525056, 'local/env_train_steps': 28523520, 'local/optimizer_steps': 44568, 'local/running_reward': 22818.245766932272, 'local/running_step': 2385.9730141932273, 'local/steps_done': 28525056, 'local/episodes_done': 7021, 'local/unclipped_grad_norm': 0.7807280807090657, 'local/model_version': 44568, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:20,175] {'global/mean_episode_return': 41880.0, 'global/mean_episode_step': 4430.6, 'global/SPS': 3326.4944619090456, 'global/env_act_steps': 28524032, 'global/env_train_steps': 28520960, 'global/optimizer_steps': 44563, 'global/running_reward': 22805.908203125, 'global/running_step': 2384.9818115234375, 'global/steps_done': 28524032, 'global/episodes_done': 7021, 'global/unclipped_grad_norm': 0.7585244012229583, 'global/model_version': 44563, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:30,192] calculate_sps 30720 steps in 10.0189
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:30,192] calculate_sps 33280 steps in 10.0189
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:30,193] {'local/mean_episode_return': 47036.36363636364, 'local/mean_episode_step': 4720.727272727273, 'local/SPS': 3066.204679109183, 'local/env_act_steps': 28558336, 'local/env_train_steps': 28554240, 'local/optimizer_steps': 44616, 'local/running_reward': 22955.3125, 'local/running_step': 2396.6451322115386, 'local/steps_done': 28558336, 'local/episodes_done': 7032, 'local/unclipped_grad_norm': 0.7863376786311468, 'local/model_version': 44616, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:30,194] {'global/mean_episode_return': 46460.0, 'global/mean_episode_step': 4653.3, 'global/SPS': 3321.7217357016148, 'global/env_act_steps': 28556928, 'global/env_train_steps': 28554240, 'global/optimizer_steps': 44616, 'global/running_reward': 22980.842655642024, 'global/running_step': 2399.404790856031, 'global/steps_done': 28556928, 'global/episodes_done': 7031, 'global/unclipped_grad_norm': 0.8071742760685255, 'global/model_version': 44616, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:40,217] calculate_sps 34560 steps in 10.0257
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:40,217] calculate_sps 32000 steps in 10.0257
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:40,218] {'local/mean_episode_return': 41960.0, 'local/mean_episode_step': 4398.0, 'local/SPS': 3447.1541783483076, 'local/env_act_steps': 28590848, 'local/env_train_steps': 28588800, 'local/optimizer_steps': 44669, 'local/running_reward': 22937.303149606298, 'local/running_step': 2391.8019808070867, 'local/steps_done': 28590848, 'local/episodes_done': 7037, 'local/unclipped_grad_norm': 0.7405477517618323, 'local/model_version': 44669, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:40,219] {'global/mean_episode_return': 43766.666666666664, 'global/mean_episode_step': 4564.166666666667, 'global/SPS': 3191.809424396581, 'global/env_act_steps': 28590336, 'global/env_train_steps': 28586240, 'global/optimizer_steps': 44665, 'global/running_reward': 22918.57040229885, 'global/running_step': 2389.9786278735633, 'global/steps_done': 28590336, 'global/episodes_done': 7037, 'global/unclipped_grad_norm': 0.7256477940447477, 'global/model_version': 44665, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:50,223] calculate_sps 32000 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:41:50,223] calculate_sps 34560 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:50,224] {'local/mean_episode_return': 46280.0, 'local/mean_episode_step': 4663.0, 'local/SPS': 3198.2278343892326, 'local/env_act_steps': 28624000, 'local/env_train_steps': 28620800, 'local/optimizer_steps': 44720, 'local/running_reward': 23036.824324324323, 'local/running_step': 2399.541747104247, 'local/steps_done': 28624000, 'local/episodes_done': 7042, 'local/unclipped_grad_norm': 0.7397357564346463, 'local/model_version': 44720, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:41:50,225] {'global/mean_episode_return': 46280.0, 'global/mean_episode_step': 4663.0, 'global/SPS': 3454.0860611403714, 'global/env_act_steps': 28623232, 'global/env_train_steps': 28620800, 'global/optimizer_steps': 44720, 'global/running_reward': 23030.325875486382, 'global/running_step': 2398.7693336575876, 'global/steps_done': 28623232, 'global/episodes_done': 7042, 'global/unclipped_grad_norm': 0.7530693184245717, 'global/model_version': 44720, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:00,228] calculate_sps 31360 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:00,241] calculate_sps 30720 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:00,242] {'local/mean_episode_return': 42771.42857142857, 'local/mean_episode_step': 4464.571428571428, 'local/SPS': 3134.430656342907, 'local/env_act_steps': 28656896, 'local/env_train_steps': 28652160, 'local/optimizer_steps': 44769, 'local/running_reward': 23307.307879377433, 'local/running_step': 2429.4312074416343, 'local/steps_done': 28656896, 'local/episodes_done': 7049, 'local/unclipped_grad_norm': 0.7380472558493517, 'local/model_version': 44769, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:00,244] {'global/mean_episode_return': 42771.42857142857, 'global/mean_episode_step': 4464.571428571428, 'global/SPS': 3070.46268376448, 'global/env_act_steps': 28656640, 'global/env_train_steps': 28651520, 'global/optimizer_steps': 44768, 'global/running_reward': 23305.597461685822, 'global/running_step': 2429.2749341475096, 'global/steps_done': 28656640, 'global/episodes_done': 7049, 'global/unclipped_grad_norm': 0.7350606623416146, 'global/model_version': 44768, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:10,233] calculate_sps 35200 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:10,233] calculate_sps 28160 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:10,233] {'local/mean_episode_return': 42366.666666666664, 'local/mean_episode_step': 4336.083333333333, 'local/SPS': 3518.2750461566648, 'local/env_act_steps': 28689024, 'local/env_train_steps': 28687360, 'local/optimizer_steps': 44824, 'local/running_reward': 23026.45044820717, 'local/running_step': 2403.430247758964, 'local/steps_done': 28689024, 'local/episodes_done': 7061, 'local/unclipped_grad_norm': 0.6271526171402497, 'local/model_version': 44824, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:10,235] {'global/mean_episode_return': 42822.22222222222, 'global/mean_episode_step': 4343.888888888889, 'global/SPS': 2814.620036925332, 'global/env_act_steps': 28682752, 'global/env_train_steps': 28679680, 'global/optimizer_steps': 44811, 'global/running_reward': 23134.321384803923, 'global/running_step': 2414.648322610294, 'global/steps_done': 28682752, 'global/episodes_done': 7058, 'global/unclipped_grad_norm': 0.6856662391923195, 'global/model_version': 44811, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:20,235] calculate_sps 30720 steps in 10.0016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:20,235] calculate_sps 33280 steps in 10.0016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:20,235] {'local/mean_episode_return': 44080.0, 'local/mean_episode_step': 4432.0, 'local/SPS': 3071.513968510413, 'local/env_act_steps': 28722432, 'local/env_train_steps': 28718080, 'local/optimizer_steps': 44872, 'local/running_reward': 22894.546216475097, 'local/running_step': 2391.3767959770116, 'local/steps_done': 28722432, 'local/episodes_done': 7066, 'local/unclipped_grad_norm': 0.7513824353615443, 'local/model_version': 44872, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:20,236] {'global/mean_episode_return': 41971.42857142857, 'global/mean_episode_step': 4312.0, 'global/SPS': 3327.473465886281, 'global/env_act_steps': 28715904, 'global/env_train_steps': 28712960, 'global/optimizer_steps': 44864, 'global/running_reward': 22841.45752895753, 'global/running_step': 2385.245234073359, 'global/steps_done': 28715904, 'global/episodes_done': 7065, 'global/unclipped_grad_norm': 0.6669533061531355, 'global/model_version': 44864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:30,244] calculate_sps 34560 steps in 10.01
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:30,244] calculate_sps 32000 steps in 10.01
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:30,244] {'local/mean_episode_return': 41822.22222222222, 'local/mean_episode_step': 4345.777777777777, 'local/SPS': 3452.543590894183, 'local/env_act_steps': 28754688, 'local/env_train_steps': 28752640, 'local/optimizer_steps': 44925, 'local/running_reward': 22973.642113095237, 'local/running_step': 2400.5700954861113, 'local/steps_done': 28754688, 'local/episodes_done': 7075, 'local/unclipped_grad_norm': 0.6984258310974769, 'local/model_version': 44925, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:30,245] {'global/mean_episode_return': 40850.0, 'global/mean_episode_step': 4314.625, 'global/SPS': 3196.7996211983177, 'global/env_act_steps': 28749184, 'global/env_train_steps': 28744960, 'global/optimizer_steps': 44913, 'global/running_reward': 22987.16346153846, 'global/running_step': 2402.105829326923, 'global/steps_done': 28749184, 'global/episodes_done': 7073, 'global/unclipped_grad_norm': 0.7366477348366562, 'global/model_version': 44913, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:40,274] calculate_sps 32000 steps in 10.0297
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:40,275] calculate_sps 34560 steps in 10.0297
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:40,275] {'local/mean_episode_return': 44333.333333333336, 'local/mean_episode_step': 4545.166666666667, 'local/SPS': 3190.5220825566676, 'local/env_act_steps': 28788096, 'local/env_train_steps': 28784640, 'local/optimizer_steps': 44976, 'local/running_reward': 22317.109674329502, 'local/running_step': 2334.863864942529, 'local/steps_done': 28788096, 'local/episodes_done': 7087, 'local/unclipped_grad_norm': 0.6550114376872194, 'local/model_version': 44976, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:40,276] {'global/mean_episode_return': 43150.0, 'global/mean_episode_step': 4438.083333333333, 'global/SPS': 3445.763849161201, 'global/env_act_steps': 28781696, 'global/env_train_steps': 28779520, 'global/optimizer_steps': 44968, 'global/running_reward': 22495.226377952757, 'global/running_step': 2352.265409694882, 'global/steps_done': 28781696, 'global/episodes_done': 7085, 'global/unclipped_grad_norm': 0.6483488516374067, 'global/model_version': 44968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:50,311] calculate_sps 32640 steps in 10.0367
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:42:50,311] calculate_sps 30720 steps in 10.0367
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:50,311] {'local/mean_episode_return': 39880.0, 'local/mean_episode_step': 4208.3, 'local/SPS': 3252.0546439489044, 'local/env_act_steps': 28820864, 'local/env_train_steps': 28817280, 'local/optimizer_steps': 45026, 'local/running_reward': 21595.1904296875, 'local/running_step': 2260.4456481933594, 'local/steps_done': 28820864, 'local/episodes_done': 7097, 'local/unclipped_grad_norm': 0.701509783565998, 'local/model_version': 45026, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:42:50,312] {'global/mean_episode_return': 43309.09090909091, 'global/mean_episode_step': 4461.818181818182, 'global/SPS': 3060.75731195191, 'global/env_act_steps': 28815232, 'global/env_train_steps': 28810240, 'global/optimizer_steps': 45016, 'global/running_reward': 21648.65219465649, 'global/running_step': 2266.6012344942746, 'global/steps_done': 28815232, 'global/episodes_done': 7096, 'global/unclipped_grad_norm': 0.7278843369955817, 'global/model_version': 45016, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:00,351] calculate_sps 33920 steps in 10.0398
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:00,351] calculate_sps 35200 steps in 10.0398
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:00,351] {'local/mean_episode_return': 41700.0, 'local/mean_episode_step': 4374.25, 'local/SPS': 3378.5504130728064, 'local/env_act_steps': 28853376, 'local/env_train_steps': 28851200, 'local/optimizer_steps': 45080, 'local/running_reward': 21881.631397637797, 'local/running_step': 2290.226839320866, 'local/steps_done': 28853376, 'local/episodes_done': 7101, 'local/unclipped_grad_norm': 0.7453122668796115, 'local/model_version': 45080, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:00,353] {'global/mean_episode_return': 40600.0, 'global/mean_episode_step': 4232.25, 'global/SPS': 3506.042881490648, 'global/env_act_steps': 28847104, 'global/env_train_steps': 28845440, 'global/optimizer_steps': 45070, 'global/running_reward': 21789.64608433735, 'global/running_step': 2280.26546812249, 'global/steps_done': 28847104, 'global/episodes_done': 7100, 'global/unclipped_grad_norm': 0.7160690333004351, 'global/model_version': 45070, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:10,369] calculate_sps 30720 steps in 10.0181
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:10,369] calculate_sps 31360 steps in 10.0181
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:10,369] {'local/mean_episode_return': 40244.444444444445, 'local/mean_episode_step': 4145.888888888889, 'local/SPS': 3066.447967407872, 'local/env_act_steps': 28886400, 'local/env_train_steps': 28881920, 'local/optimizer_steps': 45128, 'local/running_reward': 21640.195009689924, 'local/running_step': 2269.012082122093, 'local/steps_done': 28886400, 'local/episodes_done': 7110, 'local/unclipped_grad_norm': 0.7126591087629398, 'local/model_version': 45128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:10,371] {'global/mean_episode_return': 41244.444444444445, 'global/mean_episode_step': 4236.111111111111, 'global/SPS': 3130.3323000622026, 'global/env_act_steps': 28880256, 'global/env_train_steps': 28876800, 'global/optimizer_steps': 45120, 'global/running_reward': 21681.2680984556, 'global/running_step': 2272.8369027509652, 'global/steps_done': 28880256, 'global/episodes_done': 7109, 'global/unclipped_grad_norm': 0.754510853588581, 'global/model_version': 45120, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:20,385] calculate_sps 33920 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:20,385] calculate_sps 32000 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:20,385] {'local/mean_episode_return': 40050.0, 'local/mean_episode_step': 4099.75, 'local/SPS': 3386.5276097820233, 'local/env_act_steps': 28918400, 'local/env_train_steps': 28915840, 'local/optimizer_steps': 45180, 'local/running_reward': 21925.26875, 'local/running_step': 2302.07825, 'local/steps_done': 28918400, 'local/episodes_done': 7118, 'local/unclipped_grad_norm': 0.6758372508562528, 'local/model_version': 45180, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:20,386] {'global/mean_episode_return': 41033.333333333336, 'global/mean_episode_step': 4280.666666666667, 'global/SPS': 3194.83736771889, 'global/env_act_steps': 28913024, 'global/env_train_steps': 28908800, 'global/optimizer_steps': 45170, 'global/running_reward': 21917.02880859375, 'global/running_step': 2300.3932189941406, 'global/steps_done': 28913024, 'global/episodes_done': 7115, 'global/unclipped_grad_norm': 0.6463367113471031, 'global/model_version': 45170, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:30,399] calculate_sps 32640 steps in 10.0135
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:30,399] calculate_sps 34560 steps in 10.0135
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:30,399] {'local/mean_episode_return': 46644.444444444445, 'local/mean_episode_step': 4766.222222222223, 'local/SPS': 3259.6133633543363, 'local/env_act_steps': 28951168, 'local/env_train_steps': 28948480, 'local/optimizer_steps': 45232, 'local/running_reward': 21273.919677734375, 'local/running_step': 2237.3948669433594, 'local/steps_done': 28951168, 'local/episodes_done': 7127, 'local/unclipped_grad_norm': 0.7461738540576055, 'local/model_version': 45232, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:30,400] {'global/mean_episode_return': 43766.666666666664, 'global/mean_episode_step': 4463.583333333333, 'global/SPS': 3451.3553259045916, 'global/env_act_steps': 28945408, 'global/env_train_steps': 28943360, 'global/optimizer_steps': 45224, 'global/running_reward': 21370.522480237156, 'global/running_step': 2247.190773221344, 'global/steps_done': 28945408, 'global/episodes_done': 7127, 'global/unclipped_grad_norm': 0.7494290415887479, 'global/model_version': 45224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:40,408] calculate_sps 30720 steps in 10.0094
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:40,408] calculate_sps 30720 steps in 10.0094
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:40,409] {'local/mean_episode_return': 38800.0, 'local/mean_episode_step': 4385.666666666667, 'local/SPS': 3069.102929992574, 'local/env_act_steps': 28984320, 'local/env_train_steps': 28979200, 'local/optimizer_steps': 45280, 'local/running_reward': 21841.849662162163, 'local/running_step': 2289.4432010135133, 'local/steps_done': 28984320, 'local/episodes_done': 7130, 'local/unclipped_grad_norm': 0.7175999768078327, 'local/model_version': 45280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:40,410] {'global/mean_episode_return': 38800.0, 'global/mean_episode_step': 4385.666666666667, 'global/SPS': 3069.102929992574, 'global/env_act_steps': 28979072, 'global/env_train_steps': 28974080, 'global/optimizer_steps': 45272, 'global/running_reward': 21680.792538022815, 'global/running_step': 2275.063272338403, 'global/steps_done': 28979072, 'global/episodes_done': 7130, 'global/unclipped_grad_norm': 0.6811826943109432, 'global/model_version': 45272, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:50,415] calculate_sps 35840 steps in 10.007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:43:50,415] calculate_sps 35840 steps in 10.007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:50,416] {'local/mean_episode_return': 45542.857142857145, 'local/mean_episode_step': 4704.0, 'local/SPS': 3581.4763266364635, 'local/env_act_steps': 29016192, 'local/env_train_steps': 29015040, 'local/optimizer_steps': 45336, 'local/running_reward': 22236.64031124498, 'local/running_step': 2323.2996987951806, 'local/steps_done': 29016192, 'local/episodes_done': 7137, 'local/unclipped_grad_norm': 0.773087143365826, 'local/model_version': 45336, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:43:50,417] {'global/mean_episode_return': 47960.0, 'global/mean_episode_step': 4912.0, 'global/SPS': 3581.4763266364635, 'global/env_act_steps': 29011328, 'global/env_train_steps': 29009920, 'global/optimizer_steps': 45328, 'global/running_reward': 22214.006696428572, 'global/running_step': 2320.812531001984, 'global/steps_done': 29011328, 'global/episodes_done': 7135, 'global/unclipped_grad_norm': 0.7917799348277705, 'global/model_version': 45328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:00,420] calculate_sps 30720 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:00,420] calculate_sps 30720 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:00,421] {'local/mean_episode_return': 49766.666666666664, 'local/mean_episode_step': 4961.666666666667, 'local/SPS': 3070.5709775571368, 'local/env_act_steps': 29049984, 'local/env_train_steps': 29045760, 'local/optimizer_steps': 45384, 'local/running_reward': 22372.194602272728, 'local/running_step': 2336.5569957386365, 'local/steps_done': 29049984, 'local/episodes_done': 7143, 'local/unclipped_grad_norm': 0.8073867900917927, 'local/model_version': 45384, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:00,422] {'global/mean_episode_return': 47200.0, 'global/mean_episode_step': 4767.25, 'global/SPS': 3070.5709775571368, 'global/env_act_steps': 29045248, 'global/env_train_steps': 29040640, 'global/optimizer_steps': 45376, 'global/running_reward': 22385.90212264151, 'global/running_step': 2337.914003537736, 'global/steps_done': 29045248, 'global/episodes_done': 7143, 'global/unclipped_grad_norm': 0.8247052269677321, 'global/model_version': 45376, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:10,448] calculate_sps 33920 steps in 10.0283
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:10,448] calculate_sps 35840 steps in 10.0283
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:10,448] {'local/mean_episode_return': 46866.666666666664, 'local/mean_episode_step': 4653.333333333333, 'local/SPS': 3382.4236929152016, 'local/env_act_steps': 29082240, 'local/env_train_steps': 29079680, 'local/optimizer_steps': 45436, 'local/running_reward': 21995.889136904763, 'local/running_step': 2304.5931609623017, 'local/steps_done': 29082240, 'local/episodes_done': 7152, 'local/unclipped_grad_norm': 0.7249619714342631, 'local/model_version': 45436, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:10,449] {'global/mean_episode_return': 46866.666666666664, 'global/mean_episode_step': 4653.333333333333, 'global/SPS': 3573.881637797194, 'global/env_act_steps': 29077504, 'global/env_train_steps': 29076480, 'global/optimizer_steps': 45431, 'global/running_reward': 22063.082837301587, 'global/running_step': 2309.7574094742063, 'global/steps_done': 29077504, 'global/episodes_done': 7152, 'global/unclipped_grad_norm': 0.6995032901113684, 'global/model_version': 45431, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:20,453] calculate_sps 32640 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:20,454] calculate_sps 30720 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:20,454] {'local/mean_episode_return': 43971.42857142857, 'local/mean_episode_step': 4501.428571428572, 'local/SPS': 3262.202729685841, 'local/env_act_steps': 29115008, 'local/env_train_steps': 29112320, 'local/optimizer_steps': 45488, 'local/running_reward': 21981.036376953125, 'local/running_step': 2309.2561645507812, 'local/steps_done': 29115008, 'local/episodes_done': 7159, 'local/unclipped_grad_norm': 0.719097145474874, 'local/model_version': 45488, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:20,455] {'global/mean_episode_return': 42133.333333333336, 'global/mean_episode_step': 4352.5, 'global/SPS': 3070.3084514690267, 'global/env_act_steps': 29111296, 'global/env_train_steps': 29107200, 'global/optimizer_steps': 45480, 'global/running_reward': 21959.635416666668, 'global/running_step': 2306.8049834280305, 'global/steps_done': 29111296, 'global/episodes_done': 7158, 'global/unclipped_grad_norm': 0.7262535943668715, 'global/model_version': 45480, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:30,470] calculate_sps 30720 steps in 10.0169
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:30,471] calculate_sps 33920 steps in 10.0169
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:30,471] {'local/mean_episode_return': 45200.0, 'local/mean_episode_step': 4538.25, 'local/SPS': 3066.828885259073, 'local/env_act_steps': 29148032, 'local/env_train_steps': 29143040, 'local/optimizer_steps': 45536, 'local/running_reward': 21875.084786821706, 'local/running_step': 2302.3580123546512, 'local/steps_done': 29148032, 'local/episodes_done': 7167, 'local/unclipped_grad_norm': 0.730680336865286, 'local/model_version': 45536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:30,483] {'global/mean_episode_return': 45725.0, 'global/mean_episode_step': 4611.625, 'global/SPS': 3386.2902274735598, 'global/env_act_steps': 29143680, 'global/env_train_steps': 29141120, 'global/optimizer_steps': 45532, 'global/running_reward': 21900.457015810276, 'global/running_step': 2304.37132534585, 'global/steps_done': 29143680, 'global/episodes_done': 7166, 'global/unclipped_grad_norm': 0.7315323261114267, 'global/model_version': 45532, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:40,498] calculate_sps 35840 steps in 10.0273
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:40,498] calculate_sps 32640 steps in 10.0273
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:40,498] {'local/mean_episode_return': 41500.0, 'local/mean_episode_step': 4378.1875, 'local/SPS': 3574.2472050220213, 'local/env_act_steps': 29180288, 'local/env_train_steps': 29178880, 'local/optimizer_steps': 45592, 'local/running_reward': 21536.85515873016, 'local/running_step': 2272.97994171627, 'local/steps_done': 29180288, 'local/episodes_done': 7176, 'local/unclipped_grad_norm': 0.721479383962495, 'local/model_version': 45592, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:40,499] {'global/mean_episode_return': 46400.0, 'global/mean_episode_step': 4745.5, 'global/SPS': 3255.1179902879126, 'global/env_act_steps': 29177344, 'global/env_train_steps': 29173760, 'global/optimizer_steps': 45584, 'global/running_reward': 21568.714353612166, 'global/running_step': 2276.168399477186, 'global/steps_done': 29177344, 'global/episodes_done': 7174, 'global/unclipped_grad_norm': 0.7245520576834679, 'global/model_version': 45584, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:50,515] calculate_sps 30720 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:44:50,515] calculate_sps 32640 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:50,515] {'local/mean_episode_return': 44100.0, 'local/mean_episode_step': 4431.5, 'local/SPS': 3066.7585918984355, 'local/env_act_steps': 29213568, 'local/env_train_steps': 29209600, 'local/optimizer_steps': 45640, 'local/running_reward': 21383.076923076922, 'local/running_step': 2256.406159855769, 'local/steps_done': 29213568, 'local/episodes_done': 7184, 'local/unclipped_grad_norm': 0.7972442333896955, 'local/model_version': 45640, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:44:50,517] {'global/mean_episode_return': 42355.555555555555, 'global/mean_episode_step': 4325.222222222223, 'global/SPS': 3258.431003892088, 'global/env_act_steps': 29210112, 'global/env_train_steps': 29206400, 'global/optimizer_steps': 45634, 'global/running_reward': 21402.508544921875, 'global/running_step': 2258.1778869628906, 'global/steps_done': 29210112, 'global/episodes_done': 7183, 'global/unclipped_grad_norm': 0.7873582863807678, 'global/model_version': 45634, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:00,517] calculate_sps 33280 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:00,517] calculate_sps 33920 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:00,518] {'local/mean_episode_return': 43550.0, 'local/mean_episode_step': 4392.5, 'local/SPS': 3327.227431584449, 'local/env_act_steps': 29246080, 'local/env_train_steps': 29242880, 'local/optimizer_steps': 45692, 'local/running_reward': 21645.27559055118, 'local/running_step': 2287.783280019685, 'local/steps_done': 29246080, 'local/episodes_done': 7188, 'local/unclipped_grad_norm': 0.6895140332098191, 'local/model_version': 45692, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:00,519] {'global/mean_episode_return': 41100.0, 'global/mean_episode_step': 4118.5, 'global/SPS': 3391.212574499534, 'global/env_act_steps': 29243008, 'global/env_train_steps': 29240320, 'global/optimizer_steps': 45688, 'global/running_reward': 21585.244406614787, 'global/running_step': 2280.966530885214, 'global/steps_done': 29243008, 'global/episodes_done': 7187, 'global/unclipped_grad_norm': 0.6987791411854603, 'global/model_version': 45688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:10,532] calculate_sps 33280 steps in 10.0145
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:10,532] calculate_sps 30720 steps in 10.0145
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:10,532] {'local/mean_episode_return': 42044.444444444445, 'local/mean_episode_step': 4344.777777777777, 'local/SPS': 3323.1814192682355, 'local/env_act_steps': 29278336, 'local/env_train_steps': 29276160, 'local/optimizer_steps': 45744, 'local/running_reward': 21790.321180555555, 'local/running_step': 2304.0318390376983, 'local/steps_done': 29278336, 'local/episodes_done': 7197, 'local/unclipped_grad_norm': 0.6016050006907719, 'local/model_version': 45744, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:10,533] {'global/mean_episode_return': 40866.666666666664, 'global/mean_episode_step': 4245.222222222223, 'global/SPS': 3067.552079324525, 'global/env_act_steps': 29276288, 'global/env_train_steps': 29271040, 'global/optimizer_steps': 45736, 'global/running_reward': 21810.330528846152, 'global/running_step': 2306.2955228365386, 'global/steps_done': 29276288, 'global/episodes_done': 7196, 'global/unclipped_grad_norm': 0.5768516190970937, 'global/model_version': 45736, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:20,547] calculate_sps 30720 steps in 10.015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:20,547] calculate_sps 35840 steps in 10.015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:20,547] {'local/mean_episode_return': 41700.0, 'local/mean_episode_step': 4426.0, 'local/SPS': 3067.400110908129, 'local/env_act_steps': 29311872, 'local/env_train_steps': 29306880, 'local/optimizer_steps': 45792, 'local/running_reward': 21932.621660305344, 'local/running_step': 2314.7977397423665, 'local/steps_done': 29311872, 'local/episodes_done': 7203, 'local/unclipped_grad_norm': 0.6656126584857702, 'local/model_version': 45792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:20,548] {'global/mean_episode_return': 42880.0, 'global/mean_episode_step': 4492.6, 'global/SPS': 3578.633462726151, 'global/env_act_steps': 29309056, 'global/env_train_steps': 29306880, 'global/optimizer_steps': 45792, 'global/running_reward': 21897.4853515625, 'global/running_step': 2311.7169494628906, 'global/steps_done': 29309056, 'global/episodes_done': 7201, 'global/unclipped_grad_norm': 0.6760452730315072, 'global/model_version': 45792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:30,555] calculate_sps 35840 steps in 10.0094
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:30,556] calculate_sps 30720 steps in 10.0094
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:30,556] {'local/mean_episode_return': 45527.27272727273, 'local/mean_episode_step': 4710.909090909091, 'local/SPS': 3580.649850795394, 'local/env_act_steps': 29343744, 'local/env_train_steps': 29342720, 'local/optimizer_steps': 45847, 'local/running_reward': 21523.889307228917, 'local/running_step': 2268.975715361446, 'local/steps_done': 29343744, 'local/episodes_done': 7214, 'local/unclipped_grad_norm': 0.6451252422549508, 'local/model_version': 45847, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:30,557] {'global/mean_episode_return': 45050.0, 'global/mean_episode_step': 4695.916666666667, 'global/SPS': 3069.128443538909, 'global/env_act_steps': 29342720, 'global/env_train_steps': 29337600, 'global/optimizer_steps': 45840, 'global/running_reward': 21583.115494296577, 'global/running_step': 2274.996019486692, 'global/steps_done': 29342720, 'global/episodes_done': 7213, 'global/unclipped_grad_norm': 0.6441937026878198, 'global/model_version': 45840, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:40,575] calculate_sps 30720 steps in 10.0054
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:40,575] calculate_sps 35840 steps in 10.0054
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:40,576] {'local/mean_episode_return': 32225.0, 'local/mean_episode_step': 3595.5, 'local/SPS': 3070.3267419655836, 'local/env_act_steps': 29376768, 'local/env_train_steps': 29373440, 'local/optimizer_steps': 45896, 'local/running_reward': 21291.157945736435, 'local/running_step': 2244.1907703488373, 'local/steps_done': 29376768, 'local/episodes_done': 7222, 'local/unclipped_grad_norm': 0.5925165068130104, 'local/model_version': 45896, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:40,577] {'global/mean_episode_return': 33755.555555555555, 'global/mean_episode_step': 3717.5555555555557, 'global/SPS': 3582.047865626514, 'global/env_act_steps': 29374848, 'global/env_train_steps': 29373440, 'global/optimizer_steps': 45896, 'global/running_reward': 21280.266434262947, 'global/running_step': 2243.3573207171316, 'global/steps_done': 29374848, 'global/episodes_done': 7222, 'global/unclipped_grad_norm': 0.5998910612293652, 'global/model_version': 45896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:50,563] calculate_sps 31360 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:45:50,563] calculate_sps 30720 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:50,563] {'local/mean_episode_return': 48775.0, 'local/mean_episode_step': 4794.0, 'local/SPS': 3135.5615466005606, 'local/env_act_steps': 29409536, 'local/env_train_steps': 29404800, 'local/optimizer_steps': 45945, 'local/running_reward': 21226.33056640625, 'local/running_step': 2238.543701171875, 'local/steps_done': 29409536, 'local/episodes_done': 7230, 'local/unclipped_grad_norm': 0.6248178135375587, 'local/model_version': 45945, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:45:50,565] {'global/mean_episode_return': 48775.0, 'global/mean_episode_step': 4794.0, 'global/SPS': 3071.5704946291207, 'global/env_act_steps': 29408256, 'global/env_train_steps': 29404160, 'global/optimizer_steps': 45944, 'global/running_reward': 21243.27705938697, 'global/running_step': 2240.016223659004, 'global/steps_done': 29408256, 'global/episodes_done': 7230, 'global/unclipped_grad_norm': 0.6268428657203913, 'global/model_version': 45944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 13:45:52,390] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 29409536, 'env_train_steps': 29404800, 'optimizer_steps': 45945, 'running_reward': 21140.15625, 'running_step': 2230.1015625, 'steps_done': 29409536, 'episodes_done': 7230, 'unclipped_grad_norm': 0.5276153087615967, 'model_version': 45945, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 13:45:52,484] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:00,567] calculate_sps 35200 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:00,568] calculate_sps 33920 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:00,568] {'local/mean_episode_return': 47400.0, 'local/mean_episode_step': 4696.111111111111, 'local/SPS': 3518.3329813161445, 'local/env_act_steps': 29441536, 'local/env_train_steps': 29440000, 'local/optimizer_steps': 46000, 'local/running_reward': 20804.2, 'local/running_step': 2202.55128125, 'local/steps_done': 29441536, 'local/episodes_done': 7239, 'local/unclipped_grad_norm': 0.6053442919796164, 'local/model_version': 46000, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:00,569] {'global/mean_episode_return': 47400.0, 'global/mean_episode_step': 4696.111111111111, 'global/SPS': 3390.393600177376, 'global/env_act_steps': 29440640, 'global/env_train_steps': 29438080, 'global/optimizer_steps': 45996, 'global/running_reward': 20821.763833992096, 'global/running_step': 2203.856194416996, 'global/steps_done': 29440640, 'global/episodes_done': 7239, 'global/unclipped_grad_norm': 0.6002540442232902, 'global/model_version': 45996, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:10,599] calculate_sps 30720 steps in 10.0319
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:10,600] calculate_sps 32640 steps in 10.0319
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:10,600] {'local/mean_episode_return': 46377.77777777778, 'local/mean_episode_step': 4701.888888888889, 'local/SPS': 3062.2178939694522, 'local/env_act_steps': 29474816, 'local/env_train_steps': 29470720, 'local/optimizer_steps': 46048, 'local/running_reward': 20413.143028846152, 'local/running_step': 2170.669501201923, 'local/steps_done': 29474816, 'local/episodes_done': 7248, 'local/unclipped_grad_norm': 0.6285346311827501, 'local/model_version': 46048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:10,611] {'global/mean_episode_return': 46377.77777777778, 'global/mean_episode_step': 4701.888888888889, 'global/SPS': 3253.6065123425433, 'global/env_act_steps': 29473792, 'global/env_train_steps': 29470720, 'global/optimizer_steps': 46048, 'global/running_reward': 20425.476592664094, 'global/running_step': 2171.7979307432433, 'global/steps_done': 29473792, 'global/episodes_done': 7248, 'global/unclipped_grad_norm': 0.6303462185538732, 'global/model_version': 46048, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:20,646] calculate_sps 33920 steps in 10.0464
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:20,647] calculate_sps 32000 steps in 10.0464
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:20,647] {'local/mean_episode_return': 36850.0, 'local/mean_episode_step': 3868.625, 'local/SPS': 3376.327457562681, 'local/env_act_steps': 29507200, 'local/env_train_steps': 29504640, 'local/optimizer_steps': 46100, 'local/running_reward': 20319.22554347826, 'local/running_step': 2165.044373764822, 'local/steps_done': 29507200, 'local/episodes_done': 7256, 'local/unclipped_grad_norm': 0.7037278878001066, 'local/model_version': 46100, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:20,649] {'global/mean_episode_return': 36850.0, 'global/mean_episode_step': 3868.625, 'global/SPS': 3185.214582606303, 'global/env_act_steps': 29506816, 'global/env_train_steps': 29502720, 'global/optimizer_steps': 46097, 'global/running_reward': 20315.727955426355, 'global/running_step': 2164.704851017442, 'global/steps_done': 29506816, 'global/episodes_done': 7256, 'global/unclipped_grad_norm': 0.7077994498671317, 'global/model_version': 46097, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:30,655] calculate_sps 32640 steps in 10.0088
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:30,655] calculate_sps 34560 steps in 10.0088
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:30,655] {'local/mean_episode_return': 37400.0, 'local/mean_episode_step': 4049.1111111111113, 'local/SPS': 3261.1325262172963, 'local/env_act_steps': 29540224, 'local/env_train_steps': 29537280, 'local/optimizer_steps': 46152, 'local/running_reward': 20391.805959302324, 'local/running_step': 2165.829215116279, 'local/steps_done': 29540224, 'local/episodes_done': 7265, 'local/unclipped_grad_norm': 0.7564725821407942, 'local/model_version': 46152, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:30,656] {'global/mean_episode_return': 37400.0, 'global/mean_episode_step': 4049.1111111111113, 'global/SPS': 3452.963851288902, 'global/env_act_steps': 29539584, 'global/env_train_steps': 29537280, 'global/optimizer_steps': 46152, 'global/running_reward': 20391.339111328125, 'global/running_step': 2165.909454345703, 'global/steps_done': 29539584, 'global/episodes_done': 7265, 'global/unclipped_grad_norm': 0.7499682071534071, 'global/model_version': 46152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:40,675] calculate_sps 31360 steps in 10.0203
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:40,676] calculate_sps 30720 steps in 10.0203
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:40,676] {'local/mean_episode_return': 45700.0, 'local/mean_episode_step': 4670.25, 'local/SPS': 3129.6535465062966, 'local/env_act_steps': 29573248, 'local/env_train_steps': 29568640, 'local/optimizer_steps': 46200, 'local/running_reward': 20189.95276162791, 'local/running_step': 2140.9405886627906, 'local/steps_done': 29573248, 'local/episodes_done': 7273, 'local/unclipped_grad_norm': 0.7169760701557001, 'local/model_version': 46200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:40,678] {'global/mean_episode_return': 45700.0, 'global/mean_episode_step': 4670.25, 'global/SPS': 3065.783065965352, 'global/env_act_steps': 29573120, 'global/env_train_steps': 29568000, 'global/optimizer_steps': 46200, 'global/running_reward': 20191.74021946565, 'global/running_step': 2141.118499522901, 'global/steps_done': 29573120, 'global/episodes_done': 7273, 'global/unclipped_grad_norm': 0.7169760701557001, 'global/model_version': 46200, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:50,677] calculate_sps 35200 steps in 10.0017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:46:50,677] calculate_sps 35840 steps in 10.0017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:50,677] {'local/mean_episode_return': 39000.0, 'local/mean_episode_step': 4105.888888888889, 'local/SPS': 3519.3886407462005, 'local/env_act_steps': 29605632, 'local/env_train_steps': 29603840, 'local/optimizer_steps': 46256, 'local/running_reward': 20120.491600790512, 'local/running_step': 2130.8316761363635, 'local/steps_done': 29605632, 'local/episodes_done': 7282, 'local/unclipped_grad_norm': 0.7338542778577123, 'local/model_version': 46256, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:46:50,692] {'global/mean_episode_return': 39000.0, 'global/mean_episode_step': 4105.888888888889, 'global/SPS': 3583.377525123404, 'global/env_act_steps': 29605504, 'global/env_train_steps': 29603840, 'global/optimizer_steps': 46256, 'global/running_reward': 20128.18675889328, 'global/running_step': 2131.676259881423, 'global/steps_done': 29605504, 'global/episodes_done': 7282, 'global/unclipped_grad_norm': 0.7338542778577123, 'global/model_version': 46256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:00,706] calculate_sps 30720 steps in 10.0298
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:00,707] calculate_sps 25600 steps in 10.0298
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:00,707] {'local/mean_episode_return': 40625.0, 'local/mean_episode_step': 4303.0, 'local/SPS': 3062.86792591868, 'local/env_act_steps': 29639040, 'local/env_train_steps': 29634560, 'local/optimizer_steps': 46304, 'local/running_reward': 19990.367576628352, 'local/running_step': 2112.802292863985, 'local/steps_done': 29639040, 'local/episodes_done': 7290, 'local/unclipped_grad_norm': 0.7801316895832618, 'local/model_version': 46304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:00,708] {'global/mean_episode_return': 39314.28571428572, 'global/mean_episode_step': 4179.857142857143, 'global/SPS': 2552.389938265567, 'global/env_act_steps': 29632384, 'global/env_train_steps': 29629440, 'global/optimizer_steps': 46296, 'global/running_reward': 19996.183035714286, 'global/running_step': 2113.8497023809523, 'global/steps_done': 29632384, 'global/episodes_done': 7289, 'global/unclipped_grad_norm': 0.8195254974067211, 'global/model_version': 46296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:10,735] calculate_sps 35200 steps in 10.0293
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:10,736] calculate_sps 32640 steps in 10.0293
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:10,736] {'local/mean_episode_return': 39028.57142857143, 'local/mean_episode_step': 4067.4285714285716, 'local/SPS': 3509.715538305392, 'local/env_act_steps': 29671296, 'local/env_train_steps': 29669760, 'local/optimizer_steps': 46358, 'local/running_reward': 19881.49181547619, 'local/running_step': 2098.7015128968255, 'local/steps_done': 29671296, 'local/episodes_done': 7297, 'local/unclipped_grad_norm': 0.6433044075965881, 'local/model_version': 46358, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:10,737] {'global/mean_episode_return': 40375.0, 'global/mean_episode_step': 4204.625, 'global/SPS': 3254.4634991559087, 'global/env_act_steps': 29665664, 'global/env_train_steps': 29662080, 'global/optimizer_steps': 46346, 'global/running_reward': 19867.36778846154, 'global/running_step': 2097.5378305288464, 'global/steps_done': 29665664, 'global/episodes_done': 7297, 'global/unclipped_grad_norm': 0.6350193321704865, 'global/model_version': 46346, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:20,741] calculate_sps 31360 steps in 10.0057
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:20,742] calculate_sps 33920 steps in 10.0057
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:20,742] {'local/mean_episode_return': 42000.0, 'local/mean_episode_step': 4181.75, 'local/SPS': 3134.228549432925, 'local/env_act_steps': 29704448, 'local/env_train_steps': 29701120, 'local/optimizer_steps': 46408, 'local/running_reward': 20529.04198841699, 'local/running_step': 2164.777117519305, 'local/steps_done': 29704448, 'local/episodes_done': 7301, 'local/unclipped_grad_norm': 0.701778137087822, 'local/model_version': 46408, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:20,743] {'global/mean_episode_return': 36000.0, 'global/mean_episode_step': 3777.6666666666665, 'global/SPS': 3390.0839412233677, 'global/env_act_steps': 29698432, 'global/env_train_steps': 29696000, 'global/optimizer_steps': 46400, 'global/running_reward': 20423.583984375, 'global/running_step': 2153.915557861328, 'global/steps_done': 29698432, 'global/episodes_done': 7300, 'global/unclipped_grad_norm': 0.6809352272086673, 'global/model_version': 46400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:30,765] calculate_sps 32640 steps in 10.0235
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:30,765] calculate_sps 31360 steps in 10.0235
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:30,765] {'local/mean_episode_return': 37228.57142857143, 'local/mean_episode_step': 3952.8571428571427, 'local/SPS': 3256.3374477129714, 'local/env_act_steps': 29737344, 'local/env_train_steps': 29733760, 'local/optimizer_steps': 46458, 'local/running_reward': 20981.31079766537, 'local/running_step': 2205.66360651751, 'local/steps_done': 29737344, 'local/episodes_done': 7308, 'local/unclipped_grad_norm': 0.7570079985260963, 'local/model_version': 46458, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:30,766] {'global/mean_episode_return': 38366.666666666664, 'global/mean_episode_step': 3973.6666666666665, 'global/SPS': 3128.6379399595216, 'global/env_act_steps': 29732096, 'global/env_train_steps': 29727360, 'global/optimizer_steps': 46448, 'global/running_reward': 20882.349096958176, 'global/running_step': 2196.8943678707224, 'global/steps_done': 29732096, 'global/episodes_done': 7306, 'global/unclipped_grad_norm': 0.747764770872891, 'global/model_version': 46448, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:40,799] calculate_sps 33920 steps in 10.034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:40,799] calculate_sps 35200 steps in 10.034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:40,799] {'local/mean_episode_return': 37360.0, 'local/mean_episode_step': 3980.4, 'local/SPS': 3380.520362478538, 'local/env_act_steps': 29769856, 'local/env_train_steps': 29767680, 'local/optimizer_steps': 46512, 'local/running_reward': 21193.891486220473, 'local/running_step': 2223.2804502952754, 'local/steps_done': 29769856, 'local/episodes_done': 7313, 'local/unclipped_grad_norm': 0.7068790089752939, 'local/model_version': 46512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:40,801] {'global/mean_episode_return': 41266.666666666664, 'global/mean_episode_step': 4288.833333333333, 'global/SPS': 3508.0871686098035, 'global/env_act_steps': 29764352, 'global/env_train_steps': 29762560, 'global/optimizer_steps': 46504, 'global/running_reward': 21131.87003968254, 'global/running_step': 2217.5070994543653, 'global/steps_done': 29764352, 'global/episodes_done': 7312, 'global/unclipped_grad_norm': 0.7098326206739459, 'global/model_version': 46504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:50,811] calculate_sps 30720 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:47:50,811] calculate_sps 30720 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:50,811] {'local/mean_episode_return': 46960.0, 'local/mean_episode_step': 4668.4, 'local/SPS': 3068.397710522084, 'local/env_act_steps': 29803520, 'local/env_train_steps': 29798400, 'local/optimizer_steps': 46560, 'local/running_reward': 21556.327233840304, 'local/running_step': 2259.1964710076045, 'local/steps_done': 29803520, 'local/episodes_done': 7318, 'local/unclipped_grad_norm': 0.7006069452812275, 'local/model_version': 46560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:47:50,813] {'global/mean_episode_return': 44066.666666666664, 'global/mean_episode_step': 4455.5, 'global/SPS': 3068.397710522084, 'global/env_act_steps': 29797888, 'global/env_train_steps': 29793280, 'global/optimizer_steps': 46552, 'global/running_reward': 21511.981154580153, 'global/running_step': 2254.7886748568703, 'global/steps_done': 29797888, 'global/episodes_done': 7318, 'global/unclipped_grad_norm': 0.7487445337076982, 'global/model_version': 46552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:00,830] calculate_sps 35840 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:00,830] calculate_sps 35840 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:00,831] {'local/mean_episode_return': 40114.28571428572, 'local/mean_episode_step': 4146.714285714285, 'local/SPS': 3576.8601018151194, 'local/env_act_steps': 29835264, 'local/env_train_steps': 29834240, 'local/optimizer_steps': 46615, 'local/running_reward': 21783.9591733871, 'local/running_step': 2281.653351814516, 'local/steps_done': 29835264, 'local/episodes_done': 7325, 'local/unclipped_grad_norm': 0.6898476622321389, 'local/model_version': 46615, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:00,831] {'global/mean_episode_return': 41933.333333333336, 'global/mean_episode_step': 4288.333333333333, 'global/SPS': 3576.8601018151194, 'global/env_act_steps': 29830144, 'global/env_train_steps': 29829120, 'global/optimizer_steps': 46607, 'global/running_reward': 21757.3970734127, 'global/running_step': 2279.2052021329364, 'global/steps_done': 29830144, 'global/episodes_done': 7324, 'global/unclipped_grad_norm': 0.6848358419808475, 'global/model_version': 46607, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:10,863] calculate_sps 30720 steps in 10.0325
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:10,863] calculate_sps 30720 steps in 10.0325
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:10,864] {'local/mean_episode_return': 44542.857142857145, 'local/mean_episode_step': 4555.571428571428, 'local/SPS': 3062.0406934879866, 'local/env_act_steps': 29868544, 'local/env_train_steps': 29864960, 'local/optimizer_steps': 46664, 'local/running_reward': 22040.80528846154, 'local/running_step': 2303.7892427884617, 'local/steps_done': 29868544, 'local/episodes_done': 7332, 'local/unclipped_grad_norm': 0.6923371036441959, 'local/model_version': 46664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:10,865] {'global/mean_episode_return': 42625.0, 'global/mean_episode_step': 4398.25, 'global/SPS': 3062.0406934879866, 'global/env_act_steps': 29863936, 'global/env_train_steps': 29859840, 'global/optimizer_steps': 46656, 'global/running_reward': 22033.14393939394, 'global/running_step': 2303.541163589015, 'global/steps_done': 29863936, 'global/episodes_done': 7332, 'global/unclipped_grad_norm': 0.6614171704467462, 'global/model_version': 46656, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:20,885] calculate_sps 33280 steps in 10.0224
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:20,885] calculate_sps 34560 steps in 10.0224
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:20,886] {'local/mean_episode_return': 37625.0, 'local/mean_episode_step': 4090.0, 'local/SPS': 3320.5488610814273, 'local/env_act_steps': 29901312, 'local/env_train_steps': 29898240, 'local/optimizer_steps': 46715, 'local/running_reward': 22187.811279296875, 'local/running_step': 2314.5001220703125, 'local/steps_done': 29901312, 'local/episodes_done': 7340, 'local/unclipped_grad_norm': 0.603422928090189, 'local/model_version': 46715, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:20,886] {'global/mean_episode_return': 39033.333333333336, 'global/mean_episode_step': 4239.833333333333, 'global/SPS': 3448.262278815328, 'global/env_act_steps': 29896576, 'global/env_train_steps': 29894400, 'global/optimizer_steps': 46709, 'global/running_reward': 22142.230392156864, 'global/running_step': 2311.0967830882355, 'global/steps_done': 29896576, 'global/episodes_done': 7338, 'global/unclipped_grad_norm': 0.6263638757309824, 'global/model_version': 46709, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:30,915] calculate_sps 33280 steps in 10.0297
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:30,916] calculate_sps 32000 steps in 10.0297
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:30,916] {'local/mean_episode_return': 42400.0, 'local/mean_episode_step': 4402.875, 'local/SPS': 3318.1495914880147, 'local/env_act_steps': 29934080, 'local/env_train_steps': 29931520, 'local/optimizer_steps': 46768, 'local/running_reward': 22394.23828125, 'local/running_step': 2325.1679077148438, 'local/steps_done': 29934080, 'local/episodes_done': 7348, 'local/unclipped_grad_norm': 0.7826846680551205, 'local/model_version': 46768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:30,917] {'global/mean_episode_return': 41075.0, 'global/mean_episode_step': 4292.0, 'global/SPS': 3190.52845335386, 'global/env_act_steps': 29929856, 'global/env_train_steps': 29926400, 'global/optimizer_steps': 46760, 'global/running_reward': 22398.143028846152, 'global/running_step': 2326.404567307692, 'global/steps_done': 29929856, 'global/episodes_done': 7346, 'global/unclipped_grad_norm': 0.7349710365136465, 'global/model_version': 46760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:40,963] calculate_sps 31360 steps in 10.0479
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:40,963] calculate_sps 33280 steps in 10.0479
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:40,963] {'local/mean_episode_return': 48800.0, 'local/mean_episode_step': 4818.833333333333, 'local/SPS': 3121.059438795086, 'local/env_act_steps': 29967488, 'local/env_train_steps': 29962880, 'local/optimizer_steps': 46816, 'local/running_reward': 22448.844588122607, 'local/running_step': 2329.801843869732, 'local/steps_done': 29967488, 'local/episodes_done': 7354, 'local/unclipped_grad_norm': 0.6957890953247746, 'local/model_version': 46816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:40,964] {'global/mean_episode_return': 48800.0, 'global/mean_episode_step': 4786.2, 'global/SPS': 3312.1447105580505, 'global/env_act_steps': 29962752, 'global/env_train_steps': 29959680, 'global/optimizer_steps': 46811, 'global/running_reward': 22417.813715953307, 'global/running_step': 2325.9960177529183, 'global/steps_done': 29962752, 'global/episodes_done': 7351, 'global/unclipped_grad_norm': 0.73761726389913, 'global/model_version': 46811, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:50,999] calculate_sps 35200 steps in 10.0361
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:48:51,000] calculate_sps 33280 steps in 10.0361
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:51,000] {'local/mean_episode_return': 43816.666666666664, 'local/mean_episode_step': 4572.416666666667, 'local/SPS': 3507.3523704688864, 'local/env_act_steps': 29999616, 'local/env_train_steps': 29998080, 'local/optimizer_steps': 46872, 'local/running_reward': 21951.91733067729, 'local/running_step': 2283.278666583665, 'local/steps_done': 29999616, 'local/episodes_done': 7366, 'local/unclipped_grad_norm': 0.7387615463563374, 'local/model_version': 46872, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:48:51,002] {'global/mean_episode_return': 42700.0, 'global/mean_episode_step': 4492.357142857143, 'global/SPS': 3316.0422411705836, 'global/env_act_steps': 29995520, 'global/env_train_steps': 29992960, 'global/optimizer_steps': 46864, 'global/running_reward': 22114.642333984375, 'global/running_step': 2299.439971923828, 'global/steps_done': 29995520, 'global/episodes_done': 7365, 'global/unclipped_grad_norm': 0.7137555952342052, 'global/model_version': 46864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:01,013] calculate_sps 30720 steps in 10.0133
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:01,013] calculate_sps 30720 steps in 10.0133
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:01,013] {'local/mean_episode_return': 40354.545454545456, 'local/mean_episode_step': 4206.227272727273, 'local/SPS': 3067.912891182408, 'local/env_act_steps': 30032640, 'local/env_train_steps': 30028800, 'local/optimizer_steps': 46920, 'local/running_reward': 21119.97335271318, 'local/running_step': 2206.292847625969, 'local/steps_done': 30032640, 'local/episodes_done': 7378, 'local/unclipped_grad_norm': 0.6561982134977976, 'local/model_version': 46920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:01,015] {'global/mean_episode_return': 44310.0, 'global/mean_episode_step': 4533.55, 'global/SPS': 3067.912891182408, 'global/env_act_steps': 30028928, 'global/env_train_steps': 30023680, 'global/optimizer_steps': 46912, 'global/running_reward': 21200.39511494253, 'global/running_step': 2214.0049389367814, 'global/steps_done': 30028928, 'global/episodes_done': 7376, 'global/unclipped_grad_norm': 0.6968739535659552, 'global/model_version': 46912, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:11,033] calculate_sps 33280 steps in 10.0207
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:11,033] calculate_sps 35840 steps in 10.0207
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:11,033] {'local/mean_episode_return': 45028.57142857143, 'local/mean_episode_step': 4643.857142857143, 'local/SPS': 3321.128438754749, 'local/env_act_steps': 30065152, 'local/env_train_steps': 30062080, 'local/optimizer_steps': 46971, 'local/running_reward': 20770.25098425197, 'local/running_step': 2173.301150344488, 'local/steps_done': 30065152, 'local/episodes_done': 7385, 'local/unclipped_grad_norm': 0.6713092151810142, 'local/model_version': 46971, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:11,034] {'global/mean_episode_return': 43514.28571428572, 'global/mean_episode_step': 4451.142857142857, 'global/SPS': 3576.5998571204987, 'global/env_act_steps': 30061184, 'global/env_train_steps': 30059520, 'global/optimizer_steps': 46968, 'global/running_reward': 20762.562003968254, 'global/running_step': 2172.1941964285716, 'global/steps_done': 30061184, 'global/episodes_done': 7383, 'global/unclipped_grad_norm': 0.6670009706701551, 'global/model_version': 46968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:21,055] calculate_sps 33280 steps in 10.0222
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:21,056] calculate_sps 30720 steps in 10.0222
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:21,056] {'local/mean_episode_return': 45520.0, 'local/mean_episode_step': 4600.2, 'local/SPS': 3320.630618575362, 'local/env_act_steps': 30097792, 'local/env_train_steps': 30095360, 'local/optimizer_steps': 47024, 'local/running_reward': 20841.102941176472, 'local/running_step': 2182.221476715686, 'local/steps_done': 30097792, 'local/episodes_done': 7390, 'local/unclipped_grad_norm': 0.6397756071023222, 'local/model_version': 47024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:21,067] {'global/mean_episode_return': 42833.333333333336, 'global/mean_episode_step': 4394.833333333333, 'global/SPS': 3065.197494069565, 'global/env_act_steps': 30094720, 'global/env_train_steps': 30090240, 'global/optimizer_steps': 47016, 'global/running_reward': 20811.4205629771, 'global/running_step': 2178.8929508587785, 'global/steps_done': 30094720, 'global/episodes_done': 7389, 'global/unclipped_grad_norm': 0.6355220976596078, 'global/model_version': 47016, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:31,073] calculate_sps 30720 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:31,074] calculate_sps 35200 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:31,074] {'local/mean_episode_return': 39960.0, 'local/mean_episode_step': 4195.8, 'local/SPS': 3066.4693500187345, 'local/env_act_steps': 30131200, 'local/env_train_steps': 30126080, 'local/optimizer_steps': 47072, 'local/running_reward': 21168.917624521073, 'local/running_step': 2218.8021132662834, 'local/steps_done': 30131200, 'local/episodes_done': 7395, 'local/unclipped_grad_norm': 0.702535891905427, 'local/model_version': 47072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:31,075] {'global/mean_episode_return': 39333.333333333336, 'global/mean_episode_step': 4169.833333333333, 'global/SPS': 3513.6627968964667, 'global/env_act_steps': 30126976, 'global/env_train_steps': 30125440, 'global/optimizer_steps': 47070, 'global/running_reward': 21128.924851190477, 'global/running_step': 2214.4707961309523, 'global/steps_done': 30126976, 'global/episodes_done': 7395, 'global/unclipped_grad_norm': 0.6945163828355295, 'global/model_version': 47070, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:41,100] calculate_sps 35840 steps in 10.0262
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:41,100] calculate_sps 31360 steps in 10.0262
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:41,100] {'local/mean_episode_return': 42285.71428571428, 'local/mean_episode_step': 4303.714285714285, 'local/SPS': 3574.6286575185754, 'local/env_act_steps': 30163328, 'local/env_train_steps': 30161920, 'local/optimizer_steps': 47128, 'local/running_reward': 21589.741035856572, 'local/running_step': 2262.563838396414, 'local/steps_done': 30163328, 'local/episodes_done': 7402, 'local/unclipped_grad_norm': 0.7454339606421334, 'local/model_version': 47128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:41,102] {'global/mean_episode_return': 42285.71428571428, 'global/mean_episode_step': 4303.714285714285, 'global/SPS': 3127.800075328754, 'global/env_act_steps': 30160768, 'global/env_train_steps': 30156800, 'global/optimizer_steps': 47120, 'global/running_reward': 21571.496212121212, 'global/running_step': 2260.594815340909, 'global/steps_done': 30160768, 'global/episodes_done': 7402, 'global/unclipped_grad_norm': 0.7465850162506104, 'global/model_version': 47120, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:51,122] calculate_sps 30720 steps in 10.0227
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:49:51,123] calculate_sps 33280 steps in 10.0227
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:51,123] {'local/mean_episode_return': 51200.0, 'local/mean_episode_step': 5235.0, 'local/SPS': 3065.049039849723, 'local/env_act_steps': 30196352, 'local/env_train_steps': 30192640, 'local/optimizer_steps': 47176, 'local/running_reward': 22183.678536821706, 'local/running_step': 2321.411609738372, 'local/steps_done': 30196352, 'local/episodes_done': 7403, 'local/unclipped_grad_norm': 0.7083580881978074, 'local/model_version': 47176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:49:51,124] {'global/mean_episode_return': 51200.0, 'global/mean_episode_step': 5235.0, 'global/SPS': 3320.4697931705336, 'global/env_act_steps': 30193280, 'global/env_train_steps': 30190080, 'global/optimizer_steps': 47172, 'global/running_reward': 22095.047982283464, 'global/running_step': 2312.2938914862207, 'global/steps_done': 30193280, 'global/episodes_done': 7403, 'global/unclipped_grad_norm': 0.6913897340687422, 'global/model_version': 47172, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:01,162] calculate_sps 32640 steps in 10.0403
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:01,162] calculate_sps 33280 steps in 10.0403
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:01,163] {'local/mean_episode_return': 46533.333333333336, 'local/mean_episode_step': 4855.0, 'local/SPS': 3250.9050108792053, 'local/env_act_steps': 30228864, 'local/env_train_steps': 30225280, 'local/optimizer_steps': 47226, 'local/running_reward': 23135.49458661417, 'local/running_step': 2416.867433562992, 'local/steps_done': 30228864, 'local/episodes_done': 7406, 'local/unclipped_grad_norm': 0.7576686292886734, 'local/model_version': 47226, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:01,164] {'global/mean_episode_return': 46533.333333333336, 'global/mean_episode_step': 4855.0, 'global/SPS': 3314.648246386641, 'global/env_act_steps': 30225664, 'global/env_train_steps': 30223360, 'global/optimizer_steps': 47224, 'global/running_reward': 23065.736166007904, 'global/running_step': 2410.3273221343875, 'global/steps_done': 30225664, 'global/episodes_done': 7406, 'global/unclipped_grad_norm': 0.7838175623462751, 'global/model_version': 47224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:11,194] calculate_sps 33920 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:11,195] calculate_sps 31360 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:11,195] {'local/mean_episode_return': 40066.666666666664, 'local/mean_episode_step': 4130.0, 'local/SPS': 3381.296883059115, 'local/env_act_steps': 30261760, 'local/env_train_steps': 30259200, 'local/optimizer_steps': 47280, 'local/running_reward': 23730.496108949417, 'local/running_step': 2477.6096181906614, 'local/steps_done': 30261760, 'local/episodes_done': 7409, 'local/unclipped_grad_norm': 0.7321591553864656, 'local/model_version': 47280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:11,196] {'global/mean_episode_return': 40066.666666666664, 'global/mean_episode_step': 4130.0, 'global/SPS': 3126.1046654697475, 'global/env_act_steps': 30259456, 'global/env_train_steps': 30254720, 'global/optimizer_steps': 47272, 'global/running_reward': 23665.625, 'global/running_step': 2470.690370501894, 'global/steps_done': 30259456, 'global/episodes_done': 7409, 'global/unclipped_grad_norm': 0.7051718247433504, 'global/model_version': 47272, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:21,229] calculate_sps 30720 steps in 10.0348
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:21,229] calculate_sps 35200 steps in 10.0348
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:21,230] {'local/mean_episode_return': 39314.28571428572, 'local/mean_episode_step': 4136.428571428572, 'local/SPS': 3061.361117889768, 'local/env_act_steps': 30295040, 'local/env_train_steps': 30289920, 'local/optimizer_steps': 47328, 'local/running_reward': 24201.43028846154, 'local/running_step': 2525.3138221153845, 'local/steps_done': 30295040, 'local/episodes_done': 7416, 'local/unclipped_grad_norm': 0.6743200961500406, 'local/model_version': 47328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:21,243] {'global/mean_episode_return': 39314.28571428572, 'global/mean_episode_step': 4136.428571428572, 'global/SPS': 3507.809614248693, 'global/env_act_steps': 30291968, 'global/env_train_steps': 30289920, 'global/optimizer_steps': 47328, 'global/running_reward': 24187.09399606299, 'global/running_step': 2524.1184485728345, 'global/steps_done': 30291968, 'global/episodes_done': 7416, 'global/unclipped_grad_norm': 0.6950829013117722, 'global/model_version': 47328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:31,267] calculate_sps 35840 steps in 10.0382
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:31,268] calculate_sps 30720 steps in 10.0382
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:31,268] {'local/mean_episode_return': 46950.0, 'local/mean_episode_step': 4808.375, 'local/SPS': 3570.3446344003382, 'local/env_act_steps': 30327168, 'local/env_train_steps': 30325760, 'local/optimizer_steps': 47384, 'local/running_reward': 24377.88844621514, 'local/running_step': 2540.22734063745, 'local/steps_done': 30327168, 'local/episodes_done': 7424, 'local/unclipped_grad_norm': 0.671697658087526, 'local/model_version': 47384, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:31,269] {'global/mean_episode_return': 46950.0, 'global/mean_episode_step': 4808.375, 'global/SPS': 3060.2954009145756, 'global/env_act_steps': 30325504, 'global/env_train_steps': 30320640, 'global/optimizer_steps': 47376, 'global/running_reward': 24385.889790076337, 'global/running_step': 2541.1445610687024, 'global/steps_done': 30325504, 'global/episodes_done': 7424, 'global/unclipped_grad_norm': 0.6810077050079902, 'global/model_version': 47376, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:41,283] calculate_sps 30720 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:41,283] calculate_sps 35840 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:41,283] {'local/mean_episode_return': 40725.0, 'local/mean_episode_step': 4221.25, 'local/SPS': 3067.2963487183283, 'local/env_act_steps': 30360320, 'local/env_train_steps': 30356480, 'local/optimizer_steps': 47432, 'local/running_reward': 24153.72224903475, 'local/running_step': 2517.2709037162163, 'local/steps_done': 30360320, 'local/episodes_done': 7432, 'local/unclipped_grad_norm': 0.6140738961597284, 'local/model_version': 47432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:41,285] {'global/mean_episode_return': 41628.57142857143, 'global/mean_episode_step': 4249.428571428572, 'global/SPS': 3578.5124068380496, 'global/env_act_steps': 30357504, 'global/env_train_steps': 30356480, 'global/optimizer_steps': 47431, 'global/running_reward': 24151.49375, 'global/running_step': 2516.8665, 'global/steps_done': 30357504, 'global/episodes_done': 7431, 'global/unclipped_grad_norm': 0.6180473571473902, 'global/model_version': 47431, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:51,290] calculate_sps 33280 steps in 10.0076
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:50:51,290] calculate_sps 30720 steps in 10.0076
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:51,290] {'local/mean_episode_return': 55100.0, 'local/mean_episode_step': 5255.5, 'local/SPS': 3325.468102017169, 'local/env_act_steps': 30392832, 'local/env_train_steps': 30389760, 'local/optimizer_steps': 47483, 'local/running_reward': 24406.046998031496, 'local/running_step': 2545.1126968503936, 'local/steps_done': 30392832, 'local/episodes_done': 7436, 'local/unclipped_grad_norm': 0.6249091289207047, 'local/model_version': 47483, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:50:51,292] {'global/mean_episode_return': 51100.0, 'global/mean_episode_step': 5052.75, 'global/SPS': 3069.6628634004633, 'global/env_act_steps': 30391040, 'global/env_train_steps': 30387200, 'global/optimizer_steps': 47480, 'global/running_reward': 24376.64599236641, 'global/running_step': 2542.0191734255727, 'global/steps_done': 30391040, 'global/episodes_done': 7435, 'global/unclipped_grad_norm': 0.6099539414352301, 'global/model_version': 47480, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:01,296] calculate_sps 33280 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:01,297] calculate_sps 34560 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:01,306] {'local/mean_episode_return': 42333.333333333336, 'local/mean_episode_step': 4334.111111111111, 'local/SPS': 3326.0025606512963, 'local/env_act_steps': 30425600, 'local/env_train_steps': 30423040, 'local/optimizer_steps': 47536, 'local/running_reward': 24172.88818359375, 'local/running_step': 2522.932647705078, 'local/steps_done': 30425600, 'local/episodes_done': 7445, 'local/unclipped_grad_norm': 0.7450800450905314, 'local/model_version': 47536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:01,308] {'global/mean_episode_return': 43140.0, 'global/mean_episode_step': 4384.2, 'global/SPS': 3453.9257360609618, 'global/env_act_steps': 30423808, 'global/env_train_steps': 30421760, 'global/optimizer_steps': 47533, 'global/running_reward': 24186.5966796875, 'global/running_step': 2524.4129943847656, 'global/steps_done': 30423808, 'global/episodes_done': 7445, 'global/unclipped_grad_norm': 0.757465661415514, 'global/model_version': 47533, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:11,322] calculate_sps 30720 steps in 10.0258
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:11,322] calculate_sps 32000 steps in 10.0258
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:11,323] {'local/mean_episode_return': 46127.27272727273, 'local/mean_episode_step': 4613.636363636364, 'local/SPS': 3064.082397596029, 'local/env_act_steps': 30458496, 'local/env_train_steps': 30453760, 'local/optimizer_steps': 47584, 'local/running_reward': 24008.359678988327, 'local/running_step': 2506.302012402724, 'local/steps_done': 30458496, 'local/episodes_done': 7456, 'local/unclipped_grad_norm': 0.6442723044504722, 'local/model_version': 47584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:11,324] {'global/mean_episode_return': 44888.88888888889, 'global/mean_episode_step': 4564.222222222223, 'global/SPS': 3191.7524974958633, 'global/env_act_steps': 30456832, 'global/env_train_steps': 30453760, 'global/optimizer_steps': 47584, 'global/running_reward': 24030.492974806202, 'global/running_step': 2508.2273800872094, 'global/steps_done': 30456832, 'global/episodes_done': 7454, 'global/unclipped_grad_norm': 0.64040974074719, 'global/model_version': 47584, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:21,339] calculate_sps 35200 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:21,339] calculate_sps 32640 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:21,339] {'local/mean_episode_return': 38600.0, 'local/mean_episode_step': 4213.0, 'local/SPS': 3514.0030854498527, 'local/env_act_steps': 30490496, 'local/env_train_steps': 30488960, 'local/optimizer_steps': 47638, 'local/running_reward': 23755.2125, 'local/running_step': 2482.21996875, 'local/steps_done': 30490496, 'local/episodes_done': 7461, 'local/unclipped_grad_norm': 0.6796324851888197, 'local/model_version': 47638, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:21,340] {'global/mean_episode_return': 42342.857142857145, 'global/mean_episode_step': 4391.0, 'global/SPS': 3258.4392246898633, 'global/env_act_steps': 30489984, 'global/env_train_steps': 30486400, 'global/optimizer_steps': 47634, 'global/running_reward': 23753.263754826254, 'global/running_step': 2482.261613175676, 'global/steps_done': 30489984, 'global/episodes_done': 7461, 'global/unclipped_grad_norm': 0.6875503632426262, 'global/model_version': 47634, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:31,377] calculate_sps 31360 steps in 10.0376
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:31,377] calculate_sps 33920 steps in 10.0376
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:31,377] {'local/mean_episode_return': 50850.0, 'local/mean_episode_step': 5038.1875, 'local/SPS': 3124.2499027037143, 'local/env_act_steps': 30523904, 'local/env_train_steps': 30520320, 'local/optimizer_steps': 47688, 'local/running_reward': 23903.9691091954, 'local/running_step': 2496.6161997126437, 'local/steps_done': 30523904, 'local/episodes_done': 7470, 'local/unclipped_grad_norm': 0.7062566164135933, 'local/model_version': 47688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:31,379] {'global/mean_episode_return': 50850.0, 'global/mean_episode_step': 5038.1875, 'global/SPS': 3379.2907110876913, 'global/env_act_steps': 30522752, 'global/env_train_steps': 30520320, 'global/optimizer_steps': 47688, 'global/running_reward': 23921.429443359375, 'global/running_step': 2498.2005615234375, 'global/steps_done': 30522752, 'global/episodes_done': 7470, 'global/unclipped_grad_norm': 0.6969530899767522, 'global/model_version': 47688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:41,380] calculate_sps 33280 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:41,381] calculate_sps 31360 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:41,381] {'local/mean_episode_return': 44622.22222222222, 'local/mean_episode_step': 4560.444444444444, 'local/SPS': 3326.660469802034, 'local/env_act_steps': 30556672, 'local/env_train_steps': 30553600, 'local/optimizer_steps': 47739, 'local/running_reward': 23273.199462890625, 'local/running_step': 2437.821044921875, 'local/steps_done': 30556672, 'local/episodes_done': 7479, 'local/unclipped_grad_norm': 0.7904301943147883, 'local/model_version': 47739, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:41,382] {'global/mean_episode_return': 44622.22222222222, 'global/mean_episode_step': 4560.444444444444, 'global/SPS': 3134.7377503903786, 'global/env_act_steps': 30556416, 'global/env_train_steps': 30551680, 'global/optimizer_steps': 47736, 'global/running_reward': 23279.942965779468, 'global/running_step': 2438.4464413022815, 'global/steps_done': 30556416, 'global/episodes_done': 7479, 'global/unclipped_grad_norm': 0.7954955364887913, 'global/model_version': 47736, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:51,399] calculate_sps 33280 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:51:51,399] calculate_sps 35200 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:51,399] {'local/mean_episode_return': 45850.0, 'local/mean_episode_step': 4670.833333333333, 'local/SPS': 3322.0293345604778, 'local/env_act_steps': 30589440, 'local/env_train_steps': 30586880, 'local/optimizer_steps': 47792, 'local/running_reward': 22933.7890625, 'local/running_step': 2409.2691040039062, 'local/steps_done': 30589440, 'local/episodes_done': 7491, 'local/unclipped_grad_norm': 0.6192873581400458, 'local/model_version': 47792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:51:51,401] {'global/mean_episode_return': 45850.0, 'global/mean_episode_step': 4670.833333333333, 'global/SPS': 3513.6848730928127, 'global/env_act_steps': 30588800, 'global/env_train_steps': 30586880, 'global/optimizer_steps': 47792, 'global/running_reward': 22946.850296442688, 'global/running_step': 2410.5501791007905, 'global/steps_done': 30588800, 'global/episodes_done': 7491, 'global/unclipped_grad_norm': 0.6241140025002616, 'global/model_version': 47792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:01,431] calculate_sps 32000 steps in 10.0326
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:01,431] calculate_sps 30720 steps in 10.0326
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:01,431] {'local/mean_episode_return': 51333.333333333336, 'local/mean_episode_step': 5055.666666666667, 'local/SPS': 3189.6020729389884, 'local/env_act_steps': 30622976, 'local/env_train_steps': 30618880, 'local/optimizer_steps': 47841, 'local/running_reward': 22595.354246183208, 'local/running_step': 2374.1402671755727, 'local/steps_done': 30622976, 'local/episodes_done': 7494, 'local/unclipped_grad_norm': 0.6777214897530419, 'local/model_version': 47841, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:01,432] {'global/mean_episode_return': 51333.333333333336, 'global/mean_episode_step': 5055.666666666667, 'global/SPS': 3062.017990021429, 'global/env_act_steps': 30622848, 'global/env_train_steps': 30617600, 'global/optimizer_steps': 47840, 'global/running_reward': 22587.182800751878, 'global/running_step': 2373.339285714286, 'global/steps_done': 30622848, 'global/episodes_done': 7494, 'global/unclipped_grad_norm': 0.6637561585133275, 'global/model_version': 47840, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:11,438] calculate_sps 34560 steps in 10.0072
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:11,439] calculate_sps 35840 steps in 10.0072
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:11,439] {'local/mean_episode_return': 45885.71428571428, 'local/mean_episode_step': 4626.0, 'local/SPS': 3453.519311194237, 'local/env_act_steps': 30655872, 'local/env_train_steps': 30653440, 'local/optimizer_steps': 47896, 'local/running_reward': 22765.916828793775, 'local/running_step': 2395.866093142023, 'local/steps_done': 30655872, 'local/episodes_done': 7501, 'local/unclipped_grad_norm': 0.7308031057769602, 'local/model_version': 47896, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:11,450] {'global/mean_episode_return': 45885.71428571428, 'global/mean_episode_step': 4626.0, 'global/SPS': 3581.4274338310606, 'global/env_act_steps': 30655488, 'global/env_train_steps': 30653440, 'global/optimizer_steps': 47896, 'global/running_reward': 22771.899509803923, 'global/running_step': 2396.419424019608, 'global/steps_done': 30655488, 'global/episodes_done': 7501, 'global/unclipped_grad_norm': 0.7418255036962884, 'global/model_version': 47896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:21,463] calculate_sps 30720 steps in 10.0238
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:21,463] calculate_sps 30720 steps in 10.0238
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:21,464] {'local/mean_episode_return': 37950.0, 'local/mean_episode_step': 4113.0, 'local/SPS': 3064.707926710371, 'local/env_act_steps': 30689408, 'local/env_train_steps': 30684160, 'local/optimizer_steps': 47944, 'local/running_reward': 23095.831345419847, 'local/running_step': 2432.243320610687, 'local/steps_done': 30689408, 'local/episodes_done': 7505, 'local/unclipped_grad_norm': 0.7235876079648733, 'local/model_version': 47944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:21,465] {'global/mean_episode_return': 37950.0, 'global/mean_episode_step': 4113.0, 'global/SPS': 3064.707926710371, 'global/env_act_steps': 30689408, 'global/env_train_steps': 30684160, 'global/optimizer_steps': 47944, 'global/running_reward': 23089.280660377357, 'global/running_step': 2431.588708726415, 'global/steps_done': 30689408, 'global/episodes_done': 7505, 'global/unclipped_grad_norm': 0.7235876079648733, 'global/model_version': 47944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:31,486] calculate_sps 35840 steps in 10.0237
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:31,486] calculate_sps 26880 steps in 10.0237
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:31,486] {'local/mean_episode_return': 49654.545454545456, 'local/mean_episode_step': 4984.181818181818, 'local/SPS': 3575.5237925953497, 'local/env_act_steps': 30721024, 'local/env_train_steps': 30720000, 'local/optimizer_steps': 47999, 'local/running_reward': 23044.18016194332, 'local/running_step': 2431.6495129048585, 'local/steps_done': 30721024, 'local/episodes_done': 7516, 'local/unclipped_grad_norm': 0.691929051821882, 'local/model_version': 47999, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:31,487] {'global/mean_episode_return': 50320.0, 'global/mean_episode_step': 5032.0, 'global/SPS': 2681.6428444465123, 'global/env_act_steps': 30715264, 'global/env_train_steps': 30711040, 'global/optimizer_steps': 47985, 'global/running_reward': 23136.455754950493, 'global/running_step': 2440.3100634282177, 'global/steps_done': 30715264, 'global/episodes_done': 7515, 'global/unclipped_grad_norm': 0.6641714234904545, 'global/model_version': 47985, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:41,509] calculate_sps 30720 steps in 10.0232
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:41,510] calculate_sps 34560 steps in 10.0232
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:41,510] {'local/mean_episode_return': 48822.22222222222, 'local/mean_episode_step': 5039.0, 'local/SPS': 3064.887258625505, 'local/env_act_steps': 30754176, 'local/env_train_steps': 30750720, 'local/optimizer_steps': 48048, 'local/running_reward': 22331.925675675677, 'local/running_step': 2364.8195282335905, 'local/steps_done': 30754176, 'local/episodes_done': 7525, 'local/unclipped_grad_norm': 0.6943497660816932, 'local/model_version': 48048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:41,511] {'global/mean_episode_return': 48350.0, 'global/mean_episode_step': 4987.125, 'global/SPS': 3447.9981659536934, 'global/env_act_steps': 30748032, 'global/env_train_steps': 30745600, 'global/optimizer_steps': 48040, 'global/running_reward': 22416.7236328125, 'global/running_step': 2372.2942810058594, 'global/steps_done': 30748032, 'global/episodes_done': 7523, 'global/unclipped_grad_norm': 0.7111821957609871, 'global/model_version': 48040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:51,514] calculate_sps 32640 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:52:51,515] calculate_sps 31360 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:51,515] {'local/mean_episode_return': 40283.333333333336, 'local/mean_episode_step': 4208.0, 'local/SPS': 3262.2961688071755, 'local/env_act_steps': 30787072, 'local/env_train_steps': 30783360, 'local/optimizer_steps': 48099, 'local/running_reward': 21695.640807392996, 'local/running_step': 2301.8154486867707, 'local/steps_done': 30787072, 'local/episodes_done': 7537, 'local/unclipped_grad_norm': 0.6129976277257881, 'local/model_version': 48099, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:52:51,516] {'global/mean_episode_return': 39490.90909090909, 'global/mean_episode_step': 4200.636363636364, 'global/SPS': 3134.362985716698, 'global/env_act_steps': 30781568, 'global/env_train_steps': 30776960, 'global/optimizer_steps': 48088, 'global/running_reward': 21807.985448473282, 'global/running_step': 2313.2429926049617, 'global/steps_done': 30781568, 'global/episodes_done': 7534, 'global/unclipped_grad_norm': 0.6148240361362696, 'global/model_version': 48088, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:01,518] calculate_sps 33920 steps in 10.0032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:01,518] calculate_sps 35200 steps in 10.0032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:01,518] {'local/mean_episode_return': 46360.0, 'local/mean_episode_step': 4739.7, 'local/SPS': 3390.913272471224, 'local/env_act_steps': 30819200, 'local/env_train_steps': 30817280, 'local/optimizer_steps': 48152, 'local/running_reward': 21279.033864541834, 'local/running_step': 2261.480639940239, 'local/steps_done': 30819200, 'local/episodes_done': 7547, 'local/unclipped_grad_norm': 0.7642467210315308, 'local/model_version': 48152, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:01,520] {'global/mean_episode_return': 48180.0, 'global/mean_episode_step': 4852.3, 'global/SPS': 3518.8722638852323, 'global/env_act_steps': 30813824, 'global/env_train_steps': 30812160, 'global/optimizer_steps': 48144, 'global/running_reward': 21361.836557539682, 'global/running_step': 2269.9372519841268, 'global/steps_done': 30813824, 'global/episodes_done': 7544, 'global/unclipped_grad_norm': 0.7572962580514806, 'global/model_version': 48144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:11,530] calculate_sps 30720 steps in 10.0128
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:11,531] calculate_sps 30720 steps in 10.0128
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:11,531] {'local/mean_episode_return': 37550.0, 'local/mean_episode_step': 4144.916666666667, 'local/SPS': 3068.0812016911937, 'local/env_act_steps': 30852096, 'local/env_train_steps': 30848000, 'local/optimizer_steps': 48200, 'local/running_reward': 20529.736138132295, 'local/running_step': 2178.878465466926, 'local/steps_done': 30852096, 'local/episodes_done': 7559, 'local/unclipped_grad_norm': 0.7282281005755067, 'local/model_version': 48200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:11,532] {'global/mean_episode_return': 37072.72727272727, 'global/mean_episode_step': 4099.090909090909, 'global/SPS': 3068.0812016911937, 'global/env_act_steps': 30846976, 'global/env_train_steps': 30842880, 'global/optimizer_steps': 48192, 'global/running_reward': 20636.08832046332, 'global/running_step': 2191.443623310811, 'global/steps_done': 30846976, 'global/episodes_done': 7555, 'global/unclipped_grad_norm': 0.773428994230926, 'global/model_version': 48192, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:21,535] calculate_sps 32640 steps in 10.0048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:21,535] calculate_sps 33280 steps in 10.0048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:21,536] {'local/mean_episode_return': 39400.0, 'local/mean_episode_step': 4172.666666666667, 'local/SPS': 3262.4223434354803, 'local/env_act_steps': 30884224, 'local/env_train_steps': 30880640, 'local/optimizer_steps': 48250, 'local/running_reward': 20572.323207171314, 'local/running_step': 2175.31172186255, 'local/steps_done': 30884224, 'local/episodes_done': 7562, 'local/unclipped_grad_norm': 0.811872823536396, 'local/model_version': 48250, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:21,537] {'global/mean_episode_return': 41057.142857142855, 'global/mean_episode_step': 4327.142857142857, 'global/SPS': 3326.391408993039, 'global/env_act_steps': 30879360, 'global/env_train_steps': 30876160, 'global/optimizer_steps': 48244, 'global/running_reward': 20484.720849802372, 'global/running_step': 2167.345386610672, 'global/steps_done': 30879360, 'global/episodes_done': 7562, 'global/unclipped_grad_norm': 0.7596054870921832, 'global/model_version': 48244, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:31,552] calculate_sps 33920 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:31,552] calculate_sps 33280 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:31,553] {'local/mean_episode_return': 51288.88888888889, 'local/mean_episode_step': 5041.777777777777, 'local/SPS': 3386.441438977531, 'local/env_act_steps': 30916480, 'local/env_train_steps': 30914560, 'local/optimizer_steps': 48304, 'local/running_reward': 20732.8373015873, 'local/running_step': 2193.4201388888887, 'local/steps_done': 30916480, 'local/episodes_done': 7571, 'local/unclipped_grad_norm': 0.6473980043773297, 'local/model_version': 48304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:31,554] {'global/mean_episode_return': 52457.142857142855, 'global/mean_episode_step': 5091.714285714285, 'global/SPS': 3322.5463174873894, 'global/env_act_steps': 30912000, 'global/env_train_steps': 30909440, 'global/optimizer_steps': 48296, 'global/running_reward': 20772.647058823528, 'global/running_step': 2196.1956801470587, 'global/steps_done': 30912000, 'global/episodes_done': 7569, 'global/unclipped_grad_norm': 0.628368429839611, 'global/model_version': 48296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:41,583] calculate_sps 30720 steps in 10.0312
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:41,583] calculate_sps 31360 steps in 10.0312
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:41,583] {'local/mean_episode_return': 45133.333333333336, 'local/mean_episode_step': 4719.0, 'local/SPS': 3062.449340677088, 'local/env_act_steps': 30950016, 'local/env_train_steps': 30945280, 'local/optimizer_steps': 48352, 'local/running_reward': 20951.365696564884, 'local/running_step': 2220.1624522900765, 'local/steps_done': 30950016, 'local/episodes_done': 7574, 'local/unclipped_grad_norm': 0.6416561082005501, 'local/model_version': 48352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:41,585] {'global/mean_episode_return': 46450.0, 'global/mean_episode_step': 4789.25, 'global/SPS': 3126.2503686078608, 'global/env_act_steps': 30945408, 'global/env_train_steps': 30940800, 'global/optimizer_steps': 48344, 'global/running_reward': 20881.21408045977, 'global/running_step': 2212.9702466475096, 'global/steps_done': 30945408, 'global/episodes_done': 7573, 'global/unclipped_grad_norm': 0.6929252119734883, 'global/model_version': 48344, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:51,590] calculate_sps 35200 steps in 10.007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:53:51,590] calculate_sps 35200 steps in 10.007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:51,590] {'local/mean_episode_return': 48088.88888888889, 'local/mean_episode_step': 4949.222222222223, 'local/SPS': 3517.5491319696266, 'local/env_act_steps': 30982144, 'local/env_train_steps': 30980480, 'local/optimizer_steps': 48407, 'local/running_reward': 20741.7953187251, 'local/running_step': 2198.606262450199, 'local/steps_done': 30982144, 'local/episodes_done': 7583, 'local/unclipped_grad_norm': 0.6850709010254253, 'local/model_version': 48407, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:53:51,592] {'global/mean_episode_return': 47680.0, 'global/mean_episode_step': 4927.7, 'global/SPS': 3517.5491319696266, 'global/env_act_steps': 30978048, 'global/env_train_steps': 30976000, 'global/optimizer_steps': 48400, 'global/running_reward': 20819.957107843136, 'global/running_step': 2206.4555147058823, 'global/steps_done': 30978048, 'global/episodes_done': 7583, 'global/unclipped_grad_norm': 0.6655383884374585, 'global/model_version': 48400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:01,599] calculate_sps 31360 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:01,600] calculate_sps 30720 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:01,600] {'local/mean_episode_return': 49166.666666666664, 'local/mean_episode_step': 4894.333333333333, 'local/SPS': 3132.9892168911642, 'local/env_act_steps': 31015040, 'local/env_train_steps': 31011840, 'local/optimizer_steps': 48456, 'local/running_reward': 20870.324659533075, 'local/running_step': 2213.173972519455, 'local/steps_done': 31015040, 'local/episodes_done': 7589, 'local/unclipped_grad_norm': 0.6848534731840601, 'local/model_version': 48456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:01,601] {'global/mean_episode_return': 45900.0, 'global/mean_episode_step': 4755.5, 'global/SPS': 3069.0506614444057, 'global/env_act_steps': 31011584, 'global/env_train_steps': 31006720, 'global/optimizer_steps': 48448, 'global/running_reward': 20845.40791984733, 'global/running_step': 2210.253429150763, 'global/steps_done': 31011584, 'global/episodes_done': 7587, 'global/unclipped_grad_norm': 0.7158976901943485, 'global/model_version': 48448, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:11,648] calculate_sps 32000 steps in 10.0487
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:11,648] calculate_sps 35840 steps in 10.0487
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:11,648] {'local/mean_episode_return': 39577.77777777778, 'local/mean_episode_step': 4204.555555555556, 'local/SPS': 3184.497163134904, 'local/env_act_steps': 31047936, 'local/env_train_steps': 31043840, 'local/optimizer_steps': 48505, 'local/running_reward': 20736.545476653697, 'local/running_step': 2200.4874148832687, 'local/steps_done': 31047936, 'local/episodes_done': 7598, 'local/unclipped_grad_norm': 0.7214510617207508, 'local/model_version': 48505, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:11,649] {'global/mean_episode_return': 43460.0, 'global/mean_episode_step': 4472.3, 'global/SPS': 3566.6368227110925, 'global/env_act_steps': 31043968, 'global/env_train_steps': 31042560, 'global/optimizer_steps': 48504, 'global/running_reward': 20752.606225296444, 'global/running_step': 2202.9209794960475, 'global/steps_done': 31043968, 'global/episodes_done': 7597, 'global/unclipped_grad_norm': 0.6929287889174053, 'global/model_version': 48504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:21,667] calculate_sps 34560 steps in 10.0194
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:21,668] calculate_sps 30720 steps in 10.0194
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:21,668] {'local/mean_episode_return': 44022.22222222222, 'local/mean_episode_step': 4576.444444444444, 'local/SPS': 3449.3063306932345, 'local/env_act_steps': 31080320, 'local/env_train_steps': 31078400, 'local/optimizer_steps': 48560, 'local/running_reward': 20772.949604743084, 'local/running_step': 2197.522418478261, 'local/steps_done': 31080320, 'local/episodes_done': 7607, 'local/unclipped_grad_norm': 0.6991843998432159, 'local/model_version': 48560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:21,669] {'global/mean_episode_return': 42075.0, 'global/mean_episode_step': 4394.25, 'global/SPS': 3066.0500717273194, 'global/env_act_steps': 31077632, 'global/env_train_steps': 31073280, 'global/optimizer_steps': 48552, 'global/running_reward': 20774.245484790874, 'global/running_step': 2198.029883555133, 'global/steps_done': 31077632, 'global/episodes_done': 7605, 'global/unclipped_grad_norm': 0.696647177139918, 'global/model_version': 48552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:31,688] calculate_sps 30720 steps in 10.0208
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:31,689] calculate_sps 35840 steps in 10.0208
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:31,689] {'local/mean_episode_return': 42575.0, 'local/mean_episode_step': 4399.625, 'local/SPS': 3065.633023302724, 'local/env_act_steps': 31114112, 'local/env_train_steps': 31109120, 'local/optimizer_steps': 48608, 'local/running_reward': 20164.612926136364, 'local/running_step': 2138.4126716382575, 'local/steps_done': 31114112, 'local/episodes_done': 7615, 'local/unclipped_grad_norm': 0.654244102537632, 'local/model_version': 48608, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:31,699] {'global/mean_episode_return': 43555.555555555555, 'global/mean_episode_step': 4480.666666666667, 'global/SPS': 3576.5718605198444, 'global/env_act_steps': 31110144, 'global/env_train_steps': 31109120, 'global/optimizer_steps': 48607, 'global/running_reward': 20191.584645669293, 'global/running_step': 2140.873431348425, 'global/steps_done': 31110144, 'global/episodes_done': 7614, 'global/unclipped_grad_norm': 0.6577642576261, 'global/model_version': 48607, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:41,696] calculate_sps 35840 steps in 10.007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:41,696] calculate_sps 30720 steps in 10.007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:41,696] {'local/mean_episode_return': 40800.0, 'local/mean_episode_step': 4201.333333333333, 'local/SPS': 3581.482470329458, 'local/env_act_steps': 31145984, 'local/env_train_steps': 31144960, 'local/optimizer_steps': 48663, 'local/running_reward': 20372.025602409638, 'local/running_step': 2159.8702309236946, 'local/steps_done': 31145984, 'local/episodes_done': 7621, 'local/unclipped_grad_norm': 0.6907115329395641, 'local/model_version': 48663, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:41,698] {'global/mean_episode_return': 40857.142857142855, 'global/mean_episode_step': 4225.0, 'global/SPS': 3069.84211742525, 'global/env_act_steps': 31144064, 'global/env_train_steps': 31139840, 'global/optimizer_steps': 48656, 'global/running_reward': 20351.244103773584, 'global/running_step': 2157.5857311320756, 'global/steps_done': 31144064, 'global/episodes_done': 7621, 'global/unclipped_grad_norm': 0.6755398274684439, 'global/model_version': 48656, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:51,728] calculate_sps 30720 steps in 10.0329
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:54:51,728] calculate_sps 34560 steps in 10.0329
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:51,729] {'local/mean_episode_return': 40133.333333333336, 'local/mean_episode_step': 4418.0, 'local/SPS': 3061.9135729638174, 'local/env_act_steps': 31179648, 'local/env_train_steps': 31175680, 'local/optimizer_steps': 48712, 'local/running_reward': 20750.11288022814, 'local/running_step': 2203.2998752376425, 'local/steps_done': 31179648, 'local/episodes_done': 7624, 'local/unclipped_grad_norm': 0.7033377934475334, 'local/model_version': 48712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:54:51,730] {'global/mean_episode_return': 40133.333333333336, 'global/mean_episode_step': 4418.0, 'global/SPS': 3444.6527695842947, 'global/env_act_steps': 31176448, 'global/env_train_steps': 31174400, 'global/optimizer_steps': 48709, 'global/running_reward': 20691.082015810276, 'global/running_step': 2196.90257534585, 'global/steps_done': 31176448, 'global/episodes_done': 7624, 'global/unclipped_grad_norm': 0.7153841718187872, 'global/model_version': 48709, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:01,732] calculate_sps 33920 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:01,746] calculate_sps 32000 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:01,746] {'local/mean_episode_return': 43466.666666666664, 'local/mean_episode_step': 4403.444444444444, 'local/SPS': 3391.341509693743, 'local/env_act_steps': 31212288, 'local/env_train_steps': 31209600, 'local/optimizer_steps': 48764, 'local/running_reward': 21084.56495098039, 'local/running_step': 2243.175612745098, 'local/steps_done': 31212288, 'local/episodes_done': 7633, 'local/unclipped_grad_norm': 0.6665267096115992, 'local/model_version': 48764, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:01,748] {'global/mean_episode_return': 43466.666666666664, 'global/mean_episode_step': 4403.444444444444, 'global/SPS': 3199.378782729946, 'global/env_act_steps': 31209856, 'global/env_train_steps': 31206400, 'global/optimizer_steps': 48760, 'global/running_reward': 21109.812021072798, 'global/running_step': 2245.2344947318006, 'global/steps_done': 31209856, 'global/episodes_done': 7633, 'global/unclipped_grad_norm': 0.6861698253481996, 'global/model_version': 48760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:11,730] calculate_sps 32640 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:11,731] calculate_sps 33280 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:11,731] {'local/mean_episode_return': 37200.0, 'local/mean_episode_step': 3904.3333333333335, 'local/SPS': 3263.9165792805434, 'local/env_act_steps': 31244928, 'local/env_train_steps': 31242240, 'local/optimizer_steps': 48816, 'local/running_reward': 21406.335784313724, 'local/running_step': 2276.9216605392157, 'local/steps_done': 31244928, 'local/episodes_done': 7636, 'local/unclipped_grad_norm': 0.6307236615281838, 'local/model_version': 48816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:11,732] {'global/mean_episode_return': 37200.0, 'global/mean_episode_step': 3904.3333333333335, 'global/SPS': 3327.914943580162, 'global/env_act_steps': 31242880, 'global/env_train_steps': 31239680, 'global/optimizer_steps': 48811, 'global/running_reward': 21349.67296511628, 'global/running_step': 2271.186046511628, 'global/steps_done': 31242880, 'global/episodes_done': 7636, 'global/unclipped_grad_norm': 0.6000488844572329, 'global/model_version': 48811, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:21,749] calculate_sps 31360 steps in 10.0191
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:21,749] calculate_sps 33280 steps in 10.0191
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:21,750] {'local/mean_episode_return': 38971.42857142857, 'local/mean_episode_step': 4171.428571428572, 'local/SPS': 3130.0288988991615, 'local/env_act_steps': 31278208, 'local/env_train_steps': 31273600, 'local/optimizer_steps': 48864, 'local/running_reward': 21975.36658653846, 'local/running_step': 2335.070763221154, 'local/steps_done': 31278208, 'local/episodes_done': 7643, 'local/unclipped_grad_norm': 0.6639156083886822, 'local/model_version': 48864, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:21,750] {'global/mean_episode_return': 43066.666666666664, 'global/mean_episode_step': 4495.5, 'global/SPS': 3321.663321280743, 'global/env_act_steps': 31275648, 'global/env_train_steps': 31272960, 'global/optimizer_steps': 48864, 'global/running_reward': 21962.359619140625, 'global/running_step': 2333.661102294922, 'global/steps_done': 31275648, 'global/episodes_done': 7642, 'global/unclipped_grad_norm': 0.677093338572754, 'global/model_version': 48864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:31,763] calculate_sps 35200 steps in 10.0138
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:31,764] calculate_sps 31360 steps in 10.0138
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:31,764] {'local/mean_episode_return': 47514.28571428572, 'local/mean_episode_step': 4780.0, 'local/SPS': 3515.158919338782, 'local/env_act_steps': 31310336, 'local/env_train_steps': 31308800, 'local/optimizer_steps': 48920, 'local/running_reward': 22012.369272908367, 'local/running_step': 2338.258497260956, 'local/steps_done': 31310336, 'local/episodes_done': 7650, 'local/unclipped_grad_norm': 0.6711410033915725, 'local/model_version': 48920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:31,765] {'global/mean_episode_return': 43375.0, 'global/mean_episode_step': 4460.875, 'global/SPS': 3131.687037229097, 'global/env_act_steps': 31309056, 'global/env_train_steps': 31304320, 'global/optimizer_steps': 48912, 'global/running_reward': 22012.583812260535, 'global/running_step': 2338.4073874521073, 'global/steps_done': 31309056, 'global/episodes_done': 7650, 'global/unclipped_grad_norm': 0.6492961291223764, 'global/model_version': 48912, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:41,777] calculate_sps 30720 steps in 10.0138
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:41,778] calculate_sps 35200 steps in 10.0138
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:41,778] {'local/mean_episode_return': 44942.857142857145, 'local/mean_episode_step': 4708.714285714285, 'local/SPS': 3067.7671684843417, 'local/env_act_steps': 31343232, 'local/env_train_steps': 31339520, 'local/optimizer_steps': 48968, 'local/running_reward': 21642.716439688716, 'local/running_step': 2300.944309338521, 'local/steps_done': 31343232, 'local/episodes_done': 7657, 'local/unclipped_grad_norm': 0.6988977293173472, 'local/model_version': 48968, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:41,780] {'global/mean_episode_return': 44942.857142857145, 'global/mean_episode_step': 4708.714285714285, 'global/SPS': 3515.1498805549745, 'global/env_act_steps': 31341184, 'global/env_train_steps': 31339520, 'global/optimizer_steps': 48968, 'global/running_reward': 21639.859312749006, 'global/running_step': 2300.616378237052, 'global/steps_done': 31341184, 'global/episodes_done': 7657, 'global/unclipped_grad_norm': 0.7136566607015473, 'global/model_version': 48968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:51,793] calculate_sps 32000 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:55:51,793] calculate_sps 30720 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:51,793] {'local/mean_episode_return': 41642.857142857145, 'local/mean_episode_step': 4360.0, 'local/SPS': 3194.911744365409, 'local/env_act_steps': 31375616, 'local/env_train_steps': 31371520, 'local/optimizer_steps': 49017, 'local/running_reward': 21079.15019762846, 'local/running_step': 2246.9492959486165, 'local/steps_done': 31375616, 'local/episodes_done': 7671, 'local/unclipped_grad_norm': 0.6485853462803121, 'local/model_version': 49017, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:55:51,794] {'global/mean_episode_return': 41642.857142857145, 'global/mean_episode_step': 4360.0, 'global/SPS': 3067.115274590793, 'global/env_act_steps': 31373952, 'global/env_train_steps': 31370240, 'global/optimizer_steps': 49016, 'global/running_reward': 21146.368408203125, 'global/running_step': 2253.6685791015625, 'global/steps_done': 31373952, 'global/episodes_done': 7671, 'global/unclipped_grad_norm': 0.6436104687551657, 'global/model_version': 49016, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 13:55:52,410] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 31373952, 'env_train_steps': 31370240, 'optimizer_steps': 49016, 'running_reward': None, 'running_step': None, 'steps_done': 31373952, 'episodes_done': 7671, 'unclipped_grad_norm': None, 'model_version': 49016, 'virtual_batch_size': None, 'num_gradients': None}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 13:55:52,517] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:01,817] calculate_sps 34560 steps in 10.0236
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:01,817] calculate_sps 33280 steps in 10.0236
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:01,826] {'local/mean_episode_return': 43866.666666666664, 'local/mean_episode_step': 4509.75, 'local/SPS': 3447.874899793375, 'local/env_act_steps': 31407744, 'local/env_train_steps': 31406080, 'local/optimizer_steps': 49072, 'local/running_reward': 20026.91110557769, 'local/running_step': 2140.1662101593624, 'local/steps_done': 31407744, 'local/episodes_done': 7683, 'local/unclipped_grad_norm': 0.7030420501123775, 'local/model_version': 49072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:01,827] {'global/mean_episode_return': 43866.666666666664, 'global/mean_episode_step': 4509.75, 'global/SPS': 3320.1758294306574, 'global/env_act_steps': 31406592, 'global/env_train_steps': 31403520, 'global/optimizer_steps': 49067, 'global/running_reward': 20063.13725490196, 'global/running_step': 2143.8619485294116, 'global/steps_done': 31406592, 'global/episodes_done': 7683, 'global/unclipped_grad_norm': 0.7004826019207636, 'global/model_version': 49067, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:11,825] calculate_sps 30720 steps in 10.0085
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:11,825] calculate_sps 33280 steps in 10.0085
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:11,826] {'local/mean_episode_return': 46200.0, 'local/mean_episode_step': 4717.5, 'local/SPS': 3069.3808238728707, 'local/env_act_steps': 31441152, 'local/env_train_steps': 31436800, 'local/optimizer_steps': 49120, 'local/running_reward': 20309.15948275862, 'local/running_step': 2175.150323275862, 'local/steps_done': 31441152, 'local/episodes_done': 7685, 'local/unclipped_grad_norm': 0.7882215017452836, 'local/model_version': 49120, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:11,839] {'global/mean_episode_return': 46200.0, 'global/mean_episode_step': 4717.5, 'global/SPS': 3325.16255919561, 'global/env_act_steps': 31439744, 'global/env_train_steps': 31436800, 'global/optimizer_steps': 49120, 'global/running_reward': 20279.397924710425, 'global/running_step': 2171.7717181467183, 'global/steps_done': 31439744, 'global/episodes_done': 7685, 'global/unclipped_grad_norm': 0.7861266341411842, 'global/model_version': 49120, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:21,830] calculate_sps 33920 steps in 10.0056
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:21,831] calculate_sps 31360 steps in 10.0056
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:21,831] {'local/mean_episode_return': 39000.0, 'local/mean_episode_step': 4059.0, 'local/SPS': 3390.099935786951, 'local/env_act_steps': 31473280, 'local/env_train_steps': 31470720, 'local/optimizer_steps': 49172, 'local/running_reward': 20946.227589641436, 'local/running_step': 2239.6026207669324, 'local/steps_done': 31473280, 'local/episodes_done': 7688, 'local/unclipped_grad_norm': 0.6884597591482676, 'local/model_version': 49172, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:21,832] {'global/mean_episode_return': 39000.0, 'global/mean_episode_step': 4059.0, 'global/SPS': 3134.243336859634, 'global/env_act_steps': 31472768, 'global/env_train_steps': 31468160, 'global/optimizer_steps': 49168, 'global/running_reward': 20926.150678294573, 'global/running_step': 2237.6186107073645, 'global/steps_done': 31472768, 'global/episodes_done': 7688, 'global/unclipped_grad_norm': 0.6694731619209051, 'global/model_version': 49168, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:31,839] calculate_sps 32640 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:31,839] calculate_sps 35200 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:31,839] {'local/mean_episode_return': 32950.0, 'local/mean_episode_step': 3925.0, 'local/SPS': 3261.4049060979814, 'local/env_act_steps': 31506688, 'local/env_train_steps': 31503360, 'local/optimizer_steps': 49224, 'local/running_reward': 21919.14511494253, 'local/running_step': 2334.930615421456, 'local/steps_done': 31506688, 'local/episodes_done': 7692, 'local/unclipped_grad_norm': 0.6447806693613529, 'local/model_version': 49224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:31,841] {'global/mean_episode_return': 31533.333333333332, 'global/mean_episode_step': 3769.6666666666665, 'global/SPS': 3517.2013693213526, 'global/env_act_steps': 31505920, 'global/env_train_steps': 31503360, 'global/optimizer_steps': 49224, 'global/running_reward': 21902.69666988417, 'global/running_step': 2333.520813223938, 'global/steps_done': 31505920, 'global/episodes_done': 7691, 'global/unclipped_grad_norm': 0.6641748305410147, 'global/model_version': 49224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:41,860] calculate_sps 32000 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:41,860] calculate_sps 30720 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:41,860] {'local/mean_episode_return': 41850.0, 'local/mean_episode_step': 4478.875, 'local/SPS': 3193.1512099266956, 'local/env_act_steps': 31539456, 'local/env_train_steps': 31535360, 'local/optimizer_steps': 49273, 'local/running_reward': 22396.832275390625, 'local/running_step': 2372.177520751953, 'local/steps_done': 31539456, 'local/episodes_done': 7700, 'local/unclipped_grad_norm': 0.7309021259448967, 'local/model_version': 49273, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:41,861] {'global/mean_episode_return': 41333.333333333336, 'global/mean_episode_step': 4469.111111111111, 'global/SPS': 3065.4251615296275, 'global/env_act_steps': 31539328, 'global/env_train_steps': 31534080, 'global/optimizer_steps': 49272, 'global/running_reward': 22398.389607279692, 'global/running_step': 2372.3423132183907, 'global/steps_done': 31539328, 'global/episodes_done': 7700, 'global/unclipped_grad_norm': 0.7317942967638373, 'global/model_version': 49272, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:51,870] calculate_sps 34560 steps in 10.0098
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:56:51,870] calculate_sps 35840 steps in 10.0098
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:51,871] {'local/mean_episode_return': 43960.0, 'local/mean_episode_step': 4449.8, 'local/SPS': 3452.612338824463, 'local/env_act_steps': 31571968, 'local/env_train_steps': 31569920, 'local/optimizer_steps': 49328, 'local/running_reward': 22656.69291338583, 'local/running_step': 2394.8254183070867, 'local/steps_done': 31571968, 'local/episodes_done': 7705, 'local/unclipped_grad_norm': 0.7466305862773549, 'local/model_version': 49328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:56:51,872] {'global/mean_episode_return': 40700.0, 'global/mean_episode_step': 4214.0, 'global/SPS': 3580.486869892036, 'global/env_act_steps': 31571584, 'global/env_train_steps': 31569920, 'global/optimizer_steps': 49328, 'global/running_reward': 22651.835317460318, 'global/running_step': 2394.3127480158732, 'global/steps_done': 31571584, 'global/episodes_done': 7704, 'global/unclipped_grad_norm': 0.745585003069469, 'global/model_version': 49328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:01,891] calculate_sps 30720 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:01,891] calculate_sps 30720 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:01,891] {'local/mean_episode_return': 38888.88888888889, 'local/mean_episode_step': 4163.666666666667, 'local/SPS': 3065.5678173121796, 'local/env_act_steps': 31605504, 'local/env_train_steps': 31600640, 'local/optimizer_steps': 49376, 'local/running_reward': 22599.230677480915, 'local/running_step': 2390.0662571564885, 'local/steps_done': 31605504, 'local/episodes_done': 7714, 'local/unclipped_grad_norm': 0.6355311541507641, 'local/model_version': 49376, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:01,893] {'global/mean_episode_return': 40700.0, 'global/mean_episode_step': 4286.6, 'global/SPS': 3065.5678173121796, 'global/env_act_steps': 31605376, 'global/env_train_steps': 31600640, 'global/optimizer_steps': 49376, 'global/running_reward': 22600.864109848484, 'global/running_step': 2390.2523082386365, 'global/steps_done': 31605376, 'global/episodes_done': 7714, 'global/unclipped_grad_norm': 0.6355311541507641, 'global/model_version': 49376, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:11,940] calculate_sps 35200 steps in 10.0492
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:11,940] calculate_sps 26240 steps in 10.0492
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:11,940] {'local/mean_episode_return': 39028.57142857143, 'local/mean_episode_step': 4203.0, 'local/SPS': 3502.761798462163, 'local/env_act_steps': 31637376, 'local/env_train_steps': 31635840, 'local/optimizer_steps': 49430, 'local/running_reward': 22560.22841365462, 'local/running_step': 2385.51640938755, 'local/steps_done': 31637376, 'local/episodes_done': 7721, 'local/unclipped_grad_norm': 0.7261579574810134, 'local/model_version': 49430, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:11,941] {'global/mean_episode_return': 39360.0, 'global/mean_episode_step': 4293.0, 'global/SPS': 2611.1497043081577, 'global/env_act_steps': 31631616, 'global/env_train_steps': 31626880, 'global/optimizer_steps': 49417, 'global/running_reward': 22523.58231707317, 'global/running_step': 2382.4325457317073, 'global/steps_done': 31631616, 'global/episodes_done': 7719, 'global/unclipped_grad_norm': 0.7455959607188295, 'global/model_version': 49417, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:21,954] calculate_sps 31360 steps in 10.0134
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:21,954] calculate_sps 35200 steps in 10.0134
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:21,966] {'local/mean_episode_return': 41088.88888888889, 'local/mean_episode_step': 4354.222222222223, 'local/SPS': 3131.790160631024, 'local/env_act_steps': 31670528, 'local/env_train_steps': 31667200, 'local/optimizer_steps': 49480, 'local/running_reward': 22437.687017374516, 'local/running_step': 2368.9550555019305, 'local/steps_done': 31670528, 'local/episodes_done': 7730, 'local/unclipped_grad_norm': 0.6928516146540642, 'local/model_version': 49480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:21,968] {'global/mean_episode_return': 40563.63636363636, 'global/mean_episode_step': 4285.818181818182, 'global/SPS': 3515.2746700960474, 'global/env_act_steps': 31664000, 'global/env_train_steps': 31662080, 'global/optimizer_steps': 49472, 'global/running_reward': 22520.02223320158, 'global/running_step': 2377.833714179842, 'global/steps_done': 31664000, 'global/episodes_done': 7730, 'global/unclipped_grad_norm': 0.7075044550678947, 'global/model_version': 49472, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:31,961] calculate_sps 32640 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:31,961] calculate_sps 30720 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:31,974] {'local/mean_episode_return': 44480.0, 'local/mean_episode_step': 4660.2, 'local/SPS': 3262.1160584143886, 'local/env_act_steps': 31703552, 'local/env_train_steps': 31699840, 'local/optimizer_steps': 49530, 'local/running_reward': 22681.9949127907, 'local/running_step': 2392.3694282945735, 'local/steps_done': 31703552, 'local/episodes_done': 7735, 'local/unclipped_grad_norm': 0.7604897540807724, 'local/model_version': 49530, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:31,976] {'global/mean_episode_return': 45866.666666666664, 'global/mean_episode_step': 4778.0, 'global/SPS': 3070.22687850766, 'global/env_act_steps': 31697792, 'global/env_train_steps': 31692800, 'global/optimizer_steps': 49520, 'global/running_reward': 22567.288115530304, 'global/running_step': 2380.5123993844695, 'global/steps_done': 31697792, 'global/episodes_done': 7733, 'global/unclipped_grad_norm': 0.7663208379720648, 'global/model_version': 49520, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:41,995] calculate_sps 33920 steps in 10.036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:41,996] calculate_sps 35200 steps in 10.036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:41,996] {'local/mean_episode_return': 41575.0, 'local/mean_episode_step': 4411.375, 'local/SPS': 3379.8200725606057, 'local/env_act_steps': 31735680, 'local/env_train_steps': 31733760, 'local/optimizer_steps': 49584, 'local/running_reward': 22752.37798804781, 'local/running_step': 2398.702595866534, 'local/steps_done': 31735680, 'local/episodes_done': 7743, 'local/unclipped_grad_norm': 0.7032595577615278, 'local/model_version': 49584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:41,998] {'global/mean_episode_return': 41400.0, 'global/mean_episode_step': 4427.375, 'global/SPS': 3507.3604526572326, 'global/env_act_steps': 31729664, 'global/env_train_steps': 31728000, 'global/optimizer_steps': 49575, 'global/running_reward': 22774.79919678715, 'global/running_step': 2401.5568210341366, 'global/steps_done': 31729664, 'global/episodes_done': 7741, 'global/unclipped_grad_norm': 0.6734822275963697, 'global/model_version': 49575, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:52,017] calculate_sps 30720 steps in 10.0215
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:57:52,017] calculate_sps 31360 steps in 10.0215
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:52,017] {'local/mean_episode_return': 50666.666666666664, 'local/mean_episode_step': 4983.0, 'local/SPS': 3065.398834383031, 'local/env_act_steps': 31769088, 'local/env_train_steps': 31764480, 'local/optimizer_steps': 49632, 'local/running_reward': 22948.036398467433, 'local/running_step': 2419.060195162835, 'local/steps_done': 31769088, 'local/episodes_done': 7746, 'local/unclipped_grad_norm': 0.6201116554439068, 'local/model_version': 49632, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:57:52,019] {'global/mean_episode_return': 47640.0, 'global/mean_episode_step': 4757.6, 'global/SPS': 3129.2613100993444, 'global/env_act_steps': 31763072, 'global/env_train_steps': 31759360, 'global/optimizer_steps': 49624, 'global/running_reward': 22859.740181992336, 'global/running_step': 2409.988415948276, 'global/steps_done': 31763072, 'global/episodes_done': 7746, 'global/unclipped_grad_norm': 0.6717889768128492, 'global/model_version': 49624, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:02,026] calculate_sps 34560 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:02,026] calculate_sps 33920 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:02,027] {'local/mean_episode_return': 43155.555555555555, 'local/mean_episode_step': 4509.222222222223, 'local/SPS': 3452.665464100366, 'local/env_act_steps': 31801088, 'local/env_train_steps': 31799040, 'local/optimizer_steps': 49685, 'local/running_reward': 23555.99375, 'local/running_step': 2477.46175, 'local/steps_done': 31801088, 'local/episodes_done': 7755, 'local/unclipped_grad_norm': 0.68101389649904, 'local/model_version': 49685, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:02,028] {'global/mean_episode_return': 46600.0, 'global/mean_episode_step': 4806.4, 'global/SPS': 3388.7272147651743, 'global/env_act_steps': 31795968, 'global/env_train_steps': 31793280, 'global/optimizer_steps': 49676, 'global/running_reward': 23549.550097276264, 'global/running_step': 2477.899623054475, 'global/steps_done': 31795968, 'global/episodes_done': 7751, 'global/unclipped_grad_norm': 0.6154615712853578, 'global/model_version': 49676, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:12,062] calculate_sps 32000 steps in 10.0359
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:12,063] calculate_sps 32640 steps in 10.0359
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:12,063] {'local/mean_episode_return': 42775.0, 'local/mean_episode_step': 4665.375, 'local/SPS': 3188.55805699448, 'local/env_act_steps': 31834624, 'local/env_train_steps': 31831040, 'local/optimizer_steps': 49736, 'local/running_reward': 23038.97304389313, 'local/running_step': 2414.5853709446565, 'local/steps_done': 31834624, 'local/episodes_done': 7763, 'local/unclipped_grad_norm': 0.6934317762360853, 'local/model_version': 49736, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:12,064] {'global/mean_episode_return': 40945.454545454544, 'global/mean_episode_step': 4441.272727272727, 'global/SPS': 3252.32921813437, 'global/env_act_steps': 31829504, 'global/env_train_steps': 31825920, 'global/optimizer_steps': 49728, 'global/running_reward': 23069.346374045803, 'global/running_step': 2419.0098103530536, 'global/steps_done': 31829504, 'global/episodes_done': 7762, 'global/unclipped_grad_norm': 0.7385529935933076, 'global/model_version': 49728, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:22,069] calculate_sps 33280 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:22,069] calculate_sps 33920 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:22,069] {'local/mean_episode_return': 40566.666666666664, 'local/mean_episode_step': 4239.166666666667, 'local/SPS': 3325.8443049603784, 'local/env_act_steps': 31867392, 'local/env_train_steps': 31864320, 'local/optimizer_steps': 49787, 'local/running_reward': 23174.2919921875, 'local/running_step': 2420.6617126464844, 'local/steps_done': 31867392, 'local/episodes_done': 7769, 'local/unclipped_grad_norm': 0.6579291963694143, 'local/model_version': 49787, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:22,070] {'global/mean_episode_return': 41514.28571428572, 'global/mean_episode_step': 4350.714285714285, 'global/SPS': 3389.8028492865396, 'global/env_act_steps': 31862400, 'global/env_train_steps': 31859840, 'global/optimizer_steps': 49780, 'global/running_reward': 23134.43579766537, 'global/running_step': 2417.5263557879375, 'global/steps_done': 31862400, 'global/episodes_done': 7769, 'global/unclipped_grad_norm': 0.630647828659186, 'global/model_version': 49780, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:32,070] calculate_sps 33280 steps in 10.0015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:32,071] calculate_sps 32640 steps in 10.0015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:32,071] {'local/mean_episode_return': 48850.0, 'local/mean_episode_step': 4878.5, 'local/SPS': 3327.4944066559406, 'local/env_act_steps': 31900544, 'local/env_train_steps': 31897600, 'local/optimizer_steps': 49840, 'local/running_reward': 23784.821428571428, 'local/running_step': 2483.4321609555986, 'local/steps_done': 31900544, 'local/episodes_done': 7773, 'local/unclipped_grad_norm': 0.6412677860484933, 'local/model_version': 49840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:32,072] {'global/mean_episode_return': 48900.0, 'global/mean_episode_step': 4712.0, 'global/SPS': 3263.504129604865, 'global/env_act_steps': 31896064, 'global/env_train_steps': 31892480, 'global/optimizer_steps': 49832, 'global/running_reward': 23689.187262357413, 'global/running_step': 2473.420330323194, 'global/steps_done': 31896064, 'global/episodes_done': 7771, 'global/unclipped_grad_norm': 0.6698138484588037, 'global/model_version': 49832, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:42,089] calculate_sps 30720 steps in 10.0185
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:42,089] calculate_sps 33280 steps in 10.0185
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:42,092] {'local/mean_episode_return': 46628.57142857143, 'local/mean_episode_step': 4849.428571428572, 'local/SPS': 3066.3377750631234, 'local/env_act_steps': 31933568, 'local/env_train_steps': 31928320, 'local/optimizer_steps': 49888, 'local/running_reward': 23701.974321705427, 'local/running_step': 2473.4082485465115, 'local/steps_done': 31933568, 'local/episodes_done': 7780, 'local/unclipped_grad_norm': 0.6367027697463831, 'local/model_version': 49888, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:42,094] {'global/mean_episode_return': 47111.11111111111, 'global/mean_episode_step': 4892.888888888889, 'global/SPS': 3321.8659229850505, 'global/env_act_steps': 31928960, 'global/env_train_steps': 31925760, 'global/optimizer_steps': 49883, 'global/running_reward': 23729.78477626459, 'global/running_step': 2476.4579584143967, 'global/steps_done': 31928960, 'global/episodes_done': 7780, 'global/unclipped_grad_norm': 0.6444969749918171, 'global/model_version': 49883, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:52,113] calculate_sps 35840 steps in 10.0244
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:58:52,114] calculate_sps 33280 steps in 10.0244
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:52,114] {'local/mean_episode_return': 47200.0, 'local/mean_episode_step': 4748.2, 'local/SPS': 3575.2685892074182, 'local/env_act_steps': 31965696, 'local/env_train_steps': 31964160, 'local/optimizer_steps': 49944, 'local/running_reward': 23993.781125498008, 'local/running_step': 2501.229986304781, 'local/steps_done': 31965696, 'local/episodes_done': 7785, 'local/unclipped_grad_norm': 0.6524032846625362, 'local/model_version': 49944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:58:52,115] {'global/mean_episode_return': 43900.0, 'global/mean_episode_step': 4585.25, 'global/SPS': 3319.8922614068883, 'global/env_act_steps': 31961984, 'global/env_train_steps': 31959040, 'global/optimizer_steps': 49936, 'global/running_reward': 23925.7691375969, 'global/running_step': 2494.9834665697676, 'global/steps_done': 31961984, 'global/episodes_done': 7784, 'global/unclipped_grad_norm': 0.6172536102668295, 'global/model_version': 49936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:02,147] calculate_sps 30720 steps in 10.0334
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:02,147] calculate_sps 32000 steps in 10.0334
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:02,147] {'local/mean_episode_return': 44380.0, 'local/mean_episode_step': 4518.2, 'local/SPS': 3061.760998613607, 'local/env_act_steps': 31998976, 'local/env_train_steps': 31994880, 'local/optimizer_steps': 49992, 'local/running_reward': 23829.84375, 'local/running_step': 2484.7681790865386, 'local/steps_done': 31998976, 'local/episodes_done': 7795, 'local/unclipped_grad_norm': 0.6023005625853936, 'local/model_version': 49992, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:02,149] {'global/mean_episode_return': 49428.57142857143, 'global/mean_episode_step': 4907.428571428572, 'global/SPS': 3189.3343735558406, 'global/env_act_steps': 31995136, 'global/env_train_steps': 31991040, 'global/optimizer_steps': 49985, 'global/running_reward': 23866.940154440155, 'global/running_step': 2488.0318231177607, 'global/steps_done': 31995136, 'global/episodes_done': 7791, 'global/unclipped_grad_norm': 0.6211817532169576, 'global/model_version': 49985, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:12,163] calculate_sps 33920 steps in 10.0167
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:12,163] calculate_sps 34560 steps in 10.0167
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:12,164] {'local/mean_episode_return': 50288.88888888889, 'local/mean_episode_step': 5008.444444444444, 'local/SPS': 3386.3293187056083, 'local/env_act_steps': 32031360, 'local/env_train_steps': 32028800, 'local/optimizer_steps': 50044, 'local/running_reward': 23479.792490118576, 'local/running_step': 2450.7811882411065, 'local/steps_done': 32031360, 'local/episodes_done': 7804, 'local/unclipped_grad_norm': 0.6572626697329375, 'local/model_version': 50044, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:12,165] {'global/mean_episode_return': 47566.666666666664, 'global/mean_episode_step': 4723.666666666667, 'global/SPS': 3450.2223247189218, 'global/env_act_steps': 32027776, 'global/env_train_steps': 32025600, 'global/optimizer_steps': 50040, 'global/running_reward': 23561.40318627451, 'global/running_step': 2458.545986519608, 'global/steps_done': 32027776, 'global/episodes_done': 7803, 'global/unclipped_grad_norm': 0.6567989528179169, 'global/model_version': 50040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:22,185] calculate_sps 32640 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:22,185] calculate_sps 30720 steps in 10.0213
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:22,185] {'local/mean_episode_return': 41022.22222222222, 'local/mean_episode_step': 4146.0, 'local/SPS': 3257.061579415303, 'local/env_act_steps': 32063872, 'local/env_train_steps': 32061440, 'local/optimizer_steps': 50096, 'local/running_reward': 23255.616387795275, 'local/running_step': 2429.7627337598424, 'local/steps_done': 32063872, 'local/episodes_done': 7813, 'local/unclipped_grad_norm': 0.6845723705796095, 'local/model_version': 50096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:22,195] {'global/mean_episode_return': 37150.0, 'global/mean_episode_step': 3925.875, 'global/SPS': 3065.4697218026386, 'global/env_act_steps': 32060800, 'global/env_train_steps': 32056320, 'global/optimizer_steps': 50088, 'global/running_reward': 23268.241279069767, 'global/running_step': 2431.0084786821703, 'global/steps_done': 32060800, 'global/episodes_done': 7811, 'global/unclipped_grad_norm': 0.6937635950744152, 'global/model_version': 50088, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:32,207] calculate_sps 30720 steps in 10.0221
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:32,207] calculate_sps 35200 steps in 10.0221
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:32,208] {'local/mean_episode_return': 46350.0, 'local/mean_episode_step': 4722.875, 'local/SPS': 3065.2211926605983, 'local/env_act_steps': 32097280, 'local/env_train_steps': 32092160, 'local/optimizer_steps': 50144, 'local/running_reward': 23073.748802681992, 'local/running_step': 2414.147359913793, 'local/steps_done': 32097280, 'local/episodes_done': 7821, 'local/unclipped_grad_norm': 0.7971878324945768, 'local/model_version': 50144, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:32,209] {'global/mean_episode_return': 47400.0, 'global/mean_episode_step': 4768.777777777777, 'global/SPS': 3512.232616590269, 'global/env_act_steps': 32093056, 'global/env_train_steps': 32091520, 'global/optimizer_steps': 50142, 'global/running_reward': 23113.554067460318, 'global/running_step': 2418.529296875, 'global/steps_done': 32093056, 'global/episodes_done': 7820, 'global/unclipped_grad_norm': 0.7755975011322234, 'global/model_version': 50142, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:42,213] calculate_sps 35840 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:42,213] calculate_sps 31360 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:42,214] {'local/mean_episode_return': 46580.0, 'local/mean_episode_step': 4777.8, 'local/SPS': 3581.668668357972, 'local/env_act_steps': 32129024, 'local/env_train_steps': 32128000, 'local/optimizer_steps': 50199, 'local/running_reward': 22454.511088709678, 'local/running_step': 2349.8727948588707, 'local/steps_done': 32129024, 'local/episodes_done': 7831, 'local/unclipped_grad_norm': 0.752909161827781, 'local/model_version': 50199, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:42,215] {'global/mean_episode_return': 47454.545454545456, 'global/mean_episode_step': 4833.727272727273, 'global/SPS': 3133.9600848132254, 'global/env_act_steps': 32126592, 'global/env_train_steps': 32122880, 'global/optimizer_steps': 50192, 'global/running_reward': 22528.530534351146, 'global/running_step': 2357.0279103053435, 'global/steps_done': 32126592, 'global/episodes_done': 7831, 'global/unclipped_grad_norm': 0.7656696450710296, 'global/model_version': 50192, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:52,223] calculate_sps 30720 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 13:59:52,223] calculate_sps 34560 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:52,223] {'local/mean_episode_return': 48080.0, 'local/mean_episode_step': 4928.2, 'local/SPS': 3069.1459158110547, 'local/env_act_steps': 32162688, 'local/env_train_steps': 32158720, 'local/optimizer_steps': 50248, 'local/running_reward': 22537.084125475285, 'local/running_step': 2363.5198728612168, 'local/steps_done': 32162688, 'local/episodes_done': 7836, 'local/unclipped_grad_norm': 0.7280723841822877, 'local/model_version': 50248, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 13:59:52,225] {'global/mean_episode_return': 45750.0, 'global/mean_episode_step': 4811.5, 'global/SPS': 3452.7891552874366, 'global/env_act_steps': 32159616, 'global/env_train_steps': 32157440, 'global/optimizer_steps': 50245, 'global/running_reward': 22502.622335271317, 'global/running_step': 2360.072250484496, 'global/steps_done': 32159616, 'global/episodes_done': 7835, 'global/unclipped_grad_norm': 0.7116279275912158, 'global/model_version': 50245, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:02,231] calculate_sps 33920 steps in 10.0078
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:02,231] calculate_sps 32000 steps in 10.0078
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:02,231] {'local/mean_episode_return': 50560.0, 'local/mean_episode_step': 5150.0, 'local/SPS': 3389.3732241148214, 'local/env_act_steps': 32195328, 'local/env_train_steps': 32192640, 'local/optimizer_steps': 50301, 'local/running_reward': 22881.825980392157, 'local/running_step': 2397.2265625, 'local/steps_done': 32195328, 'local/episodes_done': 7841, 'local/unclipped_grad_norm': 0.6014790495611587, 'local/model_version': 50301, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:02,233] {'global/mean_episode_return': 50680.0, 'global/mean_episode_step': 5150.2, 'global/SPS': 3197.5219095422844, 'global/env_act_steps': 32193152, 'global/env_train_steps': 32189440, 'global/optimizer_steps': 50296, 'global/running_reward': 22857.35329198473, 'global/running_step': 2394.5924677958014, 'global/steps_done': 32193152, 'global/episodes_done': 7840, 'global/unclipped_grad_norm': 0.615539104622953, 'global/model_version': 50296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:12,266] calculate_sps 32640 steps in 10.0357
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:12,267] calculate_sps 32640 steps in 10.0357
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:12,267] {'local/mean_episode_return': 50888.88888888889, 'local/mean_episode_step': 5106.444444444444, 'local/SPS': 3252.4037026377996, 'local/env_act_steps': 32227840, 'local/env_train_steps': 32225280, 'local/optimizer_steps': 50352, 'local/running_reward': 22231.459153543306, 'local/running_step': 2334.947250246063, 'local/steps_done': 32227840, 'local/episodes_done': 7850, 'local/unclipped_grad_norm': 0.8601293517094032, 'local/model_version': 50352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:12,268] {'global/mean_episode_return': 51480.0, 'global/mean_episode_step': 5135.2, 'global/SPS': 3252.4037026377996, 'global/env_act_steps': 32225792, 'global/env_train_steps': 32222080, 'global/optimizer_steps': 50347, 'global/running_reward': 22271.041666666668, 'global/running_step': 2338.6579656862746, 'global/steps_done': 32225792, 'global/episodes_done': 7850, 'global/unclipped_grad_norm': 0.8067685853616864, 'global/model_version': 50347, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:22,273] calculate_sps 30720 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:22,273] calculate_sps 33920 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:22,273] {'local/mean_episode_return': 43266.666666666664, 'local/mean_episode_step': 4629.0, 'local/SPS': 3070.009835066427, 'local/env_act_steps': 32260864, 'local/env_train_steps': 32256000, 'local/optimizer_steps': 50400, 'local/running_reward': 22671.850775193798, 'local/running_step': 2384.3683684593025, 'local/steps_done': 32260864, 'local/episodes_done': 7853, 'local/unclipped_grad_norm': 0.7682803189381957, 'local/model_version': 50400, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:22,275] {'global/mean_episode_return': 48600.0, 'global/mean_episode_step': 5121.0, 'global/SPS': 3389.8025262191795, 'global/env_act_steps': 32258304, 'global/env_train_steps': 32256000, 'global/optimizer_steps': 50400, 'global/running_reward': 22617.87032480315, 'global/running_step': 2379.0049212598424, 'global/steps_done': 32258304, 'global/episodes_done': 7852, 'global/unclipped_grad_norm': 0.7972255250755346, 'global/model_version': 50400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:32,279] calculate_sps 35200 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:32,279] calculate_sps 30720 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:32,294] {'local/mean_episode_return': 36533.333333333336, 'local/mean_episode_step': 3964.0, 'local/SPS': 3518.385887593053, 'local/env_act_steps': 32292864, 'local/env_train_steps': 32291200, 'local/optimizer_steps': 50454, 'local/running_reward': 23187.44375, 'local/running_step': 2434.73178125, 'local/steps_done': 32292864, 'local/episodes_done': 7859, 'local/unclipped_grad_norm': 0.7714069681587042, 'local/model_version': 50454, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:32,296] {'global/mean_episode_return': 37100.0, 'global/mean_episode_step': 4040.0, 'global/SPS': 3070.59132008121, 'global/env_act_steps': 32291584, 'global/env_train_steps': 32286720, 'global/optimizer_steps': 50448, 'global/running_reward': 23155.985576923078, 'global/running_step': 2431.4306189903846, 'global/steps_done': 32291584, 'global/episodes_done': 7856, 'global/unclipped_grad_norm': 0.7470091168458263, 'global/model_version': 50448, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:42,282] calculate_sps 31360 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:42,282] calculate_sps 34560 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:42,282] {'local/mean_episode_return': 38625.0, 'local/mean_episode_step': 4162.625, 'local/SPS': 3134.602534942606, 'local/env_act_steps': 32325504, 'local/env_train_steps': 32322560, 'local/optimizer_steps': 50504, 'local/running_reward': 23476.507352941175, 'local/running_step': 2460.499080882353, 'local/steps_done': 32325504, 'local/episodes_done': 7867, 'local/unclipped_grad_norm': 0.7499088227748871, 'local/model_version': 50504, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:42,284] {'global/mean_episode_return': 37490.90909090909, 'global/mean_episode_step': 4051.818181818182, 'global/SPS': 3454.4599364673613, 'global/env_act_steps': 32323456, 'global/env_train_steps': 32321280, 'global/optimizer_steps': 50502, 'global/running_reward': 23492.168674698794, 'global/running_step': 2462.5292733433735, 'global/steps_done': 32323456, 'global/episodes_done': 7867, 'global/unclipped_grad_norm': 0.7798443287611008, 'global/model_version': 50502, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:52,324] calculate_sps 32640 steps in 10.0427
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:00:52,324] calculate_sps 32000 steps in 10.0427
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:52,324] {'local/mean_episode_return': 47771.42857142857, 'local/mean_episode_step': 4856.428571428572, 'local/SPS': 3250.135619520079, 'local/env_act_steps': 32358784, 'local/env_train_steps': 32355200, 'local/optimizer_steps': 50554, 'local/running_reward': 22993.623798076922, 'local/running_step': 2413.5431189903848, 'local/steps_done': 32358784, 'local/episodes_done': 7875, 'local/unclipped_grad_norm': 0.6896396088600159, 'local/model_version': 50554, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:00:52,325] {'global/mean_episode_return': 47771.42857142857, 'global/mean_episode_step': 4856.428571428572, 'global/SPS': 3186.4074701177246, 'global/env_act_steps': 32357120, 'global/env_train_steps': 32353280, 'global/optimizer_steps': 50552, 'global/running_reward': 23011.644486692014, 'global/running_step': 2414.9849096958174, 'global/steps_done': 32357120, 'global/episodes_done': 7875, 'global/unclipped_grad_norm': 0.6780815643072128, 'global/model_version': 50552, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:02,349] calculate_sps 33920 steps in 10.025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:02,350] calculate_sps 33920 steps in 10.025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:02,350] {'local/mean_episode_return': 47650.0, 'local/mean_episode_step': 4801.5, 'local/SPS': 3383.5547142153623, 'local/env_act_steps': 32391296, 'local/env_train_steps': 32389120, 'local/optimizer_steps': 50608, 'local/running_reward': 23137.038631889765, 'local/running_step': 2431.568067175197, 'local/steps_done': 32391296, 'local/episodes_done': 7883, 'local/unclipped_grad_norm': 0.7786174168189367, 'local/model_version': 50608, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:02,351] {'global/mean_episode_return': 47650.0, 'global/mean_episode_step': 4801.5, 'global/SPS': 3383.5547142153623, 'global/env_act_steps': 32389760, 'global/env_train_steps': 32387200, 'global/optimizer_steps': 50604, 'global/running_reward': 23148.4375, 'global/running_step': 2432.5323529411767, 'global/steps_done': 32389760, 'global/episodes_done': 7883, 'global/unclipped_grad_norm': 0.7404930528539878, 'global/model_version': 50604, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:12,391] calculate_sps 30720 steps in 10.0265
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:12,392] calculate_sps 32640 steps in 10.0265
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:12,392] {'local/mean_episode_return': 49076.92307692308, 'local/mean_episode_step': 4966.615384615385, 'local/SPS': 3063.8703747302507, 'local/env_act_steps': 32424704, 'local/env_train_steps': 32419840, 'local/optimizer_steps': 50656, 'local/running_reward': 22063.811063218393, 'local/running_step': 2325.925466954023, 'local/steps_done': 32424704, 'local/episodes_done': 7896, 'local/unclipped_grad_norm': 0.8091934813807408, 'local/model_version': 50656, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:12,393] {'global/mean_episode_return': 48350.0, 'global/mean_episode_step': 4930.666666666667, 'global/SPS': 3255.3622731508913, 'global/env_act_steps': 32423040, 'global/env_train_steps': 32419840, 'global/optimizer_steps': 50656, 'global/running_reward': 22119.65144230769, 'global/running_step': 2331.374909855769, 'global/steps_done': 32423040, 'global/episodes_done': 7895, 'global/unclipped_grad_norm': 0.8488899452181963, 'global/model_version': 50656, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:22,406] calculate_sps 35200 steps in 10.0303
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:22,406] calculate_sps 32000 steps in 10.0303
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:22,406] {'local/mean_episode_return': 42900.0, 'local/mean_episode_step': 4647.0, 'local/SPS': 3509.3682383701034, 'local/env_act_steps': 32456576, 'local/env_train_steps': 32455040, 'local/optimizer_steps': 50710, 'local/running_reward': 21672.602911646587, 'local/running_step': 2285.687625502008, 'local/steps_done': 32456576, 'local/episodes_done': 7900, 'local/unclipped_grad_norm': 0.7500382948804785, 'local/model_version': 50710, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:22,407] {'global/mean_episode_return': 45880.0, 'global/mean_episode_step': 4797.2, 'global/SPS': 3190.3347621546395, 'global/env_act_steps': 32455936, 'global/env_train_steps': 32451840, 'global/optimizer_steps': 50705, 'global/running_reward': 21653.313472762646, 'global/running_step': 2284.016628161479, 'global/steps_done': 32455936, 'global/episodes_done': 7900, 'global/unclipped_grad_norm': 0.7371960063369907, 'global/model_version': 50705, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:32,439] calculate_sps 31360 steps in 10.0326
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:32,439] calculate_sps 34560 steps in 10.0326
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:32,440] {'local/mean_episode_return': 48450.0, 'local/mean_episode_step': 5039.5, 'local/SPS': 3125.8131513676535, 'local/env_act_steps': 32489856, 'local/env_train_steps': 32486400, 'local/optimizer_steps': 50760, 'local/running_reward': 22278.329326923078, 'local/running_step': 2345.9360877403847, 'local/steps_done': 32489856, 'local/episodes_done': 7904, 'local/unclipped_grad_norm': 0.6708356270194054, 'local/model_version': 50760, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:32,441] {'global/mean_episode_return': 48450.0, 'global/mean_episode_step': 5039.5, 'global/SPS': 3444.7736770174142, 'global/env_act_steps': 32488832, 'global/env_train_steps': 32486400, 'global/optimizer_steps': 50760, 'global/running_reward': 22270.65296692607, 'global/running_step': 2345.186496838521, 'global/steps_done': 32488832, 'global/episodes_done': 7904, 'global/unclipped_grad_norm': 0.6894771811637012, 'global/model_version': 50760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:42,440] calculate_sps 32640 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:42,440] calculate_sps 31360 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:42,442] {'local/mean_episode_return': 49360.0, 'local/mean_episode_step': 4880.8, 'local/SPS': 3263.745159974124, 'local/env_act_steps': 32522752, 'local/env_train_steps': 32519040, 'local/optimizer_steps': 50811, 'local/running_reward': 22824.79936770428, 'local/running_step': 2398.5290612840467, 'local/steps_done': 32522752, 'local/episodes_done': 7909, 'local/unclipped_grad_norm': 0.5975242490861931, 'local/model_version': 50811, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:42,451] {'global/mean_episode_return': 49360.0, 'global/mean_episode_step': 4880.8, 'global/SPS': 3135.755153700629, 'global/env_act_steps': 32522368, 'global/env_train_steps': 32517760, 'global/optimizer_steps': 50808, 'global/running_reward': 22823.956345419847, 'global/running_step': 2398.3309875954196, 'global/steps_done': 32522368, 'global/episodes_done': 7909, 'global/unclipped_grad_norm': 0.584564204638203, 'global/model_version': 50808, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:52,467] calculate_sps 33920 steps in 10.0278
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:01:52,468] calculate_sps 35200 steps in 10.0278
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:52,478] {'local/mean_episode_return': 42377.77777777778, 'local/mean_episode_step': 4404.333333333333, 'local/SPS': 3382.604396405458, 'local/env_act_steps': 32554880, 'local/env_train_steps': 32552960, 'local/optimizer_steps': 50864, 'local/running_reward': 22593.70642430279, 'local/running_step': 2374.799489541833, 'local/steps_done': 32554880, 'local/episodes_done': 7918, 'local/unclipped_grad_norm': 0.8010634796799354, 'local/model_version': 50864, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:01:52,480] {'global/mean_episode_return': 42377.77777777778, 'global/mean_episode_step': 4404.333333333333, 'global/SPS': 3510.2498453264184, 'global/env_act_steps': 32554496, 'global/env_train_steps': 32552960, 'global/optimizer_steps': 50864, 'global/running_reward': 22584.630229083665, 'global/running_step': 2374.052010707171, 'global/steps_done': 32554496, 'global/episodes_done': 7918, 'global/unclipped_grad_norm': 0.8012682018535477, 'global/model_version': 50864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:02,468] calculate_sps 30720 steps in 10
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:02,468] calculate_sps 30720 steps in 10
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:02,469] {'local/mean_episode_return': 44000.0, 'local/mean_episode_step': 4579.0, 'local/SPS': 3071.9919433805044, 'local/env_act_steps': 32588160, 'local/env_train_steps': 32583680, 'local/optimizer_steps': 50912, 'local/running_reward': 22741.31610576923, 'local/running_step': 2387.015685096154, 'local/steps_done': 32588160, 'local/episodes_done': 7927, 'local/unclipped_grad_norm': 0.7133739097043872, 'local/model_version': 50912, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:02,470] {'global/mean_episode_return': 44000.0, 'global/mean_episode_step': 4579.0, 'global/SPS': 3071.9919433805044, 'global/env_act_steps': 32588160, 'global/env_train_steps': 32583680, 'global/optimizer_steps': 50912, 'global/running_reward': 22745.431321292777, 'global/running_step': 2387.3859612642586, 'global/steps_done': 32588160, 'global/episodes_done': 7927, 'global/unclipped_grad_norm': 0.7133739097043872, 'global/model_version': 50912, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:12,488] calculate_sps 34560 steps in 10.0212
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:12,488] calculate_sps 25600 steps in 10.0212
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:12,488] {'local/mean_episode_return': 44981.818181818184, 'local/mean_episode_step': 4633.181818181818, 'local/SPS': 3448.703568792556, 'local/env_act_steps': 32620288, 'local/env_train_steps': 32618240, 'local/optimizer_steps': 50965, 'local/running_reward': 22042.866035856572, 'local/running_step': 2316.3055590139443, 'local/steps_done': 32620288, 'local/episodes_done': 7938, 'local/unclipped_grad_norm': 0.6997778016441273, 'local/model_version': 50965, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:12,489] {'global/mean_episode_return': 43400.0, 'global/mean_episode_step': 4486.666666666667, 'global/SPS': 2554.595236142634, 'global/env_act_steps': 32614400, 'global/env_train_steps': 32609280, 'global/optimizer_steps': 50952, 'global/running_reward': 22089.67987804878, 'global/running_step': 2321.4371951219514, 'global/steps_done': 32614400, 'global/episodes_done': 7936, 'global/unclipped_grad_norm': 0.7117737926542759, 'global/model_version': 50952, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:22,496] calculate_sps 32000 steps in 10.0078
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:22,497] calculate_sps 35840 steps in 10.0078
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:22,497] {'local/mean_episode_return': 41657.142857142855, 'local/mean_episode_step': 4309.428571428572, 'local/SPS': 3197.5024848245303, 'local/env_act_steps': 32653568, 'local/env_train_steps': 32650240, 'local/optimizer_steps': 51016, 'local/running_reward': 21766.52644230769, 'local/running_step': 2286.3756009615386, 'local/steps_done': 32653568, 'local/episodes_done': 7945, 'local/unclipped_grad_norm': 0.6842863247090695, 'local/model_version': 51016, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:22,498] {'global/mean_episode_return': 43977.77777777778, 'global/mean_episode_step': 4527.888888888889, 'global/SPS': 3581.202783003474, 'global/env_act_steps': 32647296, 'global/env_train_steps': 32645120, 'global/optimizer_steps': 51008, 'global/running_reward': 21789.937986381323, 'global/running_step': 2289.2474768968873, 'global/steps_done': 32647296, 'global/episodes_done': 7945, 'global/unclipped_grad_norm': 0.6964032338666064, 'global/model_version': 51008, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:32,510] calculate_sps 32640 steps in 10.0139
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:32,510] calculate_sps 30720 steps in 10.0139
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:32,510] {'local/mean_episode_return': 50685.71428571428, 'local/mean_episode_step': 4991.857142857143, 'local/SPS': 3259.4845345287613, 'local/env_act_steps': 32686464, 'local/env_train_steps': 32682880, 'local/optimizer_steps': 51066, 'local/running_reward': 21641.840953307394, 'local/running_step': 2272.55514348249, 'local/steps_done': 32686464, 'local/episodes_done': 7952, 'local/unclipped_grad_norm': 0.714027151465416, 'local/model_version': 51066, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:32,511] {'global/mean_episode_return': 50685.71428571428, 'global/mean_episode_step': 4991.857142857143, 'global/SPS': 3067.7501501447164, 'global/env_act_steps': 32681088, 'global/env_train_steps': 32675840, 'global/optimizer_steps': 51056, 'global/running_reward': 21655.208333333332, 'global/running_step': 2273.741358901515, 'global/steps_done': 32681088, 'global/episodes_done': 7952, 'global/unclipped_grad_norm': 0.6921022006620964, 'global/model_version': 51056, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:42,511] calculate_sps 33920 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:42,511] calculate_sps 35840 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:42,511] {'local/mean_episode_return': 47085.71428571428, 'local/mean_episode_step': 4640.428571428572, 'local/SPS': 3391.7412306800325, 'local/env_act_steps': 32719616, 'local/env_train_steps': 32716800, 'local/optimizer_steps': 51120, 'local/running_reward': 21796.259652509652, 'local/running_step': 2289.935328185328, 'local/steps_done': 32719616, 'local/episodes_done': 7959, 'local/unclipped_grad_norm': 0.717207223728851, 'local/model_version': 51120, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:42,513] {'global/mean_episode_return': 53150.0, 'global/mean_episode_step': 5057.5, 'global/SPS': 3583.726583360034, 'global/env_act_steps': 32713984, 'global/env_train_steps': 32711680, 'global/optimizer_steps': 51112, 'global/running_reward': 21763.82538910506, 'global/running_step': 2286.4511490758755, 'global/steps_done': 32713984, 'global/episodes_done': 7956, 'global/unclipped_grad_norm': 0.696015864610672, 'global/model_version': 51112, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:52,516] calculate_sps 30720 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:02:52,516] calculate_sps 30720 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:52,516] {'local/mean_episode_return': 48425.0, 'local/mean_episode_step': 4894.25, 'local/SPS': 3070.5051954844807, 'local/env_act_steps': 32752640, 'local/env_train_steps': 32747520, 'local/optimizer_steps': 51168, 'local/running_reward': 21639.970930232557, 'local/running_step': 2269.3984677810076, 'local/steps_done': 32752640, 'local/episodes_done': 7967, 'local/unclipped_grad_norm': 0.7673831315090259, 'local/model_version': 51168, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:02:52,518] {'global/mean_episode_return': 45854.545454545456, 'global/mean_episode_step': 4673.363636363636, 'global/SPS': 3070.5051954844807, 'global/env_act_steps': 32747136, 'global/env_train_steps': 32742400, 'global/optimizer_steps': 51160, 'global/running_reward': 21703.903233590732, 'global/running_step': 2276.7166686776063, 'global/steps_done': 32747136, 'global/episodes_done': 7967, 'global/unclipped_grad_norm': 0.7355303882310787, 'global/model_version': 51160, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:02,551] calculate_sps 35840 steps in 10.0353
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:02,551] calculate_sps 35840 steps in 10.0353
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:02,552] {'local/mean_episode_return': 46766.666666666664, 'local/mean_episode_step': 4830.5, 'local/SPS': 3571.3866132600624, 'local/env_act_steps': 32784896, 'local/env_train_steps': 32783360, 'local/optimizer_steps': 51224, 'local/running_reward': 21507.50248015873, 'local/running_step': 2251.2863033234125, 'local/steps_done': 32784896, 'local/episodes_done': 7973, 'local/unclipped_grad_norm': 0.7041162177920341, 'local/model_version': 51224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:02,553] {'global/mean_episode_return': 46766.666666666664, 'global/mean_episode_step': 4830.5, 'global/SPS': 3571.3866132600624, 'global/env_act_steps': 32779648, 'global/env_train_steps': 32778240, 'global/optimizer_steps': 51216, 'global/running_reward': 21480.78248031496, 'global/running_step': 2248.9460814468503, 'global/steps_done': 32779648, 'global/episodes_done': 7973, 'global/unclipped_grad_norm': 0.7674838277910437, 'global/model_version': 51216, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:12,553] calculate_sps 30720 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:12,553] calculate_sps 30720 steps in 10.0019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:12,562] {'local/mean_episode_return': 46766.666666666664, 'local/mean_episode_step': 4621.833333333333, 'local/SPS': 3071.4122706679254, 'local/env_act_steps': 32817664, 'local/env_train_steps': 32814080, 'local/optimizer_steps': 51272, 'local/running_reward': 21965.49072265625, 'local/running_step': 2300.260040283203, 'local/steps_done': 32817664, 'local/episodes_done': 7979, 'local/unclipped_grad_norm': 0.6999784496923288, 'local/model_version': 51272, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:12,564] {'global/mean_episode_return': 47520.0, 'global/mean_episode_step': 4681.6, 'global/SPS': 3071.4122706679254, 'global/env_act_steps': 32813056, 'global/env_train_steps': 32808960, 'global/optimizer_steps': 51264, 'global/running_reward': 21913.52370689655, 'global/running_step': 2294.644396551724, 'global/steps_done': 32813056, 'global/episodes_done': 7978, 'global/unclipped_grad_norm': 0.6679557642589012, 'global/model_version': 51264, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:22,585] calculate_sps 33280 steps in 10.0322
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:22,585] calculate_sps 34560 steps in 10.0322
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:22,585] {'local/mean_episode_return': 41766.666666666664, 'local/mean_episode_step': 4432.833333333333, 'local/SPS': 3317.3251405502574, 'local/env_act_steps': 32850432, 'local/env_train_steps': 32847360, 'local/optimizer_steps': 51323, 'local/running_reward': 22186.517333984375, 'local/running_step': 2325.3671264648438, 'local/steps_done': 32850432, 'local/episodes_done': 7985, 'local/unclipped_grad_norm': 0.6189384548103108, 'local/model_version': 51323, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:22,587] {'global/mean_episode_return': 41066.666666666664, 'global/mean_episode_step': 4353.666666666667, 'global/SPS': 3444.9145690329597, 'global/env_act_steps': 32845568, 'global/env_train_steps': 32843520, 'global/optimizer_steps': 51317, 'global/running_reward': 22168.959153543306, 'global/running_step': 2323.108083169291, 'global/steps_done': 32845568, 'global/episodes_done': 7984, 'global/unclipped_grad_norm': 0.6312071124337754, 'global/model_version': 51317, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:32,594] calculate_sps 33280 steps in 10.0086
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:32,594] calculate_sps 32000 steps in 10.0086
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:32,602] {'local/mean_episode_return': 44866.666666666664, 'local/mean_episode_step': 4784.0, 'local/SPS': 3325.1313505668577, 'local/env_act_steps': 32883328, 'local/env_train_steps': 32880640, 'local/optimizer_steps': 51376, 'local/running_reward': 22432.31395914397, 'local/running_step': 2348.6166707198445, 'local/steps_done': 32883328, 'local/episodes_done': 7988, 'local/unclipped_grad_norm': 0.7029530698398374, 'local/model_version': 51376, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:32,603] {'global/mean_episode_return': 45450.0, 'global/mean_episode_step': 4787.5, 'global/SPS': 3197.2416832373633, 'global/env_act_steps': 32879104, 'global/env_train_steps': 32875520, 'global/optimizer_steps': 51368, 'global/running_reward': 22335.12643129771, 'global/running_step': 2339.8306595896947, 'global/steps_done': 32879104, 'global/episodes_done': 7988, 'global/unclipped_grad_norm': 0.7221893855169708, 'global/model_version': 51368, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:42,596] calculate_sps 31360 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:42,596] calculate_sps 33920 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:42,597] {'local/mean_episode_return': 40760.0, 'local/mean_episode_step': 4454.8, 'local/SPS': 3135.3297727884574, 'local/env_act_steps': 32916608, 'local/env_train_steps': 32912000, 'local/optimizer_steps': 51424, 'local/running_reward': 23142.427884615383, 'local/running_step': 2412.2408954326925, 'local/steps_done': 32916608, 'local/episodes_done': 7993, 'local/unclipped_grad_norm': 0.7430609359095494, 'local/model_version': 51424, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:42,598] {'global/mean_episode_return': 39500.0, 'global/mean_episode_step': 4380.5, 'global/SPS': 3391.275060363025, 'global/env_act_steps': 32912128, 'global/env_train_steps': 32909440, 'global/optimizer_steps': 51421, 'global/running_reward': 23053.0886627907, 'global/running_step': 2404.2345566860463, 'global/steps_done': 32912128, 'global/episodes_done': 7992, 'global/unclipped_grad_norm': 0.7236696037481416, 'global/model_version': 51421, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:52,611] calculate_sps 35200 steps in 10.0154
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:03:52,612] calculate_sps 32640 steps in 10.0154
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:52,612] {'local/mean_episode_return': 42733.333333333336, 'local/mean_episode_step': 4456.666666666667, 'local/SPS': 3514.580781867368, 'local/env_act_steps': 32948736, 'local/env_train_steps': 32947200, 'local/optimizer_steps': 51480, 'local/running_reward': 23463.93799800797, 'local/running_step': 2442.8181025896415, 'local/steps_done': 32948736, 'local/episodes_done': 7999, 'local/unclipped_grad_norm': 0.660039414784738, 'local/model_version': 51480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:03:52,623] {'global/mean_episode_return': 42466.666666666664, 'global/mean_episode_step': 4443.666666666667, 'global/SPS': 3258.9749068224687, 'global/env_act_steps': 32945408, 'global/env_train_steps': 32942080, 'global/optimizer_steps': 51472, 'global/running_reward': 23444.93389423077, 'global/running_step': 2440.4168870192307, 'global/steps_done': 32945408, 'global/episodes_done': 7998, 'global/unclipped_grad_norm': 0.6377266622057148, 'global/model_version': 51472, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:02,613] calculate_sps 30720 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:02,613] calculate_sps 32640 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:02,613] {'local/mean_episode_return': 52885.71428571428, 'local/mean_episode_step': 5165.571428571428, 'local/SPS': 3071.611059991369, 'local/env_act_steps': 32982144, 'local/env_train_steps': 32977920, 'local/optimizer_steps': 51528, 'local/running_reward': 23576.9216954023, 'local/running_step': 2460.572856800766, 'local/steps_done': 32982144, 'local/episodes_done': 8006, 'local/unclipped_grad_norm': 0.6929859717686971, 'local/model_version': 51528, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:02,615] {'global/mean_episode_return': 52200.0, 'global/mean_episode_step': 5123.625, 'global/SPS': 3263.5867512408295, 'global/env_act_steps': 32978432, 'global/env_train_steps': 32974720, 'global/optimizer_steps': 51522, 'global/running_reward': 23619.96729651163, 'global/running_step': 2463.9713541666665, 'global/steps_done': 32978432, 'global/episodes_done': 8006, 'global/unclipped_grad_norm': 0.7109114515781403, 'global/model_version': 51522, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:12,637] calculate_sps 33920 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:12,637] calculate_sps 33920 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:12,638] {'local/mean_episode_return': 44133.333333333336, 'local/mean_episode_step': 4545.5, 'local/SPS': 3383.5834420281963, 'local/env_act_steps': 33014400, 'local/env_train_steps': 33011840, 'local/optimizer_steps': 51580, 'local/running_reward': 23320.455109126986, 'local/running_step': 2437.7039930555557, 'local/steps_done': 33014400, 'local/episodes_done': 8012, 'local/unclipped_grad_norm': 0.7485966350023563, 'local/model_version': 51580, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:12,638] {'global/mean_episode_return': 42440.0, 'global/mean_episode_step': 4418.2, 'global/SPS': 3383.5834420281963, 'global/env_act_steps': 33011328, 'global/env_train_steps': 33008640, 'global/optimizer_steps': 51576, 'global/running_reward': 23291.02626459144, 'global/running_step': 2434.9032101167313, 'global/steps_done': 33011328, 'global/episodes_done': 8011, 'global/unclipped_grad_norm': 0.7588049957045803, 'global/model_version': 51576, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:22,644] calculate_sps 32640 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:22,644] calculate_sps 31360 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:22,645] {'local/mean_episode_return': 47175.0, 'local/mean_episode_step': 4824.6875, 'local/SPS': 3261.8231202892507, 'local/env_act_steps': 33047040, 'local/env_train_steps': 33044480, 'local/optimizer_steps': 51632, 'local/running_reward': 23753.87254901961, 'local/running_step': 2479.5970588235296, 'local/steps_done': 33047040, 'local/episodes_done': 8022, 'local/unclipped_grad_norm': 0.7822484895586967, 'local/model_version': 51632, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:22,655] {'global/mean_episode_return': 46425.0, 'global/mean_episode_step': 4797.6875, 'global/SPS': 3133.908488121045, 'global/env_act_steps': 33044608, 'global/env_train_steps': 33040000, 'global/optimizer_steps': 51624, 'global/running_reward': 23787.506009615383, 'global/running_step': 2483.4324519230768, 'global/steps_done': 33044608, 'global/episodes_done': 8021, 'global/unclipped_grad_norm': 0.7746969653914372, 'global/model_version': 51624, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:32,675] calculate_sps 30720 steps in 10.0305
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:32,675] calculate_sps 35200 steps in 10.0305
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:32,675] {'local/mean_episode_return': 43120.0, 'local/mean_episode_step': 4400.2, 'local/SPS': 3062.6736881382444, 'local/env_act_steps': 33080320, 'local/env_train_steps': 33075200, 'local/optimizer_steps': 51680, 'local/running_reward': 23074.092548076922, 'local/running_step': 2405.9322716346155, 'local/steps_done': 33080320, 'local/episodes_done': 8027, 'local/unclipped_grad_norm': 0.6812670376772682, 'local/model_version': 51680, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:32,677] {'global/mean_episode_return': 45700.0, 'global/mean_episode_step': 4566.5, 'global/SPS': 3509.3136009917384, 'global/env_act_steps': 33077248, 'global/env_train_steps': 33075200, 'global/optimizer_steps': 51680, 'global/running_reward': 23041.648284313724, 'global/running_step': 2402.7126838235295, 'global/steps_done': 33077248, 'global/episodes_done': 8027, 'global/unclipped_grad_norm': 0.6860070923077208, 'global/model_version': 51680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:42,690] calculate_sps 35840 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:42,691] calculate_sps 30720 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:42,691] {'local/mean_episode_return': 38366.666666666664, 'local/mean_episode_step': 4023.8333333333335, 'local/SPS': 3578.215296635176, 'local/env_act_steps': 33112064, 'local/env_train_steps': 33111040, 'local/optimizer_steps': 51735, 'local/running_reward': 23631.533518145163, 'local/running_step': 2458.0716355846776, 'local/steps_done': 33112064, 'local/episodes_done': 8033, 'local/unclipped_grad_norm': 0.6988309093497016, 'local/model_version': 51735, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:42,692] {'global/mean_episode_return': 38366.666666666664, 'global/mean_episode_step': 4023.8333333333335, 'global/SPS': 3067.041682830151, 'global/env_act_steps': 33111040, 'global/env_train_steps': 33105920, 'global/optimizer_steps': 51728, 'global/running_reward': 23604.977509469696, 'global/running_step': 2455.9779237689395, 'global/steps_done': 33111040, 'global/episodes_done': 8033, 'global/unclipped_grad_norm': 0.7327339975163341, 'global/model_version': 51728, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:52,715] calculate_sps 30720 steps in 10.0237
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:04:52,715] calculate_sps 35840 steps in 10.0237
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:52,715] {'local/mean_episode_return': 45400.0, 'local/mean_episode_step': 4664.2, 'local/SPS': 3064.7363559800324, 'local/env_act_steps': 33145728, 'local/env_train_steps': 33141760, 'local/optimizer_steps': 51784, 'local/running_reward': 24303.065589353613, 'local/running_step': 2517.1490019011408, 'local/steps_done': 33145728, 'local/episodes_done': 8038, 'local/unclipped_grad_norm': 0.7216188983649624, 'local/model_version': 51784, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:04:52,717] {'global/mean_episode_return': 45050.0, 'global/mean_episode_step': 4710.25, 'global/SPS': 3575.525748643371, 'global/env_act_steps': 33143168, 'global/env_train_steps': 33141760, 'global/optimizer_steps': 51784, 'global/running_reward': 24280.073456175298, 'global/running_step': 2515.252552290837, 'global/steps_done': 33143168, 'global/episodes_done': 8037, 'global/unclipped_grad_norm': 0.6897106098809412, 'global/model_version': 51784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:02,717] calculate_sps 33280 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:02,718] calculate_sps 30720 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:02,718] {'local/mean_episode_return': 46440.0, 'local/mean_episode_step': 4810.2, 'local/SPS': 3327.0995112978876, 'local/env_act_steps': 33178240, 'local/env_train_steps': 33175040, 'local/optimizer_steps': 51836, 'local/running_reward': 24563.250492125986, 'local/running_step': 2537.316621555118, 'local/steps_done': 33178240, 'local/episodes_done': 8043, 'local/unclipped_grad_norm': 0.629956152003545, 'local/model_version': 51836, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:02,720] {'global/mean_episode_return': 45120.0, 'global/mean_episode_step': 4627.2, 'global/SPS': 3071.1687796595884, 'global/env_act_steps': 33176576, 'global/env_train_steps': 33172480, 'global/optimizer_steps': 51832, 'global/running_reward': 24541.08596743295, 'global/running_step': 2535.448156130268, 'global/steps_done': 33176576, 'global/episodes_done': 8042, 'global/unclipped_grad_norm': 0.623626509681344, 'global/model_version': 51832, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:12,723] calculate_sps 33280 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:12,723] calculate_sps 35200 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:12,723] {'local/mean_episode_return': 44644.444444444445, 'local/mean_episode_step': 4595.555555555556, 'local/SPS': 3326.2266168688197, 'local/env_act_steps': 33210880, 'local/env_train_steps': 33208320, 'local/optimizer_steps': 51888, 'local/running_reward': 24208.11887254902, 'local/running_step': 2491.600245098039, 'local/steps_done': 33210880, 'local/episodes_done': 8052, 'local/unclipped_grad_norm': 0.7118327998771117, 'local/model_version': 51888, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:12,725] {'global/mean_episode_return': 45622.22222222222, 'global/mean_episode_step': 4714.555555555556, 'global/SPS': 3518.1243063035595, 'global/env_act_steps': 33209344, 'global/env_train_steps': 33207680, 'global/optimizer_steps': 51886, 'global/running_reward': 24221.209716796875, 'global/running_step': 2493.3907470703125, 'global/steps_done': 33209344, 'global/episodes_done': 8051, 'global/unclipped_grad_norm': 0.7077925969605092, 'global/model_version': 51886, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:22,729] calculate_sps 30720 steps in 10.0061
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:22,729] calculate_sps 31360 steps in 10.0061
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:22,729] {'local/mean_episode_return': 48200.0, 'local/mean_episode_step': 4788.625, 'local/SPS': 3070.1363119926536, 'local/env_act_steps': 33243904, 'local/env_train_steps': 33239040, 'local/optimizer_steps': 51936, 'local/running_reward': 24239.813468992248, 'local/running_step': 2493.246335998062, 'local/steps_done': 33243904, 'local/episodes_done': 8060, 'local/unclipped_grad_norm': 0.6820721483478943, 'local/model_version': 51936, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:22,730] {'global/mean_episode_return': 47800.0, 'global/mean_episode_step': 4737.0, 'global/SPS': 3134.0974851591673, 'global/env_act_steps': 33242240, 'global/env_train_steps': 33239040, 'global/optimizer_steps': 51936, 'global/running_reward': 24246.443336575874, 'global/running_step': 2493.8364542801555, 'global/steps_done': 33242240, 'global/episodes_done': 8060, 'global/unclipped_grad_norm': 0.6871523183584213, 'global/model_version': 51936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:32,742] calculate_sps 35200 steps in 10.0142
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:32,743] calculate_sps 32640 steps in 10.0142
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:32,743] {'local/mean_episode_return': 48625.0, 'local/mean_episode_step': 4928.625, 'local/SPS': 3515.0259367365093, 'local/env_act_steps': 33275776, 'local/env_train_steps': 33274240, 'local/optimizer_steps': 51990, 'local/running_reward': 24250.941265060243, 'local/running_step': 2492.8495544678717, 'local/steps_done': 33275776, 'local/episodes_done': 8068, 'local/unclipped_grad_norm': 0.6591486045055919, 'local/model_version': 51990, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:32,744] {'global/mean_episode_return': 48625.0, 'global/mean_episode_step': 4928.625, 'global/SPS': 3259.3876867920358, 'global/env_act_steps': 33275264, 'global/env_train_steps': 33271680, 'global/optimizer_steps': 51986, 'global/running_reward': 24261.56734496124, 'global/running_step': 2494.0106589147285, 'global/steps_done': 33275264, 'global/episodes_done': 8068, 'global/unclipped_grad_norm': 0.6444388940930367, 'global/model_version': 51986, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:42,762] calculate_sps 31360 steps in 10.0196
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:42,763] calculate_sps 33920 steps in 10.0196
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:42,763] {'local/mean_episode_return': 44925.0, 'local/mean_episode_step': 4572.5, 'local/SPS': 3129.865266955812, 'local/env_act_steps': 33309056, 'local/env_train_steps': 33305600, 'local/optimizer_steps': 52040, 'local/running_reward': 23830.69110576923, 'local/running_step': 2450.8559795673077, 'local/steps_done': 33309056, 'local/episodes_done': 8076, 'local/unclipped_grad_norm': 0.7515220358967781, 'local/model_version': 52040, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:42,775] {'global/mean_episode_return': 44925.0, 'global/mean_episode_step': 4572.5, 'global/SPS': 3385.3644724215924, 'global/env_act_steps': 33308032, 'global/env_train_steps': 33305600, 'global/optimizer_steps': 52040, 'global/running_reward': 23833.1298828125, 'global/running_step': 2451.0801696777344, 'global/steps_done': 33308032, 'global/episodes_done': 8076, 'global/unclipped_grad_norm': 0.7582996617312785, 'global/model_version': 52040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 14:05:52,419] saving global stats {'mean_episode_return': 48800.0, 'mean_episode_step': 4940.166666666667, 'SPS': None, 'env_act_steps': 33327744, 'env_train_steps': 33326080, 'optimizer_steps': 52072, 'running_reward': 23736.312905844155, 'running_step': 2440.1821732954545, 'steps_done': 33327744, 'episodes_done': 8082, 'unclipped_grad_norm': 0.673262644559145, 'model_version': 52072, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 14:05:52,520] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:52,766] calculate_sps 31360 steps in 10.0017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:05:52,766] calculate_sps 30720 steps in 10.0017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:52,768] {'local/mean_episode_return': 50342.857142857145, 'local/mean_episode_step': 5005.285714285715, 'local/SPS': 3135.4755149790503, 'local/env_act_steps': 33341696, 'local/env_train_steps': 33336960, 'local/optimizer_steps': 52088, 'local/running_reward': 23683.841911764706, 'local/running_step': 2434.8711397058823, 'local/steps_done': 33341696, 'local/episodes_done': 8083, 'local/unclipped_grad_norm': 0.6757150193055471, 'local/model_version': 52088, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:05:52,777] {'global/mean_episode_return': 50342.857142857145, 'global/mean_episode_step': 5005.285714285715, 'global/SPS': 3071.486218754988, 'global/env_act_steps': 33341312, 'global/env_train_steps': 33336320, 'global/optimizer_steps': 52088, 'global/running_reward': 23689.591346153848, 'global/running_step': 2435.4426682692306, 'global/steps_done': 33341312, 'global/episodes_done': 8083, 'global/unclipped_grad_norm': 0.6757150193055471, 'global/model_version': 52088, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:02,787] calculate_sps 35200 steps in 10.0228
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:02,787] calculate_sps 35840 steps in 10.0228
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:02,787] {'local/mean_episode_return': 46700.0, 'local/mean_episode_step': 4746.125, 'local/SPS': 3512.0032775636396, 'local/env_act_steps': 33374080, 'local/env_train_steps': 33372160, 'local/optimizer_steps': 52144, 'local/running_reward': 23473.425148221344, 'local/running_step': 2416.4890377964425, 'local/steps_done': 33374080, 'local/episodes_done': 8091, 'local/unclipped_grad_norm': 0.7228864708117076, 'local/model_version': 52144, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:02,789] {'global/mean_episode_return': 46700.0, 'global/mean_episode_step': 4746.125, 'global/SPS': 3575.857882610251, 'global/env_act_steps': 33373824, 'global/env_train_steps': 33372160, 'global/optimizer_steps': 52144, 'global/running_reward': 23474.231053149608, 'global/running_step': 2416.5768639271655, 'global/steps_done': 33373824, 'global/episodes_done': 8091, 'global/unclipped_grad_norm': 0.7228864708117076, 'global/model_version': 52144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:12,804] calculate_sps 30720 steps in 10.017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:12,804] calculate_sps 25600 steps in 10.017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:12,804] {'local/mean_episode_return': 50120.0, 'local/mean_episode_step': 5038.6, 'local/SPS': 3066.7943586263086, 'local/env_act_steps': 33407360, 'local/env_train_steps': 33402880, 'local/optimizer_steps': 52192, 'local/running_reward': 23688.19110576923, 'local/running_step': 2433.6417668269232, 'local/steps_done': 33407360, 'local/episodes_done': 8096, 'local/unclipped_grad_norm': 0.6821936701113979, 'local/model_version': 52192, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:12,806] {'global/mean_episode_return': 50120.0, 'global/mean_episode_step': 5038.6, 'global/SPS': 2555.661965521924, 'global/env_act_steps': 33400448, 'global/env_train_steps': 33397760, 'global/optimizer_steps': 52184, 'global/running_reward': 23671.66466346154, 'global/running_step': 2432.0463115985576, 'global/steps_done': 33400448, 'global/episodes_done': 8096, 'global/unclipped_grad_norm': 0.6695255290716886, 'global/model_version': 52184, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:22,831] calculate_sps 33920 steps in 10.028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:22,832] calculate_sps 30720 steps in 10.028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:22,832] {'local/mean_episode_return': 43700.0, 'local/mean_episode_step': 4591.25, 'local/SPS': 3382.5427926015186, 'local/env_act_steps': 33439360, 'local/env_train_steps': 33436800, 'local/optimizer_steps': 52244, 'local/running_reward': 24174.38125, 'local/running_step': 2476.15184375, 'local/steps_done': 33439360, 'local/episodes_done': 8100, 'local/unclipped_grad_norm': 0.7004794724858724, 'local/model_version': 52244, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:22,833] {'global/mean_episode_return': 43700.0, 'global/mean_episode_step': 4591.25, 'global/SPS': 3063.434981978734, 'global/env_act_steps': 33433728, 'global/env_train_steps': 33428480, 'global/optimizer_steps': 52232, 'global/running_reward': 24044.57331730769, 'global/running_step': 2465.2981971153845, 'global/steps_done': 33433728, 'global/episodes_done': 8100, 'global/unclipped_grad_norm': 0.6922965428481499, 'global/model_version': 52232, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:32,835] calculate_sps 32640 steps in 10.003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:32,835] calculate_sps 35840 steps in 10.003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:32,835] {'local/mean_episode_return': 49950.0, 'local/mean_episode_step': 4933.125, 'local/SPS': 3263.007632127871, 'local/env_act_steps': 33472000, 'local/env_train_steps': 33469440, 'local/optimizer_steps': 52296, 'local/running_reward': 24715.845588235294, 'local/running_step': 2521.6458639705884, 'local/steps_done': 33472000, 'local/episodes_done': 8108, 'local/unclipped_grad_norm': 0.6982715777479686, 'local/model_version': 52296, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:32,837] {'global/mean_episode_return': 47300.0, 'global/mean_episode_step': 4744.75, 'global/SPS': 3582.9103411600154, 'global/env_act_steps': 33465728, 'global/env_train_steps': 33464320, 'global/optimizer_steps': 52288, 'global/running_reward': 24691.51875, 'global/running_step': 2519.6534375, 'global/steps_done': 33465728, 'global/episodes_done': 8104, 'global/unclipped_grad_norm': 0.7017564858709063, 'global/model_version': 52288, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:42,841] calculate_sps 30720 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:42,842] calculate_sps 30720 steps in 10.0067
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:42,842] {'local/mean_episode_return': 45475.0, 'local/mean_episode_step': 4697.375, 'local/SPS': 3069.9549024122166, 'local/env_act_steps': 33505152, 'local/env_train_steps': 33500160, 'local/optimizer_steps': 52344, 'local/running_reward': 24351.574565637067, 'local/running_step': 2486.2016469594596, 'local/steps_done': 33505152, 'local/episodes_done': 8116, 'local/unclipped_grad_norm': 0.755898061208427, 'local/model_version': 52344, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:42,843] {'global/mean_episode_return': 48660.0, 'global/mean_episode_step': 4876.6, 'global/SPS': 3069.9549024122166, 'global/env_act_steps': 33499392, 'global/env_train_steps': 33495040, 'global/optimizer_steps': 52336, 'global/running_reward': 24416.427043726235, 'global/running_step': 2493.278754752852, 'global/steps_done': 33499392, 'global/episodes_done': 8114, 'global/unclipped_grad_norm': 0.748003976730009, 'global/model_version': 52336, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:52,876] calculate_sps 35840 steps in 10.0345
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:06:52,876] calculate_sps 35200 steps in 10.0345
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:52,877] {'local/mean_episode_return': 52116.666666666664, 'local/mean_episode_step': 5095.083333333333, 'local/SPS': 3571.6937075579704, 'local/env_act_steps': 33537536, 'local/env_train_steps': 33536000, 'local/optimizer_steps': 52400, 'local/running_reward': 24221.961462450592, 'local/running_step': 2471.08179965415, 'local/steps_done': 33537536, 'local/episodes_done': 8123, 'local/unclipped_grad_norm': 0.6725247486361435, 'local/model_version': 52400, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:06:52,878] {'global/mean_episode_return': 48816.666666666664, 'global/mean_episode_step': 4853.25, 'global/SPS': 3507.9134627801495, 'global/env_act_steps': 33531776, 'global/env_train_steps': 33530240, 'global/optimizer_steps': 52390, 'global/running_reward': 24220.238389328064, 'global/running_step': 2470.2827630928855, 'global/steps_done': 33531776, 'global/episodes_done': 8121, 'global/unclipped_grad_norm': 0.6848691056172053, 'global/model_version': 52390, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:02,908] calculate_sps 30720 steps in 10.0319
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:02,908] calculate_sps 31360 steps in 10.0319
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:02,908] {'local/mean_episode_return': 42600.0, 'local/mean_episode_step': 4336.0, 'local/SPS': 3062.240236512743, 'local/env_act_steps': 33571072, 'local/env_train_steps': 33566720, 'local/optimizer_steps': 52448, 'local/running_reward': 24280.075143129772, 'local/running_step': 2477.6014134064885, 'local/steps_done': 33571072, 'local/episodes_done': 8128, 'local/unclipped_grad_norm': 0.703366281154255, 'local/model_version': 52448, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:02,910] {'global/mean_episode_return': 45771.42857142857, 'global/mean_episode_step': 4632.857142857143, 'global/SPS': 3126.036908106759, 'global/env_act_steps': 33565696, 'global/env_train_steps': 33561600, 'global/optimizer_steps': 52440, 'global/running_reward': 24252.89504716981, 'global/running_step': 2475.057458726415, 'global/steps_done': 33565696, 'global/episodes_done': 8128, 'global/unclipped_grad_norm': 0.6841288533806801, 'global/model_version': 52440, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:12,945] calculate_sps 34560 steps in 10.0375
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:12,945] calculate_sps 34560 steps in 10.0375
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:12,945] {'local/mean_episode_return': 48222.22222222222, 'local/mean_episode_step': 4924.777777777777, 'local/SPS': 3443.083707740053, 'local/env_act_steps': 33603328, 'local/env_train_steps': 33601280, 'local/optimizer_steps': 52501, 'local/running_reward': 24171.540178571428, 'local/running_step': 2469.024925595238, 'local/steps_done': 33603328, 'local/episodes_done': 8137, 'local/unclipped_grad_norm': 0.6545779530732136, 'local/model_version': 52501, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:12,946] {'global/mean_episode_return': 49950.0, 'global/mean_episode_step': 5094.375, 'global/SPS': 3443.083707740053, 'global/env_act_steps': 33598336, 'global/env_train_steps': 33596160, 'global/optimizer_steps': 52494, 'global/running_reward': 24238.676470588234, 'global/running_step': 2475.7307598039215, 'global/steps_done': 33598336, 'global/episodes_done': 8136, 'global/unclipped_grad_norm': 0.6889415052202013, 'global/model_version': 52494, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:22,963] calculate_sps 32000 steps in 10.0176
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:22,963] calculate_sps 32000 steps in 10.0176
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:22,964] {'local/mean_episode_return': 46833.333333333336, 'local/mean_episode_step': 4833.166666666667, 'local/SPS': 3194.363963213689, 'local/env_act_steps': 33636224, 'local/env_train_steps': 33633280, 'local/optimizer_steps': 52552, 'local/running_reward': 24290.42436770428, 'local/running_step': 2478.3153270914395, 'local/steps_done': 33636224, 'local/episodes_done': 8143, 'local/unclipped_grad_norm': 0.6716881020396364, 'local/model_version': 52552, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:22,965] {'global/mean_episode_return': 43966.666666666664, 'global/mean_episode_step': 4529.0, 'global/SPS': 3194.363963213689, 'global/env_act_steps': 33631488, 'global/env_train_steps': 33628160, 'global/optimizer_steps': 52544, 'global/running_reward': 24260.243725868724, 'global/running_step': 2475.6920246139, 'global/steps_done': 33631488, 'global/episodes_done': 8142, 'global/unclipped_grad_norm': 0.6436401122808456, 'global/model_version': 52544, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:33,012] calculate_sps 32000 steps in 10.0494
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:33,012] calculate_sps 33280 steps in 10.0494
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:33,012] {'local/mean_episode_return': 51750.0, 'local/mean_episode_step': 5144.0, 'local/SPS': 3184.269452118448, 'local/env_act_steps': 33669376, 'local/env_train_steps': 33665280, 'local/optimizer_steps': 52601, 'local/running_reward': 24626.532335907337, 'local/running_step': 2511.2426701254826, 'local/steps_done': 33669376, 'local/episodes_done': 8147, 'local/unclipped_grad_norm': 0.6725917093607844, 'local/model_version': 52601, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:33,013] {'global/mean_episode_return': 51066.666666666664, 'global/mean_episode_step': 5194.0, 'global/SPS': 3311.640230203186, 'global/env_act_steps': 33664512, 'global/env_train_steps': 33661440, 'global/optimizer_steps': 52595, 'global/running_reward': 24551.86531007752, 'global/running_step': 2503.3483224321703, 'global/steps_done': 33664512, 'global/episodes_done': 8145, 'global/unclipped_grad_norm': 0.695820633687225, 'global/model_version': 52595, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:43,037] calculate_sps 34560 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:43,038] calculate_sps 33280 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:43,038] {'local/mean_episode_return': 46800.0, 'local/mean_episode_step': 4765.4, 'local/SPS': 3447.3192043370327, 'local/env_act_steps': 33701760, 'local/env_train_steps': 33699840, 'local/optimizer_steps': 52656, 'local/running_reward': 24412.895256916996, 'local/running_step': 2493.67987277668, 'local/steps_done': 33701760, 'local/episodes_done': 8157, 'local/unclipped_grad_norm': 0.6897104452956807, 'local/model_version': 52656, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:43,051] {'global/mean_episode_return': 48880.0, 'global/mean_episode_step': 4932.7, 'global/SPS': 3319.6407152875126, 'global/env_act_steps': 33697536, 'global/env_train_steps': 33694720, 'global/optimizer_steps': 52648, 'global/running_reward': 24484.85343992248, 'global/running_step': 2500.519289001938, 'global/steps_done': 33697536, 'global/episodes_done': 8155, 'global/unclipped_grad_norm': 0.6568359119712182, 'global/model_version': 52648, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:53,052] calculate_sps 30720 steps in 10.0142
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:07:53,052] calculate_sps 32000 steps in 10.0142
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:53,052] {'local/mean_episode_return': 42200.0, 'local/mean_episode_step': 4407.666666666667, 'local/SPS': 3067.635409100688, 'local/env_act_steps': 33735168, 'local/env_train_steps': 33730560, 'local/optimizer_steps': 52704, 'local/running_reward': 24258.081896551725, 'local/running_step': 2477.559806034483, 'local/steps_done': 33735168, 'local/episodes_done': 8163, 'local/unclipped_grad_norm': 0.7417115640516082, 'local/model_version': 52704, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:07:53,063] {'global/mean_episode_return': 42485.71428571428, 'global/mean_episode_step': 4379.0, 'global/SPS': 3195.4535511465497, 'global/env_act_steps': 33730944, 'global/env_train_steps': 33726720, 'global/optimizer_steps': 52698, 'global/running_reward': 24225.544779693486, 'global/running_step': 2474.54058908046, 'global/steps_done': 33730944, 'global/episodes_done': 8162, 'global/unclipped_grad_norm': 0.7822148811817169, 'global/model_version': 52698, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:03,061] calculate_sps 33920 steps in 10.0073
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:03,061] calculate_sps 34560 steps in 10.0073
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:03,069] {'local/mean_episode_return': 49080.0, 'local/mean_episode_step': 4882.2, 'local/SPS': 3389.518573824695, 'local/env_act_steps': 33767168, 'local/env_train_steps': 33764480, 'local/optimizer_steps': 52756, 'local/running_reward': 24266.9875, 'local/running_step': 2478.4026875, 'local/steps_done': 33767168, 'local/episodes_done': 8173, 'local/unclipped_grad_norm': 0.7130636890920309, 'local/model_version': 52756, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:03,071] {'global/mean_episode_return': 47860.0, 'global/mean_episode_step': 4798.9, 'global/SPS': 3453.471754462897, 'global/env_act_steps': 33763072, 'global/env_train_steps': 33761280, 'global/optimizer_steps': 52752, 'global/running_reward': 24367.41782868526, 'global/running_step': 2488.2088209661356, 'global/steps_done': 33763072, 'global/episodes_done': 8172, 'global/unclipped_grad_norm': 0.7013027204407586, 'global/model_version': 52752, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:13,070] calculate_sps 32640 steps in 10.0104
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:13,070] calculate_sps 30720 steps in 10.0104
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:13,070] {'local/mean_episode_return': 47945.454545454544, 'local/mean_episode_step': 4807.954545454545, 'local/SPS': 3260.608559869936, 'local/env_act_steps': 33799936, 'local/env_train_steps': 33797120, 'local/optimizer_steps': 52808, 'local/running_reward': 22762.725830078125, 'local/running_step': 2331.7489013671875, 'local/steps_done': 33799936, 'local/episodes_done': 8185, 'local/unclipped_grad_norm': 0.72339128359006, 'local/model_version': 52808, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:13,072] {'global/mean_episode_return': 48333.333333333336, 'global/mean_episode_step': 4852.291666666667, 'global/SPS': 3068.808056348175, 'global/env_act_steps': 33796480, 'global/env_train_steps': 33792000, 'global/optimizer_steps': 52800, 'global/running_reward': 22890.535201149425, 'global/running_step': 2343.916696599617, 'global/steps_done': 33796480, 'global/episodes_done': 8185, 'global/unclipped_grad_norm': 0.7157898939525088, 'global/model_version': 52800, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:23,084] calculate_sps 30720 steps in 10.0148
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:23,085] calculate_sps 33920 steps in 10.0148
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:23,085] {'local/mean_episode_return': 40828.57142857143, 'local/mean_episode_step': 4257.571428571428, 'local/SPS': 3067.4623277762125, 'local/env_act_steps': 33832704, 'local/env_train_steps': 33827840, 'local/optimizer_steps': 52856, 'local/running_reward': 22503.814697265625, 'local/running_step': 2309.5514221191406, 'local/steps_done': 33832704, 'local/episodes_done': 8192, 'local/unclipped_grad_norm': 0.6857879521946112, 'local/model_version': 52856, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:23,086] {'global/mean_episode_return': 40828.57142857143, 'global/mean_episode_step': 4257.571428571428, 'global/SPS': 3386.989653586235, 'global/env_act_steps': 33828608, 'global/env_train_steps': 33825920, 'global/optimizer_steps': 52853, 'global/running_reward': 22487.842380478087, 'global/running_step': 2308.114043824701, 'global/steps_done': 33828608, 'global/episodes_done': 8192, 'global/unclipped_grad_norm': 0.7146915638784193, 'global/model_version': 52853, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:33,119] calculate_sps 35840 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:33,119] calculate_sps 32640 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:33,119] {'local/mean_episode_return': 45044.444444444445, 'local/mean_episode_step': 4747.666666666667, 'local/SPS': 3571.63769858142, 'local/env_act_steps': 33864704, 'local/env_train_steps': 33863680, 'local/optimizer_steps': 52911, 'local/running_reward': 22682.2875, 'local/running_step': 2322.3645, 'local/steps_done': 33864704, 'local/episodes_done': 8201, 'local/unclipped_grad_norm': 0.8103031911633232, 'local/model_version': 52911, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:33,120] {'global/mean_episode_return': 45044.444444444445, 'global/mean_episode_step': 4747.666666666667, 'global/SPS': 3252.741475493793, 'global/env_act_steps': 33861888, 'global/env_train_steps': 33858560, 'global/optimizer_steps': 52904, 'global/running_reward': 22710.72716346154, 'global/running_step': 2325.7643629807694, 'global/steps_done': 33861888, 'global/episodes_done': 8201, 'global/unclipped_grad_norm': 0.8097227572226057, 'global/model_version': 52904, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:43,119] calculate_sps 30720 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:43,120] calculate_sps 32000 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:43,120] {'local/mean_episode_return': 49900.0, 'local/mean_episode_step': 4977.25, 'local/SPS': 3071.809948281865, 'local/env_act_steps': 33897728, 'local/env_train_steps': 33894400, 'local/optimizer_steps': 52960, 'local/running_reward': 22524.872819767443, 'local/running_step': 2304.572613856589, 'local/steps_done': 33897728, 'local/episodes_done': 8205, 'local/unclipped_grad_norm': 0.7149719379994334, 'local/model_version': 52960, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:43,131] {'global/mean_episode_return': 49900.0, 'global/mean_episode_step': 4977.25, 'global/SPS': 3199.8020294602766, 'global/env_act_steps': 33894656, 'global/env_train_steps': 33890560, 'global/optimizer_steps': 52953, 'global/running_reward': 22478.662109375, 'global/running_step': 2299.9722900390625, 'global/steps_done': 33894656, 'global/episodes_done': 8205, 'global/unclipped_grad_norm': 0.717949457618655, 'global/model_version': 52953, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:53,129] calculate_sps 32000 steps in 10.0098
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:08:53,130] calculate_sps 34560 steps in 10.0098
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:53,142] {'local/mean_episode_return': 45400.0, 'local/mean_episode_step': 4586.833333333333, 'local/SPS': 3196.8561952713403, 'local/env_act_steps': 33930624, 'local/env_train_steps': 33926400, 'local/optimizer_steps': 53010, 'local/running_reward': 23011.37524319066, 'local/running_step': 2352.589615758755, 'local/steps_done': 33930624, 'local/episodes_done': 8211, 'local/unclipped_grad_norm': 0.7418063050508499, 'local/model_version': 53010, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:08:53,144] {'global/mean_episode_return': 43440.0, 'global/mean_episode_step': 4424.2, 'global/SPS': 3452.6046908930475, 'global/env_act_steps': 33927296, 'global/env_train_steps': 33925120, 'global/optimizer_steps': 53008, 'global/running_reward': 22978.707107843136, 'global/running_step': 2348.9803921568628, 'global/steps_done': 33927296, 'global/episodes_done': 8210, 'global/unclipped_grad_norm': 0.7287505713376132, 'global/model_version': 53008, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:03,143] calculate_sps 34560 steps in 10.014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:03,144] calculate_sps 30720 steps in 10.014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:03,144] {'local/mean_episode_return': 50571.42857142857, 'local/mean_episode_step': 5067.428571428572, 'local/SPS': 3451.1632909639015, 'local/env_act_steps': 33962624, 'local/env_train_steps': 33960960, 'local/optimizer_steps': 53064, 'local/running_reward': 22919.96875, 'local/running_step': 2347.93925, 'local/steps_done': 33962624, 'local/episodes_done': 8218, 'local/unclipped_grad_norm': 0.6862603737800209, 'local/model_version': 53064, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:03,145] {'global/mean_episode_return': 50714.28571428572, 'global/mean_episode_step': 5067.428571428572, 'global/SPS': 3067.7007030790237, 'global/env_act_steps': 33960704, 'global/env_train_steps': 33955840, 'global/optimizer_steps': 53056, 'global/running_reward': 22946.37811302682, 'global/running_step': 2350.4121467911878, 'global/steps_done': 33960704, 'global/episodes_done': 8217, 'global/unclipped_grad_norm': 0.7202830311531822, 'global/model_version': 53056, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:13,148] calculate_sps 30720 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:13,148] calculate_sps 35840 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:13,148] {'local/mean_episode_return': 47280.0, 'local/mean_episode_step': 4767.2, 'local/SPS': 3070.636030676662, 'local/env_act_steps': 33995648, 'local/env_train_steps': 33991680, 'local/optimizer_steps': 53112, 'local/running_reward': 23073.25581395349, 'local/running_step': 2362.35546875, 'local/steps_done': 33995648, 'local/episodes_done': 8223, 'local/unclipped_grad_norm': 0.7160492682208618, 'local/model_version': 53112, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:13,150] {'global/mean_episode_return': 48433.333333333336, 'global/mean_episode_step': 4872.666666666667, 'global/SPS': 3582.408702456106, 'global/env_act_steps': 33992704, 'global/env_train_steps': 33991680, 'global/optimizer_steps': 53111, 'global/running_reward': 23050.58125, 'global/running_step': 2360.4290625, 'global/steps_done': 33992704, 'global/episodes_done': 8223, 'global/unclipped_grad_norm': 0.6819097123362802, 'global/model_version': 53111, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:23,152] calculate_sps 33920 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:23,152] calculate_sps 30720 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:23,152] {'local/mean_episode_return': 50862.5, 'local/mean_episode_step': 4911.5, 'local/SPS': 3390.4514503852124, 'local/env_act_steps': 34028160, 'local/env_train_steps': 34025600, 'local/optimizer_steps': 53164, 'local/running_reward': 23231.631397637797, 'local/running_step': 2381.8753383366143, 'local/steps_done': 34028160, 'local/episodes_done': 8232, 'local/unclipped_grad_norm': 0.6572259867993685, 'local/model_version': 53164, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:23,153] {'global/mean_episode_return': 50150.0, 'global/mean_episode_step': 4848.666666666667, 'global/SPS': 3070.597539971513, 'global/env_act_steps': 34026496, 'global/env_train_steps': 34022400, 'global/optimizer_steps': 53160, 'global/running_reward': 23250.041429924244, 'global/running_step': 2382.810606060606, 'global/steps_done': 34026496, 'global/episodes_done': 8230, 'global/unclipped_grad_norm': 0.6347227014449178, 'global/model_version': 53160, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:33,171] calculate_sps 32640 steps in 10.0185
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:33,171] calculate_sps 34560 steps in 10.0185
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:33,171] {'local/mean_episode_return': 49244.444444444445, 'local/mean_episode_step': 4967.888888888889, 'local/SPS': 3257.9839635377884, 'local/env_act_steps': 34061056, 'local/env_train_steps': 34058240, 'local/optimizer_steps': 53216, 'local/running_reward': 22617.5826848249, 'local/running_step': 2325.5421023832687, 'local/steps_done': 34061056, 'local/episodes_done': 8241, 'local/unclipped_grad_norm': 0.7637816355205499, 'local/model_version': 53216, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:33,173] {'global/mean_episode_return': 48860.0, 'global/mean_episode_step': 4951.6, 'global/SPS': 3449.630079040011, 'global/env_act_steps': 34059008, 'global/env_train_steps': 34056960, 'global/optimizer_steps': 53213, 'global/running_reward': 22650.246062992126, 'global/running_step': 2328.8602669783463, 'global/steps_done': 34059008, 'global/episodes_done': 8240, 'global/unclipped_grad_norm': 0.7817949663917974, 'global/model_version': 53213, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:43,175] calculate_sps 30720 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:43,186] calculate_sps 32000 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:43,186] {'local/mean_episode_return': 47400.0, 'local/mean_episode_step': 4753.333333333333, 'local/SPS': 3070.7030624210647, 'local/env_act_steps': 34094208, 'local/env_train_steps': 34088960, 'local/optimizer_steps': 53264, 'local/running_reward': 22599.137306949808, 'local/running_step': 2327.9968327702704, 'local/steps_done': 34094208, 'local/episodes_done': 8244, 'local/unclipped_grad_norm': 0.6201765201985836, 'local/model_version': 53264, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:43,188] {'global/mean_episode_return': 50700.0, 'global/mean_episode_step': 4913.75, 'global/SPS': 3198.649023355276, 'global/env_act_steps': 34092288, 'global/env_train_steps': 34088960, 'global/optimizer_steps': 53264, 'global/running_reward': 22565.16826923077, 'global/running_step': 2324.247265625, 'global/steps_done': 34092288, 'global/episodes_done': 8244, 'global/unclipped_grad_norm': 0.6185311344908733, 'global/model_version': 53264, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:53,180] calculate_sps 35840 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:09:53,180] calculate_sps 33280 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:53,180] {'local/mean_episode_return': 50280.0, 'local/mean_episode_step': 4794.0, 'local/SPS': 3582.3604671590906, 'local/env_act_steps': 34126464, 'local/env_train_steps': 34124800, 'local/optimizer_steps': 53320, 'local/running_reward': 23039.093501984127, 'local/running_step': 2377.52876984127, 'local/steps_done': 34126464, 'local/episodes_done': 8249, 'local/unclipped_grad_norm': 0.6286127577934947, 'local/model_version': 53320, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:09:53,182] {'global/mean_episode_return': 50280.0, 'global/mean_episode_step': 4794.0, 'global/SPS': 3326.477576647727, 'global/env_act_steps': 34125312, 'global/env_train_steps': 34122240, 'global/optimizer_steps': 53315, 'global/running_reward': 23028.336967054263, 'global/running_step': 2376.187378875969, 'global/steps_done': 34125312, 'global/episodes_done': 8249, 'global/unclipped_grad_norm': 0.6342254368697896, 'global/model_version': 53315, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:03,184] calculate_sps 30720 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:03,184] calculate_sps 33280 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:03,184] {'local/mean_episode_return': 44733.333333333336, 'local/mean_episode_step': 4480.0, 'local/SPS': 3070.7643156023328, 'local/env_act_steps': 34159616, 'local/env_train_steps': 34155520, 'local/optimizer_steps': 53368, 'local/running_reward': 23607.547055984556, 'local/running_step': 2436.5225929054054, 'local/steps_done': 34159616, 'local/episodes_done': 8252, 'local/unclipped_grad_norm': 0.6682206426436702, 'local/model_version': 53368, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:03,186] {'global/mean_episode_return': 44733.333333333336, 'global/mean_episode_step': 4480.0, 'global/SPS': 3326.661341902527, 'global/env_act_steps': 34158208, 'global/env_train_steps': 34155520, 'global/optimizer_steps': 53368, 'global/running_reward': 23563.284289883268, 'global/running_step': 2432.1965588521402, 'global/steps_done': 34158208, 'global/episodes_done': 8252, 'global/unclipped_grad_norm': 0.6590831698674076, 'global/model_version': 53368, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:13,184] calculate_sps 33280 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:13,184] calculate_sps 31360 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:13,184] {'local/mean_episode_return': 44755.555555555555, 'local/mean_episode_step': 4495.111111111111, 'local/SPS': 3327.840602117308, 'local/env_act_steps': 34191872, 'local/env_train_steps': 34188800, 'local/optimizer_steps': 53419, 'local/running_reward': 23704.6626984127, 'local/running_step': 2443.4115203373017, 'local/steps_done': 34191872, 'local/episodes_done': 8261, 'local/unclipped_grad_norm': 0.6639883614638272, 'local/model_version': 53419, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:13,185] {'global/mean_episode_return': 44755.555555555555, 'global/mean_episode_step': 4495.111111111111, 'global/SPS': 3135.8497981490023, 'global/env_act_steps': 34191616, 'global/env_train_steps': 34186880, 'global/optimizer_steps': 53416, 'global/running_reward': 23723.006465517243, 'global/running_step': 2445.2777478448274, 'global/steps_done': 34191616, 'global/episodes_done': 8261, 'global/unclipped_grad_norm': 0.6711613340303302, 'global/model_version': 53416, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:23,188] calculate_sps 33280 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:23,188] calculate_sps 35200 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:23,189] {'local/mean_episode_return': 37400.0, 'local/mean_episode_step': 3964.0, 'local/SPS': 3326.6652267193685, 'local/env_act_steps': 34224640, 'local/env_train_steps': 34222080, 'local/optimizer_steps': 53472, 'local/running_reward': 24012.7197265625, 'local/running_step': 2473.458740234375, 'local/steps_done': 34224640, 'local/episodes_done': 8264, 'local/unclipped_grad_norm': 0.5947385098574296, 'local/model_version': 53472, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:23,191] {'global/mean_episode_return': 37400.0, 'global/mean_episode_step': 3964.0, 'global/SPS': 3518.588220568563, 'global/env_act_steps': 34224128, 'global/env_train_steps': 34222080, 'global/optimizer_steps': 53472, 'global/running_reward': 24001.9500492126, 'global/running_step': 2472.4249815452754, 'global/steps_done': 34224128, 'global/episodes_done': 8264, 'global/unclipped_grad_norm': 0.5923000611364841, 'global/model_version': 53472, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:33,207] calculate_sps 31360 steps in 10.0187
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:33,207] calculate_sps 31360 steps in 10.0187
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:33,207] {'local/mean_episode_return': 46740.0, 'local/mean_episode_step': 4753.5, 'local/SPS': 3130.1342222721437, 'local/env_act_steps': 34258048, 'local/env_train_steps': 34253440, 'local/optimizer_steps': 53520, 'local/running_reward': 24179.352250957854, 'local/running_step': 2487.6058429118775, 'local/steps_done': 34258048, 'local/episodes_done': 8274, 'local/unclipped_grad_norm': 0.7109149396419525, 'local/model_version': 53520, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:33,208] {'global/mean_episode_return': 46740.0, 'global/mean_episode_step': 4753.5, 'global/SPS': 3130.1342222721437, 'global/env_act_steps': 34258048, 'global/env_train_steps': 34253440, 'global/optimizer_steps': 53520, 'global/running_reward': 24184.787735849055, 'global/running_step': 2488.150648584906, 'global/steps_done': 34258048, 'global/episodes_done': 8274, 'global/unclipped_grad_norm': 0.7109149396419525, 'global/model_version': 53520, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:43,207] calculate_sps 35200 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:43,207] calculate_sps 27520 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:43,208] {'local/mean_episode_return': 49228.57142857143, 'local/mean_episode_step': 4858.714285714285, 'local/SPS': 3519.9339535708077, 'local/env_act_steps': 34289792, 'local/env_train_steps': 34288640, 'local/optimizer_steps': 53576, 'local/running_reward': 24074.124243951614, 'local/running_step': 2484.814894153226, 'local/steps_done': 34289792, 'local/episodes_done': 8281, 'local/unclipped_grad_norm': 0.668256641764726, 'local/model_version': 53576, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:43,209] {'global/mean_episode_return': 49500.0, 'global/mean_episode_step': 4883.25, 'global/SPS': 2751.9483637008134, 'global/env_act_steps': 34284160, 'global/env_train_steps': 34280960, 'global/optimizer_steps': 53564, 'global/running_reward': 24100.030637254902, 'global/running_step': 2487.0263863357845, 'global/steps_done': 34284160, 'global/episodes_done': 8278, 'global/unclipped_grad_norm': 0.6289548694410108, 'global/model_version': 53564, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:53,211] calculate_sps 30720 steps in 10.0039
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:10:53,211] calculate_sps 33280 steps in 10.0039
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:53,211] {'local/mean_episode_return': 51840.0, 'local/mean_episode_step': 5066.4, 'local/SPS': 3070.813861480478, 'local/env_act_steps': 34322944, 'local/env_train_steps': 34319360, 'local/optimizer_steps': 53624, 'local/running_reward': 23882.185086872585, 'local/running_step': 2468.2052666505792, 'local/steps_done': 34322944, 'local/episodes_done': 8286, 'local/unclipped_grad_norm': 0.7580739762634039, 'local/model_version': 53624, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:10:53,220] {'global/mean_episode_return': 50725.0, 'global/mean_episode_step': 4976.25, 'global/SPS': 3326.7150166038514, 'global/env_act_steps': 34316672, 'global/env_train_steps': 34314240, 'global/optimizer_steps': 53616, 'global/running_reward': 23866.03100393701, 'global/running_step': 2466.5557947834645, 'global/steps_done': 34316672, 'global/episodes_done': 8286, 'global/unclipped_grad_norm': 0.7811402242917281, 'global/model_version': 53616, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:03,211] calculate_sps 33280 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:03,212] calculate_sps 32000 steps in 10.0008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:03,212] {'local/mean_episode_return': 49163.63636363636, 'local/mean_episode_step': 4951.0, 'local/SPS': 3327.730801806199, 'local/env_act_steps': 34355712, 'local/env_train_steps': 34352640, 'local/optimizer_steps': 53675, 'local/running_reward': 23618.505859375, 'local/running_step': 2440.157745361328, 'local/steps_done': 34355712, 'local/episodes_done': 8297, 'local/unclipped_grad_norm': 0.658143050238198, 'local/model_version': 53675, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:03,213] {'global/mean_episode_return': 48240.0, 'global/mean_episode_step': 4906.6, 'global/SPS': 3199.7411555828835, 'global/env_act_steps': 34350336, 'global/env_train_steps': 34346240, 'global/optimizer_steps': 53665, 'global/running_reward': 23763.12975285171, 'global/running_step': 2454.1350106939162, 'global/steps_done': 34350336, 'global/episodes_done': 8296, 'global/unclipped_grad_norm': 0.6452932081052235, 'global/model_version': 53665, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:13,213] calculate_sps 33280 steps in 10.0016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:13,214] calculate_sps 34560 steps in 10.0016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:13,214] {'local/mean_episode_return': 41355.555555555555, 'local/mean_episode_step': 4362.666666666667, 'local/SPS': 3327.4587916403634, 'local/env_act_steps': 34387840, 'local/env_train_steps': 34385920, 'local/optimizer_steps': 53728, 'local/running_reward': 23026.711902390438, 'local/running_step': 2382.0211030876494, 'local/steps_done': 34387840, 'local/episodes_done': 8306, 'local/unclipped_grad_norm': 0.7989764162954295, 'local/model_version': 53728, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:13,215] {'global/mean_episode_return': 43060.0, 'global/mean_episode_step': 4465.9, 'global/SPS': 3455.4379759342237, 'global/env_act_steps': 34382592, 'global/env_train_steps': 34380800, 'global/optimizer_steps': 53720, 'global/running_reward': 23080.56175595238, 'global/running_step': 2388.3132130456347, 'global/steps_done': 34382592, 'global/episodes_done': 8306, 'global/unclipped_grad_norm': 0.8047888826240193, 'global/model_version': 53720, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:23,235] calculate_sps 30720 steps in 10.0077
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:23,235] calculate_sps 30720 steps in 10.0077
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:23,236] {'local/mean_episode_return': 42150.0, 'local/mean_episode_step': 4522.083333333333, 'local/SPS': 3069.642825695753, 'local/env_act_steps': 34420864, 'local/env_train_steps': 34416640, 'local/optimizer_steps': 53776, 'local/running_reward': 23036.452277131782, 'local/running_step': 2381.239855862403, 'local/steps_done': 34420864, 'local/episodes_done': 8313, 'local/unclipped_grad_norm': 0.6409412572781245, 'local/model_version': 53776, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:23,237] {'global/mean_episode_return': 40700.0, 'global/mean_episode_step': 4361.166666666667, 'global/SPS': 3069.642825695753, 'global/env_act_steps': 34415872, 'global/env_train_steps': 34411520, 'global/optimizer_steps': 53768, 'global/running_reward': 23002.03125, 'global/running_step': 2377.898347355769, 'global/steps_done': 34415872, 'global/episodes_done': 8310, 'global/unclipped_grad_norm': 0.6208901001761357, 'global/model_version': 53768, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:33,224] calculate_sps 33920 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:33,224] calculate_sps 33920 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:33,224] {'local/mean_episode_return': 41742.857142857145, 'local/mean_episode_step': 4358.285714285715, 'local/SPS': 3391.08106261831, 'local/env_act_steps': 34453248, 'local/env_train_steps': 34450560, 'local/optimizer_steps': 53829, 'local/running_reward': 22934.974061264824, 'local/running_step': 2367.1171566205535, 'local/steps_done': 34453248, 'local/episodes_done': 8320, 'local/unclipped_grad_norm': 0.7063205354618576, 'local/model_version': 53829, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:33,226] {'global/mean_episode_return': 42300.0, 'global/mean_episode_step': 4455.7, 'global/SPS': 3391.08106261831, 'global/env_act_steps': 34448000, 'global/env_train_steps': 34445440, 'global/optimizer_steps': 53820, 'global/running_reward': 22929.92405378486, 'global/running_step': 2367.5809262948205, 'global/steps_done': 34448000, 'global/episodes_done': 8320, 'global/unclipped_grad_norm': 0.7366004024560635, 'global/model_version': 53820, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:43,256] calculate_sps 32640 steps in 10.0321
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:43,256] calculate_sps 32640 steps in 10.0321
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:43,256] {'local/mean_episode_return': 42680.0, 'local/mean_episode_step': 4388.0, 'local/SPS': 3253.55687044151, 'local/env_act_steps': 34486144, 'local/env_train_steps': 34483200, 'local/optimizer_steps': 53880, 'local/running_reward': 22783.785262645913, 'local/running_step': 2346.393421692607, 'local/steps_done': 34486144, 'local/episodes_done': 8330, 'local/unclipped_grad_norm': 0.6833668269363105, 'local/model_version': 53880, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:43,267] {'global/mean_episode_return': 42680.0, 'global/mean_episode_step': 4388.0, 'global/SPS': 3253.55687044151, 'global/env_act_steps': 34481408, 'global/env_train_steps': 34478080, 'global/optimizer_steps': 53872, 'global/running_reward': 22848.569204980842, 'global/running_step': 2353.5538194444443, 'global/steps_done': 34481408, 'global/episodes_done': 8330, 'global/unclipped_grad_norm': 0.6824511627738292, 'global/model_version': 53872, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:53,305] calculate_sps 32640 steps in 10.0492
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:11:53,305] calculate_sps 33280 steps in 10.0492
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:53,305] {'local/mean_episode_return': 52733.333333333336, 'local/mean_episode_step': 5164.333333333333, 'local/SPS': 3248.020494721276, 'local/env_act_steps': 34519424, 'local/env_train_steps': 34515840, 'local/optimizer_steps': 53930, 'local/running_reward': 23289.87980769231, 'local/running_step': 2393.6323016826923, 'local/steps_done': 34519424, 'local/episodes_done': 8333, 'local/unclipped_grad_norm': 0.7263976377248764, 'local/model_version': 53930, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:11:53,306] {'global/mean_episode_return': 51300.0, 'global/mean_episode_step': 5046.5, 'global/SPS': 3311.7071710883597, 'global/env_act_steps': 34514432, 'global/env_train_steps': 34511360, 'global/optimizer_steps': 53923, 'global/running_reward': 23183.75121124031, 'global/running_step': 2382.7635053294575, 'global/steps_done': 34514432, 'global/episodes_done': 8332, 'global/unclipped_grad_norm': 0.6873397201884026, 'global/model_version': 53923, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:03,313] calculate_sps 33920 steps in 10.0077
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:03,313] calculate_sps 33280 steps in 10.0077
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:03,313] {'local/mean_episode_return': 47800.0, 'local/mean_episode_step': 4766.125, 'local/SPS': 3389.380814291172, 'local/env_act_steps': 34552064, 'local/env_train_steps': 34549760, 'local/optimizer_steps': 53984, 'local/running_reward': 23308.468137254902, 'local/running_step': 2399.311580882353, 'local/steps_done': 34552064, 'local/episodes_done': 8341, 'local/unclipped_grad_norm': 0.7916230261325836, 'local/model_version': 53984, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:03,315] {'global/mean_episode_return': 49800.0, 'global/mean_episode_step': 4912.875, 'global/SPS': 3325.430232889452, 'global/env_act_steps': 34547840, 'global/env_train_steps': 34544640, 'global/optimizer_steps': 53976, 'global/running_reward': 23325.041906130267, 'global/running_step': 2400.7292863984676, 'global/steps_done': 34547840, 'global/episodes_done': 8340, 'global/unclipped_grad_norm': 0.7976285607185004, 'global/model_version': 53976, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:13,321] calculate_sps 30720 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:13,322] calculate_sps 33280 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:13,322] {'local/mean_episode_return': 46880.0, 'local/mean_episode_step': 4831.6, 'local/SPS': 3069.3421452828247, 'local/env_act_steps': 34585344, 'local/env_train_steps': 34580480, 'local/optimizer_steps': 54032, 'local/running_reward': 23388.888221153848, 'local/running_step': 2405.3920673076923, 'local/steps_done': 34585344, 'local/episodes_done': 8346, 'local/unclipped_grad_norm': 0.6299481578171253, 'local/model_version': 54032, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:13,323] {'global/mean_episode_return': 45666.666666666664, 'global/mean_episode_step': 4730.666666666667, 'global/SPS': 3325.1206573897266, 'global/env_act_steps': 34580992, 'global/env_train_steps': 34577920, 'global/optimizer_steps': 54027, 'global/running_reward': 23359.013030888033, 'global/running_step': 2402.784387065637, 'global/steps_done': 34580992, 'global/episodes_done': 8346, 'global/unclipped_grad_norm': 0.6849911394072514, 'global/model_version': 54027, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:23,341] calculate_sps 35200 steps in 10.0177
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:23,341] calculate_sps 33280 steps in 10.0177
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:23,350] {'local/mean_episode_return': 43777.77777777778, 'local/mean_episode_step': 4516.444444444444, 'local/SPS': 3513.796763535672, 'local/env_act_steps': 34617344, 'local/env_train_steps': 34615680, 'local/optimizer_steps': 54086, 'local/running_reward': 23443.46875, 'local/running_step': 2406.85434375, 'local/steps_done': 34617344, 'local/episodes_done': 8355, 'local/unclipped_grad_norm': 0.7429277593338931, 'local/model_version': 54086, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:23,351] {'global/mean_episode_return': 43057.142857142855, 'global/mean_episode_step': 4461.428571428572, 'global/SPS': 3322.135121888272, 'global/env_act_steps': 34613888, 'global/env_train_steps': 34611200, 'global/optimizer_steps': 54080, 'global/running_reward': 23469.388375486382, 'global/running_step': 2409.9567728599222, 'global/steps_done': 34613888, 'global/episodes_done': 8353, 'global/unclipped_grad_norm': 0.6907241535636613, 'global/model_version': 54080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:33,348] calculate_sps 31360 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:33,349] calculate_sps 31360 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:33,349] {'local/mean_episode_return': 50840.0, 'local/mean_episode_step': 5045.8, 'local/SPS': 3133.0969038469525, 'local/env_act_steps': 34650368, 'local/env_train_steps': 34647040, 'local/optimizer_steps': 54136, 'local/running_reward': 23542.52664728682, 'local/running_step': 2416.6753875968993, 'local/steps_done': 34650368, 'local/episodes_done': 8360, 'local/unclipped_grad_norm': 0.8139353561401367, 'local/model_version': 54136, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:33,350] {'global/mean_episode_return': 50600.0, 'global/mean_episode_step': 4943.0, 'global/SPS': 3133.0969038469525, 'global/env_act_steps': 34647168, 'global/env_train_steps': 34642560, 'global/optimizer_steps': 54128, 'global/running_reward': 23496.736778846152, 'global/running_step': 2412.254206730769, 'global/steps_done': 34647168, 'global/episodes_done': 8358, 'global/unclipped_grad_norm': 0.8052497766911983, 'global/model_version': 54128, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:43,365] calculate_sps 32000 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:43,365] calculate_sps 35200 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:43,365] {'local/mean_episode_return': 46533.333333333336, 'local/mean_episode_step': 4687.333333333333, 'local/SPS': 3194.5213436171907, 'local/env_act_steps': 34683136, 'local/env_train_steps': 34679040, 'local/optimizer_steps': 54185, 'local/running_reward': 23164.068603515625, 'local/running_step': 2378.8787536621094, 'local/steps_done': 34683136, 'local/episodes_done': 8369, 'local/unclipped_grad_norm': 0.6957318600343199, 'local/model_version': 54185, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:43,366] {'global/mean_episode_return': 46600.0, 'global/mean_episode_step': 4738.0, 'global/SPS': 3513.97347797891, 'global/env_act_steps': 34679680, 'global/env_train_steps': 34677760, 'global/optimizer_steps': 54184, 'global/running_reward': 23224.698572834644, 'global/running_step': 2384.861189714567, 'global/steps_done': 34679680, 'global/episodes_done': 8369, 'global/unclipped_grad_norm': 0.7347431640539851, 'global/model_version': 54184, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:53,383] calculate_sps 34560 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:12:53,384] calculate_sps 30720 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:53,384] {'local/mean_episode_return': 44880.0, 'local/mean_episode_step': 4660.7, 'local/SPS': 3449.82982530582, 'local/env_act_steps': 34715648, 'local/env_train_steps': 34713600, 'local/optimizer_steps': 54240, 'local/running_reward': 22847.982283464567, 'local/running_step': 2343.7593196358266, 'local/steps_done': 34715648, 'local/episodes_done': 8379, 'local/unclipped_grad_norm': 0.6836990296840668, 'local/model_version': 54240, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:12:53,385] {'global/mean_episode_return': 44880.0, 'global/mean_episode_step': 4660.7, 'global/SPS': 3066.5154002718405, 'global/env_act_steps': 34713216, 'global/env_train_steps': 34708480, 'global/optimizer_steps': 54232, 'global/running_reward': 22893.905057251908, 'global/running_step': 2348.9380069179388, 'global/steps_done': 34713216, 'global/episodes_done': 8379, 'global/unclipped_grad_norm': 0.662330682699879, 'global/model_version': 54232, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:03,393] calculate_sps 30720 steps in 10.0095
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:03,393] calculate_sps 35840 steps in 10.0095
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:03,393] {'local/mean_episode_return': 48166.666666666664, 'local/mean_episode_step': 4785.0, 'local/SPS': 3069.0857506229863, 'local/env_act_steps': 34748928, 'local/env_train_steps': 34744320, 'local/optimizer_steps': 54288, 'local/running_reward': 22828.52764423077, 'local/running_step': 2339.4194110576923, 'local/steps_done': 34748928, 'local/episodes_done': 8385, 'local/unclipped_grad_norm': 0.7379723644504944, 'local/model_version': 54288, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:03,395] {'global/mean_episode_return': 48166.666666666664, 'global/mean_episode_step': 4785.0, 'global/SPS': 3580.600042393484, 'global/env_act_steps': 34745344, 'global/env_train_steps': 34744320, 'global/optimizer_steps': 54287, 'global/running_reward': 22810.12823705179, 'global/running_step': 2337.4363483565735, 'global/steps_done': 34745344, 'global/episodes_done': 8385, 'global/unclipped_grad_norm': 0.7335265295072035, 'global/model_version': 54287, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:13,406] calculate_sps 33920 steps in 10.0137
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:13,406] calculate_sps 30720 steps in 10.0137
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:13,407] {'local/mean_episode_return': 49600.0, 'local/mean_episode_step': 4929.571428571428, 'local/SPS': 3387.3439913799516, 'local/env_act_steps': 34780800, 'local/env_train_steps': 34778240, 'local/optimizer_steps': 54340, 'local/running_reward': 23033.069779116468, 'local/running_step': 2358.406375502008, 'local/steps_done': 34780800, 'local/episodes_done': 8392, 'local/unclipped_grad_norm': 0.7152175032175504, 'local/model_version': 54340, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:13,408] {'global/mean_episode_return': 48166.666666666664, 'global/mean_episode_step': 4851.666666666667, 'global/SPS': 3067.7832374761824, 'global/env_act_steps': 34778752, 'global/env_train_steps': 34775040, 'global/optimizer_steps': 54336, 'global/running_reward': 23020.27658045977, 'global/running_step': 2357.4074173850577, 'global/steps_done': 34778752, 'global/episodes_done': 8391, 'global/unclipped_grad_norm': 0.7330191305705479, 'global/model_version': 54336, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:23,418] calculate_sps 32640 steps in 10.0118
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:23,419] calculate_sps 33920 steps in 10.0118
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:23,419] {'local/mean_episode_return': 44114.28571428572, 'local/mean_episode_step': 4462.428571428572, 'local/SPS': 3260.142599659126, 'local/env_act_steps': 34813824, 'local/env_train_steps': 34810880, 'local/optimizer_steps': 54392, 'local/running_reward': 22888.705184108527, 'local/running_step': 2340.9054626937987, 'local/steps_done': 34813824, 'local/episodes_done': 8399, 'local/unclipped_grad_norm': 0.7454880086275247, 'local/model_version': 54392, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:23,420] {'global/mean_episode_return': 45875.0, 'global/mean_episode_step': 4579.25, 'global/SPS': 3387.991329057523, 'global/env_act_steps': 34811520, 'global/env_train_steps': 34808960, 'global/optimizer_steps': 54388, 'global/running_reward': 22891.85791015625, 'global/running_step': 2341.302032470703, 'global/steps_done': 34811520, 'global/episodes_done': 8399, 'global/unclipped_grad_norm': 0.7559524184236159, 'global/model_version': 54388, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:33,467] calculate_sps 32000 steps in 10.0489
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:33,467] calculate_sps 32640 steps in 10.0489
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:33,467] {'local/mean_episode_return': 32200.0, 'local/mean_episode_step': 3551.0, 'local/SPS': 3184.428937074339, 'local/env_act_steps': 34846976, 'local/env_train_steps': 34842880, 'local/optimizer_steps': 54441, 'local/running_reward': 23603.263754826254, 'local/running_step': 2410.2898166023165, 'local/steps_done': 34846976, 'local/episodes_done': 8400, 'local/unclipped_grad_norm': 0.5828998538912559, 'local/model_version': 54441, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:33,468] {'global/mean_episode_return': 32200.0, 'global/mean_episode_step': 3551.0, 'global/SPS': 3248.1175158158258, 'global/env_act_steps': 34844800, 'global/env_train_steps': 34841600, 'global/optimizer_steps': 54440, 'global/running_reward': 23532.361778846152, 'global/running_step': 2403.357331730769, 'global/steps_done': 34844800, 'global/episodes_done': 8400, 'global/unclipped_grad_norm': 0.5763947510948548, 'global/model_version': 54440, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:43,469] calculate_sps 34560 steps in 10.0018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:43,469] calculate_sps 33280 steps in 10.0018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:43,470] {'local/mean_episode_return': 48072.72727272727, 'local/mean_episode_step': 4765.636363636364, 'local/SPS': 3455.381635318882, 'local/env_act_steps': 34879744, 'local/env_train_steps': 34877440, 'local/optimizer_steps': 54496, 'local/running_reward': 23860.83984375, 'local/running_step': 2436.808074951172, 'local/steps_done': 34879744, 'local/episodes_done': 8411, 'local/unclipped_grad_norm': 0.6712997880848971, 'local/model_version': 54496, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:43,471] {'global/mean_episode_return': 48240.0, 'global/mean_episode_step': 4767.2, 'global/SPS': 3327.4045377144794, 'global/env_act_steps': 34878080, 'global/env_train_steps': 34874880, 'global/optimizer_steps': 54491, 'global/running_reward': 23903.59375, 'global/running_step': 2441.007361778846, 'global/steps_done': 34878080, 'global/episodes_done': 8410, 'global/unclipped_grad_norm': 0.6864725251992544, 'global/model_version': 54491, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:53,494] calculate_sps 30720 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:13:53,495] calculate_sps 33280 steps in 10.0249
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:53,495] {'local/mean_episode_return': 44240.0, 'local/mean_episode_step': 4477.6, 'local/SPS': 3064.35617636214, 'local/env_act_steps': 34913280, 'local/env_train_steps': 34908160, 'local/optimizer_steps': 54544, 'local/running_reward': 23728.75715648855, 'local/running_step': 2422.0991471851144, 'local/steps_done': 34913280, 'local/episodes_done': 8416, 'local/unclipped_grad_norm': 0.7902570956697067, 'local/model_version': 54544, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:13:53,496] {'global/mean_episode_return': 46480.0, 'global/mean_episode_step': 4684.2, 'global/SPS': 3319.719191058985, 'global/env_act_steps': 34911232, 'global/env_train_steps': 34908160, 'global/optimizer_steps': 54544, 'global/running_reward': 23684.730936293436, 'global/running_step': 2418.0376749517372, 'global/steps_done': 34911232, 'global/episodes_done': 8415, 'global/unclipped_grad_norm': 0.7659957690059014, 'global/model_version': 54544, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:03,509] calculate_sps 35200 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:03,510] calculate_sps 31360 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:03,510] {'local/mean_episode_return': 46225.0, 'local/mean_episode_step': 4635.375, 'local/SPS': 3514.474697684288, 'local/env_act_steps': 34944896, 'local/env_train_steps': 34943360, 'local/optimizer_steps': 54598, 'local/running_reward': 24038.189524291498, 'local/running_step': 2449.7652770748987, 'local/steps_done': 34944896, 'local/episodes_done': 8424, 'local/unclipped_grad_norm': 0.656926566252002, 'local/model_version': 54598, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:03,511] {'global/mean_episode_return': 45000.0, 'global/mean_episode_step': 4533.333333333333, 'global/SPS': 3131.0774579369113, 'global/env_act_steps': 34944256, 'global/env_train_steps': 34939520, 'global/optimizer_steps': 54592, 'global/running_reward': 24032.558139534885, 'global/running_step': 2449.114007994186, 'global/steps_done': 34944256, 'global/episodes_done': 8424, 'global/unclipped_grad_norm': 0.6224086383978525, 'global/model_version': 54592, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:13,524] calculate_sps 31360 steps in 10.0141
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:13,524] calculate_sps 35200 steps in 10.0141
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:13,525] {'local/mean_episode_return': 47350.0, 'local/mean_episode_step': 4704.375, 'local/SPS': 3131.5731097978082, 'local/env_act_steps': 34978176, 'local/env_train_steps': 34974720, 'local/optimizer_steps': 54648, 'local/running_reward': 23627.46394230769, 'local/running_step': 2411.9709435096156, 'local/steps_done': 34978176, 'local/episodes_done': 8432, 'local/unclipped_grad_norm': 0.8323189601302147, 'local/model_version': 54648, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:13,526] {'global/mean_episode_return': 45942.857142857145, 'global/mean_episode_step': 4605.714285714285, 'global/SPS': 3515.031041609785, 'global/env_act_steps': 34976768, 'global/env_train_steps': 34974720, 'global/optimizer_steps': 54648, 'global/running_reward': 23631.649852362203, 'global/running_step': 2412.2345595472443, 'global/steps_done': 34976768, 'global/episodes_done': 8431, 'global/unclipped_grad_norm': 0.8431137132325343, 'global/model_version': 54648, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:23,529] calculate_sps 32000 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:23,529] calculate_sps 30720 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:23,529] {'local/mean_episode_return': 45760.0, 'local/mean_episode_step': 4757.4, 'local/SPS': 3198.916230210512, 'local/env_act_steps': 35010944, 'local/env_train_steps': 35006720, 'local/optimizer_steps': 54697, 'local/running_reward': 23207.45849609375, 'local/running_step': 2376.0047607421875, 'local/steps_done': 35010944, 'local/episodes_done': 8442, 'local/unclipped_grad_norm': 0.7665855373655047, 'local/model_version': 54697, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:23,531] {'global/mean_episode_return': 46800.0, 'global/mean_episode_step': 4815.363636363636, 'global/SPS': 3070.9595810020915, 'global/env_act_steps': 35010048, 'global/env_train_steps': 35005440, 'global/optimizer_steps': 54696, 'global/running_reward': 23237.265625, 'global/running_step': 2378.8471754807692, 'global/steps_done': 35010048, 'global/episodes_done': 8442, 'global/unclipped_grad_norm': 0.7647884003818035, 'global/model_version': 54696, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:33,528] calculate_sps 34560 steps in 10.0009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:33,528] calculate_sps 35840 steps in 10.0009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:33,529] {'local/mean_episode_return': 47960.0, 'local/mean_episode_step': 4870.8, 'local/SPS': 3455.695815349811, 'local/env_act_steps': 35043456, 'local/env_train_steps': 35041280, 'local/optimizer_steps': 54752, 'local/running_reward': 22574.600147637797, 'local/running_step': 2314.1195866141734, 'local/steps_done': 35043456, 'local/episodes_done': 8447, 'local/unclipped_grad_norm': 0.713883899287744, 'local/model_version': 54752, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:33,539] {'global/mean_episode_return': 47960.0, 'global/mean_episode_step': 4870.8, 'global/SPS': 3583.6845492516554, 'global/env_act_steps': 35042688, 'global/env_train_steps': 35041280, 'global/optimizer_steps': 54752, 'global/running_reward': 22573.339460784315, 'global/running_step': 2313.875551470588, 'global/steps_done': 35042688, 'global/episodes_done': 8447, 'global/unclipped_grad_norm': 0.7163654030965907, 'global/model_version': 54752, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:43,582] calculate_sps 30720 steps in 10.0538
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:43,582] calculate_sps 30720 steps in 10.0538
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:43,583] {'local/mean_episode_return': 45090.90909090909, 'local/mean_episode_step': 4576.454545454545, 'local/SPS': 3055.5533683671338, 'local/env_act_steps': 35076992, 'local/env_train_steps': 35072000, 'local/optimizer_steps': 54800, 'local/running_reward': 22883.748807251908, 'local/running_step': 2344.0205749045804, 'local/steps_done': 35076992, 'local/episodes_done': 8458, 'local/unclipped_grad_norm': 0.8188757623235384, 'local/model_version': 54800, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:43,584] {'global/mean_episode_return': 45090.90909090909, 'global/mean_episode_step': 4576.454545454545, 'global/SPS': 3055.5533683671338, 'global/env_act_steps': 35076352, 'global/env_train_steps': 35072000, 'global/optimizer_steps': 54800, 'global/running_reward': 22894.10052281369, 'global/running_step': 2345.1695282794676, 'global/steps_done': 35076352, 'global/episodes_done': 8458, 'global/unclipped_grad_norm': 0.8188757623235384, 'global/model_version': 54800, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:53,599] calculate_sps 35840 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:14:53,600] calculate_sps 35840 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:53,600] {'local/mean_episode_return': 42114.28571428572, 'local/mean_episode_step': 4340.928571428572, 'local/SPS': 3577.8587954459063, 'local/env_act_steps': 35109504, 'local/env_train_steps': 35107840, 'local/optimizer_steps': 54856, 'local/running_reward': 22390.342027559054, 'local/running_step': 2296.0987020177167, 'local/steps_done': 35109504, 'local/episodes_done': 8466, 'local/unclipped_grad_norm': 0.7362041124807936, 'local/model_version': 54856, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:14:53,601] {'global/mean_episode_return': 42114.28571428572, 'global/mean_episode_step': 4340.928571428572, 'global/SPS': 3577.8587954459063, 'global/env_act_steps': 35108864, 'global/env_train_steps': 35107840, 'global/optimizer_steps': 54855, 'global/running_reward': 22396.868848425198, 'global/running_step': 2296.729176919291, 'global/steps_done': 35108864, 'global/episodes_done': 8466, 'global/unclipped_grad_norm': 0.7427231520414352, 'global/model_version': 54855, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:03,610] calculate_sps 30720 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:03,611] calculate_sps 30720 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:03,611] {'local/mean_episode_return': 50360.0, 'local/mean_episode_step': 4974.9, 'local/SPS': 3068.60889885257, 'local/env_act_steps': 35142656, 'local/env_train_steps': 35138560, 'local/optimizer_steps': 54904, 'local/running_reward': 22453.432673745174, 'local/running_step': 2301.925916988417, 'local/steps_done': 35142656, 'local/episodes_done': 8472, 'local/unclipped_grad_norm': 0.7044003047049046, 'local/model_version': 54904, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:03,612] {'global/mean_episode_return': 50360.0, 'global/mean_episode_step': 4974.9, 'global/SPS': 3068.60889885257, 'global/env_act_steps': 35142400, 'global/env_train_steps': 35138560, 'global/optimizer_steps': 54904, 'global/running_reward': 22448.40171755725, 'global/running_step': 2301.4005546278627, 'global/steps_done': 35142400, 'global/episodes_done': 8472, 'global/unclipped_grad_norm': 0.6977320727036924, 'global/model_version': 54904, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:13,629] calculate_sps 33920 steps in 10.0024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:13,629] calculate_sps 25600 steps in 10.0024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:13,638] {'local/mean_episode_return': 48542.857142857145, 'local/mean_episode_step': 4984.857142857143, 'local/SPS': 3391.1741787657284, 'local/env_act_steps': 35175168, 'local/env_train_steps': 35172480, 'local/optimizer_steps': 54956, 'local/running_reward': 22248.32062007874, 'local/running_step': 2281.0784633366143, 'local/steps_done': 35175168, 'local/episodes_done': 8479, 'local/unclipped_grad_norm': 0.7427693923505453, 'local/model_version': 54956, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:13,639] {'global/mean_episode_return': 48542.857142857145, 'global/mean_episode_step': 4984.857142857143, 'global/SPS': 2559.3767386911154, 'global/env_act_steps': 35169280, 'global/env_train_steps': 35164160, 'global/optimizer_steps': 54944, 'global/running_reward': 22239.903273809523, 'global/running_step': 2280.0745163690476, 'global/steps_done': 35169280, 'global/episodes_done': 8479, 'global/unclipped_grad_norm': 0.7420495543628931, 'global/model_version': 54944, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:23,649] calculate_sps 32640 steps in 10.0359
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:23,649] calculate_sps 35840 steps in 10.0359
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:23,649] {'local/mean_episode_return': 47866.666666666664, 'local/mean_episode_step': 4773.333333333333, 'local/SPS': 3252.3092840638224, 'local/env_act_steps': 35207808, 'local/env_train_steps': 35205120, 'local/optimizer_steps': 55008, 'local/running_reward': 22566.611519607843, 'local/running_step': 2314.336182598039, 'local/steps_done': 35207808, 'local/episodes_done': 8485, 'local/unclipped_grad_norm': 0.594445678477104, 'local/model_version': 55008, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:23,651] {'global/mean_episode_return': 46040.0, 'global/mean_episode_step': 4649.2, 'global/SPS': 3571.1631354426286, 'global/env_act_steps': 35201408, 'global/env_train_steps': 35200000, 'global/optimizer_steps': 55000, 'global/running_reward': 22510.489292828686, 'global/running_step': 2308.168171065737, 'global/steps_done': 35201408, 'global/episodes_done': 8484, 'global/unclipped_grad_norm': 0.6212373359927109, 'global/model_version': 55000, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:33,686] calculate_sps 32000 steps in 10.0382
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:33,687] calculate_sps 30720 steps in 10.0382
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:33,687] {'local/mean_episode_return': 47880.0, 'local/mean_episode_step': 4868.2, 'local/SPS': 3187.8096021291185, 'local/env_act_steps': 35241216, 'local/env_train_steps': 35237120, 'local/optimizer_steps': 55057, 'local/running_reward': 22804.62164750958, 'local/running_step': 2341.5309806034484, 'local/steps_done': 35241216, 'local/episodes_done': 8490, 'local/unclipped_grad_norm': 0.7506759513397606, 'local/model_version': 55057, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:33,688] {'global/mean_episode_return': 49400.0, 'global/mean_episode_step': 4955.833333333333, 'global/SPS': 3060.2972180439538, 'global/env_act_steps': 35235328, 'global/env_train_steps': 35230720, 'global/optimizer_steps': 55048, 'global/running_reward': 22772.971698113208, 'global/running_step': 2338.102358490566, 'global/steps_done': 35235328, 'global/episodes_done': 8490, 'global/unclipped_grad_norm': 0.7440270402779182, 'global/model_version': 55048, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:43,703] calculate_sps 34560 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:43,714] calculate_sps 35840 steps in 10.0159
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:43,714] {'local/mean_episode_return': 48800.0, 'local/mean_episode_step': 4892.857142857143, 'local/SPS': 3450.4977845353346, 'local/env_act_steps': 35273344, 'local/env_train_steps': 35271680, 'local/optimizer_steps': 55112, 'local/running_reward': 22812.81748007968, 'local/running_step': 2344.7393239541834, 'local/steps_done': 35273344, 'local/episodes_done': 8497, 'local/unclipped_grad_norm': 0.7329968547279184, 'local/model_version': 55112, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:43,716] {'global/mean_episode_return': 48966.666666666664, 'global/mean_episode_step': 4917.666666666667, 'global/SPS': 3578.293998777384, 'global/env_act_steps': 35267584, 'global/env_train_steps': 35266560, 'global/optimizer_steps': 55103, 'global/running_reward': 22816.344246031746, 'global/running_step': 2344.6067708333335, 'global/steps_done': 35267584, 'global/episodes_done': 8496, 'global/unclipped_grad_norm': 0.6859201965006915, 'global/model_version': 55103, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 14:15:52,153] saving global stats {'mean_episode_return': 34800.0, 'mean_episode_step': 3706.5, 'SPS': None, 'env_act_steps': 35294208, 'env_train_steps': 35292160, 'optimizer_steps': 55144, 'running_reward': 22966.68419471154, 'running_step': 2359.2189002403848, 'steps_done': 35294208, 'episodes_done': 8500, 'unclipped_grad_norm': 0.7597574010127928, 'model_version': 55144, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 14:15:52,256] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint_v55152.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 14:15:52,420] saving global stats {'mean_episode_return': 34800.0, 'mean_episode_step': 3706.5, 'SPS': None, 'env_act_steps': 35294208, 'env_train_steps': 35292160, 'optimizer_steps': 55144, 'running_reward': 22966.68419471154, 'running_step': 2359.2189002403848, 'steps_done': 35294208, 'episodes_done': 8500, 'unclipped_grad_norm': 0.7597574010127928, 'model_version': 55144, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 14:15:52,583] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:53,721] calculate_sps 30720 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:15:53,721] calculate_sps 30720 steps in 10.0183
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:53,722] {'local/mean_episode_return': 36560.0, 'local/mean_episode_step': 3877.0, 'local/SPS': 3066.396154126883, 'local/env_act_steps': 35305856, 'local/env_train_steps': 35302400, 'local/optimizer_steps': 55160, 'local/running_reward': 23156.766732283464, 'local/running_step': 2376.5738804133857, 'local/steps_done': 35305856, 'local/episodes_done': 8502, 'local/unclipped_grad_norm': 0.6551869930699468, 'local/model_version': 55160, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:15:53,723] {'global/mean_episode_return': 34800.0, 'global/mean_episode_step': 3706.5, 'global/SPS': 3066.396154126883, 'global/env_act_steps': 35301376, 'global/env_train_steps': 35297280, 'global/optimizer_steps': 55152, 'global/running_reward': 23054.575047348484, 'global/running_step': 2367.2678740530305, 'global/steps_done': 35301376, 'global/episodes_done': 8500, 'global/unclipped_grad_norm': 0.7297731200043036, 'global/model_version': 55152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:03,728] calculate_sps 33280 steps in 10.0069
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:03,728] calculate_sps 32640 steps in 10.0069
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:03,729] {'local/mean_episode_return': 46440.0, 'local/mean_episode_step': 4698.0, 'local/SPS': 3325.7101520661945, 'local/env_act_steps': 35338880, 'local/env_train_steps': 35335680, 'local/optimizer_steps': 55212, 'local/running_reward': 23499.03100775194, 'local/running_step': 2408.4317163275196, 'local/steps_done': 35338880, 'local/episodes_done': 8507, 'local/unclipped_grad_norm': 0.7029577986552165, 'local/model_version': 55212, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:03,730] {'global/mean_episode_return': 46228.57142857143, 'global/mean_episode_step': 4684.714285714285, 'global/SPS': 3261.754187603383, 'global/env_act_steps': 35333504, 'global/env_train_steps': 35329920, 'global/optimizer_steps': 55202, 'global/running_reward': 23466.22260956175, 'global/running_step': 2405.1583976593624, 'global/steps_done': 35333504, 'global/episodes_done': 8507, 'global/unclipped_grad_norm': 0.6639026960730553, 'global/model_version': 55202, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:13,748] calculate_sps 33280 steps in 10.0204
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:13,749] calculate_sps 33920 steps in 10.0204
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:13,749] {'local/mean_episode_return': 48700.0, 'local/mean_episode_step': 4800.5, 'local/SPS': 3321.2163885405093, 'local/env_act_steps': 35371520, 'local/env_train_steps': 35368960, 'local/optimizer_steps': 55264, 'local/running_reward': 23941.623774509804, 'local/running_step': 2451.828370098039, 'local/steps_done': 35371520, 'local/episodes_done': 8513, 'local/unclipped_grad_norm': 0.6821372437362487, 'local/model_version': 55264, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:13,750] {'global/mean_episode_return': 46640.0, 'global/mean_episode_step': 4680.8, 'global/SPS': 3385.0859344739806, 'global/env_act_steps': 35366400, 'global/env_train_steps': 35363840, 'global/optimizer_steps': 55256, 'global/running_reward': 23902.07928015564, 'global/running_step': 2447.685676070039, 'global/steps_done': 35366400, 'global/episodes_done': 8512, 'global/unclipped_grad_norm': 0.6476342675310595, 'global/model_version': 55256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:23,787] calculate_sps 31360 steps in 10.0386
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:23,787] calculate_sps 32000 steps in 10.0386
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:23,787] {'local/mean_episode_return': 50320.0, 'local/mean_episode_step': 4970.0, 'local/SPS': 3123.9509439466947, 'local/env_act_steps': 35404928, 'local/env_train_steps': 35400320, 'local/optimizer_steps': 55312, 'local/running_reward': 24131.657088122607, 'local/running_step': 2474.9970965038315, 'local/steps_done': 35404928, 'local/episodes_done': 8518, 'local/unclipped_grad_norm': 0.7372904811054468, 'local/model_version': 55312, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:23,788] {'global/mean_episode_return': 49750.0, 'global/mean_episode_step': 4865.5, 'global/SPS': 3187.7050448435657, 'global/env_act_steps': 35399936, 'global/env_train_steps': 35395840, 'global/optimizer_steps': 55305, 'global/running_reward': 24068.565124045803, 'global/running_step': 2468.2134422709923, 'global/steps_done': 35399936, 'global/episodes_done': 8516, 'global/unclipped_grad_norm': 0.801102203982217, 'global/model_version': 55305, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:33,799] calculate_sps 35200 steps in 10.012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:33,799] calculate_sps 34560 steps in 10.012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:33,800] {'local/mean_episode_return': 53800.0, 'local/mean_episode_step': 5280.5, 'local/SPS': 3515.781703032889, 'local/env_act_steps': 35437568, 'local/env_train_steps': 35435520, 'local/optimizer_steps': 55368, 'local/running_reward': 24329.920343137255, 'local/running_step': 2495.243535539216, 'local/steps_done': 35437568, 'local/episodes_done': 8522, 'local/unclipped_grad_norm': 0.7948189603963068, 'local/model_version': 55368, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:33,801] {'global/mean_episode_return': 54466.666666666664, 'global/mean_episode_step': 5318.166666666667, 'global/SPS': 3451.8583993413818, 'global/env_act_steps': 35432832, 'global/env_train_steps': 35430400, 'global/optimizer_steps': 55360, 'global/running_reward': 24290.217655642024, 'global/running_step': 2491.119102626459, 'global/steps_done': 35432832, 'global/episodes_done': 8522, 'global/unclipped_grad_norm': 0.7965162762186744, 'global/model_version': 55360, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:43,807] calculate_sps 30720 steps in 10.0082
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:43,807] calculate_sps 32000 steps in 10.0082
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:43,808] {'local/mean_episode_return': 43100.0, 'local/mean_episode_step': 4469.071428571428, 'local/SPS': 3069.498254827469, 'local/env_act_steps': 35470848, 'local/env_train_steps': 35466240, 'local/optimizer_steps': 55416, 'local/running_reward': 24641.66466346154, 'local/running_step': 2526.087469951923, 'local/steps_done': 35470848, 'local/episodes_done': 8530, 'local/unclipped_grad_norm': 0.7364919778580467, 'local/model_version': 55416, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:43,809] {'global/mean_episode_return': 43650.0, 'global/mean_episode_step': 4527.916666666667, 'global/SPS': 3197.3940154452803, 'global/env_act_steps': 35466496, 'global/env_train_steps': 35462400, 'global/optimizer_steps': 55409, 'global/running_reward': 24638.81297528517, 'global/running_step': 2526.0676984315587, 'global/steps_done': 35466496, 'global/episodes_done': 8529, 'global/unclipped_grad_norm': 0.6831846495672148, 'global/model_version': 55409, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:53,825] calculate_sps 35840 steps in 10.016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:16:53,825] calculate_sps 34560 steps in 10.016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:53,836] {'local/mean_episode_return': 47742.857142857145, 'local/mean_episode_step': 4787.714285714285, 'local/SPS': 3578.257202539707, 'local/env_act_steps': 35503232, 'local/env_train_steps': 35502080, 'local/optimizer_steps': 55471, 'local/running_reward': 24518.743824110672, 'local/running_step': 2512.9094614624505, 'local/steps_done': 35503232, 'local/episodes_done': 8537, 'local/unclipped_grad_norm': 0.6885109966451471, 'local/model_version': 55471, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:16:53,838] {'global/mean_episode_return': 45942.857142857145, 'global/mean_episode_step': 4604.428571428572, 'global/SPS': 3450.4623024490033, 'global/env_act_steps': 35499520, 'global/env_train_steps': 35496960, 'global/optimizer_steps': 55464, 'global/running_reward': 24531.328730620156, 'global/running_step': 2514.4576974321703, 'global/steps_done': 35499520, 'global/episodes_done': 8536, 'global/unclipped_grad_norm': 0.7251882726495916, 'global/model_version': 55464, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:03,828] calculate_sps 30720 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:03,829] calculate_sps 30720 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:03,829] {'local/mean_episode_return': 56800.0, 'local/mean_episode_step': 5291.5, 'local/SPS': 3070.392955385457, 'local/env_act_steps': 35536640, 'local/env_train_steps': 35532800, 'local/optimizer_steps': 55520, 'local/running_reward': 24988.67337164751, 'local/running_step': 2560.815044300766, 'local/steps_done': 35536640, 'local/episodes_done': 8539, 'local/unclipped_grad_norm': 0.6325244362256965, 'local/model_version': 55520, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:03,830] {'global/mean_episode_return': 55333.333333333336, 'global/mean_episode_step': 5327.333333333333, 'global/SPS': 3070.392955385457, 'global/env_act_steps': 35532928, 'global/env_train_steps': 35527680, 'global/optimizer_steps': 55512, 'global/running_reward': 24897.7969348659, 'global/running_step': 2550.980423850575, 'global/steps_done': 35532928, 'global/episodes_done': 8539, 'global/unclipped_grad_norm': 0.6161754081646601, 'global/model_version': 55512, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:13,831] calculate_sps 32640 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:13,831] calculate_sps 35840 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:13,831] {'local/mean_episode_return': 44675.0, 'local/mean_episode_step': 4519.75, 'local/SPS': 3263.6875055069418, 'local/env_act_steps': 35569152, 'local/env_train_steps': 35565440, 'local/optimizer_steps': 55570, 'local/running_reward': 25204.422982283464, 'local/running_step': 2584.478900098425, 'local/steps_done': 35569152, 'local/episodes_done': 8547, 'local/unclipped_grad_norm': 0.7312171456217765, 'local/model_version': 55570, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:13,833] {'global/mean_episode_return': 44833.333333333336, 'global/mean_episode_step': 4516.0, 'global/SPS': 3583.656868791936, 'global/env_act_steps': 35565184, 'global/env_train_steps': 35563520, 'global/optimizer_steps': 55568, 'global/running_reward': 25216.93328373016, 'global/running_step': 2585.6644345238096, 'global/steps_done': 35565184, 'global/episodes_done': 8545, 'global/unclipped_grad_norm': 0.735637744356479, 'global/model_version': 55568, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:23,850] calculate_sps 33920 steps in 10.0209
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:23,851] calculate_sps 30720 steps in 10.0209
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:23,851] {'local/mean_episode_return': 52742.857142857145, 'local/mean_episode_step': 5049.0, 'local/SPS': 3384.936132556283, 'local/env_act_steps': 35601792, 'local/env_train_steps': 35599360, 'local/optimizer_steps': 55624, 'local/running_reward': 25203.321078431374, 'local/running_step': 2589.2145833333334, 'local/steps_done': 35601792, 'local/episodes_done': 8554, 'local/unclipped_grad_norm': 0.7118953184949027, 'local/model_version': 55624, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:23,852] {'global/mean_episode_return': 50275.0, 'global/mean_episode_step': 4914.75, 'global/SPS': 3065.602535145313, 'global/env_act_steps': 35598720, 'global/env_train_steps': 35594240, 'global/optimizer_steps': 55616, 'global/running_reward': 25214.39050572519, 'global/running_step': 2589.421875, 'global/steps_done': 35598720, 'global/episodes_done': 8553, 'global/unclipped_grad_norm': 0.7272094755123059, 'global/model_version': 55616, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:33,858] calculate_sps 31360 steps in 10.0064
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:33,874] calculate_sps 35840 steps in 10.0064
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:33,874] {'local/mean_episode_return': 51900.0, 'local/mean_episode_step': 5003.5, 'local/SPS': 3133.9892813787005, 'local/env_act_steps': 35635456, 'local/env_train_steps': 35630720, 'local/optimizer_steps': 55672, 'local/running_reward': 25188.22480988593, 'local/running_step': 2596.2347908745246, 'local/steps_done': 35635456, 'local/episodes_done': 8560, 'local/unclipped_grad_norm': 0.7875585947185755, 'local/model_version': 55672, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:33,876] {'global/mean_episode_return': 52483.333333333336, 'global/mean_episode_step': 5017.416666666667, 'global/SPS': 3581.702035861372, 'global/env_act_steps': 35631488, 'global/env_train_steps': 35630080, 'global/optimizer_steps': 55672, 'global/running_reward': 25194.49462890625, 'global/running_step': 2596.071746826172, 'global/steps_done': 35631488, 'global/episodes_done': 8560, 'global/unclipped_grad_norm': 0.7694258077868393, 'global/model_version': 55672, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:43,859] calculate_sps 35200 steps in 10.0025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:43,859] calculate_sps 30720 steps in 10.0025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:43,874] {'local/mean_episode_return': 49200.0, 'local/mean_episode_step': 5033.6, 'local/SPS': 3519.1333692414546, 'local/env_act_steps': 35667072, 'local/env_train_steps': 35665920, 'local/optimizer_steps': 55728, 'local/running_reward': 25069.281376518218, 'local/running_step': 2590.5792004048585, 'local/steps_done': 35667072, 'local/episodes_done': 8565, 'local/unclipped_grad_norm': 0.6948768251708576, 'local/model_version': 55728, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:43,876] {'global/mean_episode_return': 49200.0, 'global/mean_episode_step': 5033.6, 'global/SPS': 3071.243667701633, 'global/env_act_steps': 35665024, 'global/env_train_steps': 35660800, 'global/optimizer_steps': 55720, 'global/running_reward': 25049.958253816792, 'global/running_step': 2588.4565243320612, 'global/steps_done': 35665024, 'global/episodes_done': 8565, 'global/unclipped_grad_norm': 0.6668384658793608, 'global/model_version': 55720, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:53,871] calculate_sps 30720 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:17:53,871] calculate_sps 34560 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:53,871] {'local/mean_episode_return': 45466.666666666664, 'local/mean_episode_step': 4633.555555555556, 'local/SPS': 3068.4180973319635, 'local/env_act_steps': 35700480, 'local/env_train_steps': 35696640, 'local/optimizer_steps': 55776, 'local/running_reward': 25250.59865900383, 'local/running_step': 2611.954232519157, 'local/steps_done': 35700480, 'local/episodes_done': 8574, 'local/unclipped_grad_norm': 0.7114538333068291, 'local/model_version': 55776, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:17:53,883] {'global/mean_episode_return': 45466.666666666664, 'global/mean_episode_step': 4633.555555555556, 'global/SPS': 3451.970359498459, 'global/env_act_steps': 35697408, 'global/env_train_steps': 35695360, 'global/optimizer_steps': 55773, 'global/running_reward': 25283.998270750988, 'global/running_step': 2615.2640501482215, 'global/steps_done': 35697408, 'global/episodes_done': 8574, 'global/unclipped_grad_norm': 0.7492202272954976, 'global/model_version': 55773, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:03,876] calculate_sps 33280 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:03,876] calculate_sps 32000 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:03,890] {'local/mean_episode_return': 47300.0, 'local/mean_episode_step': 4751.0, 'local/SPS': 3326.321257391537, 'local/env_act_steps': 35733120, 'local/env_train_steps': 35729920, 'local/optimizer_steps': 55828, 'local/running_reward': 25004.748774509804, 'local/running_step': 2584.7196997549017, 'local/steps_done': 35733120, 'local/episodes_done': 8580, 'local/unclipped_grad_norm': 0.756368297796983, 'local/model_version': 55828, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:03,891] {'global/mean_episode_return': 47300.0, 'global/mean_episode_step': 4751.0, 'global/SPS': 3198.3858244149396, 'global/env_act_steps': 35731072, 'global/env_train_steps': 35727360, 'global/optimizer_steps': 55824, 'global/running_reward': 24990.102186311786, 'global/running_step': 2583.352750712928, 'global/steps_done': 35731072, 'global/episodes_done': 8580, 'global/unclipped_grad_norm': 0.7300755901663911, 'global/model_version': 55824, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:13,900] calculate_sps 33280 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:13,901] calculate_sps 33280 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:13,901] {'local/mean_episode_return': 51866.666666666664, 'local/mean_episode_step': 5178.333333333333, 'local/SPS': 3319.8223836609673, 'local/env_act_steps': 35765760, 'local/env_train_steps': 35763200, 'local/optimizer_steps': 55880, 'local/running_reward': 24966.323529411766, 'local/running_step': 2584.4559742647057, 'local/steps_done': 35765760, 'local/episodes_done': 8589, 'local/unclipped_grad_norm': 0.7332001030445099, 'local/model_version': 55880, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:13,902] {'global/mean_episode_return': 52675.0, 'global/mean_episode_step': 5247.5, 'global/SPS': 3319.8223836609673, 'global/env_act_steps': 35763840, 'global/env_train_steps': 35760640, 'global/optimizer_steps': 55876, 'global/running_reward': 24996.661376953125, 'global/running_step': 2587.0885314941406, 'global/steps_done': 35763840, 'global/episodes_done': 8588, 'global/unclipped_grad_norm': 0.753121208686095, 'global/model_version': 55876, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:23,920] calculate_sps 30720 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:23,921] calculate_sps 33280 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:23,921] {'local/mean_episode_return': 48911.11111111111, 'local/mean_episode_step': 4871.444444444444, 'local/SPS': 3065.873667625641, 'local/env_act_steps': 35798912, 'local/env_train_steps': 35793920, 'local/optimizer_steps': 55928, 'local/running_reward': 24377.22611003861, 'local/running_step': 2527.4672719594596, 'local/steps_done': 35798912, 'local/episodes_done': 8598, 'local/unclipped_grad_norm': 0.6889925636351109, 'local/model_version': 55928, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:23,927] {'global/mean_episode_return': 48560.0, 'global/mean_episode_step': 4846.8, 'global/SPS': 3321.3631399277774, 'global/env_act_steps': 35796608, 'global/env_train_steps': 35793920, 'global/optimizer_steps': 55928, 'global/running_reward': 24411.92626953125, 'global/running_step': 2530.897674560547, 'global/steps_done': 35796608, 'global/episodes_done': 8598, 'global/unclipped_grad_norm': 0.6822886489904844, 'global/model_version': 55928, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:33,932] calculate_sps 35840 steps in 10.0124
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:33,933] calculate_sps 31360 steps in 10.0124
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:33,933] {'local/mean_episode_return': 44950.0, 'local/mean_episode_step': 4594.5, 'local/SPS': 3579.5743316146245, 'local/env_act_steps': 35830784, 'local/env_train_steps': 35829760, 'local/optimizer_steps': 55983, 'local/running_reward': 24139.18172690763, 'local/running_step': 2504.0287713353414, 'local/steps_done': 35830784, 'local/episodes_done': 8606, 'local/unclipped_grad_norm': 0.8025451746853915, 'local/model_version': 55983, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:33,934] {'global/mean_episode_return': 44950.0, 'global/mean_episode_step': 4594.5, 'global/SPS': 3132.1275401627963, 'global/env_act_steps': 35829888, 'global/env_train_steps': 35825280, 'global/optimizer_steps': 55976, 'global/running_reward': 24138.780048076922, 'global/running_step': 2503.960576923077, 'global/steps_done': 35829888, 'global/episodes_done': 8606, 'global/unclipped_grad_norm': 0.8470894688119491, 'global/model_version': 55976, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:43,958] calculate_sps 30720 steps in 10.0253
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:43,958] calculate_sps 35200 steps in 10.0253
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:43,959] {'local/mean_episode_return': 46511.11111111111, 'local/mean_episode_step': 4667.222222222223, 'local/SPS': 3064.260854700562, 'local/env_act_steps': 35864192, 'local/env_train_steps': 35860480, 'local/optimizer_steps': 56032, 'local/running_reward': 23539.09841954023, 'local/running_step': 2447.7413493773947, 'local/steps_done': 35864192, 'local/episodes_done': 8615, 'local/unclipped_grad_norm': 0.6336647080523627, 'local/model_version': 56032, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:43,978] {'global/mean_episode_return': 46511.11111111111, 'global/mean_episode_step': 4667.222222222223, 'global/SPS': 3511.132229344394, 'global/env_act_steps': 35862400, 'global/env_train_steps': 35860480, 'global/optimizer_steps': 56032, 'global/running_reward': 23553.075787401576, 'global/running_step': 2449.0031680610236, 'global/steps_done': 35862400, 'global/episodes_done': 8615, 'global/unclipped_grad_norm': 0.6165939428444419, 'global/model_version': 56032, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:53,990] calculate_sps 32640 steps in 10.0324
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:18:53,990] calculate_sps 30720 steps in 10.0324
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:53,991] {'local/mean_episode_return': 43250.0, 'local/mean_episode_step': 4352.0, 'local/SPS': 3253.4654003139344, 'local/env_act_steps': 35896704, 'local/env_train_steps': 35893120, 'local/optimizer_steps': 56082, 'local/running_reward': 23911.903297244095, 'local/running_step': 2486.5078125, 'local/steps_done': 35896704, 'local/episodes_done': 8619, 'local/unclipped_grad_norm': 0.6784619343280792, 'local/model_version': 56082, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:18:53,992] {'global/mean_episode_return': 43250.0, 'global/mean_episode_step': 4352.0, 'global/SPS': 3062.085082648409, 'global/env_act_steps': 35895424, 'global/env_train_steps': 35891200, 'global/optimizer_steps': 56080, 'global/running_reward': 23881.40140503876, 'global/running_step': 2483.5503875968993, 'global/steps_done': 35895424, 'global/episodes_done': 8619, 'global/unclipped_grad_norm': 0.6840856944521269, 'global/model_version': 56080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:03,991] calculate_sps 33920 steps in 10.0004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:03,991] calculate_sps 34560 steps in 10.0004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:03,992] {'local/mean_episode_return': 48820.0, 'local/mean_episode_step': 4893.3, 'local/SPS': 3391.8490194769056, 'local/env_act_steps': 35929216, 'local/env_train_steps': 35927040, 'local/optimizer_steps': 56136, 'local/running_reward': 23641.984498031496, 'local/running_step': 2460.408987450787, 'local/steps_done': 35929216, 'local/episodes_done': 8629, 'local/unclipped_grad_norm': 0.7414385764687149, 'local/model_version': 56136, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:03,993] {'global/mean_episode_return': 48820.0, 'global/mean_episode_step': 4893.3, 'global/SPS': 3455.846170787791, 'global/env_act_steps': 35927808, 'global/env_train_steps': 35925760, 'global/optimizer_steps': 56133, 'global/running_reward': 23668.694416996048, 'global/running_step': 2462.995707756917, 'global/steps_done': 35927808, 'global/episodes_done': 8629, 'global/unclipped_grad_norm': 0.7490873876607643, 'global/model_version': 56133, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:14,015] calculate_sps 30720 steps in 10.0242
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:14,016] calculate_sps 32000 steps in 10.0242
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:14,016] {'local/mean_episode_return': 47969.230769230766, 'local/mean_episode_step': 4896.076923076923, 'local/SPS': 3064.5707446737665, 'local/env_act_steps': 35962752, 'local/env_train_steps': 35957760, 'local/optimizer_steps': 56184, 'local/running_reward': 23154.979723282442, 'local/running_step': 2410.807341364504, 'local/steps_done': 35962752, 'local/episodes_done': 8642, 'local/unclipped_grad_norm': 0.7411765071252981, 'local/model_version': 56184, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:14,017] {'global/mean_episode_return': 47416.666666666664, 'global/mean_episode_step': 4864.583333333333, 'global/SPS': 3192.2611923685067, 'global/env_act_steps': 35961728, 'global/env_train_steps': 35957760, 'global/optimizer_steps': 56184, 'global/running_reward': 23191.64504716981, 'global/running_step': 2414.5584316037734, 'global/steps_done': 35961728, 'global/episodes_done': 8641, 'global/unclipped_grad_norm': 0.7254805354511037, 'global/model_version': 56184, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:24,020] calculate_sps 35840 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:24,020] calculate_sps 33920 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:24,020] {'local/mean_episode_return': 46900.0, 'local/mean_episode_step': 4789.333333333333, 'local/SPS': 3582.2010011222924, 'local/env_act_steps': 35994624, 'local/env_train_steps': 35993600, 'local/optimizer_steps': 56239, 'local/running_reward': 22201.52484939759, 'local/running_step': 2314.3802397088352, 'local/steps_done': 35994624, 'local/episodes_done': 8648, 'local/unclipped_grad_norm': 0.813321176442233, 'local/model_version': 56239, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:24,021] {'global/mean_episode_return': 48000.0, 'global/mean_episode_step': 4858.571428571428, 'global/SPS': 3390.29737606217, 'global/env_act_steps': 35994368, 'global/env_train_steps': 35991680, 'global/optimizer_steps': 56237, 'global/running_reward': 22204.632352941175, 'global/running_step': 2314.671629901961, 'global/steps_done': 35994368, 'global/episodes_done': 8648, 'global/unclipped_grad_norm': 0.8258024347278307, 'global/model_version': 56237, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:34,023] calculate_sps 30720 steps in 10.0033
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:34,024] calculate_sps 32640 steps in 10.0033
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:34,024] {'local/mean_episode_return': 44500.0, 'local/mean_episode_step': 4515.166666666667, 'local/SPS': 3070.999910645973, 'local/env_act_steps': 36028032, 'local/env_train_steps': 36024320, 'local/optimizer_steps': 56288, 'local/running_reward': 22769.636015325672, 'local/running_step': 2372.779992816092, 'local/steps_done': 36028032, 'local/episodes_done': 8654, 'local/unclipped_grad_norm': 0.7256807575420458, 'local/model_version': 56288, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:34,025] {'global/mean_episode_return': 44500.0, 'global/mean_episode_step': 4515.166666666667, 'global/SPS': 3262.937405061347, 'global/env_act_steps': 36027776, 'global/env_train_steps': 36024320, 'global/optimizer_steps': 56288, 'global/running_reward': 22767.798132183907, 'global/running_step': 2372.590906369732, 'global/steps_done': 36027776, 'global/episodes_done': 8654, 'global/unclipped_grad_norm': 0.7161469173197653, 'global/model_version': 56288, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:44,031] calculate_sps 32640 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:44,031] calculate_sps 25600 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:44,055] {'local/mean_episode_return': 46175.0, 'local/mean_episode_step': 4849.625, 'local/SPS': 3261.9290507151723, 'local/env_act_steps': 36060672, 'local/env_train_steps': 36056960, 'local/optimizer_steps': 56338, 'local/running_reward': 22506.378676470587, 'local/running_step': 2346.709650735294, 'local/steps_done': 36060672, 'local/episodes_done': 8662, 'local/unclipped_grad_norm': 0.791466257572174, 'local/model_version': 56338, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:44,056] {'global/mean_episode_return': 45433.333333333336, 'global/mean_episode_step': 4827.166666666667, 'global/SPS': 2558.3757260511156, 'global/env_act_steps': 36054528, 'global/env_train_steps': 36049920, 'global/optimizer_steps': 56328, 'global/running_reward': 22511.214114832535, 'global/running_step': 2347.1180098684213, 'global/steps_done': 36054528, 'global/episodes_done': 8660, 'global/unclipped_grad_norm': 0.797941691428423, 'global/model_version': 56328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:54,043] calculate_sps 33920 steps in 10.0128
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:19:54,043] calculate_sps 35840 steps in 10.0128
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:54,043] {'local/mean_episode_return': 49800.0, 'local/mean_episode_step': 5021.875, 'local/SPS': 3387.6638783699473, 'local/env_act_steps': 36093440, 'local/env_train_steps': 36090880, 'local/optimizer_steps': 56392, 'local/running_reward': 22304.04052734375, 'local/running_step': 2330.85693359375, 'local/steps_done': 36093440, 'local/episodes_done': 8670, 'local/unclipped_grad_norm': 0.7544644072099969, 'local/model_version': 56392, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:19:54,044] {'global/mean_episode_return': 51200.0, 'global/mean_episode_step': 5148.111111111111, 'global/SPS': 3579.418437522963, 'global/env_act_steps': 36086784, 'global/env_train_steps': 36085760, 'global/optimizer_steps': 56383, 'global/running_reward': 22400.68824404762, 'global/running_step': 2338.97017609127, 'global/steps_done': 36086784, 'global/episodes_done': 8669, 'global/unclipped_grad_norm': 0.7777181993831288, 'global/model_version': 56383, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:04,047] calculate_sps 30720 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:04,048] calculate_sps 30720 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:04,048] {'local/mean_episode_return': 45066.666666666664, 'local/mean_episode_step': 4485.222222222223, 'local/SPS': 3070.4876345624343, 'local/env_act_steps': 36126592, 'local/env_train_steps': 36121600, 'local/optimizer_steps': 56440, 'local/running_reward': 21788.16361003861, 'local/running_step': 2287.2363959942086, 'local/steps_done': 36126592, 'local/episodes_done': 8679, 'local/unclipped_grad_norm': 0.7817923221737146, 'local/model_version': 56440, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:04,050] {'global/mean_episode_return': 43750.0, 'global/mean_episode_step': 4380.0, 'global/SPS': 3070.4876345624343, 'global/env_act_steps': 36120064, 'global/env_train_steps': 36116480, 'global/optimizer_steps': 56432, 'global/running_reward': 21816.97716346154, 'global/running_step': 2288.683683894231, 'global/steps_done': 36120064, 'global/episodes_done': 8677, 'global/unclipped_grad_norm': 0.7522990575858525, 'global/model_version': 56432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:14,085] calculate_sps 35840 steps in 10.0365
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:14,086] calculate_sps 33280 steps in 10.0365
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:14,086] {'local/mean_episode_return': 43966.666666666664, 'local/mean_episode_step': 4632.5, 'local/SPS': 3570.9562270479837, 'local/env_act_steps': 36158592, 'local/env_train_steps': 36157440, 'local/optimizer_steps': 56495, 'local/running_reward': 21731.20625, 'local/running_step': 2284.05903125, 'local/steps_done': 36158592, 'local/episodes_done': 8685, 'local/unclipped_grad_norm': 0.738103985786438, 'local/model_version': 56495, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:14,087] {'global/mean_episode_return': 44225.0, 'global/mean_episode_step': 4599.75, 'global/SPS': 3315.8879251159847, 'global/env_act_steps': 36152960, 'global/env_train_steps': 36149760, 'global/optimizer_steps': 56484, 'global/running_reward': 21750.863326848248, 'global/running_step': 2286.2334934338523, 'global/steps_done': 36152960, 'global/episodes_done': 8685, 'global/unclipped_grad_norm': 0.776461779498137, 'global/model_version': 56484, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:24,110] calculate_sps 30720 steps in 10.0258
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:24,110] calculate_sps 33280 steps in 10.0258
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:24,111] {'local/mean_episode_return': 44366.666666666664, 'local/mean_episode_step': 4570.916666666667, 'local/SPS': 3064.086915240956, 'local/env_act_steps': 36192128, 'local/env_train_steps': 36188160, 'local/optimizer_steps': 56544, 'local/running_reward': 21543.84541984733, 'local/running_step': 2267.7765982824426, 'local/steps_done': 36192128, 'local/episodes_done': 8697, 'local/unclipped_grad_norm': 0.6877160230461432, 'local/model_version': 56544, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:24,112] {'global/mean_episode_return': 45266.666666666664, 'global/mean_episode_step': 4633.111111111111, 'global/SPS': 3319.4274915110354, 'global/env_act_steps': 36185984, 'global/env_train_steps': 36183040, 'global/optimizer_steps': 56536, 'global/running_reward': 21648.340600775195, 'global/running_step': 2277.7999939437987, 'global/steps_done': 36185984, 'global/episodes_done': 8694, 'global/unclipped_grad_norm': 0.6569053209744967, 'global/model_version': 56536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:34,114] calculate_sps 33920 steps in 10.0015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:34,114] calculate_sps 32000 steps in 10.0015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:34,114] {'local/mean_episode_return': 39766.666666666664, 'local/mean_episode_step': 4212.5, 'local/SPS': 3391.5027126864666, 'local/env_act_steps': 36224768, 'local/env_train_steps': 36222080, 'local/optimizer_steps': 56596, 'local/running_reward': 21205.067401960783, 'local/running_step': 2233.749356617647, 'local/steps_done': 36224768, 'local/episodes_done': 8703, 'local/unclipped_grad_norm': 0.8053262961598543, 'local/model_version': 56596, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:34,115] {'global/mean_episode_return': 40400.0, 'global/mean_episode_step': 4269.777777777777, 'global/SPS': 3199.5308610249685, 'global/env_act_steps': 36219136, 'global/env_train_steps': 36215040, 'global/optimizer_steps': 56585, 'global/running_reward': 21202.84749034749, 'global/running_step': 2233.547538610039, 'global/steps_done': 36219136, 'global/episodes_done': 8703, 'global/unclipped_grad_norm': 0.7500425017609889, 'global/model_version': 56585, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:44,143] calculate_sps 32640 steps in 10.0318
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:44,143] calculate_sps 34560 steps in 10.0318
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:44,144] {'local/mean_episode_return': 43716.666666666664, 'local/mean_episode_step': 4459.5, 'local/SPS': 3253.646335211737, 'local/env_act_steps': 36257408, 'local/env_train_steps': 36254720, 'local/optimizer_steps': 56648, 'local/running_reward': 20963.198529411766, 'local/running_step': 2209.6407781862745, 'local/steps_done': 36257408, 'local/episodes_done': 8715, 'local/unclipped_grad_norm': 0.7841849235387949, 'local/model_version': 56648, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:44,145] {'global/mean_episode_return': 45120.0, 'global/mean_episode_step': 4592.9, 'global/SPS': 3445.037296106545, 'global/env_act_steps': 36251648, 'global/env_train_steps': 36249600, 'global/optimizer_steps': 56640, 'global/running_reward': 21066.861466535433, 'global/running_step': 2220.111589566929, 'global/steps_done': 36251648, 'global/episodes_done': 8713, 'global/unclipped_grad_norm': 0.8022962125864896, 'global/model_version': 56640, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:54,147] calculate_sps 30720 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:20:54,148] calculate_sps 30720 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:54,148] {'local/mean_episode_return': 44300.0, 'local/mean_episode_step': 4543.5, 'local/SPS': 3070.713819971341, 'local/env_act_steps': 36290432, 'local/env_train_steps': 36285440, 'local/optimizer_steps': 56696, 'local/running_reward': 20295.064195736435, 'local/running_step': 2144.9100956879847, 'local/steps_done': 36290432, 'local/episodes_done': 8723, 'local/unclipped_grad_norm': 0.8769191553195318, 'local/model_version': 56696, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:20:54,159] {'global/mean_episode_return': 42780.0, 'global/mean_episode_step': 4393.3, 'global/SPS': 3070.713819971341, 'global/env_act_steps': 36285056, 'global/env_train_steps': 36280320, 'global/optimizer_steps': 56688, 'global/running_reward': 20360.608237547895, 'global/running_step': 2150.774664750958, 'global/steps_done': 36285056, 'global/episodes_done': 8723, 'global/unclipped_grad_norm': 0.9005424032608668, 'global/model_version': 56688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:04,157] calculate_sps 35840 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:04,157] calculate_sps 35200 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:04,157] {'local/mean_episode_return': 45712.5, 'local/mean_episode_step': 4706.4375, 'local/SPS': 3580.540768789461, 'local/env_act_steps': 36322304, 'local/env_train_steps': 36321280, 'local/optimizer_steps': 56751, 'local/running_reward': 19880.484437751005, 'local/running_step': 2108.953532881526, 'local/steps_done': 36322304, 'local/episodes_done': 8732, 'local/unclipped_grad_norm': 0.7915479275313291, 'local/model_version': 56751, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:04,158] {'global/mean_episode_return': 45814.28571428572, 'global/mean_episode_step': 4708.928571428572, 'global/SPS': 3516.6025407753637, 'global/env_act_steps': 36317184, 'global/env_train_steps': 36315520, 'global/optimizer_steps': 56742, 'global/running_reward': 19946.177788844623, 'global/running_step': 2114.763010458167, 'global/steps_done': 36317184, 'global/episodes_done': 8731, 'global/unclipped_grad_norm': 0.7712695604121244, 'global/model_version': 56742, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:14,198] calculate_sps 30720 steps in 10.0408
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:14,198] calculate_sps 31360 steps in 10.0408
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:14,214] {'local/mean_episode_return': 41290.90909090909, 'local/mean_episode_step': 4397.909090909091, 'local/SPS': 3059.517431712523, 'local/env_act_steps': 36355584, 'local/env_train_steps': 36352000, 'local/optimizer_steps': 56800, 'local/running_reward': 19447.962740384617, 'local/running_step': 2063.0900540865387, 'local/steps_done': 36355584, 'local/episodes_done': 8744, 'local/unclipped_grad_norm': 0.7641948662242111, 'local/model_version': 56800, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:14,216] {'global/mean_episode_return': 43825.0, 'global/mean_episode_step': 4646.75, 'global/SPS': 3123.257378206534, 'global/env_act_steps': 36350464, 'global/env_train_steps': 36346880, 'global/optimizer_steps': 56792, 'global/running_reward': 19518.173076923078, 'global/running_step': 2069.9736177884615, 'global/steps_done': 36350464, 'global/episodes_done': 8740, 'global/unclipped_grad_norm': 0.8258382844924926, 'global/model_version': 56792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:24,210] calculate_sps 32640 steps in 10.0131
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:24,211] calculate_sps 33280 steps in 10.0131
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:24,211] {'local/mean_episode_return': 44911.11111111111, 'local/mean_episode_step': 4655.111111111111, 'local/SPS': 3259.732577893268, 'local/env_act_steps': 36388224, 'local/env_train_steps': 36384640, 'local/optimizer_steps': 56850, 'local/running_reward': 19127.34681372549, 'local/running_step': 2032.0536764705882, 'local/steps_done': 36388224, 'local/episodes_done': 8753, 'local/unclipped_grad_norm': 0.7495305186510086, 'local/model_version': 56850, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:24,212] {'global/mean_episode_return': 42700.0, 'global/mean_episode_step': 4447.166666666667, 'global/SPS': 3323.648902949999, 'global/env_act_steps': 36383232, 'global/env_train_steps': 36380160, 'global/optimizer_steps': 56843, 'global/running_reward': 19227.386474609375, 'global/running_step': 2042.1030578613281, 'global/steps_done': 36383232, 'global/episodes_done': 8752, 'global/unclipped_grad_norm': 0.7041342690879223, 'global/model_version': 56843, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:34,216] calculate_sps 33920 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:34,216] calculate_sps 33280 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:34,217] {'local/mean_episode_return': 43777.77777777778, 'local/mean_episode_step': 4426.222222222223, 'local/SPS': 3390.2058429933327, 'local/env_act_steps': 36420736, 'local/env_train_steps': 36418560, 'local/optimizer_steps': 56904, 'local/running_reward': 18548.640501968504, 'local/running_step': 1978.543030265748, 'local/steps_done': 36420736, 'local/episodes_done': 8762, 'local/unclipped_grad_norm': 0.7927525010373857, 'local/model_version': 56904, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:34,218] {'global/mean_episode_return': 43911.11111111111, 'global/mean_episode_step': 4455.333333333333, 'global/SPS': 3326.2396950123266, 'global/env_act_steps': 36416256, 'global/env_train_steps': 36413440, 'global/optimizer_steps': 56896, 'global/running_reward': 18604.469476744187, 'global/running_step': 1983.2619912790697, 'global/steps_done': 36416256, 'global/episodes_done': 8761, 'global/unclipped_grad_norm': 0.813589020720068, 'global/model_version': 56896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:44,249] calculate_sps 30720 steps in 10.0331
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:44,250] calculate_sps 32000 steps in 10.0331
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:44,250] {'local/mean_episode_return': 40150.0, 'local/mean_episode_step': 4224.416666666667, 'local/SPS': 3061.8576199938902, 'local/env_act_steps': 36454016, 'local/env_train_steps': 36449280, 'local/optimizer_steps': 56952, 'local/running_reward': 17943.31730769231, 'local/running_step': 1919.8611778846155, 'local/steps_done': 36454016, 'local/episodes_done': 8774, 'local/unclipped_grad_norm': 0.7447646576911211, 'local/model_version': 56952, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:44,251] {'global/mean_episode_return': 41563.63636363636, 'global/mean_episode_step': 4342.272727272727, 'global/SPS': 3189.435020826969, 'global/env_act_steps': 36449536, 'global/env_train_steps': 36445440, 'global/optimizer_steps': 56945, 'global/running_reward': 18021.875, 'global/running_step': 1927.7649338942308, 'global/steps_done': 36449536, 'global/episodes_done': 8772, 'global/unclipped_grad_norm': 0.762265074009798, 'global/model_version': 56945, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:54,270] calculate_sps 34560 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:21:54,270] calculate_sps 34560 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:54,270] {'local/mean_episode_return': 42320.0, 'local/mean_episode_step': 4132.8, 'local/SPS': 3448.7697022859784, 'local/env_act_steps': 36485888, 'local/env_train_steps': 36483840, 'local/optimizer_steps': 57005, 'local/running_reward': 17875.671435742974, 'local/running_step': 1915.6781814759036, 'local/steps_done': 36485888, 'local/episodes_done': 8779, 'local/unclipped_grad_norm': 0.6863265920360133, 'local/model_version': 57005, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:21:54,271] {'global/mean_episode_return': 40720.0, 'global/mean_episode_step': 4064.4, 'global/SPS': 3448.7697022859784, 'global/env_act_steps': 36481920, 'global/env_train_steps': 36480000, 'global/optimizer_steps': 57000, 'global/running_reward': 17809.25148221344, 'global/running_step': 1908.947196146245, 'global/steps_done': 36481920, 'global/episodes_done': 8777, 'global/unclipped_grad_norm': 0.6732993180101569, 'global/model_version': 57000, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:04,275] calculate_sps 32000 steps in 10.0048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:04,275] calculate_sps 30720 steps in 10.0048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:04,277] {'local/mean_episode_return': 32250.0, 'local/mean_episode_step': 3594.75, 'local/SPS': 3198.469131760118, 'local/env_act_steps': 36519296, 'local/env_train_steps': 36515840, 'local/optimizer_steps': 57056, 'local/running_reward': 18540.05627394636, 'local/running_step': 1978.3994252873563, 'local/steps_done': 36519296, 'local/episodes_done': 8783, 'local/unclipped_grad_norm': 0.7471801112679874, 'local/model_version': 57056, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:04,278] {'global/mean_episode_return': 31920.0, 'global/mean_episode_step': 3497.8, 'global/SPS': 3070.5303664897137, 'global/env_act_steps': 36515584, 'global/env_train_steps': 36510720, 'global/optimizer_steps': 57048, 'global/running_reward': 18467.04491444867, 'global/running_step': 1971.8829016159696, 'global/steps_done': 36515584, 'global/episodes_done': 8782, 'global/unclipped_grad_norm': 0.7599175448218981, 'global/model_version': 57048, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:14,291] calculate_sps 32640 steps in 10.0144
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:14,291] calculate_sps 35840 steps in 10.0144
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:14,291] {'local/mean_episode_return': 38260.0, 'local/mean_episode_step': 4096.4, 'local/SPS': 3259.299613118212, 'local/env_act_steps': 36552192, 'local/env_train_steps': 36548480, 'local/optimizer_steps': 57106, 'local/running_reward': 19058.846060311284, 'local/running_step': 2023.2150413424124, 'local/steps_done': 36552192, 'local/episodes_done': 8793, 'local/unclipped_grad_norm': 0.7336428442597389, 'local/model_version': 57106, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:14,293] {'global/mean_episode_return': 39022.22222222222, 'global/mean_episode_step': 4166.666666666667, 'global/SPS': 3578.8387908749, 'global/env_act_steps': 36548224, 'global/env_train_steps': 36546560, 'global/optimizer_steps': 57104, 'global/running_reward': 19080.95588235294, 'global/running_step': 2026.4864583333333, 'global/steps_done': 36548224, 'global/episodes_done': 8791, 'global/unclipped_grad_norm': 0.7296199481934309, 'global/model_version': 57104, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:24,296] calculate_sps 33920 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:24,296] calculate_sps 30720 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:24,296] {'local/mean_episode_return': 41775.0, 'local/mean_episode_step': 4339.875, 'local/SPS': 3389.8714217273227, 'local/env_act_steps': 36584704, 'local/env_train_steps': 36582400, 'local/optimizer_steps': 57160, 'local/running_reward': 18819.420521653545, 'local/running_step': 1996.9462967519685, 'local/steps_done': 36584704, 'local/episodes_done': 8801, 'local/unclipped_grad_norm': 0.7010514366405981, 'local/model_version': 57160, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:24,298] {'global/mean_episode_return': 40244.444444444445, 'global/mean_episode_step': 4227.0, 'global/SPS': 3070.0722309983303, 'global/env_act_steps': 36582016, 'global/env_train_steps': 36577280, 'global/optimizer_steps': 57152, 'global/running_reward': 18832.09043560606, 'global/running_step': 1997.8923709753788, 'global/steps_done': 36582016, 'global/episodes_done': 8800, 'global/unclipped_grad_norm': 0.6981202661991119, 'global/model_version': 57152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:34,299] calculate_sps 30720 steps in 10.0033
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:34,299] calculate_sps 35840 steps in 10.0033
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:34,300] {'local/mean_episode_return': 38511.11111111111, 'local/mean_episode_step': 4007.5555555555557, 'local/SPS': 3070.98044103047, 'local/env_act_steps': 36618240, 'local/env_train_steps': 36613120, 'local/optimizer_steps': 57208, 'local/running_reward': 18577.58826335878, 'local/running_step': 1971.9143905057251, 'local/steps_done': 36618240, 'local/episodes_done': 8810, 'local/unclipped_grad_norm': 0.758987441038092, 'local/model_version': 57208, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:34,301] {'global/mean_episode_return': 39120.0, 'global/mean_episode_step': 4052.8, 'global/SPS': 3582.8105145355485, 'global/env_act_steps': 36614528, 'global/env_train_steps': 36613120, 'global/optimizer_steps': 57208, 'global/running_reward': 18592.16904527559, 'global/running_step': 1973.4836368110236, 'global/steps_done': 36614528, 'global/episodes_done': 8810, 'global/unclipped_grad_norm': 0.7491866041507039, 'global/model_version': 57208, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:44,353] calculate_sps 35840 steps in 10.0541
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:44,353] calculate_sps 30720 steps in 10.0541
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:44,354] {'local/mean_episode_return': 36500.0, 'local/mean_episode_step': 3781.0, 'local/SPS': 3564.7039748394127, 'local/env_act_steps': 36650496, 'local/env_train_steps': 36648960, 'local/optimizer_steps': 57264, 'local/running_reward': 18700.837053571428, 'local/running_step': 1984.9044208829366, 'local/steps_done': 36650496, 'local/episodes_done': 8816, 'local/unclipped_grad_norm': 0.7701291766549859, 'local/model_version': 57264, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:44,355] {'global/mean_episode_return': 36500.0, 'global/mean_episode_step': 3781.0, 'global/SPS': 3055.4605498623537, 'global/env_act_steps': 36648320, 'global/env_train_steps': 36643840, 'global/optimizer_steps': 57256, 'global/running_reward': 18664.70762310606, 'global/running_step': 1981.1455078125, 'global/steps_done': 36648320, 'global/episodes_done': 8816, 'global/unclipped_grad_norm': 0.7845813905199369, 'global/model_version': 57256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:54,375] calculate_sps 30720 steps in 10.0218
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:22:54,375] calculate_sps 35840 steps in 10.0218
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:54,376] {'local/mean_episode_return': 37285.71428571428, 'local/mean_episode_step': 3803.8571428571427, 'local/SPS': 3065.318324253245, 'local/env_act_steps': 36683904, 'local/env_train_steps': 36679680, 'local/optimizer_steps': 57312, 'local/running_reward': 19067.031848659004, 'local/running_step': 2020.7008201628353, 'local/steps_done': 36683904, 'local/episodes_done': 8823, 'local/unclipped_grad_norm': 0.7306447122246027, 'local/model_version': 57312, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:22:54,377] {'global/mean_episode_return': 38033.333333333336, 'global/mean_episode_step': 3839.1666666666665, 'global/SPS': 3576.204711628786, 'global/env_act_steps': 36680704, 'global/env_train_steps': 36679680, 'global/optimizer_steps': 57311, 'global/running_reward': 19037.808794466404, 'global/running_step': 2018.1562808794467, 'global/steps_done': 36680704, 'global/episodes_done': 8822, 'global/unclipped_grad_norm': 0.730435122684999, 'global/model_version': 57311, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:04,402] calculate_sps 35200 steps in 10.0271
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:04,402] calculate_sps 30720 steps in 10.0271
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:04,402] {'local/mean_episode_return': 42433.333333333336, 'local/mean_episode_step': 4350.833333333333, 'local/SPS': 3510.4705249540752, 'local/env_act_steps': 36716416, 'local/env_train_steps': 36714880, 'local/optimizer_steps': 57366, 'local/running_reward': 19163.32431102362, 'local/running_step': 2025.406065452756, 'local/steps_done': 36716416, 'local/episodes_done': 8829, 'local/unclipped_grad_norm': 0.7104620983203253, 'local/model_version': 57366, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:04,403] {'global/mean_episode_return': 41057.142857142855, 'global/mean_episode_step': 4242.428571428572, 'global/SPS': 3063.6833672326475, 'global/env_act_steps': 36714496, 'global/env_train_steps': 36710400, 'global/optimizer_steps': 57360, 'global/running_reward': 19157.037168560608, 'global/running_step': 2024.8276515151515, 'global/steps_done': 36714496, 'global/episodes_done': 8829, 'global/unclipped_grad_norm': 0.6486139595508575, 'global/model_version': 57360, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:14,435] calculate_sps 31360 steps in 10.0333
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:14,436] calculate_sps 35840 steps in 10.0333
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:14,436] {'local/mean_episode_return': 35971.42857142857, 'local/mean_episode_step': 3931.8571428571427, 'local/SPS': 3125.580588258959, 'local/env_act_steps': 36750080, 'local/env_train_steps': 36746240, 'local/optimizer_steps': 57416, 'local/running_reward': 19545.835313688214, 'local/running_step': 2061.3417894486693, 'local/steps_done': 36750080, 'local/episodes_done': 8836, 'local/unclipped_grad_norm': 0.7847817540168762, 'local/model_version': 57416, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:14,437] {'global/mean_episode_return': 35971.42857142857, 'global/mean_episode_step': 3931.8571428571427, 'global/SPS': 3572.0921008673818, 'global/env_act_steps': 36747264, 'global/env_train_steps': 36746240, 'global/optimizer_steps': 57415, 'global/running_reward': 19522.91259765625, 'global/running_step': 2059.372802734375, 'global/steps_done': 36747264, 'global/episodes_done': 8836, 'global/unclipped_grad_norm': 0.8278775849125602, 'global/model_version': 57415, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:24,483] calculate_sps 33280 steps in 10.0475
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:24,483] calculate_sps 30720 steps in 10.0475
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:24,483] {'local/mean_episode_return': 37866.666666666664, 'local/mean_episode_step': 3981.6666666666665, 'local/SPS': 3312.2769066782084, 'local/env_act_steps': 36782592, 'local/env_train_steps': 36779520, 'local/optimizer_steps': 57467, 'local/running_reward': 20096.899606299212, 'local/running_step': 2113.6974655511813, 'local/steps_done': 36782592, 'local/episodes_done': 8842, 'local/unclipped_grad_norm': 0.7522987553886339, 'local/model_version': 57467, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:24,484] {'global/mean_episode_return': 37760.0, 'global/mean_episode_step': 4046.0, 'global/SPS': 3057.4863753952695, 'global/env_act_steps': 36780672, 'global/env_train_steps': 36776960, 'global/optimizer_steps': 57464, 'global/running_reward': 20053.735632183907, 'global/running_step': 2109.6507124042146, 'global/steps_done': 36780672, 'global/episodes_done': 8841, 'global/unclipped_grad_norm': 0.754906563126311, 'global/model_version': 57464, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:34,488] calculate_sps 33280 steps in 10.0054
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:34,489] calculate_sps 33920 steps in 10.0054
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:34,498] {'local/mean_episode_return': 40440.0, 'local/mean_episode_step': 4162.8, 'local/SPS': 3326.1883341671455, 'local/env_act_steps': 36815616, 'local/env_train_steps': 36812800, 'local/optimizer_steps': 57520, 'local/running_reward': 19742.732558139534, 'local/running_step': 2071.2232921511627, 'local/steps_done': 36815616, 'local/episodes_done': 8852, 'local/unclipped_grad_norm': 0.7991593367648575, 'local/model_version': 57520, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:34,500] {'global/mean_episode_return': 40254.545454545456, 'global/mean_episode_step': 4117.090909090909, 'global/SPS': 3390.1534944395908, 'global/env_act_steps': 36813440, 'global/env_train_steps': 36810880, 'global/optimizer_steps': 57516, 'global/running_reward': 19762.82958984375, 'global/running_step': 2073.5740661621094, 'global/steps_done': 36813440, 'global/episodes_done': 8852, 'global/unclipped_grad_norm': 0.8095668594424541, 'global/model_version': 57516, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:44,497] calculate_sps 31360 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:44,498] calculate_sps 32640 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:44,498] {'local/mean_episode_return': 38440.0, 'local/mean_episode_step': 4008.4, 'local/SPS': 3133.0816794621173, 'local/env_act_steps': 36848768, 'local/env_train_steps': 36844160, 'local/optimizer_steps': 57568, 'local/running_reward': 19984.580115830115, 'local/running_step': 2096.3466759169883, 'local/steps_done': 36848768, 'local/episodes_done': 8857, 'local/unclipped_grad_norm': 0.6613586265593767, 'local/model_version': 57568, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:44,499] {'global/mean_episode_return': 38440.0, 'global/mean_episode_step': 4008.4, 'global/SPS': 3260.9625643381223, 'global/env_act_steps': 36846848, 'global/env_train_steps': 36843520, 'global/optimizer_steps': 57568, 'global/running_reward': 19967.702346743295, 'global/running_step': 2094.4227729885056, 'global/steps_done': 36846848, 'global/episodes_done': 8857, 'global/unclipped_grad_norm': 0.6544813187076495, 'global/model_version': 57568, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:54,524] calculate_sps 35200 steps in 10.0263
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:23:54,524] calculate_sps 33280 steps in 10.0263
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:54,525] {'local/mean_episode_return': 39460.0, 'local/mean_episode_step': 4074.1, 'local/SPS': 3510.7793894771094, 'local/env_act_steps': 36881280, 'local/env_train_steps': 36879360, 'local/optimizer_steps': 57624, 'local/running_reward': 20152.68208661417, 'local/running_step': 2113.7406803641734, 'local/steps_done': 36881280, 'local/episodes_done': 8867, 'local/unclipped_grad_norm': 0.7453260602695602, 'local/model_version': 57624, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:23:54,526] {'global/mean_episode_return': 39488.88888888889, 'global/mean_episode_step': 4068.1111111111113, 'global/SPS': 3319.282331869267, 'global/env_act_steps': 36879872, 'global/env_train_steps': 36876800, 'global/optimizer_steps': 57619, 'global/running_reward': 20158.00024224806, 'global/running_step': 2114.5072977228683, 'global/steps_done': 36879872, 'global/episodes_done': 8866, 'global/unclipped_grad_norm': 0.74994556518162, 'global/model_version': 57619, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:04,524] calculate_sps 30720 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:04,525] calculate_sps 33280 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:04,525] {'local/mean_episode_return': 38333.333333333336, 'local/mean_episode_step': 3846.6666666666665, 'local/SPS': 3071.930421497812, 'local/env_act_steps': 36914432, 'local/env_train_steps': 36910080, 'local/optimizer_steps': 57672, 'local/running_reward': 20491.916023166024, 'local/running_step': 2144.7141047297296, 'local/steps_done': 36914432, 'local/episodes_done': 8870, 'local/unclipped_grad_norm': 0.7813675850629807, 'local/model_version': 57672, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:04,526] {'global/mean_episode_return': 38550.0, 'global/mean_episode_step': 3917.0, 'global/SPS': 3327.924623289296, 'global/env_act_steps': 36912768, 'global/env_train_steps': 36910080, 'global/optimizer_steps': 57672, 'global/running_reward': 20451.0031614786, 'global/running_step': 2140.4326665856033, 'global/steps_done': 36912768, 'global/episodes_done': 8870, 'global/unclipped_grad_norm': 0.7735222572425626, 'global/model_version': 57672, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:14,530] calculate_sps 33920 steps in 10.0059
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:14,530] calculate_sps 32000 steps in 10.0059
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:14,532] {'local/mean_episode_return': 41177.77777777778, 'local/mean_episode_step': 4211.666666666667, 'local/SPS': 3389.987088479076, 'local/env_act_steps': 36946688, 'local/env_train_steps': 36944000, 'local/optimizer_steps': 57725, 'local/running_reward': 20543.055555555555, 'local/running_step': 2150.495659722222, 'local/steps_done': 36946688, 'local/episodes_done': 8879, 'local/unclipped_grad_norm': 0.7643906780571308, 'local/model_version': 57725, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:14,533] {'global/mean_episode_return': 41177.77777777778, 'global/mean_episode_step': 4211.666666666667, 'global/SPS': 3198.101026867053, 'global/env_act_steps': 36946176, 'global/env_train_steps': 36942080, 'global/optimizer_steps': 57721, 'global/running_reward': 20558.38122605364, 'global/running_step': 2152.1537356321837, 'global/steps_done': 36946176, 'global/episodes_done': 8879, 'global/unclipped_grad_norm': 0.7673022245265999, 'global/model_version': 57721, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:24,531] calculate_sps 32640 steps in 10.0007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:24,531] calculate_sps 34560 steps in 10.0007
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:24,531] {'local/mean_episode_return': 42822.22222222222, 'local/mean_episode_step': 4301.666666666667, 'local/SPS': 3263.758465140443, 'local/env_act_steps': 36979200, 'local/env_train_steps': 36976640, 'local/optimizer_steps': 57776, 'local/running_reward': 20709.221210629923, 'local/running_step': 2166.7843257874015, 'local/steps_done': 36979200, 'local/episodes_done': 8888, 'local/unclipped_grad_norm': 0.7408274604993708, 'local/model_version': 57776, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:24,533] {'global/mean_episode_return': 42125.0, 'global/mean_episode_step': 4252.375, 'global/SPS': 3455.744257207528, 'global/env_act_steps': 36978432, 'global/env_train_steps': 36976640, 'global/optimizer_steps': 57776, 'global/running_reward': 20713.163442460318, 'global/running_step': 2167.1571490575398, 'global/steps_done': 36978432, 'global/episodes_done': 8887, 'global/unclipped_grad_norm': 0.7399472258307717, 'global/model_version': 57776, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:34,551] calculate_sps 30720 steps in 10.0206
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:34,552] calculate_sps 30720 steps in 10.0206
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:34,552] {'local/mean_episode_return': 37325.0, 'local/mean_episode_step': 3929.0, 'local/SPS': 3065.693928495053, 'local/env_act_steps': 37012224, 'local/env_train_steps': 37007360, 'local/optimizer_steps': 57824, 'local/running_reward': 20537.63929263566, 'local/running_step': 2151.407703488372, 'local/steps_done': 37012224, 'local/episodes_done': 8896, 'local/unclipped_grad_norm': 0.7599060460925102, 'local/model_version': 57824, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:34,553] {'global/mean_episode_return': 38555.555555555555, 'global/mean_episode_step': 4014.222222222222, 'global/SPS': 3065.693928495053, 'global/env_act_steps': 37011584, 'global/env_train_steps': 37007360, 'global/optimizer_steps': 57824, 'global/running_reward': 20541.029198841698, 'global/running_step': 2151.83412765444, 'global/steps_done': 37011584, 'global/episodes_done': 8896, 'global/unclipped_grad_norm': 0.7599060460925102, 'global/model_version': 57824, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:44,561] calculate_sps 35200 steps in 10.0077
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:44,562] calculate_sps 35200 steps in 10.0077
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:44,567] {'local/mean_episode_return': 45800.0, 'local/mean_episode_step': 4432.5, 'local/SPS': 3517.309042695259, 'local/env_act_steps': 37044224, 'local/env_train_steps': 37042560, 'local/optimizer_steps': 57878, 'local/running_reward': 20681.025, 'local/running_step': 2161.43259375, 'local/steps_done': 37044224, 'local/episodes_done': 8900, 'local/unclipped_grad_norm': 0.7225279554172799, 'local/model_version': 57878, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:44,568] {'global/mean_episode_return': 45800.0, 'global/mean_episode_step': 4432.5, 'global/SPS': 3517.309042695259, 'global/env_act_steps': 37044224, 'global/env_train_steps': 37042560, 'global/optimizer_steps': 57878, 'global/running_reward': 20673.345588235294, 'global/running_step': 2160.6477022058825, 'global/steps_done': 37044224, 'global/episodes_done': 8900, 'global/unclipped_grad_norm': 0.7225279554172799, 'global/model_version': 57878, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:54,591] calculate_sps 31360 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:24:54,591] calculate_sps 26240 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:54,591] {'local/mean_episode_return': 43266.666666666664, 'local/mean_episode_step': 4461.166666666667, 'local/SPS': 3126.090549110234, 'local/env_act_steps': 37077376, 'local/env_train_steps': 37073920, 'local/optimizer_steps': 57928, 'local/running_reward': 21190.56467181467, 'local/running_step': 2213.3009773166023, 'local/steps_done': 37077376, 'local/episodes_done': 8906, 'local/unclipped_grad_norm': 0.7752736163139343, 'local/model_version': 57928, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:24:54,593] {'global/mean_episode_return': 42950.0, 'global/mean_episode_step': 4475.75, 'global/SPS': 2615.7084186432567, 'global/env_act_steps': 37070592, 'global/env_train_steps': 37068800, 'global/optimizer_steps': 57920, 'global/running_reward': 21189.601031553397, 'global/running_step': 2213.1005764563106, 'global/steps_done': 37070592, 'global/episodes_done': 8904, 'global/unclipped_grad_norm': 0.7895644853512446, 'global/model_version': 57920, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:04,631] calculate_sps 33280 steps in 10.0409
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:04,632] calculate_sps 30720 steps in 10.0409
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:04,632] {'local/mean_episode_return': 31000.0, 'local/mean_episode_step': 3482.0, 'local/SPS': 3314.430154443233, 'local/env_act_steps': 37110272, 'local/env_train_steps': 37107200, 'local/optimizer_steps': 57979, 'local/running_reward': 21851.495622568094, 'local/running_step': 2280.1488630836575, 'local/steps_done': 37110272, 'local/episodes_done': 8908, 'local/unclipped_grad_norm': 0.7224310841046128, 'local/model_version': 57979, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:04,633] {'global/mean_episode_return': 40733.333333333336, 'global/mean_episode_step': 4224.333333333333, 'global/SPS': 3059.4739887168303, 'global/env_act_steps': 37104256, 'global/env_train_steps': 37099520, 'global/optimizer_steps': 57968, 'global/running_reward': 21645.823431558936, 'global/running_step': 2259.815916112167, 'global/steps_done': 37104256, 'global/episodes_done': 8907, 'global/unclipped_grad_norm': 0.7251934011777242, 'global/model_version': 57968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:14,677] calculate_sps 33280 steps in 10.0451
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:14,677] calculate_sps 35840 steps in 10.0451
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:14,677] {'local/mean_episode_return': 44200.0, 'local/mean_episode_step': 4375.666666666667, 'local/SPS': 3313.0608688354228, 'local/env_act_steps': 37143040, 'local/env_train_steps': 37140480, 'local/optimizer_steps': 58032, 'local/running_reward': 22319.1650390625, 'local/running_step': 2324.1845092773438, 'local/steps_done': 37143040, 'local/episodes_done': 8914, 'local/unclipped_grad_norm': 0.6480301663560687, 'local/model_version': 58032, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:14,679] {'global/mean_episode_return': 41120.0, 'global/mean_episode_step': 4151.4, 'global/SPS': 3567.9117048996864, 'global/env_act_steps': 37136512, 'global/env_train_steps': 37135360, 'global/optimizer_steps': 58024, 'global/running_reward': 22252.616567460318, 'global/running_step': 2317.547898065476, 'global/steps_done': 37136512, 'global/episodes_done': 8912, 'global/unclipped_grad_norm': 0.6312281249889306, 'global/model_version': 58024, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:24,704] calculate_sps 31360 steps in 10.0276
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:24,704] calculate_sps 30720 steps in 10.0276
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:24,705] {'local/mean_episode_return': 40200.0, 'local/mean_episode_step': 4212.25, 'local/SPS': 3127.3811625637277, 'local/env_act_steps': 37176448, 'local/env_train_steps': 37171840, 'local/optimizer_steps': 58080, 'local/running_reward': 22535.997365900384, 'local/running_step': 2345.2080639367814, 'local/steps_done': 37176448, 'local/episodes_done': 8922, 'local/unclipped_grad_norm': 0.7146856604764859, 'local/model_version': 58080, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:24,706] {'global/mean_episode_return': 40644.444444444445, 'global/mean_episode_step': 4225.888888888889, 'global/SPS': 3063.5570572052843, 'global/env_act_steps': 37170048, 'global/env_train_steps': 37166080, 'global/optimizer_steps': 58072, 'global/running_reward': 22539.044608778626, 'global/running_step': 2346.5776180820612, 'global/steps_done': 37170048, 'global/episodes_done': 8921, 'global/unclipped_grad_norm': 0.7388785208264986, 'global/model_version': 58072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:34,719] calculate_sps 35200 steps in 10.0146
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:34,719] calculate_sps 33920 steps in 10.0146
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:34,719] {'local/mean_episode_return': 36200.0, 'local/mean_episode_step': 3894.4, 'local/SPS': 3514.885433012304, 'local/env_act_steps': 37208576, 'local/env_train_steps': 37207040, 'local/optimizer_steps': 58136, 'local/running_reward': 22878.068974103586, 'local/running_step': 2375.598107569721, 'local/steps_done': 37208576, 'local/episodes_done': 8927, 'local/unclipped_grad_norm': 0.6797026119061879, 'local/model_version': 58136, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:34,721] {'global/mean_episode_return': 37333.333333333336, 'global/mean_episode_step': 3964.8333333333335, 'global/SPS': 3387.071417266402, 'global/env_act_steps': 37202688, 'global/env_train_steps': 37200000, 'global/optimizer_steps': 58125, 'global/running_reward': 22797.03431372549, 'global/running_step': 2368.096966911765, 'global/steps_done': 37202688, 'global/episodes_done': 8927, 'global/unclipped_grad_norm': 0.6794738887615923, 'global/model_version': 58125, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:44,754] calculate_sps 30720 steps in 10.0344
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:44,754] calculate_sps 32640 steps in 10.0344
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:44,754] {'local/mean_episode_return': 44844.444444444445, 'local/mean_episode_step': 4438.111111111111, 'local/SPS': 3061.4555318237817, 'local/env_act_steps': 37242112, 'local/env_train_steps': 37237760, 'local/optimizer_steps': 58184, 'local/running_reward': 23375.763358778626, 'local/running_step': 2421.884363072519, 'local/steps_done': 37242112, 'local/episodes_done': 8936, 'local/unclipped_grad_norm': 0.748171171794335, 'local/model_version': 58184, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:44,756] {'global/mean_episode_return': 43550.0, 'global/mean_episode_step': 4299.25, 'global/SPS': 3252.7965025627677, 'global/env_act_steps': 37235968, 'global/env_train_steps': 37232640, 'global/optimizer_steps': 58176, 'global/running_reward': 23365.162259615383, 'global/running_step': 2420.6896033653848, 'global/steps_done': 37235968, 'global/episodes_done': 8931, 'global/unclipped_grad_norm': 0.7086455477219001, 'global/model_version': 58176, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 14:25:52,434] saving global stats {'mean_episode_return': 41636.36363636364, 'mean_episode_step': 4209.818181818182, 'SPS': None, 'env_act_steps': 37255168, 'env_train_steps': 37253120, 'optimizer_steps': 58208, 'running_reward': 22776.40625, 'running_step': 2363.2474479166667, 'steps_done': 37255168, 'episodes_done': 8942, 'unclipped_grad_norm': 0.7562294434756041, 'model_version': 58208, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 14:25:52,529] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:54,766] calculate_sps 33280 steps in 10.0131
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:25:54,766] calculate_sps 31360 steps in 10.0131
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:54,767] {'local/mean_episode_return': 39050.0, 'local/mean_episode_step': 4024.5833333333335, 'local/SPS': 3323.6442337931835, 'local/env_act_steps': 37274112, 'local/env_train_steps': 37271040, 'local/optimizer_steps': 58235, 'local/running_reward': 22380.70625, 'local/running_step': 2324.57890625, 'local/steps_done': 37274112, 'local/episodes_done': 8948, 'local/unclipped_grad_norm': 0.7178377380558089, 'local/model_version': 58235, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:25:54,767] {'global/mean_episode_return': 41853.333333333336, 'global/mean_episode_step': 4233.733333333334, 'global/SPS': 3131.895527997423, 'global/env_act_steps': 37268608, 'global/env_train_steps': 37264000, 'global/optimizer_steps': 58224, 'global/running_reward': 22560.723039215685, 'global/running_step': 2341.9365502450983, 'global/steps_done': 37268608, 'global/episodes_done': 8946, 'global/unclipped_grad_norm': 0.7301541920751333, 'global/model_version': 58224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:04,793] calculate_sps 33280 steps in 10.0269
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:04,794] calculate_sps 35200 steps in 10.0269
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:04,794] {'local/mean_episode_return': 38857.142857142855, 'local/mean_episode_step': 4048.714285714286, 'local/SPS': 3319.0687595254167, 'local/env_act_steps': 37306880, 'local/env_train_steps': 37304320, 'local/optimizer_steps': 58288, 'local/running_reward': 22207.586669921875, 'local/running_step': 2306.4942016601562, 'local/steps_done': 37306880, 'local/episodes_done': 8955, 'local/unclipped_grad_norm': 0.849566546813497, 'local/model_version': 58288, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:04,795] {'global/mean_episode_return': 38022.22222222222, 'global/mean_episode_step': 3986.222222222222, 'global/SPS': 3510.5534956518827, 'global/env_act_steps': 37300864, 'global/env_train_steps': 37299200, 'global/optimizer_steps': 58280, 'global/running_reward': 22175.55183531746, 'global/running_step': 2304.2302207341268, 'global/steps_done': 37300864, 'global/episodes_done': 8955, 'global/unclipped_grad_norm': 0.8532385804823467, 'global/model_version': 58280, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:14,805] calculate_sps 30720 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:14,805] calculate_sps 30720 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:14,806] {'local/mean_episode_return': 38971.42857142857, 'local/mean_episode_step': 4166.857142857143, 'local/SPS': 3068.400341062975, 'local/env_act_steps': 37340160, 'local/env_train_steps': 37335040, 'local/optimizer_steps': 58336, 'local/running_reward': 22522.94471153846, 'local/running_step': 2333.3817007211537, 'local/steps_done': 37340160, 'local/episodes_done': 8962, 'local/unclipped_grad_norm': 0.662655288974444, 'local/model_version': 58336, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:14,807] {'global/mean_episode_return': 38971.42857142857, 'global/mean_episode_step': 4166.857142857143, 'global/SPS': 3068.400341062975, 'global/env_act_steps': 37334656, 'global/env_train_steps': 37329920, 'global/optimizer_steps': 58328, 'global/running_reward': 22483.72987689394, 'global/running_step': 2330.488370028409, 'global/steps_done': 37334656, 'global/episodes_done': 8962, 'global/unclipped_grad_norm': 0.6700970027595758, 'global/model_version': 58328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:24,850] calculate_sps 35840 steps in 10.0453
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:24,850] calculate_sps 35840 steps in 10.0453
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:24,850] {'local/mean_episode_return': 48200.0, 'local/mean_episode_step': 4665.25, 'local/SPS': 3567.8243133680803, 'local/env_act_steps': 37371904, 'local/env_train_steps': 37370880, 'local/optimizer_steps': 58391, 'local/running_reward': 22789.96345766129, 'local/running_step': 2360.975554435484, 'local/steps_done': 37371904, 'local/episodes_done': 8966, 'local/unclipped_grad_norm': 0.7364549208771098, 'local/model_version': 58391, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:24,851] {'global/mean_episode_return': 48066.666666666664, 'global/mean_episode_step': 4677.0, 'global/SPS': 3567.8243133680803, 'global/env_act_steps': 37366784, 'global/env_train_steps': 37365760, 'global/optimizer_steps': 58383, 'global/running_reward': 22691.428037848607, 'global/running_step': 2349.943974103586, 'global/steps_done': 37366784, 'global/episodes_done': 8965, 'global/unclipped_grad_norm': 0.7160780673677271, 'global/model_version': 58383, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:34,857] calculate_sps 30720 steps in 10.0066
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:34,857] calculate_sps 30720 steps in 10.0066
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:34,858] {'local/mean_episode_return': 41628.57142857143, 'local/mean_episode_step': 4356.571428571428, 'local/SPS': 3069.9845263024267, 'local/env_act_steps': 37405184, 'local/env_train_steps': 37401600, 'local/optimizer_steps': 58440, 'local/running_reward': 23321.502403846152, 'local/running_step': 2413.609705528846, 'local/steps_done': 37405184, 'local/episodes_done': 8973, 'local/unclipped_grad_norm': 0.7176440181780834, 'local/model_version': 58440, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:34,867] {'global/mean_episode_return': 40320.0, 'global/mean_episode_step': 4182.4, 'global/SPS': 3069.9845263024267, 'global/env_act_steps': 37400064, 'global/env_train_steps': 37396480, 'global/optimizer_steps': 58432, 'global/running_reward': 23280.552884615383, 'global/running_step': 2410.424158653846, 'global/steps_done': 37400064, 'global/episodes_done': 8970, 'global/unclipped_grad_norm': 0.7406547245930653, 'global/model_version': 58432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:44,863] calculate_sps 32000 steps in 10.0041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:44,863] calculate_sps 33280 steps in 10.0041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:44,863] {'local/mean_episode_return': 46142.857142857145, 'local/mean_episode_step': 4607.285714285715, 'local/SPS': 3198.690645225337, 'local/env_act_steps': 37437824, 'local/env_train_steps': 37433600, 'local/optimizer_steps': 58489, 'local/running_reward': 23206.482843137255, 'local/running_step': 2401.8338541666667, 'local/steps_done': 37437824, 'local/episodes_done': 8980, 'local/unclipped_grad_norm': 0.6799023601473594, 'local/model_version': 58489, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:44,864] {'global/mean_episode_return': 45900.0, 'global/mean_episode_step': 4638.5, 'global/SPS': 3326.6382710343505, 'global/env_act_steps': 37432832, 'global/env_train_steps': 37429760, 'global/optimizer_steps': 58483, 'global/running_reward': 23218.841552734375, 'global/running_step': 2402.4806213378906, 'global/steps_done': 37432832, 'global/episodes_done': 8978, 'global/unclipped_grad_norm': 0.6860185364882151, 'global/model_version': 58483, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:54,876] calculate_sps 34560 steps in 10.015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:26:54,876] calculate_sps 33280 steps in 10.015
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:54,877] {'local/mean_episode_return': 47133.333333333336, 'local/mean_episode_step': 4777.833333333333, 'local/SPS': 3450.8255355261363, 'local/env_act_steps': 37470208, 'local/env_train_steps': 37468160, 'local/optimizer_steps': 58544, 'local/running_reward': 23361.184535573124, 'local/running_step': 2416.3266119071145, 'local/steps_done': 37470208, 'local/episodes_done': 8986, 'local/unclipped_grad_norm': 0.727625728466294, 'local/model_version': 58544, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:26:54,878] {'global/mean_episode_return': 46533.333333333336, 'global/mean_episode_step': 4769.5, 'global/SPS': 3323.0171823585015, 'global/env_act_steps': 37465856, 'global/env_train_steps': 37463040, 'global/optimizer_steps': 58536, 'global/running_reward': 23321.015019379844, 'global/running_step': 2412.8084120639537, 'global/steps_done': 37465856, 'global/episodes_done': 8984, 'global/unclipped_grad_norm': 0.709330493549131, 'global/model_version': 58536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:04,879] calculate_sps 30720 steps in 10.0032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:04,880] calculate_sps 32640 steps in 10.0032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:04,880] {'local/mean_episode_return': 48314.28571428572, 'local/mean_episode_step': 4796.428571428572, 'local/SPS': 3071.0291887280146, 'local/env_act_steps': 37503872, 'local/env_train_steps': 37498880, 'local/optimizer_steps': 58592, 'local/running_reward': 23120.876901140684, 'local/running_step': 2390.789508079848, 'local/steps_done': 37503872, 'local/episodes_done': 8993, 'local/unclipped_grad_norm': 0.6794368435318271, 'local/model_version': 58592, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:04,881] {'global/mean_episode_return': 48444.444444444445, 'global/mean_episode_step': 4775.777777777777, 'global/SPS': 3262.9685130235152, 'global/env_act_steps': 37499264, 'global/env_train_steps': 37495680, 'global/optimizer_steps': 58586, 'global/running_reward': 23148.29382183908, 'global/running_step': 2393.902029454023, 'global/steps_done': 37499264, 'global/episodes_done': 8993, 'global/unclipped_grad_norm': 0.6907138293981552, 'global/model_version': 58586, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:14,926] calculate_sps 35840 steps in 10.0469
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:14,926] calculate_sps 33920 steps in 10.0469
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:14,926] {'local/mean_episode_return': 42428.57142857143, 'local/mean_episode_step': 4297.285714285715, 'local/SPS': 3567.2798216956385, 'local/env_act_steps': 37535744, 'local/env_train_steps': 37534720, 'local/optimizer_steps': 58647, 'local/running_reward': 23476.1734437751, 'local/running_step': 2420.9860379016063, 'local/steps_done': 37535744, 'local/episodes_done': 9000, 'local/unclipped_grad_norm': 0.6510895517739382, 'local/model_version': 58647, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:14,927] {'global/mean_episode_return': 42428.57142857143, 'global/mean_episode_step': 4297.285714285715, 'global/SPS': 3376.1755455333723, 'global/env_act_steps': 37532416, 'global/env_train_steps': 37529600, 'global/optimizer_steps': 58640, 'global/running_reward': 23455.278716216217, 'global/running_step': 2419.6114563223937, 'global/steps_done': 37532416, 'global/episodes_done': 9000, 'global/unclipped_grad_norm': 0.6701538204042999, 'global/model_version': 58640, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:24,939] calculate_sps 30720 steps in 10.0127
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:24,940] calculate_sps 31360 steps in 10.0127
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:24,940] {'local/mean_episode_return': 41450.0, 'local/mean_episode_step': 4388.625, 'local/SPS': 3068.0932558867835, 'local/env_act_steps': 37568896, 'local/env_train_steps': 37565440, 'local/optimizer_steps': 58696, 'local/running_reward': 23794.49806949807, 'local/running_step': 2444.7279802123553, 'local/steps_done': 37568896, 'local/episodes_done': 9008, 'local/unclipped_grad_norm': 0.735411133693189, 'local/model_version': 58696, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:24,942] {'global/mean_episode_return': 41450.0, 'global/mean_episode_step': 4388.625, 'global/SPS': 3132.0118653844247, 'global/env_act_steps': 37565568, 'global/env_train_steps': 37560960, 'global/optimizer_steps': 58688, 'global/running_reward': 23795.813223938225, 'global/running_step': 2445.4953848938226, 'global/steps_done': 37565568, 'global/episodes_done': 9008, 'global/unclipped_grad_norm': 0.7023148344208797, 'global/model_version': 58688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:34,981] calculate_sps 32000 steps in 10.0416
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:34,981] calculate_sps 35200 steps in 10.0416
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:34,981] {'local/mean_episode_return': 50125.0, 'local/mean_episode_step': 4873.375, 'local/SPS': 3186.745875887609, 'local/env_act_steps': 37601536, 'local/env_train_steps': 37597440, 'local/optimizer_steps': 58745, 'local/running_reward': 23483.308823529413, 'local/running_step': 2413.495343137255, 'local/steps_done': 37601536, 'local/episodes_done': 9016, 'local/unclipped_grad_norm': 0.6890741735696793, 'local/model_version': 58745, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:34,983] {'global/mean_episode_return': 50833.333333333336, 'global/mean_episode_step': 4888.666666666667, 'global/SPS': 3505.42046347637, 'global/env_act_steps': 37597696, 'global/env_train_steps': 37596160, 'global/optimizer_steps': 58744, 'global/running_reward': 23494.528137450197, 'global/running_step': 2414.148935507968, 'global/steps_done': 37597696, 'global/episodes_done': 9014, 'global/unclipped_grad_norm': 0.7053008923040969, 'global/model_version': 58744, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:44,983] calculate_sps 34560 steps in 10.0026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:44,984] calculate_sps 30720 steps in 10.0026
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:44,984] {'local/mean_episode_return': 39650.0, 'local/mean_episode_step': 4227.25, 'local/SPS': 3455.0904066974936, 'local/env_act_steps': 37634176, 'local/env_train_steps': 37632000, 'local/optimizer_steps': 58800, 'local/running_reward': 23696.55024509804, 'local/running_step': 2436.4386948529414, 'local/steps_done': 37634176, 'local/episodes_done': 9020, 'local/unclipped_grad_norm': 0.6390681738203222, 'local/model_version': 58800, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:44,985] {'global/mean_episode_return': 43040.0, 'global/mean_episode_step': 4454.0, 'global/SPS': 3071.1914726199943, 'global/env_act_steps': 37631616, 'global/env_train_steps': 37626880, 'global/optimizer_steps': 58792, 'global/running_reward': 23637.45283018868, 'global/running_step': 2430.772670990566, 'global/steps_done': 37631616, 'global/episodes_done': 9019, 'global/unclipped_grad_norm': 0.6369509045034647, 'global/model_version': 58792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:55,011] calculate_sps 30720 steps in 10.0275
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:27:55,011] calculate_sps 35840 steps in 10.0275
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:55,011] {'local/mean_episode_return': 50200.0, 'local/mean_episode_step': 4982.111111111111, 'local/SPS': 3063.576578489834, 'local/env_act_steps': 37667712, 'local/env_train_steps': 37662720, 'local/optimizer_steps': 58848, 'local/running_reward': 23626.723520992367, 'local/running_step': 2426.8786975190837, 'local/steps_done': 37667712, 'local/episodes_done': 9029, 'local/unclipped_grad_norm': 0.7015096026783189, 'local/model_version': 58848, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:27:55,012] {'global/mean_episode_return': 49120.0, 'global/mean_episode_step': 4913.3, 'global/SPS': 3574.172674904806, 'global/env_act_steps': 37663744, 'global/env_train_steps': 37662720, 'global/optimizer_steps': 58847, 'global/running_reward': 23691.67081673307, 'global/running_step': 2433.0454121015937, 'global/steps_done': 37663744, 'global/episodes_done': 9029, 'global/unclipped_grad_norm': 0.7022958671504801, 'global/model_version': 58847, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:05,026] calculate_sps 35840 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:05,027] calculate_sps 30720 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:05,027] {'local/mean_episode_return': 45966.666666666664, 'local/mean_episode_step': 4779.5, 'local/SPS': 3578.1875302553444, 'local/env_act_steps': 37699584, 'local/env_train_steps': 37698560, 'local/optimizer_steps': 58903, 'local/running_reward': 23593.98217871486, 'local/running_step': 2425.5592996987953, 'local/steps_done': 37699584, 'local/episodes_done': 9035, 'local/unclipped_grad_norm': 0.7120853716676886, 'local/model_version': 58903, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:05,028] {'global/mean_episode_return': 45966.666666666664, 'global/mean_episode_step': 4779.5, 'global/SPS': 3067.017883076009, 'global/env_act_steps': 37697536, 'global/env_train_steps': 37693440, 'global/optimizer_steps': 58896, 'global/running_reward': 23568.128551136364, 'global/running_step': 2423.2523970170455, 'global/steps_done': 37697536, 'global/episodes_done': 9035, 'global/unclipped_grad_norm': 0.7197451640148552, 'global/model_version': 58896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:15,041] calculate_sps 30720 steps in 10.0139
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:15,041] calculate_sps 33280 steps in 10.0139
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:15,041] {'local/mean_episode_return': 40240.0, 'local/mean_episode_step': 4185.8, 'local/SPS': 3067.7321824889086, 'local/env_act_steps': 37732352, 'local/env_train_steps': 37729280, 'local/optimizer_steps': 58952, 'local/running_reward': 23766.583251953125, 'local/running_step': 2440.8765258789062, 'local/steps_done': 37732352, 'local/episodes_done': 9040, 'local/unclipped_grad_norm': 0.7025046531034975, 'local/model_version': 58952, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:15,043] {'global/mean_episode_return': 40240.0, 'global/mean_episode_step': 4185.8, 'global/SPS': 3323.376531029651, 'global/env_act_steps': 37729792, 'global/env_train_steps': 37726720, 'global/optimizer_steps': 58947, 'global/running_reward': 23732.614087301587, 'global/running_step': 2437.6263020833335, 'global/steps_done': 37729792, 'global/episodes_done': 9040, 'global/unclipped_grad_norm': 0.6587363762014052, 'global/model_version': 58947, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:25,044] calculate_sps 32000 steps in 10.002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:25,045] calculate_sps 33280 steps in 10.002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:25,058] {'local/mean_episode_return': 49200.0, 'local/mean_episode_step': 4938.1, 'local/SPS': 3199.3667330117833, 'local/env_act_steps': 37765504, 'local/env_train_steps': 37761280, 'local/optimizer_steps': 59001, 'local/running_reward': 23685.12306949807, 'local/running_step': 2431.979247104247, 'local/steps_done': 37765504, 'local/episodes_done': 9050, 'local/unclipped_grad_norm': 0.6947418700675575, 'local/model_version': 59001, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:25,060] {'global/mean_episode_return': 49200.0, 'global/mean_episode_step': 4938.1, 'global/SPS': 3327.3414023322543, 'global/env_act_steps': 37762688, 'global/env_train_steps': 37760000, 'global/optimizer_steps': 59000, 'global/running_reward': 23740.54596303502, 'global/running_step': 2437.1945221303504, 'global/steps_done': 37762688, 'global/episodes_done': 9050, 'global/unclipped_grad_norm': 0.7117853507680713, 'global/model_version': 59000, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:35,071] calculate_sps 34560 steps in 10.0279
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:35,071] calculate_sps 32000 steps in 10.0279
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:35,071] {'local/mean_episode_return': 47833.333333333336, 'local/mean_episode_step': 4858.333333333333, 'local/SPS': 3446.3827910182677, 'local/env_act_steps': 37798144, 'local/env_train_steps': 37795840, 'local/optimizer_steps': 59056, 'local/running_reward': 23457.254901960783, 'local/running_step': 2410.8079350490198, 'local/steps_done': 37798144, 'local/episodes_done': 9056, 'local/unclipped_grad_norm': 0.6787069610574029, 'local/model_version': 59056, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:35,073] {'global/mean_episode_return': 47833.333333333336, 'global/mean_episode_step': 4858.333333333333, 'global/SPS': 3191.0951768687664, 'global/env_act_steps': 37796096, 'global/env_train_steps': 37792000, 'global/optimizer_steps': 59049, 'global/running_reward': 23445.085009578543, 'global/running_step': 2409.6493055555557, 'global/steps_done': 37796096, 'global/episodes_done': 9056, 'global/unclipped_grad_norm': 0.7026415458139108, 'global/model_version': 59049, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:45,092] calculate_sps 30720 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:45,092] calculate_sps 34560 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:45,098] {'local/mean_episode_return': 43100.0, 'local/mean_episode_step': 4381.0, 'local/SPS': 3065.5535948975094, 'local/env_act_steps': 37831296, 'local/env_train_steps': 37826560, 'local/optimizer_steps': 59104, 'local/running_reward': 23907.758204633206, 'local/running_step': 2456.198962355212, 'local/steps_done': 37831296, 'local/episodes_done': 9060, 'local/unclipped_grad_norm': 0.7593601817886034, 'local/model_version': 59104, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:45,099] {'global/mean_episode_return': 42400.0, 'global/mean_episode_step': 4240.0, 'global/SPS': 3448.7477942596984, 'global/env_act_steps': 37828864, 'global/env_train_steps': 37826560, 'global/optimizer_steps': 59104, 'global/running_reward': 23862.34130859375, 'global/running_step': 2451.7339477539062, 'global/steps_done': 37828864, 'global/episodes_done': 9059, 'global/unclipped_grad_norm': 0.7417227490381761, 'global/model_version': 59104, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:55,139] calculate_sps 35840 steps in 10.0478
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:28:55,139] calculate_sps 30720 steps in 10.0478
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:55,140] {'local/mean_episode_return': 41514.28571428572, 'local/mean_episode_step': 4438.571428571428, 'local/SPS': 3566.9506334544435, 'local/env_act_steps': 37863424, 'local/env_train_steps': 37862400, 'local/optimizer_steps': 59159, 'local/running_reward': 23887.26344621514, 'local/running_step': 2447.6967753984063, 'local/steps_done': 37863424, 'local/episodes_done': 9067, 'local/unclipped_grad_norm': 0.7324650238860737, 'local/model_version': 59159, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:28:55,141] {'global/mean_episode_return': 41975.0, 'global/mean_episode_step': 4484.25, 'global/SPS': 3057.3862572466655, 'global/env_act_steps': 37862400, 'global/env_train_steps': 37857280, 'global/optimizer_steps': 59152, 'global/running_reward': 23897.584685114503, 'global/running_step': 2449.134541984733, 'global/steps_done': 37862400, 'global/episodes_done': 9067, 'global/unclipped_grad_norm': 0.7233195627729098, 'global/model_version': 59152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:05,163] calculate_sps 30720 steps in 10.0239
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:05,164] calculate_sps 35840 steps in 10.0239
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:05,164] {'local/mean_episode_return': 50100.0, 'local/mean_episode_step': 4914.5, 'local/SPS': 3064.686641551188, 'local/env_act_steps': 37896704, 'local/env_train_steps': 37893120, 'local/optimizer_steps': 59208, 'local/running_reward': 24537.493990384617, 'local/running_step': 2511.2208533653848, 'local/steps_done': 37896704, 'local/episodes_done': 9071, 'local/unclipped_grad_norm': 0.6934905116047178, 'local/model_version': 59208, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:05,165] {'global/mean_episode_return': 50100.0, 'global/mean_episode_step': 4914.5, 'global/SPS': 3575.467748476386, 'global/env_act_steps': 37894784, 'global/env_train_steps': 37893120, 'global/optimizer_steps': 59208, 'global/running_reward': 24513.963685770752, 'global/running_step': 2509.0032114624505, 'global/steps_done': 37894784, 'global/episodes_done': 9071, 'global/unclipped_grad_norm': 0.7062012923083135, 'global/model_version': 59208, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:15,167] calculate_sps 33280 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:15,167] calculate_sps 30720 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:15,167] {'local/mean_episode_return': 49800.0, 'local/mean_episode_step': 5026.125, 'local/SPS': 3326.6563471513487, 'local/env_act_steps': 37929472, 'local/env_train_steps': 37926400, 'local/optimizer_steps': 59259, 'local/running_reward': 24722.503662109375, 'local/running_step': 2527.8306274414062, 'local/steps_done': 37929472, 'local/episodes_done': 9080, 'local/unclipped_grad_norm': 0.7103931705156962, 'local/model_version': 59259, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:15,168] {'global/mean_episode_return': 49800.0, 'global/mean_episode_step': 5026.125, 'global/SPS': 3070.7597050627837, 'global/env_act_steps': 37928576, 'global/env_train_steps': 37923840, 'global/optimizer_steps': 59256, 'global/running_reward': 24736.612215909092, 'global/running_step': 2529.1770241477275, 'global/steps_done': 37928576, 'global/episodes_done': 9080, 'global/unclipped_grad_norm': 0.6839243223269781, 'global/model_version': 59256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:25,194] calculate_sps 33280 steps in 10.0264
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:25,194] calculate_sps 35840 steps in 10.0264
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:25,194] {'local/mean_episode_return': 51360.0, 'local/mean_episode_step': 5064.5, 'local/SPS': 3319.222424657922, 'local/env_act_steps': 37962240, 'local/env_train_steps': 37959680, 'local/optimizer_steps': 59312, 'local/running_reward': 24122.943115234375, 'local/running_step': 2475.0003356933594, 'local/steps_done': 37962240, 'local/episodes_done': 9086, 'local/unclipped_grad_norm': 0.7396810122256009, 'local/model_version': 59312, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:25,196] {'global/mean_episode_return': 51360.0, 'global/mean_episode_step': 5064.5, 'global/SPS': 3574.5472265546855, 'global/env_act_steps': 37960704, 'global/env_train_steps': 37959680, 'global/optimizer_steps': 59311, 'global/running_reward': 24119.696215139444, 'global/running_step': 2474.2781685756972, 'global/steps_done': 37960704, 'global/episodes_done': 9086, 'global/unclipped_grad_norm': 0.7665893993594429, 'global/model_version': 59311, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:35,204] calculate_sps 30720 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:35,204] calculate_sps 30720 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:35,210] {'local/mean_episode_return': 52822.22222222222, 'local/mean_episode_step': 5129.666666666667, 'local/SPS': 3069.017766068181, 'local/env_act_steps': 37995392, 'local/env_train_steps': 37990400, 'local/optimizer_steps': 59360, 'local/running_reward': 24086.60111003861, 'local/running_step': 2480.462566361004, 'local/steps_done': 37995392, 'local/episodes_done': 9095, 'local/unclipped_grad_norm': 0.7808780806759993, 'local/model_version': 59360, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:35,211] {'global/mean_episode_return': 53775.0, 'global/mean_episode_step': 5185.75, 'global/SPS': 3069.017766068181, 'global/env_act_steps': 37993984, 'global/env_train_steps': 37990400, 'global/optimizer_steps': 59360, 'global/running_reward': 24105.703125, 'global/running_step': 2481.919831730769, 'global/steps_done': 37993984, 'global/episodes_done': 9094, 'global/unclipped_grad_norm': 0.7739695669436941, 'global/model_version': 59360, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:45,213] calculate_sps 35200 steps in 10.0076
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:45,213] calculate_sps 33280 steps in 10.0076
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:45,223] {'local/mean_episode_return': 45840.0, 'local/mean_episode_step': 4619.2, 'local/SPS': 3517.3221985710916, 'local/env_act_steps': 38027264, 'local/env_train_steps': 38025600, 'local/optimizer_steps': 59414, 'local/running_reward': 24045.143072289156, 'local/running_step': 2482.027045682731, 'local/steps_done': 38027264, 'local/episodes_done': 9100, 'local/unclipped_grad_norm': 0.689667816515322, 'local/model_version': 59414, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:45,225] {'global/mean_episode_return': 45733.333333333336, 'global/mean_episode_step': 4629.5, 'global/SPS': 3325.4682604672134, 'global/env_act_steps': 38026752, 'global/env_train_steps': 38023680, 'global/optimizer_steps': 59411, 'global/running_reward': 24037.005615234375, 'global/running_step': 2481.296356201172, 'global/steps_done': 38026752, 'global/episodes_done': 9100, 'global/unclipped_grad_norm': 0.6951210148194257, 'global/model_version': 59411, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:55,219] calculate_sps 31360 steps in 10.0078
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:29:55,219] calculate_sps 33280 steps in 10.0078
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:55,219] {'local/mean_episode_return': 42350.0, 'local/mean_episode_step': 4503.25, 'local/SPS': 3133.553181642247, 'local/env_act_steps': 38060544, 'local/env_train_steps': 38056960, 'local/optimizer_steps': 59464, 'local/running_reward': 24074.94591346154, 'local/running_step': 2479.7804387019232, 'local/steps_done': 38060544, 'local/episodes_done': 9108, 'local/unclipped_grad_norm': 0.7785091888904572, 'local/model_version': 59464, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:29:55,221] {'global/mean_episode_return': 41085.71428571428, 'global/mean_episode_step': 4375.428571428572, 'global/SPS': 3325.4033764366704, 'global/env_act_steps': 38059776, 'global/env_train_steps': 38056960, 'global/optimizer_steps': 59464, 'global/running_reward': 24075.024224806202, 'global/running_step': 2479.845566860465, 'global/steps_done': 38059776, 'global/episodes_done': 9107, 'global/unclipped_grad_norm': 0.7682330147275385, 'global/model_version': 59464, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:05,265] calculate_sps 33280 steps in 10.0464
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:05,265] calculate_sps 32000 steps in 10.0464
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:05,265] {'local/mean_episode_return': 50088.88888888889, 'local/mean_episode_step': 5029.333333333333, 'local/SPS': 3312.623873438258, 'local/env_act_steps': 38093312, 'local/env_train_steps': 38090240, 'local/optimizer_steps': 59515, 'local/running_reward': 23379.522705078125, 'local/running_step': 2412.3023986816406, 'local/steps_done': 38093312, 'local/episodes_done': 9117, 'local/unclipped_grad_norm': 0.7146163167906743, 'local/model_version': 59515, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:05,266] {'global/mean_episode_return': 50200.0, 'global/mean_episode_step': 5066.2, 'global/SPS': 3185.215262921402, 'global/env_act_steps': 38093056, 'global/env_train_steps': 38088960, 'global/optimizer_steps': 59513, 'global/running_reward': 23394.903846153848, 'global/running_step': 2413.7622896634616, 'global/steps_done': 38093056, 'global/episodes_done': 9117, 'global/unclipped_grad_norm': 0.7228280798513063, 'global/model_version': 59513, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:15,266] calculate_sps 33280 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:15,267] calculate_sps 34560 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:15,278] {'local/mean_episode_return': 47300.0, 'local/mean_episode_step': 4750.166666666667, 'local/SPS': 3327.6511535138607, 'local/env_act_steps': 38126336, 'local/env_train_steps': 38123520, 'local/optimizer_steps': 59568, 'local/running_reward': 23669.325339147286, 'local/running_step': 2442.9443737887595, 'local/steps_done': 38126336, 'local/episodes_done': 9123, 'local/unclipped_grad_norm': 0.7364467916623602, 'local/model_version': 59568, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:15,280] {'global/mean_episode_return': 47300.0, 'global/mean_episode_step': 4750.166666666667, 'global/SPS': 3455.6377363413167, 'global/env_act_steps': 38126080, 'global/env_train_steps': 38123520, 'global/optimizer_steps': 59568, 'global/running_reward': 23667.9566375969, 'global/running_step': 2442.8074127906975, 'global/steps_done': 38126080, 'global/episodes_done': 9123, 'global/unclipped_grad_norm': 0.7283370218493722, 'global/model_version': 59568, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:25,271] calculate_sps 31360 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:25,271] calculate_sps 25600 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:25,271] {'local/mean_episode_return': 43111.11111111111, 'local/mean_episode_step': 4376.666666666667, 'local/SPS': 3134.568396754069, 'local/env_act_steps': 38159488, 'local/env_train_steps': 38154880, 'local/optimizer_steps': 59616, 'local/running_reward': 23458.385617760618, 'local/running_step': 2422.1701254826253, 'local/steps_done': 38159488, 'local/episodes_done': 9132, 'local/unclipped_grad_norm': 0.7082827494790157, 'local/model_version': 59616, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:25,272] {'global/mean_episode_return': 42475.0, 'global/mean_episode_step': 4355.375, 'global/SPS': 2558.8313442890358, 'global/env_act_steps': 38152832, 'global/env_train_steps': 38149120, 'global/optimizer_steps': 59608, 'global/running_reward': 23502.25777511962, 'global/running_step': 2426.2849506578946, 'global/steps_done': 38152832, 'global/episodes_done': 9131, 'global/unclipped_grad_norm': 0.7224625498056412, 'global/model_version': 59608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:35,301] calculate_sps 35200 steps in 10.0303
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:35,302] calculate_sps 33280 steps in 10.0303
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:35,302] {'local/mean_episode_return': 51114.28571428572, 'local/mean_episode_step': 5186.428571428572, 'local/SPS': 3509.3589790915994, 'local/env_act_steps': 38191488, 'local/env_train_steps': 38190080, 'local/optimizer_steps': 59672, 'local/running_reward': 23104.0625, 'local/running_step': 2393.6400625, 'local/steps_done': 38191488, 'local/episodes_done': 9139, 'local/unclipped_grad_norm': 0.6768478591527257, 'local/model_version': 59672, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:35,303] {'global/mean_episode_return': 51428.57142857143, 'global/mean_episode_step': 5168.285714285715, 'global/SPS': 3317.9393984138756, 'global/env_act_steps': 38185600, 'global/env_train_steps': 38182400, 'global/optimizer_steps': 59659, 'global/running_reward': 23115.814208984375, 'global/running_step': 2393.6763916015625, 'global/steps_done': 38185600, 'global/episodes_done': 9138, 'global/unclipped_grad_norm': 0.6806192503255957, 'global/model_version': 59659, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:45,319] calculate_sps 30720 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:45,319] calculate_sps 33280 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:45,320] {'local/mean_episode_return': 44366.666666666664, 'local/mean_episode_step': 4618.0, 'local/SPS': 3066.6526834807623, 'local/env_act_steps': 38224640, 'local/env_train_steps': 38220800, 'local/optimizer_steps': 59720, 'local/running_reward': 23408.464044401546, 'local/running_step': 2419.803661920849, 'local/steps_done': 38224640, 'local/episodes_done': 9145, 'local/unclipped_grad_norm': 0.7678525876253843, 'local/model_version': 59720, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:45,321] {'global/mean_episode_return': 45800.0, 'global/mean_episode_step': 4705.666666666667, 'global/SPS': 3322.207073770826, 'global/env_act_steps': 38218368, 'global/env_train_steps': 38215680, 'global/optimizer_steps': 59712, 'global/running_reward': 23367.620849609375, 'global/running_step': 2416.5751037597656, 'global/steps_done': 38218368, 'global/episodes_done': 9144, 'global/unclipped_grad_norm': 0.737741342130697, 'global/model_version': 59712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:55,333] calculate_sps 33280 steps in 10.0152
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:30:55,334] calculate_sps 31360 steps in 10.0152
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:55,334] {'local/mean_episode_return': 50080.0, 'local/mean_episode_step': 5004.4, 'local/SPS': 3322.9616492727873, 'local/env_act_steps': 38257152, 'local/env_train_steps': 38254080, 'local/optimizer_steps': 59771, 'local/running_reward': 23649.520177165356, 'local/running_step': 2444.7462782972443, 'local/steps_done': 38257152, 'local/episodes_done': 9150, 'local/unclipped_grad_norm': 0.7429781962259143, 'local/model_version': 59771, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:30:55,335] {'global/mean_episode_return': 50080.0, 'global/mean_episode_step': 5008.2, 'global/SPS': 3131.252323353204, 'global/env_act_steps': 38251648, 'global/env_train_steps': 38247040, 'global/optimizer_steps': 59760, 'global/running_reward': 23615.372596153848, 'global/running_step': 2440.468479567308, 'global/steps_done': 38251648, 'global/episodes_done': 9149, 'global/unclipped_grad_norm': 0.7583813428257903, 'global/model_version': 59760, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:05,346] calculate_sps 33280 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:05,347] calculate_sps 35200 steps in 10.0123
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:05,347] {'local/mean_episode_return': 49342.857142857145, 'local/mean_episode_step': 5063.428571428572, 'local/SPS': 3323.916095539297, 'local/env_act_steps': 38289920, 'local/env_train_steps': 38287360, 'local/optimizer_steps': 59824, 'local/running_reward': 23365.863037109375, 'local/running_step': 2416.314727783203, 'local/steps_done': 38289920, 'local/episodes_done': 9157, 'local/unclipped_grad_norm': 0.7763493910150708, 'local/model_version': 59824, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:05,348] {'global/mean_episode_return': 48457.142857142855, 'global/mean_episode_step': 4974.0, 'global/SPS': 3515.6804856665644, 'global/env_act_steps': 38284160, 'global/env_train_steps': 38282240, 'global/optimizer_steps': 59816, 'global/running_reward': 23353.297244094487, 'global/running_step': 2415.9398068405512, 'global/steps_done': 38284160, 'global/episodes_done': 9156, 'global/unclipped_grad_norm': 0.7509463594428131, 'global/model_version': 59816, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:15,383] calculate_sps 31360 steps in 10.0372
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:15,383] calculate_sps 30720 steps in 10.0372
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:15,383] {'local/mean_episode_return': 50860.0, 'local/mean_episode_step': 5118.4, 'local/SPS': 3124.3713872784315, 'local/env_act_steps': 38323328, 'local/env_train_steps': 38318720, 'local/optimizer_steps': 59872, 'local/running_reward': 23818.229166666668, 'local/running_step': 2457.118115421456, 'local/steps_done': 38323328, 'local/episodes_done': 9163, 'local/unclipped_grad_norm': 0.7867652929077545, 'local/model_version': 59872, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:15,384] {'global/mean_episode_return': 51620.0, 'global/mean_episode_step': 5269.2, 'global/SPS': 3060.608705905402, 'global/env_act_steps': 38318080, 'global/env_train_steps': 38312960, 'global/optimizer_steps': 59864, 'global/running_reward': 23823.76179245283, 'global/running_step': 2458.1771816037735, 'global/steps_done': 38318080, 'global/episodes_done': 9162, 'global/unclipped_grad_norm': 0.7865570125480493, 'global/model_version': 59864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:25,414] calculate_sps 35200 steps in 10.0306
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:25,414] calculate_sps 35840 steps in 10.0306
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:25,415] {'local/mean_episode_return': 48333.333333333336, 'local/mean_episode_step': 4827.5, 'local/SPS': 3509.2685577149823, 'local/env_act_steps': 38355968, 'local/env_train_steps': 38353920, 'local/optimizer_steps': 59928, 'local/running_reward': 24143.780637254902, 'local/running_step': 2490.710600490196, 'local/steps_done': 38355968, 'local/episodes_done': 9169, 'local/unclipped_grad_norm': 0.6276092098227569, 'local/model_version': 59928, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:25,416] {'global/mean_episode_return': 47750.0, 'global/mean_episode_step': 4703.0, 'global/SPS': 3573.0734405825274, 'global/env_act_steps': 38350336, 'global/env_train_steps': 38348800, 'global/optimizer_steps': 59920, 'global/running_reward': 24054.94171626984, 'global/running_step': 2481.4063740079364, 'global/steps_done': 38350336, 'global/episodes_done': 9166, 'global/unclipped_grad_norm': 0.6385084390640259, 'global/model_version': 59920, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:35,423] calculate_sps 30720 steps in 10.0091
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:35,424] calculate_sps 30720 steps in 10.0091
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:35,424] {'local/mean_episode_return': 50650.0, 'local/mean_episode_step': 4913.25, 'local/SPS': 3069.202939673279, 'local/env_act_steps': 38389248, 'local/env_train_steps': 38384640, 'local/optimizer_steps': 59976, 'local/running_reward': 24228.56971153846, 'local/running_step': 2502.1021935096155, 'local/steps_done': 38389248, 'local/episodes_done': 9173, 'local/unclipped_grad_norm': 0.6662248068799576, 'local/model_version': 59976, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:35,425] {'global/mean_episode_return': 48771.42857142857, 'global/mean_episode_step': 4829.571428571428, 'global/SPS': 3069.202939673279, 'global/env_act_steps': 38384256, 'global/env_train_steps': 38379520, 'global/optimizer_steps': 59968, 'global/running_reward': 24224.404481132075, 'global/running_step': 2500.661232311321, 'global/steps_done': 38384256, 'global/episodes_done': 9173, 'global/unclipped_grad_norm': 0.6798953600227833, 'global/model_version': 59968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:45,445] calculate_sps 35200 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:45,453] calculate_sps 35840 steps in 10.02
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:45,453] {'local/mean_episode_return': 50300.0, 'local/mean_episode_step': 5064.75, 'local/SPS': 3512.989856909424, 'local/env_act_steps': 38421504, 'local/env_train_steps': 38419840, 'local/optimizer_steps': 60030, 'local/running_reward': 24673.44990079365, 'local/running_step': 2550.372488839286, 'local/steps_done': 38421504, 'local/episodes_done': 9177, 'local/unclipped_grad_norm': 0.6587268478340573, 'local/model_version': 60030, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:45,455] {'global/mean_episode_return': 50866.666666666664, 'global/mean_episode_step': 5100.666666666667, 'global/SPS': 3576.8623997623226, 'global/env_act_steps': 38417024, 'global/env_train_steps': 38415360, 'global/optimizer_steps': 60024, 'global/running_reward': 24589.58740234375, 'global/running_step': 2542.7393188476562, 'global/steps_done': 38417024, 'global/episodes_done': 9176, 'global/unclipped_grad_norm': 0.6598079896398953, 'global/model_version': 60024, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:55,450] calculate_sps 31360 steps in 10.0073
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:31:55,451] calculate_sps 30720 steps in 10.0073
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:55,451] {'local/mean_episode_return': 50955.555555555555, 'local/mean_episode_step': 5011.666666666667, 'local/SPS': 3133.7102561421398, 'local/env_act_steps': 38454272, 'local/env_train_steps': 38451200, 'local/optimizer_steps': 60080, 'local/running_reward': 24653.021240234375, 'local/running_step': 2544.510498046875, 'local/steps_done': 38454272, 'local/episodes_done': 9186, 'local/unclipped_grad_norm': 0.7691126573085785, 'local/model_version': 60080, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:31:55,452] {'global/mean_episode_return': 50720.0, 'global/mean_episode_step': 5006.2, 'global/SPS': 3069.7569856086266, 'global/env_act_steps': 38450176, 'global/env_train_steps': 38446080, 'global/optimizer_steps': 60072, 'global/running_reward': 24716.210183397685, 'global/running_step': 2550.7182673745174, 'global/steps_done': 38450176, 'global/episodes_done': 9186, 'global/unclipped_grad_norm': 0.7638679506878058, 'global/model_version': 60072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:05,454] calculate_sps 31360 steps in 10.0018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:05,457] calculate_sps 34560 steps in 10.0018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:05,457] {'local/mean_episode_return': 53000.0, 'local/mean_episode_step': 5286.5, 'local/SPS': 3135.421775640617, 'local/env_act_steps': 38487296, 'local/env_train_steps': 38482560, 'local/optimizer_steps': 60128, 'local/running_reward': 24847.95906007752, 'local/running_step': 2565.5828185562013, 'local/steps_done': 38487296, 'local/episodes_done': 9188, 'local/unclipped_grad_norm': 0.6959594370176395, 'local/model_version': 60128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:05,462] {'global/mean_episode_return': 53000.0, 'global/mean_episode_step': 5286.5, 'global/SPS': 3455.3627731549655, 'global/env_act_steps': 38482688, 'global/env_train_steps': 38480640, 'global/optimizer_steps': 60125, 'global/running_reward': 24735.60531496063, 'global/running_step': 2554.1747969980315, 'global/steps_done': 38482688, 'global/episodes_done': 9188, 'global/unclipped_grad_norm': 0.7066835727331773, 'global/model_version': 60125, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:15,483] calculate_sps 35200 steps in 10.0311
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:15,484] calculate_sps 32000 steps in 10.0311
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:15,498] {'local/mean_episode_return': 50371.42857142857, 'local/mean_episode_step': 4981.285714285715, 'local/SPS': 3509.095985936188, 'local/env_act_steps': 38519296, 'local/env_train_steps': 38517760, 'local/optimizer_steps': 60184, 'local/running_reward': 25043.51875, 'local/running_step': 2585.268375, 'local/steps_done': 38519296, 'local/episodes_done': 9195, 'local/unclipped_grad_norm': 0.7031193668288844, 'local/model_version': 60184, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:15,500] {'global/mean_episode_return': 50371.42857142857, 'global/mean_episode_step': 4981.285714285715, 'global/SPS': 3190.087259941989, 'global/env_act_steps': 38515840, 'global/env_train_steps': 38512640, 'global/optimizer_steps': 60176, 'global/running_reward': 25058.379584942086, 'global/running_step': 2586.6547719594596, 'global/steps_done': 38515840, 'global/episodes_done': 9195, 'global/unclipped_grad_norm': 0.6993624170621237, 'global/model_version': 60176, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:25,495] calculate_sps 30720 steps in 10.012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:25,496] calculate_sps 32000 steps in 10.012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:25,496] {'local/mean_episode_return': 45450.0, 'local/mean_episode_step': 4697.375, 'local/SPS': 3068.3191617264406, 'local/env_act_steps': 38552576, 'local/env_train_steps': 38548480, 'local/optimizer_steps': 60232, 'local/running_reward': 24892.77043269231, 'local/running_step': 2570.3036358173076, 'local/steps_done': 38552576, 'local/episodes_done': 9203, 'local/unclipped_grad_norm': 0.6817051200196147, 'local/model_version': 60232, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:25,497] {'global/mean_episode_return': 45450.0, 'global/mean_episode_step': 4697.375, 'global/SPS': 3196.1657934650425, 'global/env_act_steps': 38548736, 'global/env_train_steps': 38544640, 'global/optimizer_steps': 60225, 'global/running_reward': 24906.383754863815, 'global/running_step': 2572.084995136187, 'global/steps_done': 38548736, 'global/episodes_done': 9203, 'global/unclipped_grad_norm': 0.6860650242591391, 'global/model_version': 60225, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:35,508] calculate_sps 33920 steps in 10.0135
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:35,509] calculate_sps 34560 steps in 10.0135
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:35,509] {'local/mean_episode_return': 45260.0, 'local/mean_episode_step': 4595.6, 'local/SPS': 3387.442386894769, 'local/env_act_steps': 38584960, 'local/env_train_steps': 38582400, 'local/optimizer_steps': 60284, 'local/running_reward': 24931.089426877472, 'local/running_step': 2574.8219799901185, 'local/steps_done': 38584960, 'local/episodes_done': 9213, 'local/unclipped_grad_norm': 0.702896292679585, 'local/model_version': 60284, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:35,510] {'global/mean_episode_return': 45377.77777777778, 'global/mean_episode_step': 4607.666666666667, 'global/SPS': 3451.35639419467, 'global/env_act_steps': 38581632, 'global/env_train_steps': 38579200, 'global/optimizer_steps': 60280, 'global/running_reward': 24974.750729571984, 'global/running_step': 2578.9164336089493, 'global/steps_done': 38581632, 'global/episodes_done': 9212, 'global/unclipped_grad_norm': 0.7116808024319735, 'global/model_version': 60280, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:45,539] calculate_sps 32640 steps in 10.0302
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:45,539] calculate_sps 31360 steps in 10.0302
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:45,539] {'local/mean_episode_return': 44866.666666666664, 'local/mean_episode_step': 4604.666666666667, 'local/SPS': 3254.1806745445483, 'local/env_act_steps': 38617984, 'local/env_train_steps': 38615040, 'local/optimizer_steps': 60336, 'local/running_reward': 24316.59399224806, 'local/running_step': 2513.4323522286822, 'local/steps_done': 38617984, 'local/episodes_done': 9222, 'local/unclipped_grad_norm': 0.671950125350402, 'local/model_version': 60336, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:45,541] {'global/mean_episode_return': 44644.444444444445, 'global/mean_episode_step': 4575.0, 'global/SPS': 3126.5657461310366, 'global/env_act_steps': 38615296, 'global/env_train_steps': 38610560, 'global/optimizer_steps': 60329, 'global/running_reward': 24343.001425855513, 'global/running_step': 2515.772813688213, 'global/steps_done': 38615296, 'global/episodes_done': 9221, 'global/unclipped_grad_norm': 0.6614182968528903, 'global/model_version': 60329, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:55,586] calculate_sps 31360 steps in 10.0476
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:32:55,586] calculate_sps 35200 steps in 10.0476
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:55,587] {'local/mean_episode_return': 53472.72727272727, 'local/mean_episode_step': 5265.363636363636, 'local/SPS': 3121.131202009508, 'local/env_act_steps': 38651008, 'local/env_train_steps': 38646400, 'local/optimizer_steps': 60384, 'local/running_reward': 23262.65746124031, 'local/running_step': 2411.2569949127906, 'local/steps_done': 38651008, 'local/episodes_done': 9233, 'local/unclipped_grad_norm': 0.8374262532840172, 'local/model_version': 60384, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:32:55,587] {'global/mean_episode_return': 52866.666666666664, 'global/mean_episode_step': 5222.75, 'global/SPS': 3503.3105328678153, 'global/env_act_steps': 38647424, 'global/env_train_steps': 38645760, 'global/optimizer_steps': 60384, 'global/running_reward': 23371.009711155377, 'global/running_step': 2421.6090948705178, 'global/steps_done': 38647424, 'global/episodes_done': 9233, 'global/unclipped_grad_norm': 0.8124791253696788, 'global/model_version': 60384, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:05,602] calculate_sps 35200 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:05,603] calculate_sps 30720 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:05,603] {'local/mean_episode_return': 51300.0, 'local/mean_episode_step': 5283.5, 'local/SPS': 3514.4670009738134, 'local/env_act_steps': 38683392, 'local/env_train_steps': 38681600, 'local/optimizer_steps': 60440, 'local/running_reward': 23430.644762845848, 'local/running_step': 2432.21121541502, 'local/steps_done': 38683392, 'local/episodes_done': 9237, 'local/unclipped_grad_norm': 0.7236754527049405, 'local/model_version': 60440, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:05,604] {'global/mean_episode_return': 53900.0, 'global/mean_episode_step': 5396.5, 'global/SPS': 3067.1712008498735, 'global/env_act_steps': 38681344, 'global/env_train_steps': 38676480, 'global/optimizer_steps': 60432, 'global/running_reward': 23368.584905660377, 'global/running_step': 2426.002771226415, 'global/steps_done': 38681344, 'global/episodes_done': 9235, 'global/unclipped_grad_norm': 0.7164230706791083, 'global/model_version': 60432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:15,622] calculate_sps 30720 steps in 10.0197
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:15,622] calculate_sps 35840 steps in 10.0197
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:15,623] {'local/mean_episode_return': 46885.71428571428, 'local/mean_episode_step': 4822.285714285715, 'local/SPS': 3065.9590219142665, 'local/env_act_steps': 38716672, 'local/env_train_steps': 38712320, 'local/optimizer_steps': 60488, 'local/running_reward': 23329.02043269231, 'local/running_step': 2421.2225060096152, 'local/steps_done': 38716672, 'local/episodes_done': 9244, 'local/unclipped_grad_norm': 0.7536854933326443, 'local/model_version': 60488, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:15,624] {'global/mean_episode_return': 47288.88888888889, 'global/mean_episode_step': 4899.666666666667, 'global/SPS': 3576.952192233311, 'global/env_act_steps': 38713472, 'global/env_train_steps': 38712320, 'global/optimizer_steps': 60487, 'global/running_reward': 23348.12001992032, 'global/running_step': 2422.99172061753, 'global/steps_done': 38713472, 'global/episodes_done': 9244, 'global/unclipped_grad_norm': 0.7578869285908613, 'global/model_version': 60487, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:25,658] calculate_sps 35200 steps in 10.036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:25,658] calculate_sps 30720 steps in 10.036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:25,658] {'local/mean_episode_return': 38057.142857142855, 'local/mean_episode_step': 3956.285714285714, 'local/SPS': 3507.367451695792, 'local/env_act_steps': 38749056, 'local/env_train_steps': 38747520, 'local/optimizer_steps': 60542, 'local/running_reward': 23453.427618577076, 'local/running_step': 2433.4316946640315, 'local/steps_done': 38749056, 'local/episodes_done': 9251, 'local/unclipped_grad_norm': 0.7574602768377021, 'local/model_version': 60542, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:25,659] {'global/mean_episode_return': 36466.666666666664, 'global/mean_episode_step': 3837.8333333333335, 'global/SPS': 3060.975230570873, 'global/env_act_steps': 38747136, 'global/env_train_steps': 38743040, 'global/optimizer_steps': 60536, 'global/running_reward': 23418.30442015209, 'global/running_step': 2430.306499524715, 'global/steps_done': 38747136, 'global/episodes_done': 9250, 'global/unclipped_grad_norm': 0.7555474158452482, 'global/model_version': 60536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:35,659] calculate_sps 31360 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:35,660] calculate_sps 33920 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:35,670] {'local/mean_episode_return': 46366.666666666664, 'local/mean_episode_step': 4893.333333333333, 'local/SPS': 3135.598920626422, 'local/env_act_steps': 38781952, 'local/env_train_steps': 38778880, 'local/optimizer_steps': 60592, 'local/running_reward': 23869.24854085603, 'local/running_step': 2467.232277480545, 'local/steps_done': 38781952, 'local/episodes_done': 9257, 'local/unclipped_grad_norm': 0.7367360645532608, 'local/model_version': 60592, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:35,672] {'global/mean_episode_return': 46542.857142857145, 'global/mean_episode_step': 4861.0, 'global/SPS': 3391.566179453069, 'global/env_act_steps': 38779648, 'global/env_train_steps': 38776960, 'global/optimizer_steps': 60589, 'global/running_reward': 23870.17716535433, 'global/running_step': 2467.966689222441, 'global/steps_done': 38779648, 'global/episodes_done': 9257, 'global/unclipped_grad_norm': 0.7324031152815189, 'global/model_version': 60589, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:45,687] calculate_sps 31360 steps in 10.0279
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:45,687] calculate_sps 32640 steps in 10.0279
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:45,687] {'local/mean_episode_return': 49960.0, 'local/mean_episode_step': 4928.7, 'local/SPS': 3127.2901514451214, 'local/env_act_steps': 38814848, 'local/env_train_steps': 38810240, 'local/optimizer_steps': 60640, 'local/running_reward': 23721.370379377433, 'local/running_step': 2449.020853599222, 'local/steps_done': 38814848, 'local/episodes_done': 9267, 'local/unclipped_grad_norm': 0.759990381076932, 'local/model_version': 60640, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:45,689] {'global/mean_episode_return': 50155.555555555555, 'global/mean_episode_step': 4932.888888888889, 'global/SPS': 3254.9346474224735, 'global/env_act_steps': 38812672, 'global/env_train_steps': 38809600, 'global/optimizer_steps': 60640, 'global/running_reward': 23763.523498062015, 'global/running_step': 2452.9814074612405, 'global/steps_done': 38812672, 'global/episodes_done': 9266, 'global/unclipped_grad_norm': 0.7649146774235893, 'global/model_version': 60640, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:55,705] calculate_sps 35200 steps in 10.0182
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:33:55,706] calculate_sps 32000 steps in 10.0182
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:55,714] {'local/mean_episode_return': 45600.0, 'local/mean_episode_step': 4682.333333333333, 'local/SPS': 3513.6066878126344, 'local/env_act_steps': 38846976, 'local/env_train_steps': 38845440, 'local/optimizer_steps': 60696, 'local/running_reward': 23500.70966135458, 'local/running_step': 2432.5576444223107, 'local/steps_done': 38846976, 'local/episodes_done': 9270, 'local/unclipped_grad_norm': 0.7013614467744317, 'local/model_version': 60696, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:33:55,715] {'global/mean_episode_return': 46250.0, 'global/mean_episode_step': 4734.5, 'global/SPS': 3194.1878980114857, 'global/env_act_steps': 38845824, 'global/env_train_steps': 38841600, 'global/optimizer_steps': 60689, 'global/running_reward': 23468.243243243243, 'global/running_step': 2429.077129584942, 'global/steps_done': 38845824, 'global/episodes_done': 9270, 'global/unclipped_grad_norm': 0.6844610781693945, 'global/model_version': 60689, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:05,727] calculate_sps 30720 steps in 10.0219
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:05,728] calculate_sps 34560 steps in 10.0219
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:05,728] {'local/mean_episode_return': 44760.0, 'local/mean_episode_step': 4614.5, 'local/SPS': 3065.2781436962428, 'local/env_act_steps': 38880128, 'local/env_train_steps': 38876160, 'local/optimizer_steps': 60744, 'local/running_reward': 23678.782577220078, 'local/running_step': 2447.215612934363, 'local/steps_done': 38880128, 'local/episodes_done': 9280, 'local/unclipped_grad_norm': 0.7092776789019505, 'local/model_version': 60744, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:05,729] {'global/mean_episode_return': 44760.0, 'global/mean_episode_step': 4614.5, 'global/SPS': 3448.4379116582727, 'global/env_act_steps': 38878464, 'global/env_train_steps': 38876160, 'global/optimizer_steps': 60744, 'global/running_reward': 23705.147058823528, 'global/running_step': 2450.0557904411767, 'global/steps_done': 38878464, 'global/episodes_done': 9280, 'global/unclipped_grad_norm': 0.7233268504792993, 'global/model_version': 60744, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:15,737] calculate_sps 32640 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:15,737] calculate_sps 30720 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:15,748] {'local/mean_episode_return': 53120.0, 'local/mean_episode_step': 5255.0, 'local/SPS': 3261.431245298661, 'local/env_act_steps': 38912512, 'local/env_train_steps': 38908800, 'local/optimizer_steps': 60794, 'local/running_reward': 23755.095108695652, 'local/running_step': 2452.7969058794465, 'local/steps_done': 38912512, 'local/episodes_done': 9285, 'local/unclipped_grad_norm': 0.7891687190532685, 'local/model_version': 60794, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:15,749] {'global/mean_episode_return': 55400.0, 'global/mean_episode_step': 5368.0, 'global/SPS': 3069.582348516387, 'global/env_act_steps': 38911744, 'global/env_train_steps': 38906880, 'global/optimizer_steps': 60792, 'global/running_reward': 23736.20793269231, 'global/running_step': 2450.8702524038463, 'global/steps_done': 38911744, 'global/episodes_done': 9284, 'global/unclipped_grad_norm': 0.7966667537887892, 'global/model_version': 60792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:25,772] calculate_sps 33920 steps in 10.0369
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:25,772] calculate_sps 35200 steps in 10.0369
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:25,773] {'local/mean_episode_return': 49942.857142857145, 'local/mean_episode_step': 5031.214285714285, 'local/SPS': 3379.533615554215, 'local/env_act_steps': 38944768, 'local/env_train_steps': 38942720, 'local/optimizer_steps': 60848, 'local/running_reward': 23622.110615079364, 'local/running_step': 2439.033172123016, 'local/steps_done': 38944768, 'local/episodes_done': 9293, 'local/unclipped_grad_norm': 0.7881583819786707, 'local/model_version': 60848, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:25,774] {'global/mean_episode_return': 49200.0, 'global/mean_episode_step': 5002.6875, 'global/SPS': 3507.0631859524874, 'global/env_act_steps': 38943616, 'global/env_train_steps': 38942080, 'global/optimizer_steps': 60846, 'global/running_reward': 23628.664658634538, 'global/running_step': 2439.7161144578313, 'global/steps_done': 38943616, 'global/episodes_done': 9293, 'global/unclipped_grad_norm': 0.7791267782449722, 'global/model_version': 60846, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:35,798] calculate_sps 30720 steps in 10.0263
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:35,799] calculate_sps 31360 steps in 10.0263
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:35,799] {'local/mean_episode_return': 52025.0, 'local/mean_episode_step': 5107.5, 'local/SPS': 3063.938860007746, 'local/env_act_steps': 38978176, 'local/env_train_steps': 38973440, 'local/optimizer_steps': 60896, 'local/running_reward': 23424.72461685824, 'local/running_step': 2423.899754549808, 'local/steps_done': 38978176, 'local/episodes_done': 9301, 'local/unclipped_grad_norm': 0.715025999272863, 'local/model_version': 60896, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:35,800] {'global/mean_episode_return': 52025.0, 'global/mean_episode_step': 5107.5, 'global/SPS': 3127.7709195912407, 'global/env_act_steps': 38977152, 'global/env_train_steps': 38973440, 'global/optimizer_steps': 60896, 'global/running_reward': 23440.404341603054, 'global/running_step': 2425.1866948950383, 'global/steps_done': 38977152, 'global/episodes_done': 9301, 'global/unclipped_grad_norm': 0.7205477267503738, 'global/model_version': 60896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:45,803] calculate_sps 35200 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:45,804] calculate_sps 33920 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:45,804] {'local/mean_episode_return': 41800.0, 'local/mean_episode_step': 4448.0, 'local/SPS': 3518.238324134744, 'local/env_act_steps': 39010304, 'local/env_train_steps': 39008640, 'local/optimizer_steps': 60951, 'local/running_reward': 23352.11030876494, 'local/running_step': 2419.511672061753, 'local/steps_done': 39010304, 'local/episodes_done': 9305, 'local/unclipped_grad_norm': 0.7344632435928692, 'local/model_version': 60951, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:45,805] {'global/mean_episode_return': 41800.0, 'global/mean_episode_step': 4448.0, 'global/SPS': 3390.3023850752984, 'global/env_act_steps': 39009920, 'global/env_train_steps': 39007360, 'global/optimizer_steps': 60948, 'global/running_reward': 23337.12158203125, 'global/running_step': 2418.0900268554688, 'global/steps_done': 39009920, 'global/episodes_done': 9305, 'global/unclipped_grad_norm': 0.7469310055558498, 'global/model_version': 60948, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:55,806] calculate_sps 31360 steps in 10.0031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:34:55,807] calculate_sps 32640 steps in 10.0031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:55,807] {'local/mean_episode_return': 48275.0, 'local/mean_episode_step': 5024.125, 'local/SPS': 3135.0416168305637, 'local/env_act_steps': 39043456, 'local/env_train_steps': 39040000, 'local/optimizer_steps': 61000, 'local/running_reward': 23679.71163127413, 'local/running_step': 2443.302998310811, 'local/steps_done': 39043456, 'local/episodes_done': 9313, 'local/unclipped_grad_norm': 0.6876030156807024, 'local/model_version': 61000, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:34:55,808] {'global/mean_episode_return': 48275.0, 'global/mean_episode_step': 5024.125, 'global/SPS': 3263.002499150178, 'global/env_act_steps': 39043072, 'global/env_train_steps': 39040000, 'global/optimizer_steps': 61000, 'global/running_reward': 23686.824324324323, 'global/running_step': 2444.1675916988415, 'global/steps_done': 39043072, 'global/episodes_done': 9313, 'global/unclipped_grad_norm': 0.6778387284049621, 'global/model_version': 61000, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:05,843] calculate_sps 33280 steps in 10.0362
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:05,843] calculate_sps 33280 steps in 10.0362
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:05,843] {'local/mean_episode_return': 55200.0, 'local/mean_episode_step': 5394.0, 'local/SPS': 3316.0030109192144, 'local/env_act_steps': 39076352, 'local/env_train_steps': 39073280, 'local/optimizer_steps': 61051, 'local/running_reward': 24117.679961089496, 'local/running_step': 2482.455921692607, 'local/steps_done': 39076352, 'local/episodes_done': 9314, 'local/unclipped_grad_norm': 0.6166423635155547, 'local/model_version': 61051, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:05,844] {'global/mean_episode_return': 55200.0, 'global/mean_episode_step': 5394.0, 'global/SPS': 3316.0030109192144, 'global/env_act_steps': 39076352, 'global/env_train_steps': 39073280, 'global/optimizer_steps': 61051, 'global/running_reward': 24106.41826923077, 'global/running_step': 2481.296995192308, 'global/steps_done': 39076352, 'global/episodes_done': 9314, 'global/unclipped_grad_norm': 0.6166423635155547, 'global/model_version': 61051, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:15,853] calculate_sps 33280 steps in 10.0107
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:15,854] calculate_sps 28160 steps in 10.0107
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:15,854] {'local/mean_episode_return': 45290.0, 'local/mean_episode_step': 4662.45, 'local/SPS': 3324.451243030924, 'local/env_act_steps': 39109120, 'local/env_train_steps': 39106560, 'local/optimizer_steps': 61104, 'local/running_reward': 24444.610595703125, 'local/running_step': 2513.2740478515625, 'local/steps_done': 39109120, 'local/episodes_done': 9325, 'local/unclipped_grad_norm': 0.8553678601417901, 'local/model_version': 61104, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:15,855] {'global/mean_episode_return': 47442.857142857145, 'global/mean_episode_step': 4791.642857142857, 'global/SPS': 2812.9972056415513, 'global/env_act_steps': 39102464, 'global/env_train_steps': 39101440, 'global/optimizer_steps': 61095, 'global/running_reward': 24539.598651960783, 'global/running_step': 2523.502374387255, 'global/steps_done': 39102464, 'global/episodes_done': 9322, 'global/unclipped_grad_norm': 0.8437553163279187, 'global/model_version': 61095, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:25,882] calculate_sps 30720 steps in 10.0289
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:25,882] calculate_sps 30720 steps in 10.0289
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:25,883] {'local/mean_episode_return': 53428.57142857143, 'local/mean_episode_step': 5278.571428571428, 'local/SPS': 3063.153648743012, 'local/env_act_steps': 39142400, 'local/env_train_steps': 39137280, 'local/optimizer_steps': 61152, 'local/running_reward': 23792.337740384617, 'local/running_step': 2442.68359375, 'local/steps_done': 39142400, 'local/episodes_done': 9332, 'local/unclipped_grad_norm': 0.8662289176136255, 'local/model_version': 61152, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:25,884] {'global/mean_episode_return': 49480.0, 'global/mean_episode_step': 5003.3, 'global/SPS': 3063.153648743012, 'global/env_act_steps': 39135872, 'global/env_train_steps': 39132160, 'global/optimizer_steps': 61144, 'global/running_reward': 23877.63409961686, 'global/running_step': 2451.484853927203, 'global/steps_done': 39135872, 'global/episodes_done': 9332, 'global/unclipped_grad_norm': 0.8717744569389188, 'global/model_version': 61144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:35,883] calculate_sps 35840 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:35,883] calculate_sps 33280 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:35,884] {'local/mean_episode_return': 50622.22222222222, 'local/mean_episode_step': 5036.0, 'local/SPS': 3583.78818390589, 'local/env_act_steps': 39174144, 'local/env_train_steps': 39173120, 'local/optimizer_steps': 61207, 'local/running_reward': 23558.291330645163, 'local/running_step': 2422.6253465221776, 'local/steps_done': 39174144, 'local/episodes_done': 9341, 'local/unclipped_grad_norm': 0.7343592903830788, 'local/model_version': 61207, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:35,885] {'global/mean_episode_return': 49733.333333333336, 'global/mean_episode_step': 4961.0, 'global/SPS': 3327.8033136268978, 'global/env_act_steps': 39168512, 'global/env_train_steps': 39165440, 'global/optimizer_steps': 61195, 'global/running_reward': 23573.039215686276, 'global/running_step': 2423.4893075980394, 'global/steps_done': 39168512, 'global/episodes_done': 9338, 'global/unclipped_grad_norm': 0.7839878365105274, 'global/model_version': 61195, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:45,885] calculate_sps 30720 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:45,886] calculate_sps 33280 steps in 10.0027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:45,886] {'local/mean_episode_return': 36433.333333333336, 'local/mean_episode_step': 3939.5, 'local/SPS': 3071.1677548241296, 'local/env_act_steps': 39207296, 'local/env_train_steps': 39203840, 'local/optimizer_steps': 61256, 'local/running_reward': 23259.47755791506, 'local/running_step': 2393.276574565637, 'local/steps_done': 39207296, 'local/episodes_done': 9347, 'local/unclipped_grad_norm': 0.7367877455390229, 'local/model_version': 61256, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:45,887] {'global/mean_episode_return': 41755.555555555555, 'global/mean_episode_step': 4355.0, 'global/SPS': 3327.098401059474, 'global/env_act_steps': 39201536, 'global/env_train_steps': 39198720, 'global/optimizer_steps': 61248, 'global/running_reward': 23281.807170542637, 'global/running_step': 2395.6762960271317, 'global/steps_done': 39201536, 'global/episodes_done': 9347, 'global/unclipped_grad_norm': 0.7024058767084805, 'global/model_version': 61248, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 14:35:52,445] saving global stats {'mean_episode_return': 51750.0, 'mean_episode_step': 5266.75, 'SPS': None, 'env_act_steps': 39220992, 'env_train_steps': 39219200, 'optimizer_steps': 61280, 'running_reward': 23465.470805921053, 'running_step': 2412.655633223684, 'steps_done': 39220992, 'episodes_done': 9351, 'unclipped_grad_norm': 0.705668555572629, 'model_version': 61280, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 14:35:52,539] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:55,908] calculate_sps 32000 steps in 10.0234
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:35:55,909] calculate_sps 30720 steps in 10.0234
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:55,909] {'local/mean_episode_return': 49625.0, 'local/mean_episode_step': 5025.875, 'local/SPS': 3192.5427484952074, 'local/env_act_steps': 39239936, 'local/env_train_steps': 39235840, 'local/optimizer_steps': 61305, 'local/running_reward': 23431.299019607843, 'local/running_step': 2408.9376531862745, 'local/steps_done': 39239936, 'local/episodes_done': 9355, 'local/unclipped_grad_norm': 0.655136952594835, 'local/model_version': 61305, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:35:55,910] {'global/mean_episode_return': 50880.0, 'global/mean_episode_step': 5177.4, 'global/SPS': 3064.8410385553993, 'global/env_act_steps': 39234688, 'global/env_train_steps': 39229440, 'global/optimizer_steps': 61296, 'global/running_reward': 23439.14695945946, 'global/running_step': 2409.9659145752894, 'global/steps_done': 39234688, 'global/episodes_done': 9352, 'global/unclipped_grad_norm': 0.6791500436762968, 'global/model_version': 61296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:05,940] calculate_sps 34560 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:05,941] calculate_sps 35840 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:05,941] {'local/mean_episode_return': 48266.666666666664, 'local/mean_episode_step': 4847.0, 'local/SPS': 3445.0949374564566, 'local/env_act_steps': 39272448, 'local/env_train_steps': 39270400, 'local/optimizer_steps': 61360, 'local/running_reward': 22840.637303149608, 'local/running_step': 2352.0276820866143, 'local/steps_done': 39272448, 'local/episodes_done': 9364, 'local/unclipped_grad_norm': 0.6729842809113589, 'local/model_version': 61360, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:05,942] {'global/mean_episode_return': 48860.0, 'global/mean_episode_step': 4868.7, 'global/SPS': 3572.69104625114, 'global/env_act_steps': 39266816, 'global/env_train_steps': 39265280, 'global/optimizer_steps': 61352, 'global/running_reward': 22908.186005976095, 'global/running_step': 2358.18015438247, 'global/steps_done': 39266816, 'global/episodes_done': 9362, 'global/unclipped_grad_norm': 0.662242915481329, 'global/model_version': 61352, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:15,945] calculate_sps 30720 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:15,945] calculate_sps 30720 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:15,945] {'local/mean_episode_return': 42228.57142857143, 'local/mean_episode_step': 4449.857142857143, 'local/SPS': 3070.663472357956, 'local/env_act_steps': 39305600, 'local/env_train_steps': 39301120, 'local/optimizer_steps': 61408, 'local/running_reward': 22961.848455598454, 'local/running_step': 2360.8618182915056, 'local/steps_done': 39305600, 'local/episodes_done': 9371, 'local/unclipped_grad_norm': 0.7731808423995972, 'local/model_version': 61408, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:15,947] {'global/mean_episode_return': 44225.0, 'global/mean_episode_step': 4617.875, 'global/SPS': 3070.663472357956, 'global/env_act_steps': 39300736, 'global/env_train_steps': 39296000, 'global/optimizer_steps': 61400, 'global/running_reward': 22973.319575471698, 'global/running_step': 2362.80397995283, 'global/steps_done': 39300736, 'global/episodes_done': 9370, 'global/unclipped_grad_norm': 0.783483296011885, 'global/model_version': 61400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:25,955] calculate_sps 35200 steps in 10.0106
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:25,955] calculate_sps 35840 steps in 10.0106
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:25,956] {'local/mean_episode_return': 47733.333333333336, 'local/mean_episode_step': 4642.0, 'local/SPS': 3516.2867885961414, 'local/env_act_steps': 39337856, 'local/env_train_steps': 39336320, 'local/optimizer_steps': 61462, 'local/running_reward': 22859.437003968254, 'local/running_step': 2351.2960689484125, 'local/steps_done': 39337856, 'local/episodes_done': 9377, 'local/unclipped_grad_norm': 0.6922025851629399, 'local/model_version': 61462, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:25,956] {'global/mean_episode_return': 45228.57142857143, 'global/mean_episode_step': 4473.428571428572, 'global/SPS': 3580.219275661526, 'global/env_act_steps': 39332864, 'global/env_train_steps': 39331840, 'global/optimizer_steps': 61455, 'global/running_reward': 22838.327938247014, 'global/running_step': 2349.0078125, 'global/steps_done': 39332864, 'global/episodes_done': 9377, 'global/unclipped_grad_norm': 0.7030796088955619, 'global/model_version': 61455, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:35,987] calculate_sps 31360 steps in 10.0316
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:35,987] calculate_sps 30720 steps in 10.0316
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:35,987] {'local/mean_episode_return': 46880.0, 'local/mean_episode_step': 4703.2, 'local/SPS': 3126.113952617903, 'local/env_act_steps': 39371136, 'local/env_train_steps': 39367680, 'local/optimizer_steps': 61512, 'local/running_reward': 23308.42548076923, 'local/running_step': 2398.343659855769, 'local/steps_done': 39371136, 'local/episodes_done': 9382, 'local/unclipped_grad_norm': 0.7425593310594558, 'local/model_version': 61512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:35,991] {'global/mean_episode_return': 46880.0, 'global/mean_episode_step': 4703.2, 'global/SPS': 3062.3157086869255, 'global/env_act_steps': 39366528, 'global/env_train_steps': 39362560, 'global/optimizer_steps': 61504, 'global/running_reward': 23258.06202471483, 'global/running_step': 2392.8419676806084, 'global/steps_done': 39366528, 'global/episodes_done': 9382, 'global/unclipped_grad_norm': 0.7040521295703187, 'global/model_version': 61504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:46,010] calculate_sps 32640 steps in 10.0231
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:46,011] calculate_sps 34560 steps in 10.0231
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:46,011] {'local/mean_episode_return': 46366.666666666664, 'local/mean_episode_step': 4729.666666666667, 'local/SPS': 3256.4683517123567, 'local/env_act_steps': 39403904, 'local/env_train_steps': 39400320, 'local/optimizer_steps': 61562, 'local/running_reward': 23538.739013671875, 'local/running_step': 2420.847686767578, 'local/steps_done': 39403904, 'local/episodes_done': 9388, 'local/unclipped_grad_norm': 0.6999132889509201, 'local/model_version': 61562, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:46,013] {'global/mean_episode_return': 49960.0, 'global/mean_episode_step': 5051.8, 'global/SPS': 3448.0253135777893, 'global/env_act_steps': 39399168, 'global/env_train_steps': 39397120, 'global/optimizer_steps': 61557, 'global/running_reward': 23506.57475490196, 'global/running_step': 2418.0269914215687, 'global/steps_done': 39399168, 'global/episodes_done': 9387, 'global/unclipped_grad_norm': 0.6978713020963488, 'global/model_version': 61557, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:56,018] calculate_sps 33920 steps in 10.0076
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:36:56,018] calculate_sps 32000 steps in 10.0076
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:56,018] {'local/mean_episode_return': 51950.0, 'local/mean_episode_step': 5101.375, 'local/SPS': 3389.435965210434, 'local/env_act_steps': 39436288, 'local/env_train_steps': 39434240, 'local/optimizer_steps': 61616, 'local/running_reward': 23481.830533596836, 'local/running_step': 2415.370368083004, 'local/steps_done': 39436288, 'local/episodes_done': 9396, 'local/unclipped_grad_norm': 0.7603382159162451, 'local/model_version': 61616, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:36:56,020] {'global/mean_episode_return': 49333.333333333336, 'global/mean_episode_step': 4881.111111111111, 'global/SPS': 3197.5810992551264, 'global/env_act_steps': 39432192, 'global/env_train_steps': 39429120, 'global/optimizer_steps': 61608, 'global/running_reward': 23530.65649224806, 'global/running_step': 2419.8449006782944, 'global/steps_done': 39432192, 'global/episodes_done': 9396, 'global/unclipped_grad_norm': 0.7687648862015968, 'global/model_version': 61608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:06,018] calculate_sps 30720 steps in 10.0004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:06,030] calculate_sps 32640 steps in 10.0004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:06,030] {'local/mean_episode_return': 49133.333333333336, 'local/mean_episode_step': 4997.333333333333, 'local/SPS': 3071.8715385752043, 'local/env_act_steps': 39469568, 'local/env_train_steps': 39464960, 'local/optimizer_steps': 61664, 'local/running_reward': 23415.342548076922, 'local/running_step': 2410.5638822115384, 'local/steps_done': 39469568, 'local/episodes_done': 9402, 'local/unclipped_grad_norm': 0.7425098813449343, 'local/model_version': 61664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:06,032] {'global/mean_episode_return': 48700.0, 'global/mean_episode_step': 4890.0, 'global/SPS': 3263.863509736155, 'global/env_act_steps': 39465344, 'global/env_train_steps': 39461760, 'global/optimizer_steps': 61658, 'global/running_reward': 23387.64478764479, 'global/running_step': 2407.5876870173747, 'global/steps_done': 39465344, 'global/episodes_done': 9400, 'global/unclipped_grad_norm': 0.779859628379345, 'global/model_version': 61658, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:16,023] calculate_sps 35840 steps in 10.0051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:16,023] calculate_sps 33920 steps in 10.0051
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:16,023] {'local/mean_episode_return': 46600.0, 'local/mean_episode_step': 4576.0, 'local/SPS': 3582.186574756103, 'local/env_act_steps': 39501824, 'local/env_train_steps': 39500800, 'local/optimizer_steps': 61719, 'local/running_reward': 23905.667162698413, 'local/running_step': 2462.032738095238, 'local/steps_done': 39501824, 'local/episodes_done': 9404, 'local/unclipped_grad_norm': 0.757882052118128, 'local/model_version': 61719, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:16,024] {'global/mean_episode_return': 48300.0, 'global/mean_episode_step': 4894.0, 'global/SPS': 3390.283722537026, 'global/env_act_steps': 39498496, 'global/env_train_steps': 39495680, 'global/optimizer_steps': 61712, 'global/running_reward': 23811.414092664094, 'global/running_step': 2452.635436776062, 'global/steps_done': 39498496, 'global/episodes_done': 9404, 'global/unclipped_grad_norm': 0.7459325111574597, 'global/model_version': 61712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:26,071] calculate_sps 30720 steps in 10.0481
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:26,072] calculate_sps 32000 steps in 10.0481
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:26,072] {'local/mean_episode_return': 46236.36363636364, 'local/mean_episode_step': 4604.772727272727, 'local/SPS': 3057.286435823688, 'local/env_act_steps': 39535360, 'local/env_train_steps': 39531520, 'local/optimizer_steps': 61768, 'local/running_reward': 23902.474952290075, 'local/running_step': 2460.193583015267, 'local/steps_done': 39535360, 'local/episodes_done': 9416, 'local/unclipped_grad_norm': 0.7623070077020295, 'local/model_version': 61768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:26,073] {'global/mean_episode_return': 47260.0, 'global/mean_episode_step': 4690.05, 'global/SPS': 3184.673370649675, 'global/env_act_steps': 39531776, 'global/env_train_steps': 39527680, 'global/optimizer_steps': 61761, 'global/running_reward': 23979.471153846152, 'global/running_step': 2467.556580528846, 'global/steps_done': 39531776, 'global/episodes_done': 9415, 'global/unclipped_grad_norm': 0.7635048408897556, 'global/model_version': 61761, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:36,111] calculate_sps 33920 steps in 10.04
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:36,111] calculate_sps 34560 steps in 10.04
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:36,111] {'local/mean_episode_return': 48428.57142857143, 'local/mean_episode_step': 4806.214285714285, 'local/SPS': 3378.4944123950613, 'local/env_act_steps': 39568000, 'local/env_train_steps': 39565440, 'local/optimizer_steps': 61820, 'local/running_reward': 23106.979166666668, 'local/running_step': 2387.8005514705883, 'local/steps_done': 39568000, 'local/episodes_done': 9424, 'local/unclipped_grad_norm': 0.8628265915008692, 'local/model_version': 61820, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:36,112] {'global/mean_episode_return': 46685.71428571428, 'global/mean_episode_step': 4645.928571428572, 'global/SPS': 3442.239589987421, 'global/env_act_steps': 39564544, 'global/env_train_steps': 39562240, 'global/optimizer_steps': 61816, 'global/running_reward': 23148.614501953125, 'global/running_step': 2391.1265258789062, 'global/steps_done': 39564544, 'global/episodes_done': 9423, 'global/unclipped_grad_norm': 0.8368455242026936, 'global/model_version': 61816, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:46,126] calculate_sps 32640 steps in 10.0147
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:46,126] calculate_sps 31360 steps in 10.0147
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:46,138] {'local/mean_episode_return': 45375.0, 'local/mean_episode_step': 4752.5, 'local/SPS': 3259.2134839966957, 'local/env_act_steps': 39601024, 'local/env_train_steps': 39598080, 'local/optimizer_steps': 61872, 'local/running_reward': 23187.239583333332, 'local/running_step': 2396.6842902131784, 'local/steps_done': 39601024, 'local/episodes_done': 9432, 'local/unclipped_grad_norm': 0.7470111703643432, 'local/model_version': 61872, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:46,140] {'global/mean_episode_return': 45688.88888888889, 'global/mean_episode_step': 4766.0, 'global/SPS': 3131.4011905066295, 'global/env_act_steps': 39598208, 'global/env_train_steps': 39593600, 'global/optimizer_steps': 61864, 'global/running_reward': 23204.414211026615, 'global/running_step': 2398.9198253326995, 'global/steps_done': 39598208, 'global/episodes_done': 9432, 'global/unclipped_grad_norm': 0.7470482674737772, 'global/model_version': 61864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:56,132] calculate_sps 31360 steps in 10.0061
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:37:56,133] calculate_sps 35200 steps in 10.0061
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:56,133] {'local/mean_episode_return': 47400.0, 'local/mean_episode_step': 4664.0, 'local/SPS': 3134.093153877406, 'local/env_act_steps': 39634048, 'local/env_train_steps': 39629440, 'local/optimizer_steps': 61920, 'local/running_reward': 22988.14195736434, 'local/running_step': 2376.4514595445735, 'local/steps_done': 39634048, 'local/episodes_done': 9438, 'local/unclipped_grad_norm': 0.7448597593853871, 'local/model_version': 61920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:37:56,135] {'global/mean_episode_return': 47400.0, 'global/mean_episode_step': 4664.0, 'global/SPS': 3517.859662515456, 'global/env_act_steps': 39630720, 'global/env_train_steps': 39628800, 'global/optimizer_steps': 61920, 'global/running_reward': 22972.896161417324, 'global/running_step': 2374.703094242126, 'global/steps_done': 39630720, 'global/episodes_done': 9438, 'global/unclipped_grad_norm': 0.7510709932872227, 'global/model_version': 61920, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:06,148] calculate_sps 35200 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:06,149] calculate_sps 30720 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:06,158] {'local/mean_episode_return': 44700.0, 'local/mean_episode_step': 4476.625, 'local/SPS': 3514.2947540666128, 'local/env_act_steps': 39666304, 'local/env_train_steps': 39664640, 'local/optimizer_steps': 61976, 'local/running_reward': 22997.513640873014, 'local/running_step': 2377.4661768353176, 'local/steps_done': 39666304, 'local/episodes_done': 9446, 'local/unclipped_grad_norm': 0.7140005076570171, 'local/model_version': 61976, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:06,160] {'global/mean_episode_return': 44700.0, 'global/mean_episode_step': 4476.625, 'global/SPS': 3067.0208762763164, 'global/env_act_steps': 39664512, 'global/env_train_steps': 39659520, 'global/optimizer_steps': 61968, 'global/running_reward': 23006.486742424244, 'global/running_step': 2378.3723366477275, 'global/steps_done': 39664512, 'global/episodes_done': 9446, 'global/unclipped_grad_norm': 0.741835850601395, 'global/model_version': 61968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:16,156] calculate_sps 30720 steps in 10.0077
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:16,156] calculate_sps 35840 steps in 10.0077
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:16,166] {'local/mean_episode_return': 45650.0, 'local/mean_episode_step': 4652.583333333333, 'local/SPS': 3069.6276147661147, 'local/env_act_steps': 39699328, 'local/env_train_steps': 39695360, 'local/optimizer_steps': 62024, 'local/running_reward': 22323.407218992248, 'local/running_step': 2312.643683381783, 'local/steps_done': 39699328, 'local/episodes_done': 9458, 'local/unclipped_grad_norm': 0.7234034743160009, 'local/model_version': 62024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:16,167] {'global/mean_episode_return': 45650.0, 'global/mean_episode_step': 4652.583333333333, 'global/SPS': 3581.232217227134, 'global/env_act_steps': 39696384, 'global/env_train_steps': 39695360, 'global/optimizer_steps': 62023, 'global/running_reward': 22386.24497991968, 'global/running_step': 2318.6894766566265, 'global/steps_done': 39696384, 'global/episodes_done': 9458, 'global/unclipped_grad_norm': 0.6951438920064406, 'global/model_version': 62023, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:26,180] calculate_sps 33920 steps in 10.0243
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:26,180] calculate_sps 30720 steps in 10.0243
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:26,180] {'local/mean_episode_return': 47857.142857142855, 'local/mean_episode_step': 4836.142857142857, 'local/SPS': 3383.771915015877, 'local/env_act_steps': 39731840, 'local/env_train_steps': 39729280, 'local/optimizer_steps': 62076, 'local/running_reward': 21922.668553149608, 'local/running_step': 2276.2361281988187, 'local/steps_done': 39731840, 'local/episodes_done': 9465, 'local/unclipped_grad_norm': 0.7371591478586197, 'local/model_version': 62076, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:26,181] {'global/mean_episode_return': 47857.142857142855, 'global/mean_episode_step': 4836.142857142857, 'global/SPS': 3064.5481494483415, 'global/env_act_steps': 39730176, 'global/env_train_steps': 39726080, 'global/optimizer_steps': 62072, 'global/running_reward': 21931.753077651516, 'global/running_step': 2276.9479166666665, 'global/steps_done': 39730176, 'global/episodes_done': 9465, 'global/unclipped_grad_norm': 0.7551724308607529, 'global/model_version': 62072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:36,196] calculate_sps 32640 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:36,196] calculate_sps 34560 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:36,202] {'local/mean_episode_return': 42657.142857142855, 'local/mean_episode_step': 4345.857142857143, 'local/SPS': 3258.873124525028, 'local/env_act_steps': 39764864, 'local/env_train_steps': 39761920, 'local/optimizer_steps': 62128, 'local/running_reward': 22289.922480620156, 'local/running_step': 2313.3748183139537, 'local/steps_done': 39764864, 'local/episodes_done': 9472, 'local/unclipped_grad_norm': 0.725397877395153, 'local/model_version': 62128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:36,203] {'global/mean_episode_return': 42657.142857142855, 'global/mean_episode_step': 4345.857142857143, 'global/SPS': 3450.571543614735, 'global/env_act_steps': 39762688, 'global/env_train_steps': 39760640, 'global/optimizer_steps': 62125, 'global/running_reward': 22289.087106299212, 'global/running_step': 2313.173812746063, 'global/steps_done': 39762688, 'global/episodes_done': 9472, 'global/unclipped_grad_norm': 0.7171102256145118, 'global/model_version': 62125, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:46,246] calculate_sps 32000 steps in 10.0503
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:46,246] calculate_sps 32000 steps in 10.0503
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:46,246] {'local/mean_episode_return': 40700.0, 'local/mean_episode_step': 4253.5, 'local/SPS': 3183.973491584223, 'local/env_act_steps': 39798016, 'local/env_train_steps': 39793920, 'local/optimizer_steps': 62177, 'local/running_reward': 22546.157094594593, 'local/running_step': 2335.826224662162, 'local/steps_done': 39798016, 'local/episodes_done': 9474, 'local/unclipped_grad_norm': 0.8095818301852868, 'local/model_version': 62177, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:46,248] {'global/mean_episode_return': 40700.0, 'global/mean_episode_step': 4253.5, 'global/SPS': 3183.973491584223, 'global/env_act_steps': 39796224, 'global/env_train_steps': 39792640, 'global/optimizer_steps': 62176, 'global/running_reward': 22484.303435114503, 'global/running_step': 2330.0463084446565, 'global/steps_done': 39796224, 'global/episodes_done': 9474, 'global/unclipped_grad_norm': 0.8006221307258979, 'global/model_version': 62176, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:56,279] calculate_sps 34560 steps in 10.0328
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:38:56,279] calculate_sps 32640 steps in 10.0328
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:56,280] {'local/mean_episode_return': 46400.0, 'local/mean_episode_step': 4592.5, 'local/SPS': 3444.689605750201, 'local/env_act_steps': 39830528, 'local/env_train_steps': 39828480, 'local/optimizer_steps': 62232, 'local/running_reward': 23527.645177165356, 'local/running_step': 2429.397145669291, 'local/steps_done': 39830528, 'local/episodes_done': 9478, 'local/unclipped_grad_norm': 0.6887117391282862, 'local/model_version': 62232, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:38:56,281] {'global/mean_episode_return': 42866.666666666664, 'global/mean_episode_step': 4323.666666666667, 'global/SPS': 3253.3179609863005, 'global/env_act_steps': 39828992, 'global/env_train_steps': 39825280, 'global/optimizer_steps': 62227, 'global/running_reward': 23491.19873046875, 'global/running_step': 2425.950164794922, 'global/steps_done': 39828992, 'global/episodes_done': 9477, 'global/unclipped_grad_norm': 0.709871372755836, 'global/model_version': 62227, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:06,283] calculate_sps 30720 steps in 10.0036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:06,283] calculate_sps 33920 steps in 10.0036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:06,294] {'local/mean_episode_return': 45640.0, 'local/mean_episode_step': 4704.2, 'local/SPS': 3070.888732214509, 'local/env_act_steps': 39863808, 'local/env_train_steps': 39859200, 'local/optimizer_steps': 62280, 'local/running_reward': 23908.359375, 'local/running_step': 2467.7573317307692, 'local/steps_done': 39863808, 'local/episodes_done': 9483, 'local/unclipped_grad_norm': 0.774631026511391, 'local/model_version': 62280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:06,296] {'global/mean_episode_return': 47533.333333333336, 'global/mean_episode_step': 4820.0, 'global/SPS': 3390.7729751535207, 'global/env_act_steps': 39861888, 'global/env_train_steps': 39859200, 'global/optimizer_steps': 62280, 'global/running_reward': 23891.94430933852, 'global/running_step': 2465.852565661479, 'global/steps_done': 39861888, 'global/episodes_done': 9483, 'global/unclipped_grad_norm': 0.7472605750245868, 'global/model_version': 62280, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:16,324] calculate_sps 35200 steps in 10.0414
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:16,324] calculate_sps 31360 steps in 10.0414
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:16,324] {'local/mean_episode_return': 44711.11111111111, 'local/mean_episode_step': 4608.444444444444, 'local/SPS': 3505.4926250017215, 'local/env_act_steps': 39895936, 'local/env_train_steps': 39894400, 'local/optimizer_steps': 62334, 'local/running_reward': 23836.024651394422, 'local/running_step': 2463.405689741036, 'local/steps_done': 39895936, 'local/episodes_done': 9492, 'local/unclipped_grad_norm': 0.7570321620614441, 'local/model_version': 62334, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:16,325] {'global/mean_episode_return': 44711.11111111111, 'global/mean_episode_step': 4608.444444444444, 'global/SPS': 3123.0752477288065, 'global/env_act_steps': 39895296, 'global/env_train_steps': 39890560, 'global/optimizer_steps': 62328, 'global/running_reward': 23856.561302681992, 'global/running_step': 2465.4860213122606, 'global/steps_done': 39895296, 'global/episodes_done': 9492, 'global/unclipped_grad_norm': 0.7485234259317318, 'global/model_version': 62328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:26,346] calculate_sps 31360 steps in 10.022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:26,347] calculate_sps 35200 steps in 10.022
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:26,347] {'local/mean_episode_return': 49257.142857142855, 'local/mean_episode_step': 4850.142857142857, 'local/SPS': 3129.1255989476435, 'local/env_act_steps': 39928832, 'local/env_train_steps': 39925760, 'local/optimizer_steps': 62384, 'local/running_reward': 23641.676799610894, 'local/running_step': 2443.947531614786, 'local/steps_done': 39928832, 'local/episodes_done': 9499, 'local/unclipped_grad_norm': 0.7549057632684708, 'local/model_version': 62384, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:26,348] {'global/mean_episode_return': 49257.142857142855, 'global/mean_episode_step': 4850.142857142857, 'global/SPS': 3512.2838355534773, 'global/env_act_steps': 39927424, 'global/env_train_steps': 39925760, 'global/optimizer_steps': 62384, 'global/running_reward': 23639.000249003984, 'global/running_step': 2443.5986055776893, 'global/steps_done': 39927424, 'global/episodes_done': 9499, 'global/unclipped_grad_norm': 0.7624267941074712, 'global/model_version': 62384, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:36,390] calculate_sps 31360 steps in 10.0438
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:36,390] calculate_sps 30720 steps in 10.0438
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:36,390] {'local/mean_episode_return': 48400.0, 'local/mean_episode_step': 4824.0, 'local/SPS': 3122.310546447303, 'local/env_act_steps': 39961728, 'local/env_train_steps': 39957120, 'local/optimizer_steps': 62432, 'local/running_reward': 23867.62524319066, 'local/running_step': 2468.535293044747, 'local/steps_done': 39961728, 'local/episodes_done': 9503, 'local/unclipped_grad_norm': 0.7014332072188457, 'local/model_version': 62432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:36,391] {'global/mean_episode_return': 49600.0, 'global/mean_episode_step': 4815.0, 'global/SPS': 3058.5899230504187, 'global/env_act_steps': 39960576, 'global/env_train_steps': 39956480, 'global/optimizer_steps': 62432, 'global/running_reward': 23844.805743243243, 'global/running_step': 2466.195463320463, 'global/steps_done': 39960576, 'global/episodes_done': 9502, 'global/unclipped_grad_norm': 0.7014332072188457, 'global/model_version': 62432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:46,400] calculate_sps 35200 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:46,400] calculate_sps 34560 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:46,410] {'local/mean_episode_return': 46569.230769230766, 'local/mean_episode_step': 4680.538461538462, 'local/SPS': 3516.5760723675885, 'local/env_act_steps': 39993856, 'local/env_train_steps': 39992320, 'local/optimizer_steps': 62488, 'local/running_reward': 23706.990786852588, 'local/running_step': 2451.0284175796814, 'local/steps_done': 39993856, 'local/episodes_done': 9516, 'local/unclipped_grad_norm': 0.7280897250665086, 'local/model_version': 62488, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:46,412] {'global/mean_episode_return': 46442.857142857145, 'global/mean_episode_step': 4692.714285714285, 'global/SPS': 3452.6383255972687, 'global/env_act_steps': 39993088, 'global/env_train_steps': 39991040, 'global/optimizer_steps': 62485, 'global/running_reward': 23743.30708661417, 'global/running_step': 2454.6495755413384, 'global/steps_done': 39993088, 'global/episodes_done': 9516, 'global/unclipped_grad_norm': 0.7276282501670549, 'global/model_version': 62485, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:56,402] calculate_sps 30720 steps in 10.002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:39:56,402] calculate_sps 32000 steps in 10.002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:56,402] {'local/mean_episode_return': 49900.0, 'local/mean_episode_step': 5090.4, 'local/SPS': 3071.390013723032, 'local/env_act_steps': 40026752, 'local/env_train_steps': 40023040, 'local/optimizer_steps': 62536, 'local/running_reward': 22394.406614785992, 'local/running_step': 2325.6442728599222, 'local/steps_done': 40026752, 'local/episodes_done': 9526, 'local/unclipped_grad_norm': 0.727642735466361, 'local/model_version': 62536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:39:56,404] {'global/mean_episode_return': 49900.0, 'global/mean_episode_step': 5090.4, 'global/SPS': 3199.3645976281587, 'global/env_act_steps': 40025984, 'global/env_train_steps': 40023040, 'global/optimizer_steps': 62536, 'global/running_reward': 22411.606274319067, 'global/running_step': 2327.2865393968873, 'global/steps_done': 40025984, 'global/episodes_done': 9526, 'global/unclipped_grad_norm': 0.7281486009265862, 'global/model_version': 62536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:06,423] calculate_sps 33280 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:06,423] calculate_sps 32640 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:06,423] {'local/mean_episode_return': 46233.333333333336, 'local/mean_episode_step': 4630.5, 'local/SPS': 3320.8917955701136, 'local/env_act_steps': 40059392, 'local/env_train_steps': 40056320, 'local/optimizer_steps': 62587, 'local/running_reward': 22465.27573529412, 'local/running_step': 2334.7502144607843, 'local/steps_done': 40059392, 'local/episodes_done': 9532, 'local/unclipped_grad_norm': 0.7486220785215789, 'local/model_version': 62587, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:06,424] {'global/mean_episode_return': 46233.333333333336, 'global/mean_episode_step': 4630.5, 'global/SPS': 3257.02849180915, 'global/env_act_steps': 40059264, 'global/env_train_steps': 40055680, 'global/optimizer_steps': 62586, 'global/running_reward': 22458.311298076922, 'global/running_step': 2333.9662860576923, 'global/steps_done': 40059264, 'global/episodes_done': 9532, 'global/unclipped_grad_norm': 0.7571078234910965, 'global/model_version': 62586, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:16,438] calculate_sps 33280 steps in 10.0144
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:16,439] calculate_sps 33920 steps in 10.0144
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:16,450] {'local/mean_episode_return': 48533.333333333336, 'local/mean_episode_step': 4776.666666666667, 'local/SPS': 3323.2300763831518, 'local/env_act_steps': 40091904, 'local/env_train_steps': 40089600, 'local/optimizer_steps': 62640, 'local/running_reward': 22942.89493110236, 'local/running_step': 2381.617279773622, 'local/steps_done': 40091904, 'local/episodes_done': 9535, 'local/unclipped_grad_norm': 0.6573763169207663, 'local/model_version': 62640, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:16,452] {'global/mean_episode_return': 48533.333333333336, 'global/mean_episode_step': 4776.666666666667, 'global/SPS': 3387.1383470828277, 'global/env_act_steps': 40091904, 'global/env_train_steps': 40089600, 'global/optimizer_steps': 62640, 'global/running_reward': 22942.861519607843, 'global/running_step': 2381.679381127451, 'global/steps_done': 40091904, 'global/episodes_done': 9535, 'global/unclipped_grad_norm': 0.6512088819786355, 'global/model_version': 62640, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:26,444] calculate_sps 30720 steps in 10.0062
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:26,444] calculate_sps 25600 steps in 10.0062
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:26,444] {'local/mean_episode_return': 42171.42857142857, 'local/mean_episode_step': 4499.0, 'local/SPS': 3070.1073435406224, 'local/env_act_steps': 40124928, 'local/env_train_steps': 40120320, 'local/optimizer_steps': 62688, 'local/running_reward': 23177.374031007752, 'local/running_step': 2399.7845809108526, 'local/steps_done': 40124928, 'local/episodes_done': 9542, 'local/unclipped_grad_norm': 0.7716201810787121, 'local/model_version': 62688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:26,446] {'global/mean_episode_return': 42133.333333333336, 'global/mean_episode_step': 4521.333333333333, 'global/SPS': 2558.422786283852, 'global/env_act_steps': 40118272, 'global/env_train_steps': 40115200, 'global/optimizer_steps': 62680, 'global/running_reward': 23176.547330097088, 'global/running_step': 2400.4827821601943, 'global/steps_done': 40118272, 'global/episodes_done': 9541, 'global/unclipped_grad_norm': 0.784087048470974, 'global/model_version': 62680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:36,465] calculate_sps 35200 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:36,465] calculate_sps 32640 steps in 10.0052
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:36,474] {'local/mean_episode_return': 51740.0, 'local/mean_episode_step': 5097.5, 'local/SPS': 3518.177709323524, 'local/env_act_steps': 40157184, 'local/env_train_steps': 40155520, 'local/optimizer_steps': 62742, 'local/running_reward': 23043.768601190477, 'local/running_step': 2386.7425905257937, 'local/steps_done': 40157184, 'local/episodes_done': 9552, 'local/unclipped_grad_norm': 0.7632714471331349, 'local/model_version': 62742, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:36,476] {'global/mean_episode_return': 49275.0, 'global/mean_episode_step': 4920.25, 'global/SPS': 3262.3102395545407, 'global/env_act_steps': 40151552, 'global/env_train_steps': 40147840, 'global/optimizer_steps': 62731, 'global/running_reward': 23158.118990384617, 'global/running_step': 2397.2453725961536, 'global/steps_done': 40151552, 'global/episodes_done': 9549, 'global/unclipped_grad_norm': 0.7748307311067394, 'global/model_version': 62731, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:46,471] calculate_sps 31360 steps in 10.0223
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:46,471] calculate_sps 33920 steps in 10.0223
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:46,486] {'local/mean_episode_return': 49400.0, 'local/mean_episode_step': 5048.666666666667, 'local/SPS': 3129.0301689720973, 'local/env_act_steps': 40190336, 'local/env_train_steps': 40186880, 'local/optimizer_steps': 62792, 'local/running_reward': 22819.679054054053, 'local/running_step': 2366.6598696911196, 'local/steps_done': 40190336, 'local/episodes_done': 9555, 'local/unclipped_grad_norm': 0.7224296873807907, 'local/model_version': 62792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:46,488] {'global/mean_episode_return': 52480.0, 'global/mean_episode_step': 5145.4, 'global/SPS': 3384.461203173901, 'global/env_act_steps': 40184192, 'global/env_train_steps': 40181760, 'global/optimizer_steps': 62784, 'global/running_reward': 22692.787990196077, 'global/running_step': 2353.734650735294, 'global/steps_done': 40184192, 'global/episodes_done': 9554, 'global/unclipped_grad_norm': 0.734910896364248, 'global/model_version': 62784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:56,503] calculate_sps 32640 steps in 10.0324
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:40:56,504] calculate_sps 30720 steps in 10.0324
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:56,504] {'local/mean_episode_return': 51466.666666666664, 'local/mean_episode_step': 4977.333333333333, 'local/SPS': 3253.471585790174, 'local/env_act_steps': 40223104, 'local/env_train_steps': 40219520, 'local/optimizer_steps': 62842, 'local/running_reward': 23620.697021484375, 'local/running_step': 2446.3299560546875, 'local/steps_done': 40223104, 'local/episodes_done': 9558, 'local/unclipped_grad_norm': 0.7590883880853653, 'local/model_version': 62842, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:40:56,505] {'global/mean_episode_return': 48200.0, 'global/mean_episode_step': 4976.666666666667, 'global/SPS': 3062.090904273105, 'global/env_act_steps': 40217728, 'global/env_train_steps': 40212480, 'global/optimizer_steps': 62832, 'global/running_reward': 23493.18344465649, 'global/running_step': 2433.55859375, 'global/steps_done': 40217728, 'global/episodes_done': 9557, 'global/unclipped_grad_norm': 0.75382867641747, 'global/model_version': 62832, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:06,505] calculate_sps 33920 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:06,505] calculate_sps 35840 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:06,505] {'local/mean_episode_return': 44225.0, 'local/mean_episode_step': 4622.0, 'local/SPS': 3391.5114442790427, 'local/env_act_steps': 40255488, 'local/env_train_steps': 40253440, 'local/optimizer_steps': 62896, 'local/running_reward': 23921.07831027668, 'local/running_step': 2477.594861660079, 'local/steps_done': 40255488, 'local/episodes_done': 9566, 'local/unclipped_grad_norm': 0.7272613062350838, 'local/model_version': 62896, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:06,515] {'global/mean_episode_return': 46257.142857142855, 'global/mean_episode_step': 4735.428571428572, 'global/SPS': 3583.4837901816304, 'global/env_act_steps': 40249728, 'global/env_train_steps': 40248320, 'global/optimizer_steps': 62888, 'global/running_reward': 23943.6375, 'global/running_step': 2480.4255, 'global/steps_done': 40249728, 'global/episodes_done': 9564, 'global/unclipped_grad_norm': 0.7126679662615061, 'global/model_version': 62888, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:16,508] calculate_sps 30720 steps in 10.0028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:16,508] calculate_sps 30720 steps in 10.0028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:16,508] {'local/mean_episode_return': 43900.0, 'local/mean_episode_step': 4581.625, 'local/SPS': 3071.1517235584874, 'local/env_act_steps': 40288896, 'local/env_train_steps': 40284160, 'local/optimizer_steps': 62944, 'local/running_reward': 23743.372844827587, 'local/running_step': 2453.138080699234, 'local/steps_done': 40288896, 'local/episodes_done': 9574, 'local/unclipped_grad_norm': 0.8602274730801582, 'local/model_version': 62944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:16,510] {'global/mean_episode_return': 44733.333333333336, 'global/mean_episode_step': 4583.0, 'global/SPS': 3071.1517235584874, 'global/env_act_steps': 40283648, 'global/env_train_steps': 40279040, 'global/optimizer_steps': 62936, 'global/running_reward': 23766.5625, 'global/running_step': 2456.7814268867924, 'global/steps_done': 40283648, 'global/episodes_done': 9573, 'global/unclipped_grad_norm': 0.822703417390585, 'global/model_version': 62936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:26,511] calculate_sps 35840 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:26,511] calculate_sps 35840 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:26,511] {'local/mean_episode_return': 45688.88888888889, 'local/mean_episode_step': 4616.277777777777, 'local/SPS': 3582.799328151786, 'local/env_act_steps': 40321024, 'local/env_train_steps': 40320000, 'local/optimizer_steps': 62999, 'local/running_reward': 23369.005229083665, 'local/running_step': 2410.1297933266933, 'local/steps_done': 40321024, 'local/episodes_done': 9584, 'local/unclipped_grad_norm': 0.7429616841402921, 'local/model_version': 62999, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:26,512] {'global/mean_episode_return': 43844.444444444445, 'global/mean_episode_step': 4531.388888888889, 'global/SPS': 3582.799328151786, 'global/env_act_steps': 40316288, 'global/env_train_steps': 40314880, 'global/optimizer_steps': 62992, 'global/running_reward': 23461.011029411766, 'global/running_step': 2419.524417892157, 'global/steps_done': 40316288, 'global/episodes_done': 9583, 'global/unclipped_grad_norm': 0.7856583712356431, 'global/model_version': 62992, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:36,534] calculate_sps 30720 steps in 10.0231
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:36,535] calculate_sps 30720 steps in 10.0231
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:36,535] {'local/mean_episode_return': 40942.857142857145, 'local/mean_episode_step': 4337.0, 'local/SPS': 3064.9051929713255, 'local/env_act_steps': 40354432, 'local/env_train_steps': 40350720, 'local/optimizer_steps': 63048, 'local/running_reward': 23248.563218390806, 'local/running_step': 2393.6080878831417, 'local/steps_done': 40354432, 'local/episodes_done': 9591, 'local/unclipped_grad_norm': 0.7859259101809287, 'local/model_version': 63048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:36,536] {'global/mean_episode_return': 43171.42857142857, 'global/mean_episode_step': 4479.428571428572, 'global/SPS': 3064.9051929713255, 'global/env_act_steps': 40349696, 'global/env_train_steps': 40345600, 'global/optimizer_steps': 63040, 'global/running_reward': 23224.066091954024, 'global/running_step': 2392.328424329502, 'global/steps_done': 40349696, 'global/episodes_done': 9590, 'global/unclipped_grad_norm': 0.788153904179732, 'global/model_version': 63040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:46,556] calculate_sps 32640 steps in 10.0226
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:46,557] calculate_sps 34560 steps in 10.0226
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:46,557] {'local/mean_episode_return': 44066.666666666664, 'local/mean_episode_step': 4448.0, 'local/SPS': 3256.6281618071885, 'local/env_act_steps': 40386944, 'local/env_train_steps': 40383360, 'local/optimizer_steps': 63098, 'local/running_reward': 23506.6437007874, 'local/running_step': 2413.898160679134, 'local/steps_done': 40386944, 'local/episodes_done': 9597, 'local/unclipped_grad_norm': 0.796712052822113, 'local/model_version': 63098, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:46,558] {'global/mean_episode_return': 43233.333333333336, 'global/mean_episode_step': 4398.0, 'global/SPS': 3448.1945242664347, 'global/env_act_steps': 40382336, 'global/env_train_steps': 40380160, 'global/optimizer_steps': 63093, 'global/running_reward': 23455.287990196077, 'global/running_step': 2409.096231617647, 'global/steps_done': 40382336, 'global/episodes_done': 9596, 'global/unclipped_grad_norm': 0.7354015387454123, 'global/model_version': 63093, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:56,586] calculate_sps 33920 steps in 10.0295
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:41:56,587] calculate_sps 32000 steps in 10.0295
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:56,587] {'local/mean_episode_return': 45742.857142857145, 'local/mean_episode_step': 4616.285714285715, 'local/SPS': 3382.0067090633447, 'local/env_act_steps': 40419968, 'local/env_train_steps': 40417280, 'local/optimizer_steps': 63152, 'local/running_reward': 23645.046027131782, 'local/running_step': 2426.659429505814, 'local/steps_done': 40419968, 'local/episodes_done': 9604, 'local/unclipped_grad_norm': 0.678030959158032, 'local/model_version': 63152, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:41:56,588] {'global/mean_episode_return': 45750.0, 'global/mean_episode_step': 4626.75, 'global/SPS': 3190.5723670408915, 'global/env_act_steps': 40415744, 'global/env_train_steps': 40412160, 'global/optimizer_steps': 63144, 'global/running_reward': 23657.21384099617, 'global/running_step': 2427.8972701149423, 'global/steps_done': 40415744, 'global/episodes_done': 9604, 'global/unclipped_grad_norm': 0.7534404359027451, 'global/model_version': 63144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:06,615] calculate_sps 31360 steps in 10.0295
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:06,616] calculate_sps 33920 steps in 10.0295
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:06,616] {'local/mean_episode_return': 44285.71428571428, 'local/mean_episode_step': 4466.428571428572, 'local/SPS': 3126.782103369673, 'local/env_act_steps': 40453248, 'local/env_train_steps': 40448640, 'local/optimizer_steps': 63200, 'local/running_reward': 23713.143028846152, 'local/running_step': 2431.158143028846, 'local/steps_done': 40453248, 'local/episodes_done': 9611, 'local/unclipped_grad_norm': 0.7676628269255161, 'local/model_version': 63200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:06,617] {'global/mean_episode_return': 44285.71428571428, 'global/mean_episode_step': 4466.428571428572, 'global/SPS': 3382.0296220120954, 'global/env_act_steps': 40448768, 'global/env_train_steps': 40446080, 'global/optimizer_steps': 63197, 'global/running_reward': 23703.809350775195, 'global/running_step': 2430.317496366279, 'global/steps_done': 40448768, 'global/episodes_done': 9611, 'global/unclipped_grad_norm': 0.7174337832432873, 'global/model_version': 63197, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:16,617] calculate_sps 35200 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:16,617] calculate_sps 32640 steps in 10.0012
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:16,618] {'local/mean_episode_return': 43400.0, 'local/mean_episode_step': 4453.8, 'local/SPS': 3519.567260542807, 'local/env_act_steps': 40485120, 'local/env_train_steps': 40483840, 'local/optimizer_steps': 63256, 'local/running_reward': 23786.163403614457, 'local/running_step': 2434.548161395582, 'local/steps_done': 40485120, 'local/episodes_done': 9616, 'local/unclipped_grad_norm': 0.7172698631350484, 'local/model_version': 63256, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:16,619] {'global/mean_episode_return': 43400.0, 'global/mean_episode_step': 4453.8, 'global/SPS': 3263.59873250333, 'global/env_act_steps': 40481792, 'global/env_train_steps': 40478720, 'global/optimizer_steps': 63248, 'global/running_reward': 23730.741279069767, 'global/running_step': 2429.9675084786822, 'global/steps_done': 40481792, 'global/episodes_done': 9616, 'global/unclipped_grad_norm': 0.7441077507009694, 'global/model_version': 63248, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:26,621] calculate_sps 30720 steps in 10.0041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:26,621] calculate_sps 32640 steps in 10.0041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:26,622] {'local/mean_episode_return': 51075.0, 'local/mean_episode_step': 5080.875, 'local/SPS': 3070.730139392191, 'local/env_act_steps': 40518528, 'local/env_train_steps': 40514560, 'local/optimizer_steps': 63304, 'local/running_reward': 24153.891283524903, 'local/running_step': 2464.707525143678, 'local/steps_done': 40518528, 'local/episodes_done': 9624, 'local/unclipped_grad_norm': 0.7990667059396704, 'local/model_version': 63304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:26,623] {'global/mean_episode_return': 50057.142857142855, 'global/mean_episode_step': 5035.857142857143, 'global/SPS': 3262.650773104203, 'global/env_act_steps': 40514944, 'global/env_train_steps': 40511360, 'global/optimizer_steps': 63298, 'global/running_reward': 24172.617036679538, 'global/running_step': 2467.176097972973, 'global/steps_done': 40514944, 'global/episodes_done': 9623, 'global/unclipped_grad_norm': 0.7887227582931519, 'global/model_version': 63298, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:36,634] calculate_sps 33280 steps in 10.013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:36,635] calculate_sps 33920 steps in 10.013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:36,635] {'local/mean_episode_return': 48181.818181818184, 'local/mean_episode_step': 4852.181818181818, 'local/SPS': 3323.695120396244, 'local/env_act_steps': 40551040, 'local/env_train_steps': 40547840, 'local/optimizer_steps': 63356, 'local/running_reward': 23859.836368110235, 'local/running_step': 2434.3948695866143, 'local/steps_done': 40551040, 'local/episodes_done': 9635, 'local/unclipped_grad_norm': 0.7259105994151189, 'local/model_version': 63356, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:36,636] {'global/mean_episode_return': 49440.0, 'global/mean_episode_step': 4940.2, 'global/SPS': 3387.6123342500177, 'global/env_act_steps': 40547968, 'global/env_train_steps': 40545280, 'global/optimizer_steps': 63352, 'global/running_reward': 23924.84253875969, 'global/running_step': 2440.9353500484494, 'global/steps_done': 40547968, 'global/episodes_done': 9633, 'global/unclipped_grad_norm': 0.7383368506475732, 'global/model_version': 63352, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:46,662] calculate_sps 33280 steps in 10.0278
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:46,662] calculate_sps 32000 steps in 10.0278
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:46,663] {'local/mean_episode_return': 47257.142857142855, 'local/mean_episode_step': 4711.857142857143, 'local/SPS': 3318.762971151132, 'local/env_act_steps': 40583936, 'local/env_train_steps': 40581120, 'local/optimizer_steps': 63408, 'local/running_reward': 23346.321741245138, 'local/running_step': 2382.9064627918287, 'local/steps_done': 40583936, 'local/episodes_done': 9642, 'local/unclipped_grad_norm': 0.7376401539032276, 'local/model_version': 63408, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:46,664] {'global/mean_episode_return': 48857.142857142855, 'global/mean_episode_step': 4803.428571428572, 'global/SPS': 3191.1182414914733, 'global/env_act_steps': 40581376, 'global/env_train_steps': 40577280, 'global/optimizer_steps': 63401, 'global/running_reward': 23346.20450191571, 'global/running_step': 2382.7172832854408, 'global/steps_done': 40581376, 'global/episodes_done': 9640, 'global/unclipped_grad_norm': 0.7510978409222194, 'global/model_version': 63401, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:56,687] calculate_sps 31360 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:42:56,687] calculate_sps 34560 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:56,687] {'local/mean_episode_return': 43828.57142857143, 'local/mean_episode_step': 4542.571428571428, 'local/SPS': 3128.1220889982965, 'local/env_act_steps': 40617088, 'local/env_train_steps': 40612480, 'local/optimizer_steps': 63456, 'local/running_reward': 23345.59000965251, 'local/running_step': 2381.4503197393824, 'local/steps_done': 40617088, 'local/episodes_done': 9649, 'local/unclipped_grad_norm': 0.6735886173943678, 'local/model_version': 63456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:42:56,688] {'global/mean_episode_return': 42342.857142857145, 'global/mean_episode_step': 4403.571428571428, 'global/SPS': 3447.318220528735, 'global/env_act_steps': 40614272, 'global/env_train_steps': 40611840, 'global/optimizer_steps': 63456, 'global/running_reward': 23328.45938715953, 'global/running_step': 2380.1636369163425, 'global/steps_done': 40614272, 'global/episodes_done': 9647, 'global/unclipped_grad_norm': 0.6508406920866533, 'global/model_version': 63456, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:06,703] calculate_sps 35200 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:06,703] calculate_sps 30720 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:06,703] {'local/mean_episode_return': 52850.0, 'local/mean_episode_step': 5185.5, 'local/SPS': 3514.6098975739137, 'local/env_act_steps': 40649216, 'local/env_train_steps': 40647680, 'local/optimizer_steps': 63512, 'local/running_reward': 22828.498505976095, 'local/running_step': 2330.6345244023905, 'local/steps_done': 40649216, 'local/episodes_done': 9657, 'local/unclipped_grad_norm': 0.750594651060445, 'local/model_version': 63512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:06,704] {'global/mean_episode_return': 51580.0, 'global/mean_episode_step': 5118.4, 'global/SPS': 3067.295910609961, 'global/env_act_steps': 40647552, 'global/env_train_steps': 40642560, 'global/optimizer_steps': 63504, 'global/running_reward': 22884.98798076923, 'global/running_step': 2335.9243088942308, 'global/steps_done': 40647552, 'global/episodes_done': 9657, 'global/unclipped_grad_norm': 0.7669147724906603, 'global/model_version': 63504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:16,711] calculate_sps 30720 steps in 10.0082
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:16,712] calculate_sps 35840 steps in 10.0082
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:16,712] {'local/mean_episode_return': 41250.0, 'local/mean_episode_step': 4275.0, 'local/SPS': 3069.4926243711425, 'local/env_act_steps': 40682496, 'local/env_train_steps': 40678400, 'local/optimizer_steps': 63560, 'local/running_reward': 23118.677884615383, 'local/running_step': 2362.6491286057694, 'local/steps_done': 40682496, 'local/episodes_done': 9661, 'local/unclipped_grad_norm': 0.7441585877289375, 'local/model_version': 63560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:16,714] {'global/mean_episode_return': 40333.333333333336, 'global/mean_episode_step': 4047.3333333333335, 'global/SPS': 3581.0747284329996, 'global/env_act_steps': 40680064, 'global/env_train_steps': 40678400, 'global/optimizer_steps': 63560, 'global/running_reward': 23080.241141732284, 'global/running_step': 2358.814468503937, 'global/steps_done': 40680064, 'global/episodes_done': 9660, 'global/unclipped_grad_norm': 0.7310893498361111, 'global/model_version': 63560, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:26,713] calculate_sps 33920 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:26,713] calculate_sps 30720 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:26,713] {'local/mean_episode_return': 41514.28571428572, 'local/mean_episode_step': 4362.571428571428, 'local/SPS': 3391.2050569505705, 'local/env_act_steps': 40714880, 'local/env_train_steps': 40712320, 'local/optimizer_steps': 63612, 'local/running_reward': 23522.79520750988, 'local/running_step': 2399.145195158103, 'local/steps_done': 40714880, 'local/episodes_done': 9668, 'local/unclipped_grad_norm': 0.728351907661328, 'local/model_version': 63612, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:26,714] {'global/mean_episode_return': 41825.0, 'global/mean_episode_step': 4437.0, 'global/SPS': 3071.2800515778754, 'global/env_act_steps': 40713472, 'global/env_train_steps': 40709120, 'global/optimizer_steps': 63608, 'global/running_reward': 23511.943247126437, 'global/running_step': 2398.2249760536397, 'global/steps_done': 40713472, 'global/episodes_done': 9668, 'global/unclipped_grad_norm': 0.7078303222854933, 'global/model_version': 63608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:36,741] calculate_sps 32640 steps in 10.0281
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:36,741] calculate_sps 35200 steps in 10.0281
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:36,742] {'local/mean_episode_return': 53950.0, 'local/mean_episode_step': 5205.75, 'local/SPS': 3254.8468142369734, 'local/env_act_steps': 40747776, 'local/env_train_steps': 40744960, 'local/optimizer_steps': 63664, 'local/running_reward': 23920.482733463035, 'local/running_step': 2436.5509788424124, 'local/steps_done': 40747776, 'local/episodes_done': 9672, 'local/unclipped_grad_norm': 0.6727779986193547, 'local/model_version': 63664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:36,743] {'global/mean_episode_return': 53533.333333333336, 'global/mean_episode_step': 5142.666666666667, 'global/SPS': 3510.1289173143828, 'global/env_act_steps': 40745856, 'global/env_train_steps': 40744320, 'global/optimizer_steps': 63662, 'global/running_reward': 23892.990365612648, 'global/running_step': 2434.0594429347825, 'global/steps_done': 40745856, 'global/episodes_done': 9671, 'global/unclipped_grad_norm': 0.6838128933752025, 'global/model_version': 63662, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:46,761] calculate_sps 30720 steps in 10.0196
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:46,761] calculate_sps 31360 steps in 10.0196
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:46,761] {'local/mean_episode_return': 47680.0, 'local/mean_episode_step': 4736.7, 'local/SPS': 3065.9927272242717, 'local/env_act_steps': 40780800, 'local/env_train_steps': 40775680, 'local/optimizer_steps': 63712, 'local/running_reward': 23575.93871124031, 'local/running_step': 2403.431655765504, 'local/steps_done': 40780800, 'local/episodes_done': 9682, 'local/unclipped_grad_norm': 0.7129596568023165, 'local/model_version': 63712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:46,771] {'global/mean_episode_return': 48363.63636363636, 'global/mean_episode_step': 4796.545454545455, 'global/SPS': 3129.8675757081105, 'global/env_act_steps': 40779008, 'global/env_train_steps': 40775680, 'global/optimizer_steps': 63712, 'global/running_reward': 23615.359555984556, 'global/running_step': 2407.0378559362935, 'global/steps_done': 40779008, 'global/episodes_done': 9682, 'global/unclipped_grad_norm': 0.7235813388228416, 'global/model_version': 63712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:56,792] calculate_sps 35840 steps in 10.0313
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:43:56,792] calculate_sps 33280 steps in 10.0313
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:56,793] {'local/mean_episode_return': 47942.857142857145, 'local/mean_episode_step': 4919.571428571428, 'local/SPS': 3572.82521037939, 'local/env_act_steps': 40812928, 'local/env_train_steps': 40811520, 'local/optimizer_steps': 63768, 'local/running_reward': 23426.01469123506, 'local/running_step': 2388.6324389940237, 'local/steps_done': 40812928, 'local/episodes_done': 9689, 'local/unclipped_grad_norm': 0.828931262716651, 'local/model_version': 63768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:43:56,794] {'global/mean_episode_return': 47942.857142857145, 'global/mean_episode_step': 4919.571428571428, 'global/SPS': 3317.623409638005, 'global/env_act_steps': 40812032, 'global/env_train_steps': 40808960, 'global/optimizer_steps': 63763, 'global/running_reward': 23426.489825581397, 'global/running_step': 2388.8052022771317, 'global/steps_done': 40812032, 'global/episodes_done': 9689, 'global/unclipped_grad_norm': 0.8570167349249709, 'global/model_version': 63763, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:06,817] calculate_sps 30720 steps in 10.025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:06,817] calculate_sps 33280 steps in 10.025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:06,818] {'local/mean_episode_return': 48000.0, 'local/mean_episode_step': 4783.0, 'local/SPS': 3064.3287744208765, 'local/env_act_steps': 40846464, 'local/env_train_steps': 40842240, 'local/optimizer_steps': 63816, 'local/running_reward': 23672.495229007633, 'local/running_step': 2414.120855200382, 'local/steps_done': 40846464, 'local/episodes_done': 9693, 'local/unclipped_grad_norm': 0.7076824295024077, 'local/model_version': 63816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:06,819] {'global/mean_episode_return': 45266.666666666664, 'global/mean_episode_step': 4579.666666666667, 'global/SPS': 3319.6895056226163, 'global/env_act_steps': 40845312, 'global/env_train_steps': 40842240, 'global/optimizer_steps': 63816, 'global/running_reward': 23649.62139423077, 'global/running_step': 2411.683173076923, 'global/steps_done': 40845312, 'global/episodes_done': 9692, 'global/unclipped_grad_norm': 0.6920953556051794, 'global/model_version': 63816, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:16,822] calculate_sps 33920 steps in 10.0037
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:16,823] calculate_sps 32640 steps in 10.0037
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:16,823] {'local/mean_episode_return': 42450.0, 'local/mean_episode_step': 4405.75, 'local/SPS': 3390.733458016235, 'local/env_act_steps': 40878848, 'local/env_train_steps': 40876160, 'local/optimizer_steps': 63868, 'local/running_reward': 24104.829545454544, 'local/running_step': 2461.8523036067195, 'local/steps_done': 40878848, 'local/episodes_done': 9697, 'local/unclipped_grad_norm': 0.7675608562735411, 'local/model_version': 63868, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:16,824] {'global/mean_episode_return': 45200.0, 'global/mean_episode_step': 4603.2, 'global/SPS': 3262.781252053358, 'global/env_act_steps': 40878464, 'global/env_train_steps': 40874880, 'global/optimizer_steps': 63866, 'global/running_reward': 24100.609314671816, 'global/running_step': 2461.407577220077, 'global/steps_done': 40878464, 'global/episodes_done': 9697, 'global/unclipped_grad_norm': 0.7680602413415909, 'global/model_version': 63866, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:26,834] calculate_sps 32640 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:26,834] calculate_sps 33920 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:26,834] {'local/mean_episode_return': 51250.0, 'local/mean_episode_step': 5131.75, 'local/SPS': 3259.802046114949, 'local/env_act_steps': 40911232, 'local/env_train_steps': 40908800, 'local/optimizer_steps': 63920, 'local/running_reward': 24545.170454545456, 'local/running_step': 2506.7836277173915, 'local/steps_done': 40911232, 'local/episodes_done': 9701, 'local/unclipped_grad_norm': 0.7187387874493232, 'local/model_version': 63920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:26,836] {'global/mean_episode_return': 51250.0, 'global/mean_episode_step': 5131.75, 'global/SPS': 3387.637420472398, 'global/env_act_steps': 40910848, 'global/env_train_steps': 40908800, 'global/optimizer_steps': 63920, 'global/running_reward': 24538.148468379448, 'global/running_step': 2506.0244256422925, 'global/steps_done': 40910848, 'global/episodes_done': 9701, 'global/unclipped_grad_norm': 0.7200846186390629, 'global/model_version': 63920, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:36,856] calculate_sps 30720 steps in 10.0219
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:36,856] calculate_sps 30720 steps in 10.0219
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:36,856] {'local/mean_episode_return': 45610.0, 'local/mean_episode_step': 4675.4, 'local/SPS': 3065.284706691652, 'local/env_act_steps': 40944512, 'local/env_train_steps': 40939520, 'local/optimizer_steps': 63968, 'local/running_reward': 24468.80408653846, 'local/running_step': 2494.1368689903848, 'local/steps_done': 40944512, 'local/episodes_done': 9712, 'local/unclipped_grad_norm': 0.7744059041142464, 'local/model_version': 63968, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:36,867] {'global/mean_episode_return': 45033.333333333336, 'global/mean_episode_step': 4642.888888888889, 'global/SPS': 3065.284706691652, 'global/env_act_steps': 40944384, 'global/env_train_steps': 40939520, 'global/optimizer_steps': 63968, 'global/running_reward': 24469.716125954197, 'global/running_step': 2494.262434398855, 'global/steps_done': 40944384, 'global/episodes_done': 9711, 'global/unclipped_grad_norm': 0.7744059041142464, 'global/model_version': 63968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:46,870] calculate_sps 34560 steps in 10.014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:46,870] calculate_sps 26880 steps in 10.014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:46,871] {'local/mean_episode_return': 50720.0, 'local/mean_episode_step': 4887.0, 'local/SPS': 3451.1606616222225, 'local/env_act_steps': 40976256, 'local/env_train_steps': 40974080, 'local/optimizer_steps': 64022, 'local/running_reward': 24482.535282258064, 'local/running_step': 2494.896988407258, 'local/steps_done': 40976256, 'local/episodes_done': 9717, 'local/unclipped_grad_norm': 0.7114032473829057, 'local/model_version': 64022, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:46,872] {'global/mean_episode_return': 49320.0, 'global/mean_episode_step': 4801.8, 'global/SPS': 2684.2360701506177, 'global/env_act_steps': 40970496, 'global/env_train_steps': 40966400, 'global/optimizer_steps': 64009, 'global/running_reward': 24503.04074754902, 'global/running_step': 2496.639744178922, 'global/steps_done': 40970496, 'global/episodes_done': 9716, 'global/unclipped_grad_norm': 0.7310460551482875, 'global/model_version': 64009, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:56,875] calculate_sps 32000 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:44:56,875] calculate_sps 34560 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:56,875] {'local/mean_episode_return': 50040.0, 'local/mean_episode_step': 4929.5, 'local/SPS': 3198.311133504275, 'local/env_act_steps': 41009408, 'local/env_train_steps': 41006080, 'local/optimizer_steps': 64072, 'local/running_reward': 24206.774855212356, 'local/running_step': 2470.016710907336, 'local/steps_done': 41009408, 'local/episodes_done': 9727, 'local/unclipped_grad_norm': 0.6964873632788658, 'local/model_version': 64072, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:44:56,877] {'global/mean_episode_return': 53244.444444444445, 'global/mean_episode_step': 5126.777777777777, 'global/SPS': 3454.176024184617, 'global/env_act_steps': 41003136, 'global/env_train_steps': 41000960, 'global/optimizer_steps': 64064, 'global/running_reward': 24302.861519607843, 'global/running_step': 2478.939338235294, 'global/steps_done': 41003136, 'global/episodes_done': 9725, 'global/unclipped_grad_norm': 0.696575477719307, 'global/model_version': 64064, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:06,881] calculate_sps 32000 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:06,881] calculate_sps 30720 steps in 10.006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:06,881] {'local/mean_episode_return': 49200.0, 'local/mean_episode_step': 4966.75, 'local/SPS': 3198.077099171543, 'local/env_act_steps': 41042176, 'local/env_train_steps': 41038080, 'local/optimizer_steps': 64121, 'local/running_reward': 24174.163818359375, 'local/running_step': 2468.8562622070312, 'local/steps_done': 41042176, 'local/episodes_done': 9731, 'local/unclipped_grad_norm': 0.7660271890309392, 'local/model_version': 64121, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:06,882] {'global/mean_episode_return': 46280.0, 'global/mean_episode_step': 4683.0, 'global/SPS': 3070.1540152046814, 'global/env_act_steps': 41036544, 'global/env_train_steps': 41031680, 'global/optimizer_steps': 64112, 'global/running_reward': 24087.03903256705, 'global/running_step': 2460.002394636015, 'global/steps_done': 41036544, 'global/episodes_done': 9730, 'global/unclipped_grad_norm': 0.7130042370408773, 'global/model_version': 64112, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:16,896] calculate_sps 34560 steps in 10.0147
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:16,896] calculate_sps 35840 steps in 10.0147
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:16,896] {'local/mean_episode_return': 45000.0, 'local/mean_episode_step': 4559.222222222223, 'local/SPS': 3450.939811223272, 'local/env_act_steps': 41074304, 'local/env_train_steps': 41072640, 'local/optimizer_steps': 64176, 'local/running_reward': 24052.96937250996, 'local/running_step': 2456.007221115538, 'local/steps_done': 41074304, 'local/episodes_done': 9740, 'local/unclipped_grad_norm': 0.8413764322345907, 'local/model_version': 64176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:16,897] {'global/mean_episode_return': 45300.0, 'global/mean_episode_step': 4690.125, 'global/SPS': 3578.752396824134, 'global/env_act_steps': 41068928, 'global/env_train_steps': 41067520, 'global/optimizer_steps': 64168, 'global/running_reward': 24111.845355731224, 'global/running_step': 2462.3667860671935, 'global/steps_done': 41068928, 'global/episodes_done': 9738, 'global/unclipped_grad_norm': 0.8191848224295037, 'global/model_version': 64168, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:26,904] calculate_sps 30720 steps in 10.0089
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:26,905] calculate_sps 30720 steps in 10.0089
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:26,905] {'local/mean_episode_return': 46844.444444444445, 'local/mean_episode_step': 4671.555555555556, 'local/SPS': 3069.263548126645, 'local/env_act_steps': 41107456, 'local/env_train_steps': 41103360, 'local/optimizer_steps': 64224, 'local/running_reward': 23788.278233590732, 'local/running_step': 2431.735551399614, 'local/steps_done': 41107456, 'local/episodes_done': 9749, 'local/unclipped_grad_norm': 0.7993665169924498, 'local/model_version': 64224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:26,907] {'global/mean_episode_return': 47444.444444444445, 'global/mean_episode_step': 4666.444444444444, 'global/SPS': 3069.263548126645, 'global/env_act_steps': 41102080, 'global/env_train_steps': 41098240, 'global/optimizer_steps': 64216, 'global/running_reward': 23852.720801158302, 'global/running_step': 2437.660261824324, 'global/steps_done': 41102080, 'global/episodes_done': 9747, 'global/unclipped_grad_norm': 0.7946236381928126, 'global/model_version': 64216, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:36,950] calculate_sps 34560 steps in 10.046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:36,951] calculate_sps 33920 steps in 10.046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:36,951] {'local/mean_episode_return': 43550.0, 'local/mean_episode_step': 4495.375, 'local/SPS': 3440.1913585081375, 'local/env_act_steps': 41139968, 'local/env_train_steps': 41137920, 'local/optimizer_steps': 64277, 'local/running_reward': 23757.449557086613, 'local/running_step': 2425.178026574803, 'local/steps_done': 41139968, 'local/episodes_done': 9757, 'local/unclipped_grad_norm': 0.7365803457093689, 'local/model_version': 64277, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:36,952] {'global/mean_episode_return': 44400.0, 'global/mean_episode_step': 4519.5, 'global/SPS': 3376.4841111283567, 'global/env_act_steps': 41134720, 'global/env_train_steps': 41132160, 'global/optimizer_steps': 64268, 'global/running_reward': 23722.99019607843, 'global/running_step': 2422.3635110294117, 'global/steps_done': 41134720, 'global/episodes_done': 9753, 'global/unclipped_grad_norm': 0.7779967592885861, 'global/model_version': 64268, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:46,968] calculate_sps 32000 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:46,969] calculate_sps 32640 steps in 10.018
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:46,978] {'local/mean_episode_return': 52200.0, 'local/mean_episode_step': 5104.0, 'local/SPS': 3194.2421751105967, 'local/env_act_steps': 41173632, 'local/env_train_steps': 41169920, 'local/optimizer_steps': 64328, 'local/running_reward': 23894.944153992394, 'local/running_step': 2435.2570104562737, 'local/steps_done': 41173632, 'local/episodes_done': 9760, 'local/unclipped_grad_norm': 0.7489830115262199, 'local/model_version': 64328, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:46,979] {'global/mean_episode_return': 45366.666666666664, 'global/mean_episode_step': 4672.833333333333, 'global/SPS': 3258.1270186128086, 'global/env_act_steps': 41168512, 'global/env_train_steps': 41164800, 'global/optimizer_steps': 64320, 'global/running_reward': 23828.78787878788, 'global/running_step': 2429.524650804924, 'global/steps_done': 41168512, 'global/episodes_done': 9759, 'global/unclipped_grad_norm': 0.775090754032135, 'global/model_version': 64320, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 14:45:52,450] saving global stats {'mean_episode_return': 48300.0, 'mean_episode_step': 4680.5, 'SPS': None, 'env_act_steps': 41181184, 'env_train_steps': 41179520, 'optimizer_steps': 64343, 'running_reward': 24357.780934343435, 'running_step': 2480.040640782828, 'steps_done': 41181184, 'episodes_done': 9761, 'unclipped_grad_norm': 0.6316193601359492, 'model_version': 64343, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 14:45:52,543] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:57,011] calculate_sps 32000 steps in 10.0428
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:45:57,011] calculate_sps 32640 steps in 10.0428
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:57,011] {'local/mean_episode_return': 45200.0, 'local/mean_episode_step': 4555.714285714285, 'local/SPS': 3186.375925556148, 'local/env_act_steps': 41206016, 'local/env_train_steps': 41201920, 'local/optimizer_steps': 64377, 'local/running_reward': 24417.12574110672, 'local/running_step': 2485.2300209980235, 'local/steps_done': 41206016, 'local/episodes_done': 9767, 'local/unclipped_grad_norm': 0.7246477841114511, 'local/model_version': 64377, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:45:57,012] {'global/mean_episode_return': 43200.0, 'global/mean_episode_step': 4369.333333333333, 'global/SPS': 3250.103444067271, 'global/env_act_steps': 41201024, 'global/env_train_steps': 41197440, 'global/optimizer_steps': 64370, 'global/running_reward': 24400.695127952757, 'global/running_step': 2483.5055364173227, 'global/steps_done': 41201024, 'global/episodes_done': 9765, 'global/unclipped_grad_norm': 0.6814895015954971, 'global/model_version': 64370, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:07,041] calculate_sps 34560 steps in 10.0298
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:07,041] calculate_sps 33920 steps in 10.0298
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:07,042] {'local/mean_episode_return': 48911.11111111111, 'local/mean_episode_step': 4894.333333333333, 'local/SPS': 3445.7178982157043, 'local/env_act_steps': 41238400, 'local/env_train_steps': 41236480, 'local/optimizer_steps': 64432, 'local/running_reward': 24043.292984189724, 'local/running_step': 2450.4624505928855, 'local/steps_done': 41238400, 'local/episodes_done': 9776, 'local/unclipped_grad_norm': 0.7661454764279452, 'local/model_version': 64432, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:07,047] {'global/mean_episode_return': 49581.818181818184, 'global/mean_episode_step': 4945.636363636364, 'global/SPS': 3381.908307508006, 'global/env_act_steps': 41233920, 'global/env_train_steps': 41231360, 'global/optimizer_steps': 64424, 'global/running_reward': 24141.08098249027, 'global/running_step': 2459.650291828794, 'global/steps_done': 41233920, 'global/episodes_done': 9776, 'global/unclipped_grad_norm': 0.8056970100711893, 'global/model_version': 64424, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:17,046] calculate_sps 30720 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:17,046] calculate_sps 30720 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:17,046] {'local/mean_episode_return': 48825.0, 'local/mean_episode_step': 4835.5, 'local/SPS': 3070.4950979297605, 'local/env_act_steps': 41271424, 'local/env_train_steps': 41267200, 'local/optimizer_steps': 64480, 'local/running_reward': 23384.580910852714, 'local/running_step': 2392.4398619186045, 'local/steps_done': 41271424, 'local/episodes_done': 9784, 'local/unclipped_grad_norm': 0.8347264714539051, 'local/model_version': 64480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:17,048] {'global/mean_episode_return': 48825.0, 'global/mean_episode_step': 4835.5, 'global/SPS': 3070.4950979297605, 'global/env_act_steps': 41266944, 'global/env_train_steps': 41262080, 'global/optimizer_steps': 64472, 'global/running_reward': 23423.964389534885, 'global/running_step': 2395.4908854166665, 'global/steps_done': 41266944, 'global/episodes_done': 9784, 'global/unclipped_grad_norm': 0.7843025314311186, 'global/model_version': 64472, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:27,069] calculate_sps 34560 steps in 10.0234
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:27,069] calculate_sps 35840 steps in 10.0234
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:27,069] {'local/mean_episode_return': 55200.0, 'local/mean_episode_step': 5396.0, 'local/SPS': 3447.934850497667, 'local/env_act_steps': 41303808, 'local/env_train_steps': 41301760, 'local/optimizer_steps': 64533, 'local/running_reward': 23914.988883399208, 'local/running_step': 2443.3395195158105, 'local/steps_done': 41303808, 'local/episodes_done': 9786, 'local/unclipped_grad_norm': 0.7171040582207014, 'local/model_version': 64533, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:27,070] {'global/mean_episode_return': 55200.0, 'global/mean_episode_step': 5396.0, 'global/SPS': 3575.63614125684, 'global/env_act_steps': 41299456, 'global/env_train_steps': 41297920, 'global/optimizer_steps': 64528, 'global/running_reward': 23794.678887795275, 'global/running_step': 2431.8777066929133, 'global/steps_done': 41299456, 'global/episodes_done': 9786, 'global/unclipped_grad_norm': 0.7579070457390377, 'global/model_version': 64528, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:37,093] calculate_sps 32000 steps in 10.024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:37,094] calculate_sps 30720 steps in 10.024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:37,094] {'local/mean_episode_return': 39600.0, 'local/mean_episode_step': 4163.333333333333, 'local/SPS': 3192.338486273164, 'local/env_act_steps': 41336960, 'local/env_train_steps': 41333760, 'local/optimizer_steps': 64584, 'local/running_reward': 24839.508928571428, 'local/running_step': 2532.752352799228, 'local/steps_done': 41336960, 'local/episodes_done': 9789, 'local/unclipped_grad_norm': 0.7296490721842822, 'local/model_version': 64584, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:37,095] {'global/mean_episode_return': 39600.0, 'global/mean_episode_step': 4163.333333333333, 'global/SPS': 3064.6449468222377, 'global/env_act_steps': 41332992, 'global/env_train_steps': 41328640, 'global/optimizer_steps': 64576, 'global/running_reward': 24729.126908396946, 'global/running_step': 2522.405951812977, 'global/steps_done': 41332992, 'global/episodes_done': 9789, 'global/unclipped_grad_norm': 0.7563248587151369, 'global/model_version': 64576, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:47,094] calculate_sps 32000 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:47,095] calculate_sps 35840 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:47,096] {'local/mean_episode_return': 54266.666666666664, 'local/mean_episode_step': 5230.888888888889, 'local/SPS': 3199.695158437416, 'local/env_act_steps': 41369984, 'local/env_train_steps': 41365760, 'local/optimizer_steps': 64634, 'local/running_reward': 25107.18265503876, 'local/running_step': 2555.388687015504, 'local/steps_done': 41369984, 'local/episodes_done': 9798, 'local/unclipped_grad_norm': 0.763637684583664, 'local/model_version': 64634, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:47,098] {'global/mean_episode_return': 54800.0, 'global/mean_episode_step': 5225.375, 'global/SPS': 3583.6585774499063, 'global/env_act_steps': 41365504, 'global/env_train_steps': 41364480, 'global/optimizer_steps': 64631, 'global/running_reward': 25181.059301181103, 'global/running_step': 2562.859005905512, 'global/steps_done': 41365504, 'global/episodes_done': 9797, 'global/unclipped_grad_norm': 0.7399722782048312, 'global/model_version': 64631, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:57,128] calculate_sps 34560 steps in 10.0337
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:46:57,128] calculate_sps 30720 steps in 10.0337
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:57,129] {'local/mean_episode_return': 46222.22222222222, 'local/mean_episode_step': 4716.666666666667, 'local/SPS': 3444.3924831315708, 'local/env_act_steps': 41402112, 'local/env_train_steps': 41400320, 'local/optimizer_steps': 64688, 'local/running_reward': 24703.815986055775, 'local/running_step': 2511.5561192729083, 'local/steps_done': 41402112, 'local/episodes_done': 9807, 'local/unclipped_grad_norm': 0.7335879681286989, 'local/model_version': 64688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:46:57,130] {'global/mean_episode_return': 46600.0, 'global/mean_episode_step': 4772.5, 'global/SPS': 3061.682207228063, 'global/env_act_steps': 41398912, 'global/env_train_steps': 41395200, 'global/optimizer_steps': 64680, 'global/running_reward': 24732.764607279692, 'global/running_step': 2515.2509578544064, 'global/steps_done': 41398912, 'global/episodes_done': 9807, 'global/unclipped_grad_norm': 0.7350370999501676, 'global/model_version': 64680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:07,139] calculate_sps 30720 steps in 10.0102
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:07,139] calculate_sps 33280 steps in 10.0102
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:07,139] {'local/mean_episode_return': 44028.57142857143, 'local/mean_episode_step': 4521.714285714285, 'local/SPS': 3068.8584162278753, 'local/env_act_steps': 41435136, 'local/env_train_steps': 41431040, 'local/optimizer_steps': 64736, 'local/running_reward': 24527.598110465115, 'local/running_step': 2486.5524467054265, 'local/steps_done': 41435136, 'local/episodes_done': 9814, 'local/unclipped_grad_norm': 0.8113747971753279, 'local/model_version': 64736, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:07,141] {'global/mean_episode_return': 41640.0, 'global/mean_episode_step': 4366.8, 'global/SPS': 3324.596617580198, 'global/env_act_steps': 41431680, 'global/env_train_steps': 41428480, 'global/optimizer_steps': 64731, 'global/running_reward': 24487.432861328125, 'global/running_step': 2483.25244140625, 'global/steps_done': 41431680, 'global/episodes_done': 9812, 'global/unclipped_grad_norm': 0.8140407683802586, 'global/model_version': 64731, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:17,180] calculate_sps 33920 steps in 10.0426
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:17,181] calculate_sps 33280 steps in 10.0426
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:17,181] {'local/mean_episode_return': 51800.0, 'local/mean_episode_step': 5017.166666666667, 'local/SPS': 3377.6268797871608, 'local/env_act_steps': 41467520, 'local/env_train_steps': 41464960, 'local/optimizer_steps': 64788, 'local/running_reward': 24648.548666007904, 'local/running_step': 2496.718132411067, 'local/steps_done': 41467520, 'local/episodes_done': 9820, 'local/unclipped_grad_norm': 0.767387775847545, 'local/model_version': 64788, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:17,182] {'global/mean_episode_return': 51314.28571428572, 'global/mean_episode_step': 4970.857142857143, 'global/SPS': 3313.8980707345727, 'global/env_act_steps': 41464448, 'global/env_train_steps': 41461760, 'global/optimizer_steps': 64784, 'global/running_reward': 24666.30859375, 'global/running_step': 2498.3382873535156, 'global/steps_done': 41464448, 'global/episodes_done': 9819, 'global/unclipped_grad_norm': 0.744718757440459, 'global/model_version': 64784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:27,187] calculate_sps 32640 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:27,187] calculate_sps 31360 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:27,187] {'local/mean_episode_return': 51500.0, 'local/mean_episode_step': 5098.9, 'local/SPS': 3262.1011343194386, 'local/env_act_steps': 41500288, 'local/env_train_steps': 41497600, 'local/optimizer_steps': 64840, 'local/running_reward': 24135.3759765625, 'local/running_step': 2448.6890869140625, 'local/steps_done': 41500288, 'local/episodes_done': 9830, 'local/unclipped_grad_norm': 0.8823917553975031, 'local/model_version': 64840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:27,189] {'global/mean_episode_return': 51480.0, 'global/mean_episode_step': 5071.8, 'global/SPS': 3134.175599640245, 'global/env_act_steps': 41497856, 'global/env_train_steps': 41493120, 'global/optimizer_steps': 64832, 'global/running_reward': 24190.277777777777, 'global/running_step': 2453.9363625478927, 'global/steps_done': 41497856, 'global/episodes_done': 9829, 'global/unclipped_grad_norm': 0.914332078769803, 'global/model_version': 64832, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:37,235] calculate_sps 31360 steps in 10.0484
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:37,235] calculate_sps 35200 steps in 10.0484
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:37,235] {'local/mean_episode_return': 46709.09090909091, 'local/mean_episode_step': 4602.272727272727, 'local/SPS': 3120.894743957713, 'local/env_act_steps': 41533568, 'local/env_train_steps': 41528960, 'local/optimizer_steps': 64888, 'local/running_reward': 23804.158653846152, 'local/running_step': 2412.6904747596154, 'local/steps_done': 41533568, 'local/episodes_done': 9841, 'local/unclipped_grad_norm': 0.7756675658747554, 'local/model_version': 64888, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:37,236] {'global/mean_episode_return': 45840.0, 'global/mean_episode_step': 4600.2, 'global/SPS': 3503.0451207688616, 'global/env_act_steps': 41530496, 'global/env_train_steps': 41528320, 'global/optimizer_steps': 64888, 'global/running_reward': 23850.085784313724, 'global/running_step': 2417.4387254901962, 'global/steps_done': 41530496, 'global/episodes_done': 9839, 'global/unclipped_grad_norm': 0.7589480597525835, 'global/model_version': 64888, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:47,255] calculate_sps 35200 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:47,255] calculate_sps 30720 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:47,256] {'local/mean_episode_return': 50680.0, 'local/mean_episode_step': 5077.2, 'local/SPS': 3512.993618436588, 'local/env_act_steps': 41565824, 'local/env_train_steps': 41564160, 'local/optimizer_steps': 64944, 'local/running_reward': 23394.37003968254, 'local/running_step': 2375.4063740079364, 'local/steps_done': 41565824, 'local/episodes_done': 9846, 'local/unclipped_grad_norm': 0.651962833745139, 'local/model_version': 64944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:47,257] {'global/mean_episode_return': 51514.28571428572, 'global/mean_episode_step': 5057.857142857143, 'global/SPS': 3065.8853397264766, 'global/env_act_steps': 41564032, 'global/env_train_steps': 41559040, 'global/optimizer_steps': 64936, 'global/running_reward': 23393.553196564884, 'global/running_step': 2375.0522423664124, 'global/steps_done': 41564032, 'global/episodes_done': 9846, 'global/unclipped_grad_norm': 0.6638593481232723, 'global/model_version': 64936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:57,290] calculate_sps 30720 steps in 10.0348
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:47:57,290] calculate_sps 35840 steps in 10.0348
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:57,290] {'local/mean_episode_return': 44025.0, 'local/mean_episode_step': 4528.75, 'local/SPS': 3061.3326784700453, 'local/env_act_steps': 41599232, 'local/env_train_steps': 41594880, 'local/optimizer_steps': 64992, 'local/running_reward': 23267.379070881227, 'local/running_step': 2357.696569683908, 'local/steps_done': 41599232, 'local/episodes_done': 9854, 'local/unclipped_grad_norm': 0.7452370946606001, 'local/model_version': 64992, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:47:57,292] {'global/mean_episode_return': 44025.0, 'global/mean_episode_step': 4528.75, 'global/SPS': 3571.554791548386, 'global/env_act_steps': 41596544, 'global/env_train_steps': 41594880, 'global/optimizer_steps': 64992, 'global/running_reward': 23267.427411417324, 'global/running_step': 2358.1163570374015, 'global/steps_done': 41596544, 'global/episodes_done': 9854, 'global/unclipped_grad_norm': 0.7217151879199913, 'global/model_version': 64992, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:07,315] calculate_sps 34560 steps in 10.0251
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:07,315] calculate_sps 30720 steps in 10.0251
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:07,315] {'local/mean_episode_return': 50550.0, 'local/mean_episode_step': 5045.5, 'local/SPS': 3447.3508504701454, 'local/env_act_steps': 41631488, 'local/env_train_steps': 41629440, 'local/optimizer_steps': 65045, 'local/running_reward': 23599.088541666668, 'local/running_step': 2386.8817274305557, 'local/steps_done': 41631488, 'local/episodes_done': 9858, 'local/unclipped_grad_norm': 0.7063753022900168, 'local/model_version': 65045, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:07,316] {'global/mean_episode_return': 50550.0, 'global/mean_episode_step': 5045.5, 'global/SPS': 3064.311867084574, 'global/env_act_steps': 41630080, 'global/env_train_steps': 41625600, 'global/optimizer_steps': 65040, 'global/running_reward': 23568.851383587786, 'global/running_step': 2383.8548127385498, 'global/steps_done': 41630080, 'global/episodes_done': 9858, 'global/unclipped_grad_norm': 0.690801247023046, 'global/model_version': 65040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:17,323] calculate_sps 32000 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:17,323] calculate_sps 35200 steps in 10.0079
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:17,338] {'local/mean_episode_return': 45700.0, 'local/mean_episode_step': 4635.75, 'local/SPS': 3197.4877831362373, 'local/env_act_steps': 41664256, 'local/env_train_steps': 41661440, 'local/optimizer_steps': 65096, 'local/running_reward': 24002.96630859375, 'local/running_step': 2431.6954650878906, 'local/steps_done': 41664256, 'local/episodes_done': 9865, 'local/unclipped_grad_norm': 0.7392399053947598, 'local/model_version': 65096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:17,340] {'global/mean_episode_return': 45700.0, 'global/mean_episode_step': 4635.75, 'global/SPS': 3517.2365614498613, 'global/env_act_steps': 41662336, 'global/env_train_steps': 41660800, 'global/optimizer_steps': 65094, 'global/running_reward': 24007.59548611111, 'global/running_step': 2432.012214781746, 'global/steps_done': 41662336, 'global/episodes_done': 9865, 'global/unclipped_grad_norm': 0.7376627855830722, 'global/model_version': 65094, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:27,336] calculate_sps 32000 steps in 10.0132
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:27,336] calculate_sps 31360 steps in 10.0132
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:27,336] {'local/mean_episode_return': 51360.0, 'local/mean_episode_step': 5141.0, 'local/SPS': 3195.792283223897, 'local/env_act_steps': 41697536, 'local/env_train_steps': 41693440, 'local/optimizer_steps': 65145, 'local/running_reward': 24006.08173076923, 'local/running_step': 2433.643028846154, 'local/steps_done': 41697536, 'local/episodes_done': 9870, 'local/unclipped_grad_norm': 0.7271958978808656, 'local/model_version': 65145, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:27,337] {'global/mean_episode_return': 50550.0, 'global/mean_episode_step': 5076.5, 'global/SPS': 3131.876437559419, 'global/env_act_steps': 41696256, 'global/env_train_steps': 41692160, 'global/optimizer_steps': 65144, 'global/running_reward': 23983.549528301886, 'global/running_step': 2431.4088738207547, 'global/steps_done': 41696256, 'global/episodes_done': 9869, 'global/unclipped_grad_norm': 0.7439522349834442, 'global/model_version': 65144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:37,347] calculate_sps 34560 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:37,347] calculate_sps 33920 steps in 10.011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:37,347] {'local/mean_episode_return': 47900.0, 'local/mean_episode_step': 4741.0, 'local/SPS': 3452.1933150096133, 'local/env_act_steps': 41729792, 'local/env_train_steps': 41728000, 'local/optimizer_steps': 65200, 'local/running_reward': 24203.974454365078, 'local/running_step': 2450.4719742063494, 'local/steps_done': 41729792, 'local/episodes_done': 9876, 'local/unclipped_grad_norm': 0.7203679702498696, 'local/model_version': 65200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:37,359] {'global/mean_episode_return': 47466.666666666664, 'global/mean_episode_step': 4741.166666666667, 'global/SPS': 3388.263809176102, 'global/env_act_steps': 41728640, 'global/env_train_steps': 41726080, 'global/optimizer_steps': 65196, 'global/running_reward': 24198.2398715415, 'global/running_step': 2450.0015130928855, 'global/steps_done': 41728640, 'global/episodes_done': 9875, 'global/unclipped_grad_norm': 0.7180651793113122, 'global/model_version': 65196, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:47,368] calculate_sps 30720 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:47,369] calculate_sps 32640 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:47,369] {'local/mean_episode_return': 45280.0, 'local/mean_episode_step': 4633.6, 'local/SPS': 3065.449520012613, 'local/env_act_steps': 41763328, 'local/env_train_steps': 41758720, 'local/optimizer_steps': 65248, 'local/running_reward': 24308.104723282442, 'local/running_step': 2460.434309398855, 'local/steps_done': 41763328, 'local/episodes_done': 9881, 'local/unclipped_grad_norm': 0.761809416115284, 'local/model_version': 65248, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:47,370] {'global/mean_episode_return': 47266.666666666664, 'global/mean_episode_step': 4761.0, 'global/SPS': 3257.040115013401, 'global/env_act_steps': 41762304, 'global/env_train_steps': 41758720, 'global/optimizer_steps': 65248, 'global/running_reward': 24302.00213878327, 'global/running_step': 2459.8966848859313, 'global/steps_done': 41762304, 'global/episodes_done': 9881, 'global/unclipped_grad_norm': 0.75826084957673, 'global/model_version': 65248, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:57,386] calculate_sps 35200 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:48:57,386] calculate_sps 33280 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:57,388] {'local/mean_episode_return': 51275.0, 'local/mean_episode_step': 5044.875, 'local/SPS': 3513.8834040801075, 'local/env_act_steps': 41795584, 'local/env_train_steps': 41793920, 'local/optimizer_steps': 65303, 'local/running_reward': 24718.179563492064, 'local/running_step': 2498.6061817956347, 'local/steps_done': 41795584, 'local/episodes_done': 9889, 'local/unclipped_grad_norm': 0.7774952113628387, 'local/model_version': 65303, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:48:57,389] {'global/mean_episode_return': 51275.0, 'global/mean_episode_step': 5044.875, 'global/SPS': 3322.2170365848287, 'global/env_act_steps': 41795200, 'global/env_train_steps': 41792000, 'global/optimizer_steps': 65299, 'global/running_reward': 24722.945038910504, 'global/running_step': 2499.0755107003893, 'global/steps_done': 41795200, 'global/episodes_done': 9889, 'global/unclipped_grad_norm': 0.7882780683975593, 'global/model_version': 65299, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:07,410] calculate_sps 31360 steps in 10.0244
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:07,410] calculate_sps 33280 steps in 10.0244
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:07,411] {'local/mean_episode_return': 49000.0, 'local/mean_episode_step': 4837.071428571428, 'local/SPS': 3128.3575602195765, 'local/env_act_steps': 41828864, 'local/env_train_steps': 41825280, 'local/optimizer_steps': 65352, 'local/running_reward': 24522.69230769231, 'local/running_step': 2480.9756610576924, 'local/steps_done': 41828864, 'local/episodes_done': 9897, 'local/unclipped_grad_norm': 0.6509522461161321, 'local/model_version': 65352, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:07,412] {'global/mean_episode_return': 50000.0, 'global/mean_episode_step': 4914.083333333333, 'global/SPS': 3319.889655743224, 'global/env_act_steps': 41828096, 'global/env_train_steps': 41825280, 'global/optimizer_steps': 65352, 'global/running_reward': 24525.863326848248, 'global/running_step': 2481.161357003891, 'global/steps_done': 41828096, 'global/episodes_done': 9896, 'global/unclipped_grad_norm': 0.6501267018183222, 'global/model_version': 65352, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:17,413] calculate_sps 32640 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:17,416] calculate_sps 32000 steps in 10.001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:17,416] {'local/mean_episode_return': 46175.0, 'local/mean_episode_step': 4803.875, 'local/SPS': 3263.665097842667, 'local/env_act_steps': 41861632, 'local/env_train_steps': 41857920, 'local/optimizer_steps': 65402, 'local/running_reward': 23722.59521484375, 'local/running_step': 2405.405487060547, 'local/steps_done': 41861632, 'local/episodes_done': 9905, 'local/unclipped_grad_norm': 0.7086765462160111, 'local/model_version': 65402, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:17,424] {'global/mean_episode_return': 45822.22222222222, 'global/mean_episode_step': 4756.222222222223, 'global/SPS': 3199.671664551634, 'global/env_act_steps': 41861504, 'global/env_train_steps': 41857280, 'global/optimizer_steps': 65402, 'global/running_reward': 23730.118534482757, 'global/running_step': 2406.1596324233715, 'global/steps_done': 41861504, 'global/episodes_done': 9905, 'global/unclipped_grad_norm': 0.7086765462160111, 'global/model_version': 65402, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:27,429] calculate_sps 33920 steps in 10.0182
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:27,430] calculate_sps 34560 steps in 10.0182
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:27,438] {'local/mean_episode_return': 47520.0, 'local/mean_episode_step': 4790.4, 'local/SPS': 3385.8418309708254, 'local/env_act_steps': 41893888, 'local/env_train_steps': 41891840, 'local/optimizer_steps': 65456, 'local/running_reward': 24221.8501984127, 'local/running_step': 2454.5505952380954, 'local/steps_done': 41893888, 'local/episodes_done': 9910, 'local/unclipped_grad_norm': 0.7008983617027601, 'local/model_version': 65456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:27,440] {'global/mean_episode_return': 47520.0, 'global/mean_episode_step': 4790.4, 'global/SPS': 3449.72563910235, 'global/env_act_steps': 41893760, 'global/env_train_steps': 41891840, 'global/optimizer_steps': 65456, 'global/running_reward': 24219.952876984127, 'global/running_step': 2454.3565228174602, 'global/steps_done': 41893760, 'global/episodes_done': 9910, 'global/unclipped_grad_norm': 0.7008983617027601, 'global/model_version': 65456, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:37,430] calculate_sps 30720 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:37,431] calculate_sps 25600 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:37,431] {'local/mean_episode_return': 52742.857142857145, 'local/mean_episode_step': 5242.714285714285, 'local/SPS': 3071.6730816689355, 'local/env_act_steps': 41927040, 'local/env_train_steps': 41922560, 'local/optimizer_steps': 65504, 'local/running_reward': 24312.156129343628, 'local/running_step': 2465.4013634169883, 'local/steps_done': 41927040, 'local/episodes_done': 9917, 'local/unclipped_grad_norm': 0.681696331128478, 'local/model_version': 65504, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:37,432] {'global/mean_episode_return': 53200.0, 'global/mean_episode_step': 5184.0, 'global/SPS': 2559.727568057446, 'global/env_act_steps': 41920384, 'global/env_train_steps': 41917440, 'global/optimizer_steps': 65496, 'global/running_reward': 24359.247295673078, 'global/running_step': 2470.146259014423, 'global/steps_done': 41920384, 'global/episodes_done': 9915, 'global/unclipped_grad_norm': 0.6915094420313835, 'global/model_version': 65496, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:47,433] calculate_sps 34560 steps in 10.003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:47,433] calculate_sps 32000 steps in 10.003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:47,433] {'local/mean_episode_return': 47960.0, 'local/mean_episode_step': 4823.2, 'local/SPS': 3454.961774392022, 'local/env_act_steps': 41959168, 'local/env_train_steps': 41957120, 'local/optimizer_steps': 65557, 'local/running_reward': 24356.542579681274, 'local/running_step': 2467.499875498008, 'local/steps_done': 41959168, 'local/episodes_done': 9922, 'local/unclipped_grad_norm': 0.7757208066166572, 'local/model_version': 65557, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:47,434] {'global/mean_episode_return': 48200.0, 'global/mean_episode_step': 4916.833333333333, 'global/SPS': 3199.038679992613, 'global/env_act_steps': 41953536, 'global/env_train_steps': 41949440, 'global/optimizer_steps': 65545, 'global/running_reward': 24317.217664092663, 'global/running_step': 2464.1082589285716, 'global/steps_done': 41953536, 'global/episodes_done': 9921, 'global/unclipped_grad_norm': 0.7182072808547896, 'global/model_version': 65545, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:57,461] calculate_sps 32000 steps in 10.0274
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:49:57,461] calculate_sps 34560 steps in 10.0274
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:57,461] {'local/mean_episode_return': 47828.57142857143, 'local/mean_episode_step': 4897.857142857143, 'local/SPS': 3191.2544357808497, 'local/env_act_steps': 41992320, 'local/env_train_steps': 41989120, 'local/optimizer_steps': 65608, 'local/running_reward': 24251.936534749035, 'local/running_step': 2457.489412403475, 'local/steps_done': 41992320, 'local/episodes_done': 9929, 'local/unclipped_grad_norm': 0.8137523073191736, 'local/model_version': 65608, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:49:57,475] {'global/mean_episode_return': 48575.0, 'global/mean_episode_step': 4959.875, 'global/SPS': 3446.5547906433176, 'global/env_act_steps': 41986176, 'global/env_train_steps': 41984000, 'global/optimizer_steps': 65600, 'global/running_reward': 24265.998774509804, 'global/running_step': 2458.743780637255, 'global/steps_done': 41986176, 'global/episodes_done': 9929, 'global/unclipped_grad_norm': 0.8411339637908068, 'global/model_version': 65600, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:07,495] calculate_sps 31360 steps in 10.0342
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:07,495] calculate_sps 30720 steps in 10.0342
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:07,495] {'local/mean_episode_return': 51300.0, 'local/mean_episode_step': 5143.0, 'local/SPS': 3125.3041721158497, 'local/env_act_steps': 42025088, 'local/env_train_steps': 42020480, 'local/optimizer_steps': 65656, 'local/running_reward': 24420.05615234375, 'local/running_step': 2474.193115234375, 'local/steps_done': 42025088, 'local/episodes_done': 9935, 'local/unclipped_grad_norm': 0.6633872396002213, 'local/model_version': 65656, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:07,496] {'global/mean_episode_return': 51250.0, 'global/mean_episode_step': 5204.5, 'global/SPS': 3061.5224543175673, 'global/env_act_steps': 42019584, 'global/env_train_steps': 42014720, 'global/optimizer_steps': 65648, 'global/running_reward': 24362.47006704981, 'global/running_step': 2468.417654454023, 'global/steps_done': 42019584, 'global/episodes_done': 9933, 'global/unclipped_grad_norm': 0.6857672308882078, 'global/model_version': 65648, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:17,511] calculate_sps 35200 steps in 10.0163
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:17,512] calculate_sps 35200 steps in 10.0163
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:17,512] {'local/mean_episode_return': 53700.0, 'local/mean_episode_step': 5169.5, 'local/SPS': 3514.283544799626, 'local/env_act_steps': 42057088, 'local/env_train_steps': 42055680, 'local/optimizer_steps': 65712, 'local/running_reward': 24776.08125, 'local/running_step': 2512.18665625, 'local/steps_done': 42057088, 'local/episodes_done': 9937, 'local/unclipped_grad_norm': 0.7312715207891805, 'local/model_version': 65712, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:17,513] {'global/mean_episode_return': 52550.0, 'global/mean_episode_step': 5094.75, 'global/SPS': 3514.283544799626, 'global/env_act_steps': 42051584, 'global/env_train_steps': 42049920, 'global/optimizer_steps': 65703, 'global/running_reward': 24676.94375, 'global/running_step': 2501.68025, 'global/steps_done': 42051584, 'global/episodes_done': 9937, 'global/unclipped_grad_norm': 0.6949760924686085, 'global/model_version': 65703, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:27,527] calculate_sps 30720 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:27,527] calculate_sps 31360 steps in 10.0153
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:27,527] {'local/mean_episode_return': 52142.857142857145, 'local/mean_episode_step': 5036.714285714285, 'local/SPS': 3067.3040886534523, 'local/env_act_steps': 42090368, 'local/env_train_steps': 42086400, 'local/optimizer_steps': 65760, 'local/running_reward': 25191.189903846152, 'local/running_step': 2558.889122596154, 'local/steps_done': 42090368, 'local/episodes_done': 9944, 'local/unclipped_grad_norm': 0.8029364986966053, 'local/model_version': 65760, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:27,529] {'global/mean_episode_return': 53700.0, 'global/mean_episode_step': 5148.0, 'global/SPS': 3131.206257167066, 'global/env_act_steps': 42085376, 'global/env_train_steps': 42081280, 'global/optimizer_steps': 65752, 'global/running_reward': 25185.398910984848, 'global/running_step': 2557.497247869318, 'global/steps_done': 42085376, 'global/episodes_done': 9943, 'global/unclipped_grad_norm': 0.8082102537155151, 'global/model_version': 65752, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:37,540] calculate_sps 34560 steps in 10.0137
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:37,540] calculate_sps 34560 steps in 10.0137
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:37,540] {'local/mean_episode_return': 46400.0, 'local/mean_episode_step': 4827.5, 'local/SPS': 3451.2770959978343, 'local/env_act_steps': 42123008, 'local/env_train_steps': 42120960, 'local/optimizer_steps': 65813, 'local/running_reward': 25470.44730392157, 'local/running_step': 2585.178370098039, 'local/steps_done': 42123008, 'local/episodes_done': 9946, 'local/unclipped_grad_norm': 0.8324286853367427, 'local/model_version': 65813, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:37,541] {'global/mean_episode_return': 45200.0, 'global/mean_episode_step': 4674.666666666667, 'global/SPS': 3451.2770959978343, 'global/env_act_steps': 42118016, 'global/env_train_steps': 42115840, 'global/optimizer_steps': 65806, 'global/running_reward': 25354.66911764706, 'global/running_step': 2574.3279411764706, 'global/steps_done': 42118016, 'global/episodes_done': 9946, 'global/unclipped_grad_norm': 0.8479065944751104, 'global/model_version': 65806, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:47,562] calculate_sps 32000 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:47,574] calculate_sps 32000 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:47,574] {'local/mean_episode_return': 49128.57142857143, 'local/mean_episode_step': 4911.571428571428, 'local/SPS': 3193.1584268763145, 'local/env_act_steps': 42155776, 'local/env_train_steps': 42152960, 'local/optimizer_steps': 65864, 'local/running_reward': 25676.287841796875, 'local/running_step': 2603.6128540039062, 'local/steps_done': 42155776, 'local/episodes_done': 9954, 'local/unclipped_grad_norm': 0.723501207781773, 'local/model_version': 65864, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:47,576] {'global/mean_episode_return': 50483.333333333336, 'global/mean_episode_step': 4965.666666666667, 'global/SPS': 3193.1584268763145, 'global/env_act_steps': 42151424, 'global/env_train_steps': 42147840, 'global/optimizer_steps': 65856, 'global/running_reward': 25694.695881226053, 'global/running_step': 2605.5471443965516, 'global/steps_done': 42151424, 'global/episodes_done': 9953, 'global/unclipped_grad_norm': 0.7394248348474503, 'global/model_version': 65856, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:57,562] calculate_sps 31360 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:50:57,563] calculate_sps 33280 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:57,563] {'local/mean_episode_return': 48422.22222222222, 'local/mean_episode_step': 4814.111111111111, 'local/SPS': 3135.6426493677145, 'local/env_act_steps': 42188928, 'local/env_train_steps': 42184320, 'local/optimizer_steps': 65912, 'local/running_reward': 25559.93605212355, 'local/running_step': 2590.661015926641, 'local/steps_done': 42188928, 'local/episodes_done': 9963, 'local/unclipped_grad_norm': 0.79657442184786, 'local/model_version': 65912, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:50:57,564] {'global/mean_episode_return': 47680.0, 'global/mean_episode_step': 4791.4, 'global/SPS': 3327.6207707575745, 'global/env_act_steps': 42184192, 'global/env_train_steps': 42181120, 'global/optimizer_steps': 65907, 'global/running_reward': 25631.7626953125, 'global/running_step': 2597.4931030273438, 'global/steps_done': 42184192, 'global/episodes_done': 9963, 'global/unclipped_grad_norm': 0.7869527018537709, 'global/model_version': 65907, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:07,563] calculate_sps 35200 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:07,563] calculate_sps 33280 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:07,575] {'local/mean_episode_return': 47057.142857142855, 'local/mean_episode_step': 4857.0, 'local/SPS': 3519.8966934006316, 'local/env_act_steps': 42220800, 'local/env_train_steps': 42219520, 'local/optimizer_steps': 65968, 'local/running_reward': 25360.924949799195, 'local/running_step': 2573.023311997992, 'local/steps_done': 42220800, 'local/episodes_done': 9970, 'local/unclipped_grad_norm': 0.8083929360977241, 'local/model_version': 65968, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:07,577] {'global/mean_episode_return': 47300.0, 'global/mean_episode_step': 4874.166666666667, 'global/SPS': 3327.9023283060515, 'global/env_act_steps': 42216960, 'global/env_train_steps': 42214400, 'global/optimizer_steps': 65960, 'global/running_reward': 25354.00390625, 'global/running_step': 2572.7249145507812, 'global/steps_done': 42216960, 'global/episodes_done': 9969, 'global/unclipped_grad_norm': 0.775092398782946, 'global/model_version': 65960, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:17,579] calculate_sps 30720 steps in 10.0161
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:17,580] calculate_sps 32000 steps in 10.0161
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:17,580] {'local/mean_episode_return': 48925.0, 'local/mean_episode_step': 4815.0, 'local/SPS': 3067.0508086007185, 'local/env_act_steps': 42254464, 'local/env_train_steps': 42250240, 'local/optimizer_steps': 66016, 'local/running_reward': 25355.008317490494, 'local/running_step': 2570.893357889734, 'local/steps_done': 42254464, 'local/episodes_done': 9978, 'local/unclipped_grad_norm': 0.685523608699441, 'local/model_version': 66016, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:17,581] {'global/mean_episode_return': 51857.142857142855, 'global/mean_episode_step': 5070.857142857143, 'global/SPS': 3194.844592292415, 'global/env_act_steps': 42250496, 'global/env_train_steps': 42246400, 'global/optimizer_steps': 66009, 'global/running_reward': 25353.03554389313, 'global/running_step': 2570.4634422709923, 'global/steps_done': 42250496, 'global/episodes_done': 9976, 'global/unclipped_grad_norm': 0.7451895974120315, 'global/model_version': 66009, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:27,608] calculate_sps 34560 steps in 10.0295
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:27,609] calculate_sps 34560 steps in 10.0295
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:27,609] {'local/mean_episode_return': 44550.0, 'local/mean_episode_step': 4745.5, 'local/SPS': 3445.8270849081077, 'local/env_act_steps': 42286848, 'local/env_train_steps': 42284800, 'local/optimizer_steps': 66069, 'local/running_reward': 25495.855978260868, 'local/running_step': 2580.3929718379445, 'local/steps_done': 42286848, 'local/episodes_done': 9982, 'local/unclipped_grad_norm': 0.8760986586786667, 'local/model_version': 66069, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:27,610] {'global/mean_episode_return': 42033.333333333336, 'global/mean_episode_step': 4460.0, 'global/SPS': 3445.8270849081077, 'global/env_act_steps': 42283264, 'global/env_train_steps': 42280960, 'global/optimizer_steps': 66064, 'global/running_reward': 25464.0625, 'global/running_step': 2578.259796142578, 'global/steps_done': 42283264, 'global/episodes_done': 9982, 'global/unclipped_grad_norm': 0.8371727829629725, 'global/model_version': 66064, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:37,621] calculate_sps 32000 steps in 10.0118
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:37,621] calculate_sps 30720 steps in 10.0118
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:37,621] {'local/mean_episode_return': 50257.142857142855, 'local/mean_episode_step': 4847.428571428572, 'local/SPS': 3196.2281297745835, 'local/env_act_steps': 42319872, 'local/env_train_steps': 42316800, 'local/optimizer_steps': 66120, 'local/running_reward': 25887.772529069767, 'local/running_step': 2618.4737766472867, 'local/steps_done': 42319872, 'local/episodes_done': 9989, 'local/unclipped_grad_norm': 0.6852061129083821, 'local/model_version': 66120, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:37,627] {'global/mean_episode_return': 50257.142857142855, 'global/mean_episode_step': 4847.428571428572, 'global/SPS': 3068.3790045836004, 'global/env_act_steps': 42316800, 'global/env_train_steps': 42311680, 'global/optimizer_steps': 66112, 'global/running_reward': 25888.53172709924, 'global/running_step': 2618.3775047709923, 'global/steps_done': 42316800, 'global/episodes_done': 9989, 'global/unclipped_grad_norm': 0.7162754957874616, 'global/model_version': 66112, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:47,658] calculate_sps 32000 steps in 10.0379
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:47,658] calculate_sps 35840 steps in 10.0379
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:47,659] {'local/mean_episode_return': 48276.92307692308, 'local/mean_episode_step': 4798.7692307692305, 'local/SPS': 3187.921662446395, 'local/env_act_steps': 42352896, 'local/env_train_steps': 42348800, 'local/optimizer_steps': 66169, 'local/running_reward': 25387.148740310076, 'local/running_step': 2568.6363250968993, 'local/steps_done': 42352896, 'local/episodes_done': 10002, 'local/unclipped_grad_norm': 0.8183192063351067, 'local/model_version': 66169, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:47,659] {'global/mean_episode_return': 48220.0, 'global/mean_episode_step': 4784.8, 'global/SPS': 3570.4722619399627, 'global/env_act_steps': 42349312, 'global/env_train_steps': 42347520, 'global/optimizer_steps': 66168, 'global/running_reward': 25483.69217519685, 'global/running_step': 2577.953371062992, 'global/steps_done': 42349312, 'global/episodes_done': 9999, 'global/unclipped_grad_norm': 0.7941922917962074, 'global/model_version': 66168, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:57,668] calculate_sps 34560 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:51:57,668] calculate_sps 30720 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:57,669] {'local/mean_episode_return': 51850.0, 'local/mean_episode_step': 5087.5, 'local/SPS': 3452.7000868706136, 'local/env_act_steps': 42385280, 'local/env_train_steps': 42383360, 'local/optimizer_steps': 66224, 'local/running_reward': 24418.299160079052, 'local/running_step': 2474.982923666008, 'local/steps_done': 42385280, 'local/episodes_done': 10010, 'local/unclipped_grad_norm': 0.7570097939534621, 'local/model_version': 66224, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:51:57,679] {'global/mean_episode_return': 50360.0, 'global/mean_episode_step': 5023.1, 'global/SPS': 3069.0667438849896, 'global/env_act_steps': 42382848, 'global/env_train_steps': 42378240, 'global/optimizer_steps': 66216, 'global/running_reward': 24469.62070610687, 'global/running_step': 2479.7546517175574, 'global/steps_done': 42382848, 'global/episodes_done': 10009, 'global/unclipped_grad_norm': 0.7287776246666908, 'global/model_version': 66216, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:07,676] calculate_sps 30720 steps in 10.0078
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:07,677] calculate_sps 35200 steps in 10.0078
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:07,677] {'local/mean_episode_return': 45675.0, 'local/mean_episode_step': 4665.125, 'local/SPS': 3069.6088938288885, 'local/env_act_steps': 42418304, 'local/env_train_steps': 42414080, 'local/optimizer_steps': 66272, 'local/running_reward': 23917.07848837209, 'local/running_step': 2427.2112100290697, 'local/steps_done': 42418304, 'local/episodes_done': 10018, 'local/unclipped_grad_norm': 0.7316550879428784, 'local/model_version': 66272, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:07,678] {'global/mean_episode_return': 51542.857142857145, 'global/mean_episode_step': 5042.0, 'global/SPS': 3517.2601908456013, 'global/env_act_steps': 42414976, 'global/env_train_steps': 42413440, 'global/optimizer_steps': 66270, 'global/running_reward': 23915.2265936255, 'global/running_step': 2427.191857569721, 'global/steps_done': 42414976, 'global/episodes_done': 10016, 'global/unclipped_grad_norm': 0.7629327040027689, 'global/model_version': 66270, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:17,697] calculate_sps 33920 steps in 10.0043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:17,697] calculate_sps 31360 steps in 10.0043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:17,698] {'local/mean_episode_return': 39920.0, 'local/mean_episode_step': 4205.8, 'local/SPS': 3390.543400727803, 'local/env_act_steps': 42450688, 'local/env_train_steps': 42448000, 'local/optimizer_steps': 66324, 'local/running_reward': 24258.769762845848, 'local/running_step': 2456.065155632411, 'local/steps_done': 42450688, 'local/episodes_done': 10023, 'local/unclipped_grad_norm': 0.7367575260309073, 'local/model_version': 66324, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:17,706] {'global/mean_episode_return': 37257.142857142855, 'global/mean_episode_step': 4008.714285714286, 'global/SPS': 3134.6533327483467, 'global/env_act_steps': 42448256, 'global/env_train_steps': 42444800, 'global/optimizer_steps': 66320, 'global/running_reward': 24228.55769230769, 'global/running_step': 2453.675841346154, 'global/steps_done': 42448256, 'global/episodes_done': 10023, 'global/unclipped_grad_norm': 0.7141512149572372, 'global/model_version': 66320, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:27,689] calculate_sps 32640 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:27,689] calculate_sps 33280 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:27,689] {'local/mean_episode_return': 51309.09090909091, 'local/mean_episode_step': 5020.545454545455, 'local/SPS': 3261.1658526302763, 'local/env_act_steps': 42483456, 'local/env_train_steps': 42480640, 'local/optimizer_steps': 66376, 'local/running_reward': 23667.9931640625, 'local/running_step': 2403.761749267578, 'local/steps_done': 42483456, 'local/episodes_done': 10034, 'local/unclipped_grad_norm': 0.8767937192550073, 'local/model_version': 66376, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:27,691] {'global/mean_episode_return': 51309.09090909091, 'global/mean_episode_step': 5020.545454545455, 'global/SPS': 3325.1102811132228, 'global/env_act_steps': 42481280, 'global/env_train_steps': 42478080, 'global/optimizer_steps': 66372, 'global/running_reward': 23737.239583333332, 'global/running_step': 2410.0307049418607, 'global/steps_done': 42481280, 'global/episodes_done': 10034, 'global/unclipped_grad_norm': 0.8596522361040115, 'global/model_version': 66372, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:37,691] calculate_sps 31360 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:37,691] calculate_sps 33280 steps in 10.0002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:37,691] {'local/mean_episode_return': 41750.0, 'local/mean_episode_step': 4397.125, 'local/SPS': 3135.927401888198, 'local/env_act_steps': 42516736, 'local/env_train_steps': 42512000, 'local/optimizer_steps': 66424, 'local/running_reward': 23531.436298076922, 'local/running_step': 2385.911778846154, 'local/steps_done': 42516736, 'local/episodes_done': 10042, 'local/unclipped_grad_norm': 0.7293072504301866, 'local/model_version': 66424, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:37,693] {'global/mean_episode_return': 42766.666666666664, 'global/mean_episode_step': 4475.0, 'global/SPS': 3327.9229571058427, 'global/env_act_steps': 42514432, 'global/env_train_steps': 42511360, 'global/optimizer_steps': 66424, 'global/running_reward': 23519.636824324323, 'global/running_step': 2385.219624758687, 'global/steps_done': 42514432, 'global/episodes_done': 10040, 'global/unclipped_grad_norm': 0.7578298816314111, 'global/model_version': 66424, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:47,689] calculate_sps 35200 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:47,690] calculate_sps 33280 steps in 10.0003
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:47,690] {'local/mean_episode_return': 41166.666666666664, 'local/mean_episode_step': 4093.1666666666665, 'local/SPS': 3519.8897281860627, 'local/env_act_steps': 42549248, 'local/env_train_steps': 42547200, 'local/optimizer_steps': 66480, 'local/running_reward': 23724.64936023622, 'local/running_step': 2403.377091535433, 'local/steps_done': 42549248, 'local/episodes_done': 10048, 'local/unclipped_grad_norm': 0.7219057458319834, 'local/model_version': 66480, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:47,691] {'global/mean_episode_return': 40550.0, 'global/mean_episode_step': 4110.75, 'global/SPS': 3327.8957430122778, 'global/env_act_steps': 42547712, 'global/env_train_steps': 42544640, 'global/optimizer_steps': 66475, 'global/running_reward': 23719.21875, 'global/running_step': 2402.712560096154, 'global/steps_done': 42547712, 'global/episodes_done': 10048, 'global/unclipped_grad_norm': 0.7338374598937876, 'global/model_version': 66475, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:57,699] calculate_sps 30720 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:52:57,699] calculate_sps 33280 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:57,699] {'local/mean_episode_return': 55333.333333333336, 'local/mean_episode_step': 5319.333333333333, 'local/SPS': 3069.135388560501, 'local/env_act_steps': 42582528, 'local/env_train_steps': 42577920, 'local/optimizer_steps': 66528, 'local/running_reward': 24150.45673076923, 'local/running_step': 2447.9846153846156, 'local/steps_done': 42582528, 'local/episodes_done': 10051, 'local/unclipped_grad_norm': 0.7032280856122574, 'local/model_version': 66528, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:52:57,701] {'global/mean_episode_return': 55333.333333333336, 'global/mean_episode_step': 5319.333333333333, 'global/SPS': 3324.8966709405427, 'global/env_act_steps': 42580608, 'global/env_train_steps': 42577920, 'global/optimizer_steps': 66528, 'global/running_reward': 24115.7405155642, 'global/running_step': 2444.538211332685, 'global/steps_done': 42580608, 'global/episodes_done': 10051, 'global/unclipped_grad_norm': 0.6935086683282312, 'global/model_version': 66528, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:07,707] calculate_sps 33920 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:07,708] calculate_sps 30720 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:07,708] {'local/mean_episode_return': 53690.90909090909, 'local/mean_episode_step': 5133.272727272727, 'local/SPS': 3388.9385413805744, 'local/env_act_steps': 42614400, 'local/env_train_steps': 42611840, 'local/optimizer_steps': 66580, 'local/running_reward': 24053.564257028112, 'local/running_step': 2444.350338855422, 'local/steps_done': 42614400, 'local/episodes_done': 10062, 'local/unclipped_grad_norm': 0.6700293774215075, 'local/model_version': 66580, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:07,709] {'global/mean_episode_return': 53690.90909090909, 'global/mean_episode_step': 5133.272727272727, 'global/SPS': 3069.2273582314638, 'global/env_act_steps': 42613632, 'global/env_train_steps': 42608640, 'global/optimizer_steps': 66576, 'global/running_reward': 24093.507751937985, 'global/running_step': 2447.7378270348836, 'global/steps_done': 42613632, 'global/episodes_done': 10062, 'global/unclipped_grad_norm': 0.6434587448214492, 'global/model_version': 66576, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:17,720] calculate_sps 32640 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:17,720] calculate_sps 35840 steps in 10.0119
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:17,734] {'local/mean_episode_return': 49833.333333333336, 'local/mean_episode_step': 4940.333333333333, 'local/SPS': 3260.1223367896614, 'local/env_act_steps': 42647296, 'local/env_train_steps': 42644480, 'local/optimizer_steps': 66632, 'local/running_reward': 23298.346303501945, 'local/running_step': 2379.4083171206225, 'local/steps_done': 42647296, 'local/episodes_done': 10068, 'local/unclipped_grad_norm': 0.6482575595951997, 'local/model_version': 66632, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:17,735] {'global/mean_episode_return': 49833.333333333336, 'global/mean_episode_step': 4940.333333333333, 'global/SPS': 3579.742173729824, 'global/env_act_steps': 42646144, 'global/env_train_steps': 42644480, 'global/optimizer_steps': 66632, 'global/running_reward': 23288.884104330707, 'global/running_step': 2378.4324557086616, 'global/steps_done': 42646144, 'global/episodes_done': 10068, 'global/unclipped_grad_norm': 0.6725875173828432, 'global/model_version': 66632, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:27,751] calculate_sps 31360 steps in 10.0315
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:27,751] calculate_sps 30720 steps in 10.0315
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:27,751] {'local/mean_episode_return': 47777.77777777778, 'local/mean_episode_step': 4916.0, 'local/SPS': 3126.138545252743, 'local/env_act_steps': 42680448, 'local/env_train_steps': 42675840, 'local/optimizer_steps': 66680, 'local/running_reward': 23081.237934362933, 'local/running_step': 2358.2668315637065, 'local/steps_done': 42680448, 'local/episodes_done': 10077, 'local/unclipped_grad_norm': 0.6586485834171375, 'local/model_version': 66680, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:27,752] {'global/mean_episode_return': 47777.77777777778, 'global/mean_episode_step': 4916.0, 'global/SPS': 3062.3397994312586, 'global/env_act_steps': 42679680, 'global/env_train_steps': 42675200, 'global/optimizer_steps': 66680, 'global/running_reward': 23100.846851145037, 'global/running_step': 2360.156130725191, 'global/steps_done': 42679680, 'global/episodes_done': 10077, 'global/unclipped_grad_norm': 0.6586485834171375, 'global/model_version': 66680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:37,761] calculate_sps 35200 steps in 10.0102
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:37,761] calculate_sps 33920 steps in 10.0102
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:37,761] {'local/mean_episode_return': 42200.0, 'local/mean_episode_step': 4345.8, 'local/SPS': 3516.412663901432, 'local/env_act_steps': 42712064, 'local/env_train_steps': 42711040, 'local/optimizer_steps': 66735, 'local/running_reward': 23310.30490890688, 'local/running_step': 2382.414378795547, 'local/steps_done': 42712064, 'local/episodes_done': 10082, 'local/unclipped_grad_norm': 0.726028313961896, 'local/model_version': 66735, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:37,762] {'global/mean_episode_return': 42200.0, 'global/mean_episode_step': 4345.8, 'global/SPS': 3388.5431124868346, 'global/env_act_steps': 42711808, 'global/env_train_steps': 42709120, 'global/optimizer_steps': 66733, 'global/running_reward': 23303.16857569721, 'global/running_step': 2381.6800298804783, 'global/steps_done': 42711808, 'global/episodes_done': 10082, 'global/unclipped_grad_norm': 0.7277689064448735, 'global/model_version': 66733, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:47,772] calculate_sps 30720 steps in 10.0104
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:47,772] calculate_sps 32640 steps in 10.0104
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:47,772] {'local/mean_episode_return': 49342.857142857145, 'local/mean_episode_step': 4866.857142857143, 'local/SPS': 3068.8141959257364, 'local/env_act_steps': 42745344, 'local/env_train_steps': 42741760, 'local/optimizer_steps': 66784, 'local/running_reward': 23262.181490384617, 'local/running_step': 2379.2224158653844, 'local/steps_done': 42745344, 'local/episodes_done': 10089, 'local/unclipped_grad_norm': 0.7397977557717538, 'local/model_version': 66784, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:47,774] {'global/mean_episode_return': 49342.857142857145, 'global/mean_episode_step': 4866.857142857143, 'global/SPS': 3260.615083171095, 'global/env_act_steps': 42744832, 'global/env_train_steps': 42741760, 'global/optimizer_steps': 66784, 'global/running_reward': 23262.294089147286, 'global/running_step': 2379.14964874031, 'global/steps_done': 42744832, 'global/episodes_done': 10089, 'global/unclipped_grad_norm': 0.7374489266498416, 'global/model_version': 66784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:57,785] calculate_sps 32640 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:53:57,785] calculate_sps 32000 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:57,785] {'local/mean_episode_return': 51342.857142857145, 'local/mean_episode_step': 4992.142857142857, 'local/SPS': 3259.557717365264, 'local/env_act_steps': 42777984, 'local/env_train_steps': 42774400, 'local/optimizer_steps': 66834, 'local/running_reward': 23427.1875, 'local/running_step': 2403.509344362745, 'local/steps_done': 42777984, 'local/episodes_done': 10096, 'local/unclipped_grad_norm': 0.6578301501274109, 'local/model_version': 66834, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:53:57,786] {'global/mean_episode_return': 51342.857142857145, 'global/mean_episode_step': 4992.142857142857, 'global/SPS': 3195.6448209463374, 'global/env_act_steps': 42777856, 'global/env_train_steps': 42773760, 'global/optimizer_steps': 66833, 'global/running_reward': 23431.72843992248, 'global/running_step': 2403.8472625968993, 'global/steps_done': 42777856, 'global/episodes_done': 10096, 'global/unclipped_grad_norm': 0.6557042148648476, 'global/model_version': 66833, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:07,801] calculate_sps 33920 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:07,802] calculate_sps 34560 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:07,802] {'local/mean_episode_return': 43563.63636363636, 'local/mean_episode_step': 4366.363636363636, 'local/SPS': 3386.67755259908, 'local/env_act_steps': 42810624, 'local/env_train_steps': 42808320, 'local/optimizer_steps': 66888, 'local/running_reward': 22582.63480392157, 'local/running_step': 2324.955300245098, 'local/steps_done': 42810624, 'local/episodes_done': 10107, 'local/unclipped_grad_norm': 0.7108376765692676, 'local/model_version': 66888, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:07,803] {'global/mean_episode_return': 43563.63636363636, 'global/mean_episode_step': 4366.363636363636, 'global/SPS': 3450.5771290632138, 'global/env_act_steps': 42810496, 'global/env_train_steps': 42808320, 'global/optimizer_steps': 66888, 'global/running_reward': 22574.332107843136, 'global/running_step': 2324.213449754902, 'global/steps_done': 42810496, 'global/episodes_done': 10107, 'global/unclipped_grad_norm': 0.7117679184133356, 'global/model_version': 66888, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:17,813] calculate_sps 30720 steps in 10.0115
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:17,813] calculate_sps 25600 steps in 10.0115
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:17,813] {'local/mean_episode_return': 47085.71428571428, 'local/mean_episode_step': 4843.571428571428, 'local/SPS': 3068.456241123199, 'local/env_act_steps': 42844160, 'local/env_train_steps': 42839040, 'local/optimizer_steps': 66936, 'local/running_reward': 22839.87356870229, 'local/running_step': 2349.3806953721373, 'local/steps_done': 42844160, 'local/episodes_done': 10114, 'local/unclipped_grad_norm': 0.8875885761032501, 'local/model_version': 66936, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:17,815] {'global/mean_episode_return': 39333.333333333336, 'global/mean_episode_step': 4254.333333333333, 'global/SPS': 2557.046867602666, 'global/env_act_steps': 42837504, 'global/env_train_steps': 42833920, 'global/optimizer_steps': 66928, 'global/running_reward': 22804.902251184834, 'global/running_step': 2345.7442609597156, 'global/steps_done': 42837504, 'global/episodes_done': 10110, 'global/unclipped_grad_norm': 0.8604957893490791, 'global/model_version': 66928, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:27,837] calculate_sps 35840 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:27,838] calculate_sps 32640 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:27,838] {'local/mean_episode_return': 54960.0, 'local/mean_episode_step': 5259.6, 'local/SPS': 3575.003134706478, 'local/env_act_steps': 42875904, 'local/env_train_steps': 42874880, 'local/optimizer_steps': 66991, 'local/running_reward': 22653.263608870966, 'local/running_step': 2335.297820060484, 'local/steps_done': 42875904, 'local/episodes_done': 10119, 'local/unclipped_grad_norm': 0.7556394197724082, 'local/model_version': 66991, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:27,839] {'global/mean_episode_return': 53714.28571428572, 'global/mean_episode_step': 5284.142857142857, 'global/SPS': 3255.8064262505422, 'global/env_act_steps': 42870272, 'global/env_train_steps': 42866560, 'global/optimizer_steps': 66979, 'global/running_reward': 22706.93359375, 'global/running_step': 2339.4597778320312, 'global/steps_done': 42870272, 'global/episodes_done': 10117, 'global/unclipped_grad_norm': 0.8004720146749534, 'global/model_version': 66979, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:37,867] calculate_sps 30720 steps in 10.0292
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:37,867] calculate_sps 33920 steps in 10.0292
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:37,868] {'local/mean_episode_return': 50400.0, 'local/mean_episode_step': 5147.166666666667, 'local/SPS': 3063.051921229258, 'local/env_act_steps': 42909440, 'local/env_train_steps': 42905600, 'local/optimizer_steps': 67040, 'local/running_reward': 22982.5143129771, 'local/running_step': 2370.3470300572517, 'local/steps_done': 42909440, 'local/episodes_done': 10125, 'local/unclipped_grad_norm': 0.6930047741958073, 'local/model_version': 67040, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:37,869] {'global/mean_episode_return': 53066.666666666664, 'global/mean_episode_step': 5265.0, 'global/SPS': 3382.119829690639, 'global/env_act_steps': 42903168, 'global/env_train_steps': 42900480, 'global/optimizer_steps': 67032, 'global/running_reward': 22962.706712062256, 'global/running_step': 2368.56000729572, 'global/steps_done': 42903168, 'global/episodes_done': 10123, 'global/unclipped_grad_norm': 0.723657785159237, 'global/model_version': 67032, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:47,914] calculate_sps 33280 steps in 10.0476
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:47,915] calculate_sps 30720 steps in 10.0476
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:47,915] {'local/mean_episode_return': 46280.0, 'local/mean_episode_step': 4879.2, 'local/SPS': 3312.2292771334833, 'local/env_act_steps': 42941952, 'local/env_train_steps': 42938880, 'local/optimizer_steps': 67091, 'local/running_reward': 22915.828001968504, 'local/running_step': 2359.033126230315, 'local/steps_done': 42941952, 'local/episodes_done': 10130, 'local/unclipped_grad_norm': 0.7111066939199672, 'local/model_version': 67091, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:47,916] {'global/mean_episode_return': 46542.857142857145, 'global/mean_episode_step': 4877.142857142857, 'global/SPS': 3057.442409661677, 'global/env_act_steps': 42936448, 'global/env_train_steps': 42931200, 'global/optimizer_steps': 67080, 'global/running_reward': 22871.935096153848, 'global/running_step': 2355.9549278846152, 'global/steps_done': 42936448, 'global/episodes_done': 10130, 'global/unclipped_grad_norm': 0.7068317532539368, 'global/model_version': 67080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:57,921] calculate_sps 33280 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:54:57,921] calculate_sps 35840 steps in 10.0063
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:57,922] {'local/mean_episode_return': 49600.0, 'local/mean_episode_step': 4769.0, 'local/SPS': 3325.909998659261, 'local/env_act_steps': 42974464, 'local/env_train_steps': 42972160, 'local/optimizer_steps': 67144, 'local/running_reward': 23215.022145669293, 'local/running_step': 2387.875246062992, 'local/steps_done': 42974464, 'local/episodes_done': 10135, 'local/unclipped_grad_norm': 0.7732302096654784, 'local/model_version': 67144, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:54:57,923] {'global/mean_episode_return': 49600.0, 'global/mean_episode_step': 4769.0, 'global/SPS': 3581.749229325358, 'global/env_act_steps': 42968448, 'global/env_train_steps': 42967040, 'global/optimizer_steps': 67136, 'global/running_reward': 23161.375, 'global/running_step': 2381.96821875, 'global/steps_done': 42968448, 'global/episodes_done': 10135, 'global/unclipped_grad_norm': 0.7284208826188531, 'global/model_version': 67136, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:07,923] calculate_sps 30720 steps in 10.0016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:07,923] calculate_sps 30720 steps in 10.0016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:07,923] {'local/mean_episode_return': 52300.0, 'local/mean_episode_step': 5047.75, 'local/SPS': 3071.5174098079056, 'local/env_act_steps': 43008000, 'local/env_train_steps': 43002880, 'local/optimizer_steps': 67192, 'local/running_reward': 23819.298664122136, 'local/running_step': 2450.486313215649, 'local/steps_done': 43008000, 'local/episodes_done': 10139, 'local/unclipped_grad_norm': 0.8230396223564943, 'local/model_version': 67192, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:07,935] {'global/mean_episode_return': 52300.0, 'global/mean_episode_step': 5047.75, 'global/SPS': 3071.5174098079056, 'global/env_act_steps': 43002496, 'global/env_train_steps': 42997760, 'global/optimizer_steps': 67184, 'global/running_reward': 23734.3867481203, 'global/running_step': 2441.556479088346, 'global/steps_done': 43002496, 'global/episodes_done': 10139, 'global/unclipped_grad_norm': 0.8230468481779099, 'global/model_version': 67184, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:17,952] calculate_sps 35840 steps in 10.0296
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:17,952] calculate_sps 35840 steps in 10.0296
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:17,962] {'local/mean_episode_return': 49466.666666666664, 'local/mean_episode_step': 4921.0, 'local/SPS': 3573.4265252983882, 'local/env_act_steps': 43040128, 'local/env_train_steps': 43038720, 'local/optimizer_steps': 67248, 'local/running_reward': 24436.840139442233, 'local/running_step': 2509.0614728585656, 'local/steps_done': 43040128, 'local/episodes_done': 10142, 'local/unclipped_grad_norm': 0.7248868681490421, 'local/model_version': 67248, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:17,964] {'global/mean_episode_return': 49466.666666666664, 'global/mean_episode_step': 4921.0, 'global/SPS': 3573.4265252983882, 'global/env_act_steps': 43035264, 'global/env_train_steps': 43033600, 'global/optimizer_steps': 67240, 'global/running_reward': 24319.17724609375, 'global/running_step': 2497.9710693359375, 'global/steps_done': 43035264, 'global/episodes_done': 10142, 'global/unclipped_grad_norm': 0.7720661211226668, 'global/model_version': 67240, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:27,968] calculate_sps 30720 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:27,968] calculate_sps 30720 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:27,968] {'local/mean_episode_return': 53360.0, 'local/mean_episode_step': 5144.6, 'local/SPS': 3067.17886714094, 'local/env_act_steps': 43073664, 'local/env_train_steps': 43069440, 'local/optimizer_steps': 67296, 'local/running_reward': 24809.112595419847, 'local/running_step': 2550.933116650763, 'local/steps_done': 43073664, 'local/episodes_done': 10147, 'local/unclipped_grad_norm': 0.6824726002911726, 'local/model_version': 67296, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:27,970] {'global/mean_episode_return': 53866.666666666664, 'global/mean_episode_step': 5186.666666666667, 'global/SPS': 3067.17886714094, 'global/env_act_steps': 43068928, 'global/env_train_steps': 43064320, 'global/optimizer_steps': 67288, 'global/running_reward': 24731.547053231938, 'global/running_step': 2542.1174251425855, 'global/steps_done': 43068928, 'global/episodes_done': 10145, 'global/unclipped_grad_norm': 0.6514961725721756, 'global/model_version': 67288, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:37,994] calculate_sps 34560 steps in 10.0269
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:37,995] calculate_sps 35840 steps in 10.0269
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:37,995] {'local/mean_episode_return': 47400.0, 'local/mean_episode_step': 4793.1, 'local/SPS': 3446.7409039052554, 'local/env_act_steps': 43106048, 'local/env_train_steps': 43104000, 'local/optimizer_steps': 67349, 'local/running_reward': 24725.345849802372, 'local/running_step': 2545.69126729249, 'local/steps_done': 43106048, 'local/episodes_done': 10157, 'local/unclipped_grad_norm': 0.7907210076754948, 'local/model_version': 67349, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:37,996] {'global/mean_episode_return': 48500.0, 'global/mean_episode_step': 4834.6, 'global/SPS': 3574.3979744202647, 'global/env_act_steps': 43101312, 'global/env_train_steps': 43100160, 'global/optimizer_steps': 67344, 'global/running_reward': 24838.481966403164, 'global/running_step': 2556.831645256917, 'global/steps_done': 43101312, 'global/episodes_done': 10155, 'global/unclipped_grad_norm': 0.7911696322262287, 'global/model_version': 67344, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:48,019] calculate_sps 32000 steps in 10.0242
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:48,019] calculate_sps 30720 steps in 10.0242
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:48,019] {'local/mean_episode_return': 47575.0, 'local/mean_episode_step': 4727.125, 'local/SPS': 3192.2851090412623, 'local/env_act_steps': 43139328, 'local/env_train_steps': 43136000, 'local/optimizer_steps': 67400, 'local/running_reward': 24205.76923076923, 'local/running_step': 2492.759314903846, 'local/steps_done': 43139328, 'local/episodes_done': 10165, 'local/unclipped_grad_norm': 0.7654833644628525, 'local/model_version': 67400, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:48,021] {'global/mean_episode_return': 47555.555555555555, 'global/mean_episode_step': 4757.444444444444, 'global/SPS': 3064.593704679612, 'global/env_act_steps': 43135360, 'global/env_train_steps': 43130880, 'global/optimizer_steps': 67392, 'global/running_reward': 24237.200422932332, 'global/running_step': 2496.1756637687968, 'global/steps_done': 43135360, 'global/episodes_done': 10164, 'global/unclipped_grad_norm': 0.7694399397199353, 'global/model_version': 67392, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 14:55:52,463] saving global stats {'mean_episode_return': 43200.0, 'mean_episode_step': 4539.333333333333, 'SPS': None, 'env_act_steps': 43141632, 'env_train_steps': 43138560, 'optimizer_steps': 67403, 'running_reward': 24125.605867346938, 'running_step': 2483.6358418367345, 'steps_done': 43141632, 'episodes_done': 10167, 'unclipped_grad_norm': 0.6809686639092185, 'model_version': 67403, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 14:55:52,560] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:58,028] calculate_sps 31360 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:55:58,038] calculate_sps 34560 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:58,038] {'local/mean_episode_return': 48654.545454545456, 'local/mean_episode_step': 4891.090909090909, 'local/SPS': 3133.261097791447, 'local/env_act_steps': 43172096, 'local/env_train_steps': 43167360, 'local/optimizer_steps': 67449, 'local/running_reward': 23886.309814453125, 'local/running_step': 2461.9246215820312, 'local/steps_done': 43172096, 'local/episodes_done': 10176, 'local/unclipped_grad_norm': 0.6940082335958675, 'local/model_version': 67449, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:55:58,039] {'global/mean_episode_return': 47909.09090909091, 'global/mean_episode_step': 4838.181818181818, 'global/SPS': 3452.981617974248, 'global/env_act_steps': 43167488, 'global/env_train_steps': 43165440, 'global/optimizer_steps': 67445, 'global/running_reward': 24004.973854581673, 'global/running_step': 2473.191515189243, 'global/steps_done': 43167488, 'global/episodes_done': 10175, 'global/unclipped_grad_norm': 0.7007235232389198, 'global/model_version': 67445, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:08,066] calculate_sps 35200 steps in 10.0381
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:08,066] calculate_sps 32000 steps in 10.0381
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:08,066] {'local/mean_episode_return': 47575.0, 'local/mean_episode_step': 4937.0, 'local/SPS': 3506.6434492073427, 'local/env_act_steps': 43204480, 'local/env_train_steps': 43202560, 'local/optimizer_steps': 67504, 'local/running_reward': 23355.583003952568, 'local/running_step': 2414.597177618577, 'local/steps_done': 43204480, 'local/episodes_done': 10184, 'local/unclipped_grad_norm': 0.6907025385986675, 'local/model_version': 67504, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:08,068] {'global/mean_episode_return': 49825.0, 'global/mean_episode_step': 5112.0, 'global/SPS': 3187.857681097584, 'global/env_act_steps': 43201024, 'global/env_train_steps': 43197440, 'global/optimizer_steps': 67496, 'global/running_reward': 23385.75858778626, 'global/running_step': 2417.3131261927483, 'global/steps_done': 43201024, 'global/episodes_done': 10183, 'global/unclipped_grad_norm': 0.6910545469499102, 'global/model_version': 67496, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:18,083] calculate_sps 30720 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:18,084] calculate_sps 33920 steps in 10.0174
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:18,084] {'local/mean_episode_return': 47220.0, 'local/mean_episode_step': 4740.05, 'local/SPS': 3066.6644345019395, 'local/env_act_steps': 43238144, 'local/env_train_steps': 43233280, 'local/optimizer_steps': 67552, 'local/running_reward': 22612.428707224335, 'local/running_step': 2343.7519605513307, 'local/steps_done': 43238144, 'local/episodes_done': 10195, 'local/unclipped_grad_norm': 0.7781512786944708, 'local/model_version': 67552, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:18,085] {'global/mean_episode_return': 45400.0, 'global/mean_episode_step': 4593.55, 'global/SPS': 3386.108646429225, 'global/env_act_steps': 43234048, 'global/env_train_steps': 43231360, 'global/optimizer_steps': 67549, 'global/running_reward': 22697.18992248062, 'global/running_step': 2351.969718992248, 'global/steps_done': 43234048, 'global/episodes_done': 10194, 'global/unclipped_grad_norm': 0.7769055029131332, 'global/model_version': 67549, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:28,105] calculate_sps 35840 steps in 10.0221
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:28,105] calculate_sps 32640 steps in 10.0221
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:28,105] {'local/mean_episode_return': 41333.333333333336, 'local/mean_episode_step': 4450.0, 'local/SPS': 3576.089349697979, 'local/env_act_steps': 43270144, 'local/env_train_steps': 43269120, 'local/optimizer_steps': 67607, 'local/running_reward': 22743.0625, 'local/running_step': 2355.93221875, 'local/steps_done': 43270144, 'local/episodes_done': 10198, 'local/unclipped_grad_norm': 0.7751708800142462, 'local/model_version': 67607, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:28,106] {'global/mean_episode_return': 44800.0, 'global/mean_episode_step': 4686.25, 'global/SPS': 3256.7956577606597, 'global/env_act_steps': 43267200, 'global/env_train_steps': 43264000, 'global/optimizer_steps': 67600, 'global/running_reward': 22665.401785714286, 'global/running_step': 2348.108047779923, 'global/steps_done': 43267200, 'global/episodes_done': 10198, 'global/unclipped_grad_norm': 0.7589418034927518, 'global/model_version': 67600, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:38,145] calculate_sps 30720 steps in 10.0375
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:38,146] calculate_sps 32640 steps in 10.0375
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:38,146] {'local/mean_episode_return': 53800.0, 'local/mean_episode_step': 5396.333333333333, 'local/SPS': 3060.5228495957836, 'local/env_act_steps': 43303680, 'local/env_train_steps': 43299840, 'local/optimizer_steps': 67656, 'local/running_reward': 23249.743559160306, 'local/running_step': 2406.4475489026718, 'local/steps_done': 43303680, 'local/episodes_done': 10201, 'local/unclipped_grad_norm': 0.7117597028917196, 'local/model_version': 67656, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:38,147] {'global/mean_episode_return': 53800.0, 'global/mean_episode_step': 5396.333333333333, 'global/SPS': 3251.8055276955197, 'global/env_act_steps': 43300224, 'global/env_train_steps': 43296640, 'global/optimizer_steps': 67650, 'global/running_reward': 23187.772529069767, 'global/running_step': 2399.8151344476746, 'global/steps_done': 43300224, 'global/episodes_done': 10201, 'global/unclipped_grad_norm': 0.7068387281894684, 'global/model_version': 67650, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:48,157] calculate_sps 32640 steps in 10.0147
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:48,157] calculate_sps 33920 steps in 10.0147
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:48,157] {'local/mean_episode_return': 39500.0, 'local/mean_episode_step': 4065.5, 'local/SPS': 3259.216432485966, 'local/env_act_steps': 43336064, 'local/env_train_steps': 43332480, 'local/optimizer_steps': 67706, 'local/running_reward': 24061.542737154152, 'local/running_step': 2492.870615118577, 'local/steps_done': 43336064, 'local/episodes_done': 10203, 'local/unclipped_grad_norm': 0.5746360889077187, 'local/model_version': 67706, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:48,158] {'global/mean_episode_return': 39500.0, 'global/mean_episode_step': 4065.5, 'global/SPS': 3387.0288416030626, 'global/env_act_steps': 43332992, 'global/env_train_steps': 43330560, 'global/optimizer_steps': 67704, 'global/running_reward': 23969.6533203125, 'global/running_step': 2483.4149475097656, 'global/steps_done': 43332992, 'global/episodes_done': 10203, 'global/unclipped_grad_norm': 0.6123081895488279, 'global/model_version': 67704, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:58,166] calculate_sps 33920 steps in 10.0089
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:56:58,167] calculate_sps 30720 steps in 10.0089
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:58,167] {'local/mean_episode_return': 46057.142857142855, 'local/mean_episode_step': 4623.714285714285, 'local/SPS': 3388.98108434071, 'local/env_act_steps': 43368192, 'local/env_train_steps': 43366400, 'local/optimizer_steps': 67760, 'local/running_reward': 24508.304282868525, 'local/running_step': 2539.1221675796814, 'local/steps_done': 43368192, 'local/episodes_done': 10210, 'local/unclipped_grad_norm': 0.7849166332571594, 'local/model_version': 67760, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:56:58,169] {'global/mean_episode_return': 46000.0, 'global/mean_episode_step': 4587.833333333333, 'global/SPS': 3069.2658877047943, 'global/env_act_steps': 43366144, 'global/env_train_steps': 43361280, 'global/optimizer_steps': 67752, 'global/running_reward': 24506.587837837837, 'global/running_step': 2538.95493484556, 'global/steps_done': 43366144, 'global/episodes_done': 10209, 'global/unclipped_grad_norm': 0.7932463176548481, 'global/model_version': 67752, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:08,178] calculate_sps 30720 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:08,178] calculate_sps 35840 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:08,178] {'local/mean_episode_return': 48828.57142857143, 'local/mean_episode_step': 4870.642857142857, 'local/SPS': 3068.446668550059, 'local/env_act_steps': 43401472, 'local/env_train_steps': 43397120, 'local/optimizer_steps': 67808, 'local/running_reward': 24404.759615384617, 'local/running_step': 2531.5403245192306, 'local/steps_done': 43401472, 'local/episodes_done': 10218, 'local/unclipped_grad_norm': 0.7562998092422882, 'local/model_version': 67808, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:08,191] {'global/mean_episode_return': 49228.57142857143, 'global/mean_episode_step': 4946.214285714285, 'global/SPS': 3579.854446641735, 'global/env_act_steps': 43398272, 'global/env_train_steps': 43397120, 'global/optimizer_steps': 67807, 'global/running_reward': 24434.80453187251, 'global/running_step': 2533.784611553785, 'global/steps_done': 43398272, 'global/episodes_done': 10217, 'global/unclipped_grad_norm': 0.7392488913102584, 'global/model_version': 67807, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:18,225] calculate_sps 34560 steps in 10.0473
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:18,225] calculate_sps 30720 steps in 10.0473
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:18,225] {'local/mean_episode_return': 45942.857142857145, 'local/mean_episode_step': 4717.0, 'local/SPS': 3439.743673564229, 'local/env_act_steps': 43433728, 'local/env_train_steps': 43431680, 'local/optimizer_steps': 67861, 'local/running_reward': 24408.004712301587, 'local/running_step': 2539.310484871032, 'local/steps_done': 43433728, 'local/episodes_done': 10225, 'local/unclipped_grad_norm': 0.7206588528066311, 'local/model_version': 67861, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:18,226] {'global/mean_episode_return': 46433.333333333336, 'global/mean_episode_step': 4673.333333333333, 'global/SPS': 3057.5499320570925, 'global/env_act_steps': 43431808, 'global/env_train_steps': 43427840, 'global/optimizer_steps': 67856, 'global/running_reward': 24400.703721374044, 'global/running_step': 2538.2533396946565, 'global/steps_done': 43431808, 'global/episodes_done': 10223, 'global/unclipped_grad_norm': 0.727707216934282, 'global/model_version': 67856, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:28,234] calculate_sps 32000 steps in 10.0091
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:28,235] calculate_sps 34560 steps in 10.0091
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:28,235] {'local/mean_episode_return': 46675.0, 'local/mean_episode_step': 4726.0, 'local/SPS': 3197.0838062224757, 'local/env_act_steps': 43466880, 'local/env_train_steps': 43463680, 'local/optimizer_steps': 67912, 'local/running_reward': 24255.152027027027, 'local/running_step': 2525.831895511583, 'local/steps_done': 43466880, 'local/episodes_done': 10233, 'local/unclipped_grad_norm': 0.8186112887719098, 'local/model_version': 67912, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:28,236] {'global/mean_episode_return': 46000.0, 'global/mean_episode_step': 4709.7, 'global/SPS': 3452.8505107202736, 'global/env_act_steps': 43464448, 'global/env_train_steps': 43462400, 'global/optimizer_steps': 67909, 'global/running_reward': 24267.64093137255, 'global/running_step': 2527.0836703431373, 'global/steps_done': 43464448, 'global/episodes_done': 10233, 'global/unclipped_grad_norm': 0.7732192879577853, 'global/model_version': 67909, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:38,279] calculate_sps 32640 steps in 10.0454
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:38,279] calculate_sps 32000 steps in 10.0454
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:38,280] {'local/mean_episode_return': 46900.0, 'local/mean_episode_step': 4667.0, 'local/SPS': 3249.25060248473, 'local/env_act_steps': 43499904, 'local/env_train_steps': 43496320, 'local/optimizer_steps': 67962, 'local/running_reward': 24226.23546511628, 'local/running_step': 2526.4154857073645, 'local/steps_done': 43499904, 'local/episodes_done': 10237, 'local/unclipped_grad_norm': 0.6694238981604577, 'local/model_version': 67962, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:38,280] {'global/mean_episode_return': 46900.0, 'global/mean_episode_step': 4667.0, 'global/SPS': 3185.5398063575785, 'global/env_act_steps': 43497984, 'global/env_train_steps': 43494400, 'global/optimizer_steps': 67960, 'global/running_reward': 24188.53172709924, 'global/running_step': 2522.528238311069, 'global/steps_done': 43497984, 'global/episodes_done': 10237, 'global/unclipped_grad_norm': 0.6988884184290381, 'global/model_version': 67960, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:48,285] calculate_sps 33920 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:48,298] calculate_sps 32640 steps in 10.0055
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:48,298] {'local/mean_episode_return': 47220.0, 'local/mean_episode_step': 4741.7, 'local/SPS': 3390.1505862340064, 'local/env_act_steps': 43532032, 'local/env_train_steps': 43530240, 'local/optimizer_steps': 68016, 'local/running_reward': 24085.613794820718, 'local/running_step': 2513.3448393924305, 'local/steps_done': 43532032, 'local/episodes_done': 10247, 'local/unclipped_grad_norm': 0.7467451956537035, 'local/model_version': 68016, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:48,300] {'global/mean_episode_return': 47220.0, 'global/mean_episode_step': 4741.7, 'global/SPS': 3262.2203754327234, 'global/env_act_steps': 43530624, 'global/env_train_steps': 43527040, 'global/optimizer_steps': 68010, 'global/running_reward': 24135.968137254902, 'global/running_step': 2518.0550551470587, 'global/steps_done': 43530624, 'global/episodes_done': 10247, 'global/unclipped_grad_norm': 0.7731635910272598, 'global/model_version': 68010, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:58,296] calculate_sps 30720 steps in 10.0113
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:57:58,297] calculate_sps 33920 steps in 10.0113
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:58,297] {'local/mean_episode_return': 48800.0, 'local/mean_episode_step': 4916.75, 'local/SPS': 3068.532020012268, 'local/env_act_steps': 43565440, 'local/env_train_steps': 43560960, 'local/optimizer_steps': 68064, 'local/running_reward': 23716.002155172413, 'local/running_step': 2481.1232638888887, 'local/steps_done': 43565440, 'local/episodes_done': 10255, 'local/unclipped_grad_norm': 0.5779580197607478, 'local/model_version': 68064, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:57:58,298] {'global/mean_episode_return': 47971.42857142857, 'global/mean_episode_step': 4848.428571428572, 'global/SPS': 3388.1707720968793, 'global/env_act_steps': 43563776, 'global/env_train_steps': 43560960, 'global/optimizer_steps': 68064, 'global/running_reward': 23708.723455598454, 'global/running_step': 2480.4577401061774, 'global/steps_done': 43563776, 'global/episodes_done': 10254, 'global/unclipped_grad_norm': 0.5744240154270772, 'global/model_version': 68064, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:08,300] calculate_sps 34560 steps in 10.0039
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:08,300] calculate_sps 32000 steps in 10.0039
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:08,300] {'local/mean_episode_return': 44140.0, 'local/mean_episode_step': 4615.9, 'local/SPS': 3454.6362012333866, 'local/env_act_steps': 43597568, 'local/env_train_steps': 43595520, 'local/optimizer_steps': 68117, 'local/running_reward': 23234.599103585657, 'local/running_step': 2432.3175112051795, 'local/steps_done': 43597568, 'local/episodes_done': 10265, 'local/unclipped_grad_norm': 0.6565197155160724, 'local/model_version': 68117, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:08,301] {'global/mean_episode_return': 45090.90909090909, 'global/mean_episode_step': 4686.727272727273, 'global/SPS': 3198.737223364247, 'global/env_act_steps': 43597056, 'global/env_train_steps': 43592960, 'global/optimizer_steps': 68113, 'global/running_reward': 23266.88701923077, 'global/running_step': 2435.4876802884614, 'global/steps_done': 43597056, 'global/episodes_done': 10265, 'global/unclipped_grad_norm': 0.6464267068979691, 'global/model_version': 68113, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:18,304] calculate_sps 32000 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:18,304] calculate_sps 34560 steps in 10.0034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:18,304] {'local/mean_episode_return': 45990.90909090909, 'local/mean_episode_step': 4653.363636363636, 'local/SPS': 3198.9172976027307, 'local/env_act_steps': 43630464, 'local/env_train_steps': 43627520, 'local/optimizer_steps': 68168, 'local/running_reward': 22561.03477626459, 'local/running_step': 2367.9869892996107, 'local/steps_done': 43630464, 'local/episodes_done': 10277, 'local/unclipped_grad_norm': 0.7770485676386777, 'local/model_version': 68168, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:18,315] {'global/mean_episode_return': 45990.90909090909, 'global/mean_episode_step': 4653.363636363636, 'global/SPS': 3454.830681410949, 'global/env_act_steps': 43629568, 'global/env_train_steps': 43627520, 'global/optimizer_steps': 68168, 'global/running_reward': 22573.929625984252, 'global/running_step': 2369.3776759350394, 'global/steps_done': 43629568, 'global/episodes_done': 10277, 'global/unclipped_grad_norm': 0.7772747860713438, 'global/model_version': 68168, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:28,359] calculate_sps 31360 steps in 10.0553
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:28,359] calculate_sps 30720 steps in 10.0553
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:28,359] {'local/mean_episode_return': 48571.42857142857, 'local/mean_episode_step': 4816.857142857143, 'local/SPS': 3118.7418332221305, 'local/env_act_steps': 43663488, 'local/env_train_steps': 43658880, 'local/optimizer_steps': 68216, 'local/running_reward': 22189.783187984496, 'local/running_step': 2329.1911942829456, 'local/steps_done': 43663488, 'local/episodes_done': 10284, 'local/unclipped_grad_norm': 0.6588808527837197, 'local/model_version': 68216, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:28,360] {'global/mean_episode_return': 48571.42857142857, 'global/mean_episode_step': 4816.857142857143, 'global/SPS': 3055.094040707393, 'global/env_act_steps': 43662848, 'global/env_train_steps': 43658240, 'global/optimizer_steps': 68216, 'global/running_reward': 22193.00480769231, 'global/running_step': 2329.4881009615383, 'global/steps_done': 43662848, 'global/episodes_done': 10284, 'global/unclipped_grad_norm': 0.6588808527837197, 'global/model_version': 68216, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:38,386] calculate_sps 35200 steps in 10.0271
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:38,387] calculate_sps 34560 steps in 10.0271
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:38,387] {'local/mean_episode_return': 40777.77777777778, 'local/mean_episode_step': 4343.444444444444, 'local/SPS': 3510.4868850629323, 'local/env_act_steps': 43695488, 'local/env_train_steps': 43694080, 'local/optimizer_steps': 68272, 'local/running_reward': 22190.73125, 'local/running_step': 2326.5818125, 'local/steps_done': 43695488, 'local/episodes_done': 10293, 'local/unclipped_grad_norm': 0.7190397858087506, 'local/model_version': 68272, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:38,388] {'global/mean_episode_return': 40777.77777777778, 'global/mean_episode_step': 4343.444444444444, 'global/SPS': 3446.659850789061, 'global/env_act_steps': 43694848, 'global/env_train_steps': 43692800, 'global/optimizer_steps': 68269, 'global/running_reward': 22194.93125, 'global/running_step': 2327.19903125, 'global/steps_done': 43694848, 'global/episodes_done': 10293, 'global/unclipped_grad_norm': 0.733548714586024, 'global/model_version': 68269, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:48,399] calculate_sps 30720 steps in 10.0128
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:48,399] calculate_sps 32000 steps in 10.0128
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:48,400] {'local/mean_episode_return': 40750.0, 'local/mean_episode_step': 4198.375, 'local/SPS': 3068.065202632427, 'local/env_act_steps': 43728640, 'local/env_train_steps': 43724800, 'local/optimizer_steps': 68320, 'local/running_reward': 21878.824806949808, 'local/running_step': 2287.681376689189, 'local/steps_done': 43728640, 'local/episodes_done': 10301, 'local/unclipped_grad_norm': 0.7384981252253056, 'local/model_version': 68320, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:48,401] {'global/mean_episode_return': 40750.0, 'global/mean_episode_step': 4198.375, 'global/SPS': 3195.9012527421114, 'global/env_act_steps': 43728128, 'global/env_train_steps': 43724800, 'global/optimizer_steps': 68320, 'global/running_reward': 21881.67668269231, 'global/running_step': 2287.892938701923, 'global/steps_done': 43728128, 'global/episodes_done': 10301, 'global/unclipped_grad_norm': 0.7222756106479495, 'global/model_version': 68320, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:58,449] calculate_sps 33280 steps in 10.0508
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:58:58,450] calculate_sps 32640 steps in 10.0508
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:58,450] {'local/mean_episode_return': 47355.555555555555, 'local/mean_episode_step': 4843.0, 'local/SPS': 3311.175254312175, 'local/env_act_steps': 43761152, 'local/env_train_steps': 43758080, 'local/optimizer_steps': 68371, 'local/running_reward': 21584.479576771653, 'local/running_step': 2257.878537155512, 'local/steps_done': 43761152, 'local/episodes_done': 10310, 'local/unclipped_grad_norm': 0.7709325318242989, 'local/model_version': 68371, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:58:58,451] {'global/mean_episode_return': 47355.555555555555, 'global/mean_episode_step': 4843.0, 'global/SPS': 3247.498807113864, 'global/env_act_steps': 43761024, 'global/env_train_steps': 43757440, 'global/optimizer_steps': 68370, 'global/running_reward': 21592.923151750972, 'global/running_step': 2258.6619041828794, 'global/steps_done': 43761024, 'global/episodes_done': 10310, 'global/unclipped_grad_norm': 0.7764675050973893, 'global/model_version': 68370, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:08,482] calculate_sps 33280 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:08,482] calculate_sps 33920 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:08,482] {'local/mean_episode_return': 47314.28571428572, 'local/mean_episode_step': 4839.571428571428, 'local/SPS': 3317.471627098211, 'local/env_act_steps': 43793408, 'local/env_train_steps': 43791360, 'local/optimizer_steps': 68424, 'local/running_reward': 21549.82638888889, 'local/running_step': 2253.4178757440477, 'local/steps_done': 43793408, 'local/episodes_done': 10317, 'local/unclipped_grad_norm': 0.7518424031869421, 'local/model_version': 68424, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:08,484] {'global/mean_episode_return': 47314.28571428572, 'global/mean_episode_step': 4839.571428571428, 'global/SPS': 3381.2691583885608, 'global/env_act_steps': 43793280, 'global/env_train_steps': 43791360, 'global/optimizer_steps': 68424, 'global/running_reward': 21549.44816468254, 'global/running_step': 2253.3671875, 'global/steps_done': 43793280, 'global/episodes_done': 10317, 'global/unclipped_grad_norm': 0.7470709488347724, 'global/model_version': 68424, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:18,503] calculate_sps 30720 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:18,504] calculate_sps 30720 steps in 10.021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:18,504] {'local/mean_episode_return': 49840.0, 'local/mean_episode_step': 4945.2, 'local/SPS': 3065.576423760532, 'local/env_act_steps': 43826560, 'local/env_train_steps': 43822080, 'local/optimizer_steps': 68472, 'local/running_reward': 21799.414816602315, 'local/running_step': 2278.0103462837837, 'local/steps_done': 43826560, 'local/episodes_done': 10322, 'local/unclipped_grad_norm': 0.7586971273024877, 'local/model_version': 68472, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:18,505] {'global/mean_episode_return': 49840.0, 'global/mean_episode_step': 4945.2, 'global/SPS': 3065.576423760532, 'global/env_act_steps': 43826560, 'global/env_train_steps': 43822080, 'global/optimizer_steps': 68472, 'global/running_reward': 21796.47235576923, 'global/running_step': 2277.812049278846, 'global/steps_done': 43826560, 'global/episodes_done': 10322, 'global/unclipped_grad_norm': 0.7586971273024877, 'global/model_version': 68472, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:28,513] calculate_sps 33920 steps in 10.0108
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:28,513] calculate_sps 25600 steps in 10.0108
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:28,514] {'local/mean_episode_return': 48040.0, 'local/mean_episode_step': 4763.0, 'local/SPS': 3388.326831991105, 'local/env_act_steps': 43858560, 'local/env_train_steps': 43856000, 'local/optimizer_steps': 68524, 'local/running_reward': 21898.80625, 'local/running_step': 2289.86665625, 'local/steps_done': 43858560, 'local/episodes_done': 10328, 'local/unclipped_grad_norm': 0.7442257272509428, 'local/model_version': 68524, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:28,515] {'global/mean_episode_return': 48950.0, 'global/mean_episode_step': 4824.75, 'global/SPS': 2557.227797729136, 'global/env_act_steps': 43852800, 'global/env_train_steps': 43847680, 'global/optimizer_steps': 68512, 'global/running_reward': 21855.518292682926, 'global/running_step': 2285.64775152439, 'global/steps_done': 43852800, 'global/episodes_done': 10326, 'global/unclipped_grad_norm': 0.711751700937748, 'global/model_version': 68512, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:38,539] calculate_sps 32640 steps in 10.0261
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:38,540] calculate_sps 35840 steps in 10.0261
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:38,540] {'local/mean_episode_return': 45375.0, 'local/mean_episode_step': 4651.875, 'local/SPS': 3255.507188295457, 'local/env_act_steps': 43892096, 'local/env_train_steps': 43888640, 'local/optimizer_steps': 68576, 'local/running_reward': 21914.909351145037, 'local/running_step': 2291.865040553435, 'local/steps_done': 43892096, 'local/episodes_done': 10336, 'local/unclipped_grad_norm': 0.6916389600015603, 'local/model_version': 68576, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:38,551] {'global/mean_episode_return': 45914.28571428572, 'global/mean_episode_step': 4625.571428571428, 'global/SPS': 3574.6745596969727, 'global/env_act_steps': 43885568, 'global/env_train_steps': 43883520, 'global/optimizer_steps': 68568, 'global/running_reward': 21949.957275390625, 'global/running_step': 2295.6455078125, 'global/steps_done': 43885568, 'global/episodes_done': 10334, 'global/unclipped_grad_norm': 0.7408963327429124, 'global/model_version': 68568, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:48,582] calculate_sps 32640 steps in 10.043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:48,582] calculate_sps 30720 steps in 10.043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:48,583] {'local/mean_episode_return': 48280.0, 'local/mean_episode_step': 4798.8, 'local/SPS': 3250.0137882526915, 'local/env_act_steps': 43924864, 'local/env_train_steps': 43921280, 'local/optimizer_steps': 68626, 'local/running_reward': 21915.936279296875, 'local/running_step': 2290.625, 'local/steps_done': 43924864, 'local/episodes_done': 10341, 'local/unclipped_grad_norm': 0.8548607152700424, 'local/model_version': 68626, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:48,583] {'global/mean_episode_return': 46771.42857142857, 'global/mean_episode_step': 4763.714285714285, 'global/SPS': 3058.8365065907687, 'global/env_act_steps': 43919232, 'global/env_train_steps': 43914240, 'global/optimizer_steps': 68616, 'global/running_reward': 21886.097908745247, 'global/running_step': 2287.7749524714827, 'global/steps_done': 43919232, 'global/episodes_done': 10341, 'global/unclipped_grad_norm': 0.8450768434753021, 'global/model_version': 68616, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:58,599] calculate_sps 33920 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 14:59:58,599] calculate_sps 35840 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:58,599] {'local/mean_episode_return': 43271.42857142857, 'local/mean_episode_step': 4389.928571428572, 'local/SPS': 3386.5043940167725, 'local/env_act_steps': 43957120, 'local/env_train_steps': 43955200, 'local/optimizer_steps': 68680, 'local/running_reward': 21975.70064484127, 'local/running_step': 2296.1154203869046, 'local/steps_done': 43957120, 'local/episodes_done': 10349, 'local/unclipped_grad_norm': 0.7959061783772928, 'local/model_version': 68680, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 14:59:58,601] {'global/mean_episode_return': 45980.0, 'global/mean_episode_step': 4622.3, 'global/SPS': 3578.193321979986, 'global/env_act_steps': 43951104, 'global/env_train_steps': 43950080, 'global/optimizer_steps': 68671, 'global/running_reward': 21981.143323293174, 'global/running_step': 2296.5495419176705, 'global/steps_done': 43951104, 'global/episodes_done': 10347, 'global/unclipped_grad_norm': 0.7944039122624831, 'global/model_version': 68671, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:08,611] calculate_sps 30720 steps in 10.0126
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:08,612] calculate_sps 30720 steps in 10.0126
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:08,612] {'local/mean_episode_return': 42371.42857142857, 'local/mean_episode_step': 4483.571428571428, 'local/SPS': 3068.1344600342263, 'local/env_act_steps': 43990528, 'local/env_train_steps': 43985920, 'local/optimizer_steps': 68728, 'local/running_reward': 22005.980603448275, 'local/running_step': 2297.7819085249043, 'local/steps_done': 43990528, 'local/episodes_done': 10356, 'local/unclipped_grad_norm': 0.7684385894487301, 'local/model_version': 68728, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:08,613] {'global/mean_episode_return': 41066.666666666664, 'global/mean_episode_step': 4333.666666666667, 'global/SPS': 3068.1344600342263, 'global/env_act_steps': 43984512, 'global/env_train_steps': 43980800, 'global/optimizer_steps': 68720, 'global/running_reward': 22010.452586206895, 'global/running_step': 2298.0172713122606, 'global/steps_done': 43984512, 'global/episodes_done': 10356, 'global/unclipped_grad_norm': 0.7624393263641669, 'global/model_version': 68720, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:18,617] calculate_sps 34560 steps in 10.0056
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:18,617] calculate_sps 34560 steps in 10.0056
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:18,617] {'local/mean_episode_return': 48520.0, 'local/mean_episode_step': 4948.8, 'local/SPS': 3454.052892051228, 'local/env_act_steps': 44022528, 'local/env_train_steps': 44020480, 'local/optimizer_steps': 68781, 'local/running_reward': 22169.05625, 'local/running_step': 2315.83603125, 'local/steps_done': 44022528, 'local/episodes_done': 10361, 'local/unclipped_grad_norm': 0.6404188126325607, 'local/model_version': 68781, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:18,618] {'global/mean_episode_return': 53350.0, 'global/mean_episode_step': 5301.25, 'global/SPS': 3454.052892051228, 'global/env_act_steps': 44017408, 'global/env_train_steps': 44015360, 'global/optimizer_steps': 68773, 'global/running_reward': 22103.131079766536, 'global/running_step': 2309.3564567120625, 'global/steps_done': 44017408, 'global/episodes_done': 10360, 'global/unclipped_grad_norm': 0.6728863046979005, 'global/model_version': 68773, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:28,636] calculate_sps 32000 steps in 10.0186
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:28,636] calculate_sps 32000 steps in 10.0186
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:28,636] {'local/mean_episode_return': 44850.0, 'local/mean_episode_step': 4579.125, 'local/SPS': 3194.0484888184874, 'local/env_act_steps': 44055936, 'local/env_train_steps': 44052480, 'local/optimizer_steps': 68832, 'local/running_reward': 21893.71408045977, 'local/running_step': 2288.154094827586, 'local/steps_done': 44055936, 'local/episodes_done': 10374, 'local/unclipped_grad_norm': 0.702895464850407, 'local/model_version': 68832, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:28,637] {'global/mean_episode_return': 43646.153846153844, 'global/mean_episode_step': 4499.115384615385, 'global/SPS': 3194.0484888184874, 'global/env_act_steps': 44050816, 'global/env_train_steps': 44047360, 'global/optimizer_steps': 68824, 'global/running_reward': 22070.222701149425, 'global/running_step': 2305.762631704981, 'global/steps_done': 44050816, 'global/episodes_done': 10374, 'global/unclipped_grad_norm': 0.6899737134283664, 'global/model_version': 68824, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:38,658] calculate_sps 32640 steps in 10.0232
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:38,659] calculate_sps 33280 steps in 10.0232
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:38,659] {'local/mean_episode_return': 43400.0, 'local/mean_episode_step': 4535.0, 'local/SPS': 3256.4420926106627, 'local/env_act_steps': 44088704, 'local/env_train_steps': 44085120, 'local/optimizer_steps': 68882, 'local/running_reward': 21866.8701171875, 'local/running_step': 2288.2594604492188, 'local/steps_done': 44088704, 'local/episodes_done': 10376, 'local/unclipped_grad_norm': 0.6325383642315865, 'local/model_version': 68882, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:38,660] {'global/mean_episode_return': 50000.0, 'global/mean_episode_step': 4995.0, 'global/SPS': 3320.2938983481263, 'global/env_act_steps': 44083840, 'global/env_train_steps': 44080640, 'global/optimizer_steps': 68876, 'global/running_reward': 21718.507751937985, 'global/running_step': 2273.0709484011627, 'global/steps_done': 44083840, 'global/episodes_done': 10375, 'global/unclipped_grad_norm': 0.6358345256975064, 'global/model_version': 68876, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:48,668] calculate_sps 33920 steps in 10.0089
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:48,668] calculate_sps 33280 steps in 10.0089
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:48,668] {'local/mean_episode_return': 52300.0, 'local/mean_episode_step': 5268.666666666667, 'local/SPS': 3388.9899644102056, 'local/env_act_steps': 44121088, 'local/env_train_steps': 44119040, 'local/optimizer_steps': 68936, 'local/running_reward': 22325.809041501976, 'local/running_step': 2331.7465106225295, 'local/steps_done': 44121088, 'local/episodes_done': 10382, 'local/unclipped_grad_norm': 0.7573391784120489, 'local/model_version': 68936, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:48,670] {'global/mean_episode_return': 49166.666666666664, 'global/mean_episode_step': 5067.5, 'global/SPS': 3325.0467575345415, 'global/env_act_steps': 44116736, 'global/env_train_steps': 44113920, 'global/optimizer_steps': 68928, 'global/running_reward': 22299.264348249028, 'global/running_step': 2329.5790065661477, 'global/steps_done': 44116736, 'global/episodes_done': 10381, 'global/unclipped_grad_norm': 0.7217323573736044, 'global/model_version': 68928, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:58,700] calculate_sps 30720 steps in 10.0325
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:00:58,700] calculate_sps 32000 steps in 10.0325
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:58,701] {'local/mean_episode_return': 48366.666666666664, 'local/mean_episode_step': 4877.833333333333, 'local/SPS': 3062.0601954524222, 'local/env_act_steps': 44154624, 'local/env_train_steps': 44149760, 'local/optimizer_steps': 68984, 'local/running_reward': 22570.509303435116, 'local/running_step': 2355.145664360687, 'local/steps_done': 44154624, 'local/episodes_done': 10388, 'local/unclipped_grad_norm': 0.7794935985778769, 'local/model_version': 68984, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:00:58,702] {'global/mean_episode_return': 48733.333333333336, 'global/mean_episode_step': 4859.166666666667, 'global/SPS': 3189.6460369296065, 'global/env_act_steps': 44150016, 'global/env_train_steps': 44145920, 'global/optimizer_steps': 68977, 'global/running_reward': 22557.001201923078, 'global/running_step': 2353.7609975961536, 'global/steps_done': 44150016, 'global/episodes_done': 10387, 'global/unclipped_grad_norm': 0.7844783536025456, 'global/model_version': 68977, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:08,706] calculate_sps 35200 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:08,706] calculate_sps 34560 steps in 10.0058
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:08,706] {'local/mean_episode_return': 42360.0, 'local/mean_episode_step': 4327.2, 'local/SPS': 3517.9762618244813, 'local/env_act_steps': 44186624, 'local/env_train_steps': 44184960, 'local/optimizer_steps': 69039, 'local/running_reward': 22766.49375, 'local/running_step': 2374.46778125, 'local/steps_done': 44186624, 'local/episodes_done': 10393, 'local/unclipped_grad_norm': 0.7923686853863976, 'local/model_version': 69039, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:08,708] {'global/mean_episode_return': 44200.0, 'global/mean_episode_step': 4505.0, 'global/SPS': 3454.0130570640363, 'global/env_act_steps': 44182784, 'global/env_train_steps': 44180480, 'global/optimizer_steps': 69032, 'global/running_reward': 22727.862548828125, 'global/running_step': 2370.501007080078, 'global/steps_done': 44182784, 'global/episodes_done': 10393, 'global/unclipped_grad_norm': 0.8086915986104445, 'global/model_version': 69032, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:18,718] calculate_sps 31360 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:18,718] calculate_sps 30720 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:18,718] {'local/mean_episode_return': 43700.0, 'local/mean_episode_step': 4630.25, 'local/SPS': 3132.3711489082193, 'local/env_act_steps': 44219264, 'local/env_train_steps': 44216320, 'local/optimizer_steps': 69088, 'local/running_reward': 23376.354166666668, 'local/running_step': 2436.343474264706, 'local/steps_done': 44219264, 'local/episodes_done': 10397, 'local/unclipped_grad_norm': 0.7786324401291049, 'local/model_version': 69088, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:18,720] {'global/mean_episode_return': 42666.666666666664, 'global/mean_episode_step': 4590.333333333333, 'global/SPS': 3068.445207093766, 'global/env_act_steps': 44215808, 'global/env_train_steps': 44211200, 'global/optimizer_steps': 69080, 'global/running_reward': 23300.859980620156, 'global/running_step': 2429.3732134205425, 'global/steps_done': 44215808, 'global/episodes_done': 10396, 'global/unclipped_grad_norm': 0.776507668197155, 'global/model_version': 69080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:28,727] calculate_sps 31360 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:28,727] calculate_sps 35840 steps in 10.0097
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:28,727] {'local/mean_episode_return': 43911.11111111111, 'local/mean_episode_step': 4549.0, 'local/SPS': 3132.9513826910697, 'local/env_act_steps': 44252288, 'local/env_train_steps': 44247680, 'local/optimizer_steps': 69136, 'local/running_reward': 23014.492490310076, 'local/running_step': 2392.940073885659, 'local/steps_done': 44252288, 'local/episodes_done': 10406, 'local/unclipped_grad_norm': 0.7176434028272828, 'local/model_version': 69136, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:28,728] {'global/mean_episode_return': 44200.0, 'global/mean_episode_step': 4569.1, 'global/SPS': 3580.515865932651, 'global/env_act_steps': 44248064, 'global/env_train_steps': 44247040, 'global/optimizer_steps': 69135, 'global/running_reward': 23052.969990079364, 'global/running_step': 2396.8980964781745, 'global/steps_done': 44248064, 'global/episodes_done': 10406, 'global/unclipped_grad_norm': 0.7160772781480442, 'global/model_version': 69135, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:38,752] calculate_sps 35200 steps in 10.025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:38,752] calculate_sps 30720 steps in 10.025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:38,753] {'local/mean_episode_return': 46550.0, 'local/mean_episode_step': 4624.0, 'local/SPS': 3511.211139585693, 'local/env_act_steps': 44284544, 'local/env_train_steps': 44282880, 'local/optimizer_steps': 69192, 'local/running_reward': 23386.011904761905, 'local/running_step': 2433.3919890873017, 'local/steps_done': 44284544, 'local/episodes_done': 10410, 'local/unclipped_grad_norm': 0.6317098736763, 'local/model_version': 69192, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:38,754] {'global/mean_episode_return': 46550.0, 'global/mean_episode_step': 4624.0, 'global/SPS': 3064.3297218202415, 'global/env_act_steps': 44281472, 'global/env_train_steps': 44277760, 'global/optimizer_steps': 69184, 'global/running_reward': 23326.2811302682, 'global/running_step': 2426.958093869732, 'global/steps_done': 44281472, 'global/episodes_done': 10410, 'global/unclipped_grad_norm': 0.6300397351080057, 'global/model_version': 69184, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:48,782] calculate_sps 30720 steps in 10.0303
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:48,783] calculate_sps 33280 steps in 10.0303
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:48,783] {'local/mean_episode_return': 48400.0, 'local/mean_episode_step': 4931.5, 'local/SPS': 3062.730326145826, 'local/env_act_steps': 44317696, 'local/env_train_steps': 44313600, 'local/optimizer_steps': 69240, 'local/running_reward': 23944.811776061775, 'local/running_step': 2490.4490528474903, 'local/steps_done': 44317696, 'local/episodes_done': 10414, 'local/unclipped_grad_norm': 0.7177321538329124, 'local/model_version': 69240, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:48,784] {'global/mean_episode_return': 48400.0, 'global/mean_episode_step': 4931.5, 'global/SPS': 3317.9578533246445, 'global/env_act_steps': 44314112, 'global/env_train_steps': 44311040, 'global/optimizer_steps': 69235, 'global/running_reward': 23893.235294117647, 'global/running_step': 2485.288082107843, 'global/steps_done': 44314112, 'global/episodes_done': 10414, 'global/unclipped_grad_norm': 0.7105437663255953, 'global/model_version': 69235, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:58,823] calculate_sps 34560 steps in 10.041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:01:58,823] calculate_sps 33280 steps in 10.041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:58,823] {'local/mean_episode_return': 45285.71428571428, 'local/mean_episode_step': 4739.428571428572, 'local/SPS': 3441.8990021934055, 'local/env_act_steps': 44350208, 'local/env_train_steps': 44348160, 'local/optimizer_steps': 69293, 'local/running_reward': 24253.235728346455, 'local/running_step': 2521.3877030019685, 'local/steps_done': 44350208, 'local/episodes_done': 10421, 'local/unclipped_grad_norm': 0.6902271556966709, 'local/model_version': 69293, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:01:58,824] {'global/mean_episode_return': 45285.71428571428, 'global/mean_episode_step': 4739.428571428572, 'global/SPS': 3314.4212613714276, 'global/env_act_steps': 44347008, 'global/env_train_steps': 44344320, 'global/optimizer_steps': 69288, 'global/running_reward': 24247.622811284047, 'global/running_step': 2521.0457502431905, 'global/steps_done': 44347008, 'global/episodes_done': 10421, 'global/unclipped_grad_norm': 0.6875228108662479, 'global/model_version': 69288, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:08,824] calculate_sps 32000 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:08,824] calculate_sps 32000 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:08,834] {'local/mean_episode_return': 44475.0, 'local/mean_episode_step': 4681.75, 'local/SPS': 3199.8255252605372, 'local/env_act_steps': 44383360, 'local/env_train_steps': 44380160, 'local/optimizer_steps': 69344, 'local/running_reward': 24304.470318532818, 'local/running_step': 2522.6345921814673, 'local/steps_done': 44383360, 'local/episodes_done': 10429, 'local/unclipped_grad_norm': 0.6628688909843856, 'local/model_version': 69344, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:08,836] {'global/mean_episode_return': 45171.42857142857, 'global/mean_episode_step': 4690.0, 'global/SPS': 3199.8255252605372, 'global/env_act_steps': 44380544, 'global/env_train_steps': 44376320, 'global/optimizer_steps': 69337, 'global/running_reward': 24314.831822519085, 'global/running_step': 2524.078065362595, 'global/steps_done': 44380544, 'global/episodes_done': 10428, 'global/unclipped_grad_norm': 0.6887170590308248, 'global/model_version': 69337, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:18,831] calculate_sps 31360 steps in 10.0071
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:18,831] calculate_sps 34560 steps in 10.0071
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:18,831] {'local/mean_episode_return': 49875.0, 'local/mean_episode_step': 4957.375, 'local/SPS': 3133.7675205823184, 'local/env_act_steps': 44416128, 'local/env_train_steps': 44411520, 'local/optimizer_steps': 69392, 'local/running_reward': 24066.88232421875, 'local/running_step': 2498.7081909179688, 'local/steps_done': 44416128, 'local/episodes_done': 10437, 'local/unclipped_grad_norm': 0.7760021748642126, 'local/model_version': 69392, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:18,832] {'global/mean_episode_return': 51000.0, 'global/mean_episode_step': 5028.333333333333, 'global/SPS': 3453.5397165601057, 'global/env_act_steps': 44412928, 'global/env_train_steps': 44410880, 'global/optimizer_steps': 69392, 'global/running_reward': 24060.289031620552, 'global/running_step': 2497.5937808794465, 'global/steps_done': 44412928, 'global/episodes_done': 10434, 'global/unclipped_grad_norm': 0.7409792255271564, 'global/model_version': 69392, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:28,847] calculate_sps 35200 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:28,847] calculate_sps 30720 steps in 10.0157
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:28,847] {'local/mean_episode_return': 43244.444444444445, 'local/mean_episode_step': 4467.833333333333, 'local/SPS': 3514.4895892415693, 'local/env_act_steps': 44448128, 'local/env_train_steps': 44446720, 'local/optimizer_steps': 69448, 'local/running_reward': 23887.00625, 'local/running_step': 2484.3, 'local/steps_done': 44448128, 'local/episodes_done': 10447, 'local/unclipped_grad_norm': 0.6995008130158696, 'local/model_version': 69448, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:28,849] {'global/mean_episode_return': 45036.36363636364, 'global/mean_episode_step': 4628.318181818182, 'global/SPS': 3067.1909142471877, 'global/env_act_steps': 44446464, 'global/env_train_steps': 44441600, 'global/optimizer_steps': 69440, 'global/running_reward': 23939.71851145038, 'global/running_step': 2489.513478053435, 'global/steps_done': 44446464, 'global/episodes_done': 10446, 'global/unclipped_grad_norm': 0.6741425885508457, 'global/model_version': 69440, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:38,879] calculate_sps 30720 steps in 10.0321
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:38,879] calculate_sps 34560 steps in 10.0321
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:38,879] {'local/mean_episode_return': 49850.0, 'local/mean_episode_step': 5109.25, 'local/SPS': 3062.171172180245, 'local/env_act_steps': 44481152, 'local/env_train_steps': 44477440, 'local/optimizer_steps': 69496, 'local/running_reward': 23560.356104651164, 'local/running_step': 2449.9756540697676, 'local/steps_done': 44481152, 'local/episodes_done': 10451, 'local/unclipped_grad_norm': 0.8154737285027901, 'local/model_version': 69496, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:38,881] {'global/mean_episode_return': 45160.0, 'global/mean_episode_step': 4769.8, 'global/SPS': 3444.942568702775, 'global/env_act_steps': 44478336, 'global/env_train_steps': 44476160, 'global/optimizer_steps': 69494, 'global/running_reward': 23530.358935742974, 'global/running_step': 2446.846699297189, 'global/steps_done': 44478336, 'global/episodes_done': 10451, 'global/unclipped_grad_norm': 0.8018300963772668, 'global/model_version': 69494, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:48,886] calculate_sps 32000 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:48,886] calculate_sps 32000 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:48,886] {'local/mean_episode_return': 48350.0, 'local/mean_episode_step': 4922.75, 'local/SPS': 3197.91075824267, 'local/env_act_steps': 44513664, 'local/env_train_steps': 44509440, 'local/optimizer_steps': 69546, 'local/running_reward': 24183.37844488189, 'local/running_step': 2510.293061023622, 'local/steps_done': 44513664, 'local/episodes_done': 10455, 'local/unclipped_grad_norm': 0.8025465506315231, 'local/model_version': 69546, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:48,900] {'global/mean_episode_return': 47533.333333333336, 'global/mean_episode_step': 4765.333333333333, 'global/SPS': 3197.91075824267, 'global/env_act_steps': 44511360, 'global/env_train_steps': 44508160, 'global/optimizer_steps': 69544, 'global/running_reward': 24133.242490310076, 'global/running_step': 2505.592659883721, 'global/steps_done': 44511360, 'global/episodes_done': 10454, 'global/unclipped_grad_norm': 0.8146937733888626, 'global/model_version': 69544, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:58,899] calculate_sps 34560 steps in 10.0133
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:02:58,899] calculate_sps 32000 steps in 10.0133
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:58,899] {'local/mean_episode_return': 47028.57142857143, 'local/mean_episode_step': 4752.857142857143, 'local/SPS': 3451.419588838255, 'local/env_act_steps': 44545920, 'local/env_train_steps': 44544000, 'local/optimizer_steps': 69600, 'local/running_reward': 24293.700396825396, 'local/running_step': 2521.937468998016, 'local/steps_done': 44545920, 'local/episodes_done': 10462, 'local/unclipped_grad_norm': 0.7315830019889055, 'local/model_version': 69600, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:02:58,901] {'global/mean_episode_return': 47500.0, 'global/mean_episode_step': 4833.125, 'global/SPS': 3195.75887855394, 'global/env_act_steps': 44544256, 'global/env_train_steps': 44540160, 'global/optimizer_steps': 69593, 'global/running_reward': 24300.711332684827, 'global/running_step': 2522.538484922179, 'global/steps_done': 44544256, 'global/episodes_done': 10462, 'global/unclipped_grad_norm': 0.7350201253988304, 'global/model_version': 69593, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:08,908] calculate_sps 30720 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:08,918] calculate_sps 34560 steps in 10.0093
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:08,918] {'local/mean_episode_return': 44461.53846153846, 'local/mean_episode_step': 4559.192307692308, 'local/SPS': 3069.1483283161447, 'local/env_act_steps': 44578944, 'local/env_train_steps': 44574720, 'local/optimizer_steps': 69648, 'local/running_reward': 23482.249273255813, 'local/running_step': 2442.036730862403, 'local/steps_done': 44578944, 'local/episodes_done': 10476, 'local/unclipped_grad_norm': 0.7883935272693634, 'local/model_version': 69648, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:08,920] {'global/mean_episode_return': 44461.53846153846, 'global/mean_episode_step': 4559.192307692308, 'global/SPS': 3452.791869355663, 'global/env_act_steps': 44576768, 'global/env_train_steps': 44574720, 'global/optimizer_steps': 69648, 'global/running_reward': 23542.63656496063, 'global/running_step': 2448.3156065452754, 'global/steps_done': 44576768, 'global/episodes_done': 10476, 'global/unclipped_grad_norm': 0.7887661668387327, 'global/model_version': 69648, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:18,949] calculate_sps 33920 steps in 10.041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:18,949] calculate_sps 30720 steps in 10.041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:18,949] {'local/mean_episode_return': 51680.0, 'local/mean_episode_step': 5077.2, 'local/SPS': 3378.1499447631513, 'local/env_act_steps': 44611200, 'local/env_train_steps': 44608640, 'local/optimizer_steps': 69700, 'local/running_reward': 23396.248759920636, 'local/running_step': 2432.0047433035716, 'local/steps_done': 44611200, 'local/episodes_done': 10481, 'local/unclipped_grad_norm': 0.6305333037789052, 'local/model_version': 69700, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:18,950] {'global/mean_episode_return': 50050.0, 'global/mean_episode_step': 4996.5, 'global/SPS': 3059.4565537477597, 'global/env_act_steps': 44610304, 'global/env_train_steps': 44605440, 'global/optimizer_steps': 69696, 'global/running_reward': 23371.851145038167, 'global/running_step': 2429.3911915553435, 'global/steps_done': 44610304, 'global/episodes_done': 10480, 'global/unclipped_grad_norm': 0.6368202287703753, 'global/model_version': 69696, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:28,952] calculate_sps 32640 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:28,962] calculate_sps 35840 steps in 10.0023
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:28,962] {'local/mean_episode_return': 34240.0, 'local/mean_episode_step': 3821.0, 'local/SPS': 3263.263290402965, 'local/env_act_steps': 44644224, 'local/env_train_steps': 44641280, 'local/optimizer_steps': 69752, 'local/running_reward': 23708.539244186046, 'local/running_step': 2462.0994428294575, 'local/steps_done': 44644224, 'local/episodes_done': 10486, 'local/unclipped_grad_norm': 0.6404317299333903, 'local/model_version': 69752, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:28,964] {'global/mean_episode_return': 38233.333333333336, 'global/mean_episode_step': 4084.1666666666665, 'global/SPS': 3583.191063971883, 'global/env_act_steps': 44642432, 'global/env_train_steps': 44641280, 'global/optimizer_steps': 69751, 'global/running_reward': 23696.258715139444, 'global/running_step': 2461.1565612549803, 'global/steps_done': 44642432, 'global/episodes_done': 10486, 'global/unclipped_grad_norm': 0.6271489417011088, 'global/model_version': 69751, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:38,961] calculate_sps 31360 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:38,961] calculate_sps 30720 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:38,974] {'local/mean_episode_return': 45600.0, 'local/mean_episode_step': 4751.0, 'local/SPS': 3132.981157458337, 'local/env_act_steps': 44677376, 'local/env_train_steps': 44672640, 'local/optimizer_steps': 69801, 'local/running_reward': 24205.152027027027, 'local/running_step': 2507.7407697876447, 'local/steps_done': 44677376, 'local/episodes_done': 10489, 'local/unclipped_grad_norm': 0.7001764515832979, 'local/model_version': 69801, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:38,979] {'global/mean_episode_return': 45600.0, 'global/mean_episode_step': 4751.0, 'global/SPS': 3069.0427664897993, 'global/env_act_steps': 44676224, 'global/env_train_steps': 44672000, 'global/optimizer_steps': 69800, 'global/running_reward': 24181.457149621212, 'global/running_step': 2505.323982007576, 'global/steps_done': 44676224, 'global/episodes_done': 10489, 'global/unclipped_grad_norm': 0.7012657848547916, 'global/model_version': 69800, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:49,000] calculate_sps 35200 steps in 10.0395
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:49,001] calculate_sps 34560 steps in 10.0395
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:49,001] {'local/mean_episode_return': 42600.0, 'local/mean_episode_step': 4526.75, 'local/SPS': 3506.1427952962813, 'local/env_act_steps': 44709504, 'local/env_train_steps': 44707840, 'local/optimizer_steps': 69856, 'local/running_reward': 24973.63047808765, 'local/running_step': 2580.613141185259, 'local/steps_done': 44709504, 'local/episodes_done': 10493, 'local/unclipped_grad_norm': 0.6378411504355344, 'local/model_version': 69856, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:49,011] {'global/mean_episode_return': 42600.0, 'global/mean_episode_step': 4526.75, 'global/SPS': 3442.3947444727123, 'global/env_act_steps': 44708608, 'global/env_train_steps': 44706560, 'global/optimizer_steps': 69853, 'global/running_reward': 24938.549901185772, 'global/running_step': 2577.3580471837945, 'global/steps_done': 44708608, 'global/episodes_done': 10493, 'global/unclipped_grad_norm': 0.6491399705410004, 'global/model_version': 69853, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:59,016] calculate_sps 30720 steps in 10.016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:03:59,017] calculate_sps 32000 steps in 10.016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:59,017] {'local/mean_episode_return': 43700.0, 'local/mean_episode_step': 4512.125, 'local/SPS': 3067.097533396864, 'local/env_act_steps': 44742656, 'local/env_train_steps': 44738560, 'local/optimizer_steps': 69904, 'local/running_reward': 25007.64358108108, 'local/running_step': 2582.2944015444014, 'local/steps_done': 44742656, 'local/episodes_done': 10506, 'local/unclipped_grad_norm': 0.6237351447343826, 'local/model_version': 69904, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:03:59,018] {'global/mean_episode_return': 44100.0, 'global/mean_episode_step': 4517.45, 'global/SPS': 3194.8932639550667, 'global/env_act_steps': 44741632, 'global/env_train_steps': 44738560, 'global/optimizer_steps': 69904, 'global/running_reward': 25037.94815891473, 'global/running_step': 2585.3244912790697, 'global/steps_done': 44741632, 'global/episodes_done': 10504, 'global/unclipped_grad_norm': 0.619458302563312, 'global/model_version': 69904, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:09,027] calculate_sps 33920 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:09,027] calculate_sps 32640 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:09,027] {'local/mean_episode_return': 45260.0, 'local/mean_episode_step': 4654.2, 'local/SPS': 3388.2518665765424, 'local/env_act_steps': 44775040, 'local/env_train_steps': 44772480, 'local/optimizer_steps': 69956, 'local/running_reward': 24291.396986166008, 'local/running_step': 2505.7606225296445, 'local/steps_done': 44775040, 'local/episodes_done': 10516, 'local/unclipped_grad_norm': 0.7339897958131937, 'local/model_version': 69956, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:09,028] {'global/mean_episode_return': 44666.666666666664, 'global/mean_episode_step': 4626.083333333333, 'global/SPS': 3260.393305573654, 'global/env_act_steps': 44774784, 'global/env_train_steps': 44771200, 'global/optimizer_steps': 69954, 'global/running_reward': 24303.462837837837, 'global/running_step': 2507.092513272201, 'global/steps_done': 44774784, 'global/episodes_done': 10516, 'global/unclipped_grad_norm': 0.7200555241107941, 'global/model_version': 69954, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:19,041] calculate_sps 32640 steps in 10.0132
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:19,041] calculate_sps 33920 steps in 10.0132
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:19,041] {'local/mean_episode_return': 45381.818181818184, 'local/mean_episode_step': 4661.272727272727, 'local/SPS': 3259.6870176617585, 'local/env_act_steps': 44808064, 'local/env_train_steps': 44805120, 'local/optimizer_steps': 70008, 'local/running_reward': 23371.73570736434, 'local/running_step': 2410.4840721899227, 'local/steps_done': 44808064, 'local/episodes_done': 10527, 'local/unclipped_grad_norm': 0.6919314614855326, 'local/model_version': 70008, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:19,043] {'global/mean_episode_return': 45381.818181818184, 'global/mean_episode_step': 4661.272727272727, 'global/SPS': 3387.5178810994744, 'global/env_act_steps': 44807936, 'global/env_train_steps': 44805120, 'global/optimizer_steps': 70008, 'global/running_reward': 23369.045608108107, 'global/running_step': 2410.246651785714, 'global/steps_done': 44807936, 'global/episodes_done': 10527, 'global/unclipped_grad_norm': 0.7063912809998901, 'global/model_version': 70008, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:29,051] calculate_sps 31360 steps in 10.0102
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:29,051] calculate_sps 31360 steps in 10.0102
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:29,051] {'local/mean_episode_return': 48550.0, 'local/mean_episode_step': 4919.5, 'local/SPS': 3132.8196790429597, 'local/env_act_steps': 44841088, 'local/env_train_steps': 44836480, 'local/optimizer_steps': 70056, 'local/running_reward': 22923.10440891473, 'local/running_step': 2366.6713602228683, 'local/steps_done': 44841088, 'local/episodes_done': 10535, 'local/unclipped_grad_norm': 0.7472471756239732, 'local/model_version': 70056, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:29,052] {'global/mean_episode_return': 48550.0, 'global/mean_episode_step': 4919.5, 'global/SPS': 3132.8196790429597, 'global/env_act_steps': 44841088, 'global/env_train_steps': 44836480, 'global/optimizer_steps': 70056, 'global/running_reward': 22930.869932432433, 'global/running_step': 2367.416113658301, 'global/steps_done': 44841088, 'global/episodes_done': 10535, 'global/unclipped_grad_norm': 0.7472471756239732, 'global/model_version': 70056, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:39,072] calculate_sps 35200 steps in 10.0208
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:39,072] calculate_sps 27520 steps in 10.0208
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:39,073] {'local/mean_episode_return': 50250.0, 'local/mean_episode_step': 5070.25, 'local/SPS': 3512.6950618249743, 'local/env_act_steps': 44873216, 'local/env_train_steps': 44871680, 'local/optimizer_steps': 70112, 'local/running_reward': 22442.019422310757, 'local/running_step': 2316.0771289840636, 'local/steps_done': 44873216, 'local/episodes_done': 10543, 'local/unclipped_grad_norm': 0.6686094605496952, 'local/model_version': 70112, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:39,075] {'global/mean_episode_return': 50250.0, 'global/mean_episode_step': 5070.25, 'global/SPS': 2746.2888665177074, 'global/env_act_steps': 44867072, 'global/env_train_steps': 44864000, 'global/optimizer_steps': 70099, 'global/running_reward': 22448.60683497537, 'global/running_step': 2316.6135314039407, 'global/steps_done': 44867072, 'global/episodes_done': 10543, 'global/unclipped_grad_norm': 0.6705062458681506, 'global/model_version': 70099, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:49,096] calculate_sps 30720 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:49,097] calculate_sps 33280 steps in 10.0246
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:49,106] {'local/mean_episode_return': 51600.0, 'local/mean_episode_step': 5153.166666666667, 'local/SPS': 3064.448807297216, 'local/env_act_steps': 44906624, 'local/env_train_steps': 44902400, 'local/optimizer_steps': 70160, 'local/running_reward': 22801.538553639846, 'local/running_step': 2353.658644636015, 'local/steps_done': 44906624, 'local/episodes_done': 10549, 'local/unclipped_grad_norm': 0.7368593129018942, 'local/model_version': 70160, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:49,107] {'global/mean_episode_return': 51266.666666666664, 'global/mean_episode_step': 5169.666666666667, 'global/SPS': 3319.8195412386503, 'global/env_act_steps': 44900224, 'global/env_train_steps': 44897280, 'global/optimizer_steps': 70152, 'global/running_reward': 22689.864864864863, 'global/running_step': 2342.3083976833977, 'global/steps_done': 44900224, 'global/episodes_done': 10546, 'global/unclipped_grad_norm': 0.7293736366730816, 'global/model_version': 70152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:59,107] calculate_sps 34560 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:04:59,108] calculate_sps 32000 steps in 10.0116
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:59,108] {'local/mean_episode_return': 47960.0, 'local/mean_episode_step': 4730.8, 'local/SPS': 3451.999296050524, 'local/env_act_steps': 44939008, 'local/env_train_steps': 44936960, 'local/optimizer_steps': 70213, 'local/running_reward': 22812.141798418972, 'local/running_step': 2355.896646492095, 'local/steps_done': 44939008, 'local/episodes_done': 10554, 'local/unclipped_grad_norm': 0.7545597345199225, 'local/model_version': 70213, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:04:59,109] {'global/mean_episode_return': 48400.0, 'global/mean_episode_step': 4840.142857142857, 'global/SPS': 3196.295644491226, 'global/env_act_steps': 44933504, 'global/env_train_steps': 44929280, 'global/optimizer_steps': 70201, 'global/running_reward': 22826.640625, 'global/running_step': 2357.0365685096153, 'global/steps_done': 44933504, 'global/episodes_done': 10553, 'global/unclipped_grad_norm': 0.7599098895277295, 'global/model_version': 70201, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:09,127] calculate_sps 32000 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:09,127] calculate_sps 34560 steps in 10.005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:09,128] {'local/mean_episode_return': 53560.0, 'local/mean_episode_step': 5166.4, 'local/SPS': 3198.401982499474, 'local/env_act_steps': 44972288, 'local/env_train_steps': 44968960, 'local/optimizer_steps': 70264, 'local/running_reward': 23096.08173076923, 'local/running_step': 2391.2434795673075, 'local/steps_done': 44972288, 'local/episodes_done': 10559, 'local/unclipped_grad_norm': 0.658742002120205, 'local/model_version': 70264, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:09,129] {'global/mean_episode_return': 54100.0, 'global/mean_episode_step': 5169.166666666667, 'global/SPS': 3454.274141099432, 'global/env_act_steps': 44966784, 'global/env_train_steps': 44963840, 'global/optimizer_steps': 70256, 'global/running_reward': 23084.53125, 'global/running_step': 2388.5271935096152, 'global/steps_done': 44966784, 'global/episodes_done': 10559, 'global/unclipped_grad_norm': 0.6582839795134284, 'global/model_version': 70256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:19,132] calculate_sps 33280 steps in 10.0193
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:19,132] calculate_sps 33280 steps in 10.0193
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:19,132] {'local/mean_episode_return': 55500.0, 'local/mean_episode_step': 5323.75, 'local/SPS': 3321.5846745276735, 'local/env_act_steps': 45005312, 'local/env_train_steps': 45002240, 'local/optimizer_steps': 70315, 'local/running_reward': 23492.29651162791, 'local/running_step': 2434.2691981589146, 'local/steps_done': 45005312, 'local/episodes_done': 10563, 'local/unclipped_grad_norm': 0.7086978671597499, 'local/model_version': 70315, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:19,133] {'global/mean_episode_return': 56000.0, 'global/mean_episode_step': 5390.333333333333, 'global/SPS': 3321.5846745276735, 'global/env_act_steps': 45000320, 'global/env_train_steps': 44997120, 'global/optimizer_steps': 70308, 'global/running_reward': 23411.408635496184, 'global/running_step': 2425.83346254771, 'global/steps_done': 45000320, 'global/episodes_done': 10562, 'global/unclipped_grad_norm': 0.7238464985902493, 'global/model_version': 70308, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:29,137] calculate_sps 33280 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:29,138] calculate_sps 33280 steps in 10.0053
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:29,138] {'local/mean_episode_return': 46150.0, 'local/mean_episode_step': 4660.125, 'local/SPS': 3326.253486620525, 'local/env_act_steps': 45038080, 'local/env_train_steps': 45035520, 'local/optimizer_steps': 70368, 'local/running_reward': 23442.535400390625, 'local/running_step': 2431.47802734375, 'local/steps_done': 45038080, 'local/episodes_done': 10571, 'local/unclipped_grad_norm': 0.6184946450422395, 'local/model_version': 70368, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:29,139] {'global/mean_episode_return': 49000.0, 'global/mean_episode_step': 4881.571428571428, 'global/SPS': 3326.253486620525, 'global/env_act_steps': 45033088, 'global/env_train_steps': 45030400, 'global/optimizer_steps': 70360, 'global/running_reward': 23466.900634765625, 'global/running_step': 2433.8408813476562, 'global/steps_done': 45033088, 'global/episodes_done': 10569, 'global/unclipped_grad_norm': 0.6072790737335498, 'global/model_version': 70360, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:39,159] calculate_sps 30720 steps in 10.0211
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:39,159] calculate_sps 31360 steps in 10.0211
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:39,159] {'local/mean_episode_return': 44240.0, 'local/mean_episode_step': 4489.8, 'local/SPS': 3065.540393697372, 'local/env_act_steps': 45071104, 'local/env_train_steps': 45066240, 'local/optimizer_steps': 70416, 'local/running_reward': 23025.47843992248, 'local/running_step': 2386.651253633721, 'local/steps_done': 45071104, 'local/episodes_done': 10581, 'local/unclipped_grad_norm': 0.8025732462604841, 'local/model_version': 70416, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:39,160] {'global/mean_episode_return': 43036.36363636364, 'global/mean_episode_step': 4387.363636363636, 'global/SPS': 3129.4058185660674, 'global/env_act_steps': 45066368, 'global/env_train_steps': 45061760, 'global/optimizer_steps': 70408, 'global/running_reward': 23073.587740384617, 'global/running_step': 2391.908112980769, 'global/steps_done': 45066368, 'global/episodes_done': 10580, 'global/unclipped_grad_norm': 0.777417437483867, 'global/model_version': 70408, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:49,187] calculate_sps 35840 steps in 10.029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:49,187] calculate_sps 35200 steps in 10.029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:49,188] {'local/mean_episode_return': 48400.0, 'local/mean_episode_step': 4879.333333333333, 'local/SPS': 3573.6202971292073, 'local/env_act_steps': 45103104, 'local/env_train_steps': 45102080, 'local/optimizer_steps': 70471, 'local/running_reward': 23084.3375, 'local/running_step': 2390.47621875, 'local/steps_done': 45103104, 'local/episodes_done': 10587, 'local/unclipped_grad_norm': 0.6896708732301539, 'local/model_version': 70471, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:49,188] {'global/mean_episode_return': 47200.0, 'global/mean_episode_step': 4791.5, 'global/SPS': 3509.805648966186, 'global/env_act_steps': 45099136, 'global/env_train_steps': 45096960, 'global/optimizer_steps': 70464, 'global/running_reward': 23074.176025390625, 'global/running_step': 2389.765380859375, 'global/steps_done': 45099136, 'global/episodes_done': 10586, 'global/unclipped_grad_norm': 0.6605209841259888, 'global/model_version': 70464, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 15:05:52,489] saving global stats {'mean_episode_return': 56400.0, 'mean_episode_step': 5398.0, 'SPS': None, 'env_act_steps': 45105920, 'env_train_steps': 45102080, 'optimizer_steps': 70472, 'running_reward': 23121.196933962263, 'running_step': 2394.762824292453, 'steps_done': 45105920, 'episodes_done': 10587, 'unclipped_grad_norm': 1.0777524672448635, 'model_version': 70472, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 15:05:52,596] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:59,208] calculate_sps 30720 steps in 10.0207
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:05:59,209] calculate_sps 30720 steps in 10.0207
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:59,209] {'local/mean_episode_return': 50720.0, 'local/mean_episode_step': 4946.1, 'local/SPS': 3065.6681802561898, 'local/env_act_steps': 45136000, 'local/env_train_steps': 45132800, 'local/optimizer_steps': 70520, 'local/running_reward': 22945.62864785992, 'local/running_step': 2378.732733463035, 'local/steps_done': 45136000, 'local/episodes_done': 10597, 'local/unclipped_grad_norm': 0.7938129092965808, 'local/model_version': 70520, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:05:59,210] {'global/mean_episode_return': 50000.0, 'global/mean_episode_step': 4863.571428571428, 'global/SPS': 3065.6681802561898, 'global/env_act_steps': 45132032, 'global/env_train_steps': 45127680, 'global/optimizer_steps': 70512, 'global/running_reward': 23020.282101167315, 'global/running_step': 2385.5670598249026, 'global/steps_done': 45132032, 'global/episodes_done': 10593, 'global/unclipped_grad_norm': 0.7864109892398119, 'global/model_version': 70512, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:09,233] calculate_sps 31360 steps in 10.025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:09,233] calculate_sps 33920 steps in 10.025
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:09,233] {'local/mean_episode_return': 44500.0, 'local/mean_episode_step': 4598.166666666667, 'local/SPS': 3128.18629138019, 'local/env_act_steps': 45168768, 'local/env_train_steps': 45164160, 'local/optimizer_steps': 70568, 'local/running_reward': 22508.282470703125, 'local/running_step': 2339.9765014648438, 'local/steps_done': 45168768, 'local/episodes_done': 10603, 'local/unclipped_grad_norm': 0.6716629167397817, 'local/model_version': 70568, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:09,234] {'global/mean_episode_return': 48177.77777777778, 'global/mean_episode_step': 4845.0, 'global/SPS': 3383.5484376153076, 'global/env_act_steps': 45164160, 'global/env_train_steps': 45161600, 'global/optimizer_steps': 70564, 'global/running_reward': 22485.371015936256, 'global/running_step': 2337.3663159860557, 'global/steps_done': 45164160, 'global/episodes_done': 10602, 'global/unclipped_grad_norm': 0.7158659948752477, 'global/model_version': 70564, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:19,237] calculate_sps 35200 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:19,237] calculate_sps 32640 steps in 10.004
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:19,238] {'local/mean_episode_return': 46433.333333333336, 'local/mean_episode_step': 4872.333333333333, 'local/SPS': 3518.576900040334, 'local/env_act_steps': 45201024, 'local/env_train_steps': 45199360, 'local/optimizer_steps': 70624, 'local/running_reward': 22505.115327380954, 'local/running_step': 2336.5773189484125, 'local/steps_done': 45201024, 'local/episodes_done': 10609, 'local/unclipped_grad_norm': 0.7000475275729384, 'local/model_version': 70624, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:19,239] {'global/mean_episode_return': 49166.666666666664, 'global/mean_episode_step': 5085.166666666667, 'global/SPS': 3262.6803982192187, 'global/env_act_steps': 45197696, 'global/env_train_steps': 45194240, 'global/optimizer_steps': 70616, 'global/running_reward': 22502.600190839694, 'global/running_step': 2337.212666984733, 'global/steps_done': 45197696, 'global/episodes_done': 10608, 'global/unclipped_grad_norm': 0.710602013537517, 'global/model_version': 70616, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:29,267] calculate_sps 30720 steps in 10.0295
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:29,267] calculate_sps 32640 steps in 10.0295
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:29,267] {'local/mean_episode_return': 53200.0, 'local/mean_episode_step': 5054.0, 'local/SPS': 3062.9775049510786, 'local/env_act_steps': 45234048, 'local/env_train_steps': 45230080, 'local/optimizer_steps': 70672, 'local/running_reward': 23183.181928294573, 'local/running_step': 2398.89964874031, 'local/steps_done': 45234048, 'local/episodes_done': 10612, 'local/unclipped_grad_norm': 0.7864884051183859, 'local/model_version': 70672, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:29,269] {'global/mean_episode_return': 47550.0, 'global/mean_episode_step': 4670.75, 'global/SPS': 3254.413599010521, 'global/env_act_steps': 45230464, 'global/env_train_steps': 45226880, 'global/optimizer_steps': 70666, 'global/running_reward': 23114.044189453125, 'global/running_step': 2392.1190795898438, 'global/steps_done': 45230464, 'global/episodes_done': 10612, 'global/unclipped_grad_norm': 0.7640744632482529, 'global/model_version': 70666, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:39,270] calculate_sps 33280 steps in 10.0028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:39,270] calculate_sps 33920 steps in 10.0028
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:39,282] {'local/mean_episode_return': 51350.0, 'local/mean_episode_step': 5176.75, 'local/SPS': 3327.0734208910603, 'local/env_act_steps': 45266560, 'local/env_train_steps': 45263360, 'local/optimizer_steps': 70724, 'local/running_reward': 23520.890748031496, 'local/running_step': 2428.8540846456694, 'local/steps_done': 45266560, 'local/episodes_done': 10619, 'local/unclipped_grad_norm': 0.8145331215973084, 'local/model_version': 70724, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:39,284] {'global/mean_episode_return': 50925.0, 'global/mean_episode_step': 5069.875, 'global/SPS': 3391.055602062042, 'global/env_act_steps': 45263104, 'global/env_train_steps': 45260800, 'global/optimizer_steps': 70720, 'global/running_reward': 23506.446078431374, 'global/running_step': 2428.097549019608, 'global/steps_done': 45263104, 'global/episodes_done': 10617, 'global/unclipped_grad_norm': 0.8120382055640221, 'global/model_version': 70720, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:49,291] calculate_sps 33280 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:49,291] calculate_sps 30720 steps in 10.0214
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:49,292] {'local/mean_episode_return': 45700.0, 'local/mean_episode_step': 4725.75, 'local/SPS': 3320.8829467963083, 'local/env_act_steps': 45299456, 'local/env_train_steps': 45296640, 'local/optimizer_steps': 70776, 'local/running_reward': 23717.631322957197, 'local/running_step': 2444.199933122568, 'local/steps_done': 45299456, 'local/episodes_done': 10623, 'local/unclipped_grad_norm': 0.680864367634058, 'local/model_version': 70776, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:49,293] {'global/mean_episode_return': 48320.0, 'global/mean_episode_step': 4946.4, 'global/SPS': 3065.4304124273613, 'global/env_act_steps': 45296768, 'global/env_train_steps': 45291520, 'global/optimizer_steps': 70768, 'global/running_reward': 23659.23835551331, 'global/running_step': 2438.7226711026615, 'global/steps_done': 45296768, 'global/episodes_done': 10622, 'global/unclipped_grad_norm': 0.7036453022932013, 'global/model_version': 70768, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:59,339] calculate_sps 32000 steps in 10.0486
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:06:59,339] calculate_sps 35840 steps in 10.0486
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:59,339] {'local/mean_episode_return': 53200.0, 'local/mean_episode_step': 5258.666666666667, 'local/SPS': 3184.5208124960036, 'local/env_act_steps': 45332736, 'local/env_train_steps': 45328640, 'local/optimizer_steps': 70825, 'local/running_reward': 24223.677884615383, 'local/running_step': 2496.0620192307692, 'local/steps_done': 45332736, 'local/episodes_done': 10626, 'local/unclipped_grad_norm': 0.7407461806219451, 'local/model_version': 70825, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:06:59,340] {'global/mean_episode_return': 51300.0, 'global/mean_episode_step': 5182.0, 'global/SPS': 3566.663309995524, 'global/env_act_steps': 45329536, 'global/env_train_steps': 45327360, 'global/optimizer_steps': 70824, 'global/running_reward': 24185.31494140625, 'global/running_step': 2491.668487548828, 'global/steps_done': 45329536, 'global/episodes_done': 10626, 'global/unclipped_grad_norm': 0.7265744065599782, 'global/model_version': 70824, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:09,373] calculate_sps 34560 steps in 10.0332
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:09,373] calculate_sps 30720 steps in 10.0332
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:09,373] {'local/mean_episode_return': 50150.0, 'local/mean_episode_step': 5043.125, 'local/SPS': 3444.5691134849344, 'local/env_act_steps': 45365376, 'local/env_train_steps': 45363200, 'local/optimizer_steps': 70880, 'local/running_reward': 24698.664215686276, 'local/running_step': 2546.0301470588233, 'local/steps_done': 45365376, 'local/episodes_done': 10634, 'local/unclipped_grad_norm': 0.7518147354776209, 'local/model_version': 70880, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:09,375] {'global/mean_episode_return': 50900.0, 'global/mean_episode_step': 5085.0, 'global/SPS': 3061.8392119866085, 'global/env_act_steps': 45363200, 'global/env_train_steps': 45358080, 'global/optimizer_steps': 70872, 'global/running_reward': 24703.903279467682, 'global/running_step': 2546.6643892585553, 'global/steps_done': 45363200, 'global/episodes_done': 10632, 'global/unclipped_grad_norm': 0.7343622539192438, 'global/model_version': 70872, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:19,394] calculate_sps 30720 steps in 10.0218
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:19,395] calculate_sps 35840 steps in 10.0218
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:19,395] {'local/mean_episode_return': 48300.0, 'local/mean_episode_step': 4806.75, 'local/SPS': 3065.3276585443073, 'local/env_act_steps': 45398272, 'local/env_train_steps': 45393920, 'local/optimizer_steps': 70928, 'local/running_reward': 24684.320282101166, 'local/running_step': 2547.988722033074, 'local/steps_done': 45398272, 'local/episodes_done': 10638, 'local/unclipped_grad_norm': 0.7028266185273727, 'local/model_version': 70928, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:19,396] {'global/mean_episode_return': 48920.0, 'global/mean_episode_step': 4952.6, 'global/SPS': 3576.215601635025, 'global/env_act_steps': 45395072, 'global/env_train_steps': 45393920, 'global/optimizer_steps': 70927, 'global/running_reward': 24657.62424698795, 'global/running_step': 2544.882404618474, 'global/steps_done': 45395072, 'global/episodes_done': 10637, 'global/unclipped_grad_norm': 0.734843370589343, 'global/model_version': 70927, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:29,414] calculate_sps 34560 steps in 10.0193
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:29,414] calculate_sps 30720 steps in 10.0193
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:29,415] {'local/mean_episode_return': 50900.0, 'local/mean_episode_step': 5135.333333333333, 'local/SPS': 3449.3494224918486, 'local/env_act_steps': 45430656, 'local/env_train_steps': 45428480, 'local/optimizer_steps': 70982, 'local/running_reward': 24316.946640316204, 'local/running_step': 2511.417768033597, 'local/steps_done': 45430656, 'local/episodes_done': 10650, 'local/unclipped_grad_norm': 0.8209268075448496, 'local/model_version': 70982, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:29,416] {'global/mean_episode_return': 50254.545454545456, 'global/mean_episode_step': 5059.545454545455, 'global/SPS': 3066.08837554831, 'global/env_act_steps': 45428864, 'global/env_train_steps': 45424640, 'global/optimizer_steps': 70976, 'global/running_reward': 24384.04356060606, 'global/running_step': 2518.3004261363635, 'global/steps_done': 45428864, 'global/episodes_done': 10648, 'global/unclipped_grad_norm': 0.8106809264543106, 'global/model_version': 70976, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:39,432] calculate_sps 32000 steps in 10.0185
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:39,433] calculate_sps 35200 steps in 10.0185
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:39,433] {'local/mean_episode_return': 42566.666666666664, 'local/mean_episode_step': 4391.5, 'local/SPS': 3194.0760808389555, 'local/env_act_steps': 45463936, 'local/env_train_steps': 45460480, 'local/optimizer_steps': 71032, 'local/running_reward': 23628.419471153848, 'local/running_step': 2442.3738581730768, 'local/steps_done': 45463936, 'local/episodes_done': 10656, 'local/unclipped_grad_norm': 0.785869329571724, 'local/model_version': 71032, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:39,443] {'global/mean_episode_return': 44725.0, 'global/mean_episode_step': 4577.125, 'global/SPS': 3513.483688922851, 'global/env_act_steps': 45461504, 'global/env_train_steps': 45459840, 'global/optimizer_steps': 71030, 'global/running_reward': 23620.839460784315, 'global/running_step': 2441.848835784314, 'global/steps_done': 45461504, 'global/episodes_done': 10656, 'global/unclipped_grad_norm': 0.7806984495233606, 'global/model_version': 71030, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:49,459] calculate_sps 32640 steps in 10.027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:49,459] calculate_sps 31360 steps in 10.027
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:49,459] {'local/mean_episode_return': 43866.666666666664, 'local/mean_episode_step': 4798.333333333333, 'local/SPS': 3255.2262721154666, 'local/env_act_steps': 45496704, 'local/env_train_steps': 45493120, 'local/optimizer_steps': 71082, 'local/running_reward': 24335.107421875, 'local/running_step': 2506.0391540527344, 'local/steps_done': 45496704, 'local/episodes_done': 10659, 'local/unclipped_grad_norm': 0.7561002916097641, 'local/model_version': 71082, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:49,460] {'global/mean_episode_return': 43866.666666666664, 'global/mean_episode_step': 4798.333333333333, 'global/SPS': 3127.570339875644, 'global/env_act_steps': 45495424, 'global/env_train_steps': 45491200, 'global/optimizer_steps': 71080, 'global/running_reward': 24291.880896226416, 'global/running_step': 2502.0792158018867, 'global/steps_done': 45495424, 'global/episodes_done': 10659, 'global/unclipped_grad_norm': 0.7721435886621475, 'global/model_version': 71080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:59,476] calculate_sps 33920 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:07:59,477] calculate_sps 35840 steps in 10.0172
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:59,486] {'local/mean_episode_return': 45542.857142857145, 'local/mean_episode_step': 4746.857142857143, 'local/SPS': 3386.181905146211, 'local/env_act_steps': 45529728, 'local/env_train_steps': 45527040, 'local/optimizer_steps': 71136, 'local/running_reward': 24686.12524224806, 'local/running_step': 2534.674085513566, 'local/steps_done': 45529728, 'local/episodes_done': 10666, 'local/unclipped_grad_norm': 0.8229421073639834, 'local/model_version': 71136, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:07:59,487] {'global/mean_episode_return': 45542.857142857145, 'global/mean_episode_step': 4746.857142857143, 'global/SPS': 3577.8525790224116, 'global/env_act_steps': 45528064, 'global/env_train_steps': 45527040, 'global/optimizer_steps': 71135, 'global/running_reward': 24683.235294117647, 'global/running_step': 2534.7783394607845, 'global/steps_done': 45528064, 'global/episodes_done': 10666, 'global/unclipped_grad_norm': 0.8238754971460862, 'global/model_version': 71135, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:09,511] calculate_sps 31360 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:09,511] calculate_sps 30720 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:09,511] {'local/mean_episode_return': 48200.0, 'local/mean_episode_step': 4801.0, 'local/SPS': 3125.174224410361, 'local/env_act_steps': 45563008, 'local/env_train_steps': 45558400, 'local/optimizer_steps': 71184, 'local/running_reward': 25138.31730769231, 'local/running_step': 2575.1708834134615, 'local/steps_done': 45563008, 'local/episodes_done': 10670, 'local/unclipped_grad_norm': 0.7983386864264806, 'local/model_version': 71184, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:09,512] {'global/mean_episode_return': 48200.0, 'global/mean_episode_step': 4801.0, 'global/SPS': 3061.395158606068, 'global/env_act_steps': 45561728, 'global/env_train_steps': 45557760, 'global/optimizer_steps': 71184, 'global/running_reward': 25112.339591254753, 'global/running_step': 2572.547498811787, 'global/steps_done': 45561728, 'global/episodes_done': 10670, 'global/unclipped_grad_norm': 0.7926030280638714, 'global/model_version': 71184, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:19,525] calculate_sps 35200 steps in 10.0141
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:19,525] calculate_sps 33920 steps in 10.0141
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:19,526] {'local/mean_episode_return': 46450.0, 'local/mean_episode_step': 4622.25, 'local/SPS': 3515.038154982518, 'local/env_act_steps': 45595136, 'local/env_train_steps': 45593600, 'local/optimizer_steps': 71240, 'local/running_reward': 25611.124252988047, 'local/running_step': 2625.789124750996, 'local/steps_done': 45595136, 'local/episodes_done': 10674, 'local/unclipped_grad_norm': 0.7247647850641182, 'local/model_version': 71240, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:19,529] {'global/mean_episode_return': 46450.0, 'global/mean_episode_step': 4622.25, 'global/SPS': 3387.2185857104264, 'global/env_act_steps': 45594368, 'global/env_train_steps': 45591680, 'global/optimizer_steps': 71237, 'global/running_reward': 25595.882352941175, 'global/running_step': 2624.117524509804, 'global/steps_done': 45594368, 'global/episodes_done': 10674, 'global/unclipped_grad_norm': 0.7249031775402572, 'global/model_version': 71237, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:29,545] calculate_sps 30720 steps in 10.0196
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:29,545] calculate_sps 32640 steps in 10.0196
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:29,545] {'local/mean_episode_return': 49969.230769230766, 'local/mean_episode_step': 5008.615384615385, 'local/SPS': 3065.9831700156415, 'local/env_act_steps': 45628544, 'local/env_train_steps': 45624320, 'local/optimizer_steps': 71288, 'local/running_reward': 25012.236590038316, 'local/running_step': 2570.1560404693487, 'local/steps_done': 45628544, 'local/episodes_done': 10689, 'local/unclipped_grad_norm': 0.8159285622338454, 'local/model_version': 71288, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:29,547] {'global/mean_episode_return': 49969.230769230766, 'global/mean_episode_step': 5008.615384615385, 'global/SPS': 3257.6071181416187, 'global/env_act_steps': 45627904, 'global/env_train_steps': 45624320, 'global/optimizer_steps': 71288, 'global/running_reward': 25054.252146946565, 'global/running_step': 2574.1645097805344, 'global/steps_done': 45627904, 'global/episodes_done': 10689, 'global/unclipped_grad_norm': 0.8104221674741483, 'global/model_version': 71288, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:39,585] calculate_sps 35200 steps in 10.041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:39,586] calculate_sps 33920 steps in 10.041
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:39,586] {'local/mean_episode_return': 44400.0, 'local/mean_episode_step': 4583.571428571428, 'local/SPS': 3505.6389547233944, 'local/env_act_steps': 45661056, 'local/env_train_steps': 45659520, 'local/optimizer_steps': 71342, 'local/running_reward': 24201.753198818897, 'local/running_step': 2493.5746493602364, 'local/steps_done': 45661056, 'local/episodes_done': 10696, 'local/unclipped_grad_norm': 0.8037741606434187, 'local/model_version': 71342, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:39,587] {'global/mean_episode_return': 44400.0, 'global/mean_episode_step': 4583.571428571428, 'global/SPS': 3378.1611745516343, 'global/env_act_steps': 45660928, 'global/env_train_steps': 45658240, 'global/optimizer_steps': 71341, 'global/running_reward': 24201.42320736434, 'global/running_step': 2493.5360646802324, 'global/steps_done': 45660928, 'global/episodes_done': 10696, 'global/unclipped_grad_norm': 0.8062772157619584, 'global/model_version': 71341, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:49,587] calculate_sps 31360 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:49,587] calculate_sps 32640 steps in 10.0013
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:49,588] {'local/mean_episode_return': 44600.0, 'local/mean_episode_step': 4400.333333333333, 'local/SPS': 3135.5815042195172, 'local/env_act_steps': 45693952, 'local/env_train_steps': 45690880, 'local/optimizer_steps': 71392, 'local/running_reward': 24563.527480544748, 'local/running_step': 2528.753009484436, 'local/steps_done': 45693952, 'local/episodes_done': 10699, 'local/unclipped_grad_norm': 0.7632481771707534, 'local/model_version': 71392, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:49,589] {'global/mean_episode_return': 44600.0, 'global/mean_episode_step': 4400.333333333333, 'global/SPS': 3263.564422759089, 'global/env_act_steps': 45693824, 'global/env_train_steps': 45690880, 'global/optimizer_steps': 71392, 'global/running_reward': 24548.89348249027, 'global/running_step': 2527.3974039396885, 'global/steps_done': 45693824, 'global/episodes_done': 10699, 'global/unclipped_grad_norm': 0.7614415901548722, 'global/model_version': 71392, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:59,604] calculate_sps 30720 steps in 10.0169
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:08:59,604] calculate_sps 25600 steps in 10.0169
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:59,605] {'local/mean_episode_return': 46660.0, 'local/mean_episode_step': 4737.2, 'local/SPS': 3066.8023150118606, 'local/env_act_steps': 45726848, 'local/env_train_steps': 45721600, 'local/optimizer_steps': 71440, 'local/running_reward': 24663.80714980545, 'local/running_step': 2539.410505836576, 'local/steps_done': 45726848, 'local/episodes_done': 10709, 'local/unclipped_grad_norm': 0.7149977417041858, 'local/model_version': 71440, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:08:59,606] {'global/mean_episode_return': 45625.0, 'global/mean_episode_step': 4652.875, 'global/SPS': 2555.668595843217, 'global/env_act_steps': 45720064, 'global/env_train_steps': 45716480, 'global/optimizer_steps': 71432, 'global/running_reward': 24698.11737804878, 'global/running_step': 2542.7720655487806, 'global/steps_done': 45720064, 'global/episodes_done': 10707, 'global/unclipped_grad_norm': 0.6994889572262764, 'global/model_version': 71432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:09,635] calculate_sps 35840 steps in 10.0307
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:09,635] calculate_sps 33920 steps in 10.0307
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:09,635] {'local/mean_episode_return': 49100.0, 'local/mean_episode_step': 4815.4, 'local/SPS': 3573.01560487378, 'local/env_act_steps': 45759104, 'local/env_train_steps': 45757440, 'local/optimizer_steps': 71496, 'local/running_reward': 23893.23536706349, 'local/running_step': 2464.9229290674602, 'local/steps_done': 45759104, 'local/episodes_done': 10719, 'local/unclipped_grad_norm': 0.7402120269834995, 'local/model_version': 71496, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:09,637] {'global/mean_episode_return': 48509.09090909091, 'global/mean_episode_step': 4809.454545454545, 'global/SPS': 3381.6040546126846, 'global/env_act_steps': 45752960, 'global/env_train_steps': 45750400, 'global/optimizer_steps': 71484, 'global/running_reward': 24044.272859922177, 'global/running_step': 2479.1730909533076, 'global/steps_done': 45752960, 'global/episodes_done': 10718, 'global/unclipped_grad_norm': 0.7950856582476542, 'global/model_version': 71484, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:19,655] calculate_sps 30720 steps in 10.0205
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:19,656] calculate_sps 32640 steps in 10.0205
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:19,656] {'local/mean_episode_return': 49175.0, 'local/mean_episode_step': 4963.625, 'local/SPS': 3065.727919750362, 'local/env_act_steps': 45792128, 'local/env_train_steps': 45788160, 'local/optimizer_steps': 71544, 'local/running_reward': 23423.4738372093, 'local/running_step': 2426.9179081879847, 'local/steps_done': 45792128, 'local/episodes_done': 10727, 'local/unclipped_grad_norm': 0.8739254350463549, 'local/model_version': 71544, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:19,671] {'global/mean_episode_return': 49475.0, 'global/mean_episode_step': 4964.0, 'global/SPS': 3257.3359147347596, 'global/env_act_steps': 45786112, 'global/env_train_steps': 45783040, 'global/optimizer_steps': 71536, 'global/running_reward': 23509.51978764479, 'global/running_step': 2433.842935569498, 'global/steps_done': 45786112, 'global/episodes_done': 10726, 'global/unclipped_grad_norm': 0.7783374534203455, 'global/model_version': 71536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:29,669] calculate_sps 33920 steps in 10.0137
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:29,669] calculate_sps 32640 steps in 10.0137
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:29,669] {'local/mean_episode_return': 45860.0, 'local/mean_episode_step': 4622.8, 'local/SPS': 3387.3560082306553, 'local/env_act_steps': 45824640, 'local/env_train_steps': 45822080, 'local/optimizer_steps': 71596, 'local/running_reward': 23365.846456692914, 'local/running_step': 2426.494217519685, 'local/steps_done': 45824640, 'local/episodes_done': 10737, 'local/unclipped_grad_norm': 0.7404465188200657, 'local/model_version': 71596, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:29,670] {'global/mean_episode_return': 47833.333333333336, 'global/mean_episode_step': 4660.5, 'global/SPS': 3259.5312532030835, 'global/env_act_steps': 45819264, 'global/env_train_steps': 45815680, 'global/optimizer_steps': 71586, 'global/running_reward': 23360.9013030888, 'global/running_step': 2424.966125723938, 'global/steps_done': 45819264, 'global/episodes_done': 10732, 'global/unclipped_grad_norm': 0.7648928606510162, 'global/model_version': 71586, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:39,677] calculate_sps 32640 steps in 10.0085
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:39,678] calculate_sps 33920 steps in 10.0085
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:39,678] {'local/mean_episode_return': 42600.0, 'local/mean_episode_step': 4476.0, 'local/SPS': 3261.229399986036, 'local/env_act_steps': 45857152, 'local/env_train_steps': 45854720, 'local/optimizer_steps': 71648, 'local/running_reward': 23042.54429133858, 'local/running_step': 2395.8042568897636, 'local/steps_done': 45857152, 'local/episodes_done': 10744, 'local/unclipped_grad_norm': 0.8210906294675974, 'local/model_version': 71648, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:39,691] {'global/mean_episode_return': 44175.0, 'global/mean_episode_step': 4580.625, 'global/SPS': 3389.120749005096, 'global/env_act_steps': 45851776, 'global/env_train_steps': 45849600, 'global/optimizer_steps': 71640, 'global/running_reward': 23089.812992125986, 'global/running_step': 2400.697496309055, 'global/steps_done': 45851776, 'global/episodes_done': 10740, 'global/unclipped_grad_norm': 0.8315033636711262, 'global/model_version': 71640, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:49,703] calculate_sps 30720 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:49,703] calculate_sps 30720 steps in 10.0252
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:49,714] {'local/mean_episode_return': 43142.857142857145, 'local/mean_episode_step': 4378.714285714285, 'local/SPS': 3064.274700751142, 'local/env_act_steps': 45890688, 'local/env_train_steps': 45885440, 'local/optimizer_steps': 71696, 'local/running_reward': 22688.567509541987, 'local/running_step': 2360.691704437023, 'local/steps_done': 45890688, 'local/episodes_done': 10751, 'local/unclipped_grad_norm': 0.8180280141532421, 'local/model_version': 71696, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:49,716] {'global/mean_episode_return': 43181.818181818184, 'global/mean_episode_step': 4454.454545454545, 'global/SPS': 3064.274700751142, 'global/env_act_steps': 45885440, 'global/env_train_steps': 45880320, 'global/optimizer_steps': 71688, 'global/running_reward': 22728.332937262356, 'global/running_step': 2365.003950807985, 'global/steps_done': 45885440, 'global/episodes_done': 10751, 'global/unclipped_grad_norm': 0.8053689487278461, 'global/model_version': 71688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:59,707] calculate_sps 35840 steps in 10.0043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:09:59,707] calculate_sps 35840 steps in 10.0043
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:59,707] {'local/mean_episode_return': 46333.333333333336, 'local/mean_episode_step': 4788.666666666667, 'local/SPS': 3582.469745446219, 'local/env_act_steps': 45922688, 'local/env_train_steps': 45921280, 'local/optimizer_steps': 71752, 'local/running_reward': 23245.55, 'local/running_step': 2412.44628125, 'local/steps_done': 45922688, 'local/episodes_done': 10754, 'local/unclipped_grad_norm': 0.8685735442808696, 'local/model_version': 71752, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:09:59,709] {'global/mean_episode_return': 46333.333333333336, 'global/mean_episode_step': 4788.666666666667, 'global/SPS': 3582.469745446219, 'global/env_act_steps': 45917568, 'global/env_train_steps': 45916160, 'global/optimizer_steps': 71744, 'global/running_reward': 23123.543326693227, 'global/running_step': 2401.0167766434265, 'global/steps_done': 45917568, 'global/episodes_done': 10754, 'global/unclipped_grad_norm': 0.880976853626115, 'global/model_version': 71744, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:09,712] calculate_sps 30720 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:09,712] calculate_sps 30720 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:09,712] {'local/mean_episode_return': 46815.38461538462, 'local/mean_episode_step': 4912.0, 'local/SPS': 3070.5881003831864, 'local/env_act_steps': 45955840, 'local/env_train_steps': 45952000, 'local/optimizer_steps': 71800, 'local/running_reward': 23197.87644787645, 'local/running_step': 2397.367036679537, 'local/steps_done': 45955840, 'local/episodes_done': 10767, 'local/unclipped_grad_norm': 0.7365836519747972, 'local/model_version': 71800, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:09,713] {'global/mean_episode_return': 46183.333333333336, 'global/mean_episode_step': 4871.916666666667, 'global/SPS': 3070.5881003831864, 'global/env_act_steps': 45951104, 'global/env_train_steps': 45946880, 'global/optimizer_steps': 71792, 'global/running_reward': 23344.99045801527, 'global/running_step': 2413.8039420324426, 'global/steps_done': 45951104, 'global/episodes_done': 10766, 'global/unclipped_grad_norm': 0.7697669031719366, 'global/model_version': 71792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:19,735] calculate_sps 33280 steps in 10.024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:19,735] calculate_sps 34560 steps in 10.024
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:19,736] {'local/mean_episode_return': 44925.0, 'local/mean_episode_step': 4655.375, 'local/SPS': 3320.0437917318736, 'local/env_act_steps': 45988352, 'local/env_train_steps': 45985280, 'local/optimizer_steps': 71851, 'local/running_reward': 22491.141732283464, 'local/running_step': 2321.4453125, 'local/steps_done': 45988352, 'local/episodes_done': 10775, 'local/unclipped_grad_norm': 0.8709197885849896, 'local/model_version': 71851, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:19,737] {'global/mean_episode_return': 45975.0, 'global/mean_episode_step': 4723.25, 'global/SPS': 3447.7377837215613, 'global/env_act_steps': 45983488, 'global/env_train_steps': 45981440, 'global/optimizer_steps': 71845, 'global/running_reward': 22524.518280632412, 'global/running_step': 2325.0708683300395, 'global/steps_done': 45983488, 'global/episodes_done': 10774, 'global/unclipped_grad_norm': 0.8432001679573419, 'global/model_version': 71845, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:29,740] calculate_sps 33280 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:29,740] calculate_sps 32000 steps in 10.0044
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:29,740] {'local/mean_episode_return': 48680.0, 'local/mean_episode_step': 4898.4, 'local/SPS': 3326.5290257015304, 'local/env_act_steps': 46021376, 'local/env_train_steps': 46018560, 'local/optimizer_steps': 71904, 'local/running_reward': 22679.88129844961, 'local/running_step': 2340.488765746124, 'local/steps_done': 46021376, 'local/episodes_done': 10780, 'local/unclipped_grad_norm': 0.7330272377661939, 'local/model_version': 71904, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:29,751] {'global/mean_episode_return': 47120.0, 'global/mean_episode_step': 4788.4, 'global/SPS': 3198.5856016360867, 'global/env_act_steps': 46016896, 'global/env_train_steps': 46013440, 'global/optimizer_steps': 71896, 'global/running_reward': 22625.826149425287, 'global/running_step': 2334.637841235632, 'global/steps_done': 46016896, 'global/episodes_done': 10779, 'global/unclipped_grad_norm': 0.7154198668751062, 'global/model_version': 71896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:39,757] calculate_sps 32640 steps in 10.0152
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:39,757] calculate_sps 35200 steps in 10.0152
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:39,765] {'local/mean_episode_return': 43600.0, 'local/mean_episode_step': 4387.125, 'local/SPS': 3259.0437220845965, 'local/env_act_steps': 46054912, 'local/env_train_steps': 46051200, 'local/optimizer_steps': 71954, 'local/running_reward': 22861.59947519084, 'local/running_step': 2364.541716364504, 'local/steps_done': 46054912, 'local/episodes_done': 10788, 'local/unclipped_grad_norm': 0.8059709852933884, 'local/model_version': 71954, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:39,767] {'global/mean_episode_return': 45100.0, 'global/mean_episode_step': 4562.333333333333, 'global/SPS': 3514.654994404957, 'global/env_act_steps': 46050304, 'global/env_train_steps': 46048640, 'global/optimizer_steps': 71950, 'global/running_reward': 22843.989463601534, 'global/running_step': 2362.027538314176, 'global/steps_done': 46050304, 'global/episodes_done': 10785, 'global/unclipped_grad_norm': 0.7960020342358837, 'global/model_version': 71950, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:49,781] calculate_sps 33920 steps in 10.0262
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:49,782] calculate_sps 31360 steps in 10.0262
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:49,782] {'local/mean_episode_return': 49622.22222222222, 'local/mean_episode_step': 4899.111111111111, 'local/SPS': 3383.1363251772545, 'local/env_act_steps': 46087168, 'local/env_train_steps': 46085120, 'local/optimizer_steps': 72008, 'local/running_reward': 22471.075148809523, 'local/running_step': 2328.0446738591268, 'local/steps_done': 46087168, 'local/episodes_done': 10797, 'local/unclipped_grad_norm': 0.8257083236067383, 'local/model_version': 72008, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:49,783] {'global/mean_episode_return': 48018.181818181816, 'global/mean_episode_step': 4752.272727272727, 'global/SPS': 3127.8052817676503, 'global/env_act_steps': 46083456, 'global/env_train_steps': 46080000, 'global/optimizer_steps': 72000, 'global/running_reward': 22568.550916988417, 'global/running_step': 2337.188827220077, 'global/steps_done': 46083456, 'global/episodes_done': 10796, 'global/unclipped_grad_norm': 0.8365852147340774, 'global/model_version': 72000, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:59,784] calculate_sps 30720 steps in 10.0031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:10:59,785] calculate_sps 32000 steps in 10.0031
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:59,785] {'local/mean_episode_return': 51200.0, 'local/mean_episode_step': 5107.4, 'local/SPS': 3071.0548075077504, 'local/env_act_steps': 46120320, 'local/env_train_steps': 46115840, 'local/optimizer_steps': 72056, 'local/running_reward': 22191.855694980695, 'local/running_step': 2306.5273588320465, 'local/steps_done': 46120320, 'local/episodes_done': 10802, 'local/unclipped_grad_norm': 0.8401165461788574, 'local/model_version': 72056, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:10:59,786] {'global/mean_episode_return': 51066.666666666664, 'global/mean_episode_step': 5079.5, 'global/SPS': 3199.01542448724, 'global/env_act_steps': 46116224, 'global/env_train_steps': 46112000, 'global/optimizer_steps': 72049, 'global/running_reward': 22167.999267578125, 'global/running_step': 2303.691925048828, 'global/steps_done': 46116224, 'global/episodes_done': 10802, 'global/unclipped_grad_norm': 0.8730800249138657, 'global/model_version': 72049, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:09,832] calculate_sps 35200 steps in 10.0475
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:09,832] calculate_sps 34560 steps in 10.0475
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:09,832] {'local/mean_episode_return': 49457.142857142855, 'local/mean_episode_step': 4923.428571428572, 'local/SPS': 3503.359496775019, 'local/env_act_steps': 46152576, 'local/env_train_steps': 46151040, 'local/optimizer_steps': 72110, 'local/running_reward': 22163.343253968254, 'local/running_step': 2309.4495907738096, 'local/steps_done': 46152576, 'local/episodes_done': 10809, 'local/unclipped_grad_norm': 0.8525078158687662, 'local/model_version': 72110, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:09,833] {'global/mean_episode_return': 49457.142857142855, 'global/mean_episode_step': 4923.428571428572, 'global/SPS': 3439.6620513791095, 'global/env_act_steps': 46148992, 'global/env_train_steps': 46146560, 'global/optimizer_steps': 72104, 'global/running_reward': 22181.43310546875, 'global/running_step': 2310.4487915039062, 'global/steps_done': 46148992, 'global/episodes_done': 10809, 'global/unclipped_grad_norm': 0.8337296117435802, 'global/model_version': 72104, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:19,861] calculate_sps 31360 steps in 10.0289
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:19,861] calculate_sps 31360 steps in 10.0289
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:19,862] {'local/mean_episode_return': 46942.857142857145, 'local/mean_episode_step': 4720.428571428572, 'local/SPS': 3126.9655585214437, 'local/env_act_steps': 46185856, 'local/env_train_steps': 46182400, 'local/optimizer_steps': 72160, 'local/running_reward': 22322.15144230769, 'local/running_step': 2325.666316105769, 'local/steps_done': 46185856, 'local/episodes_done': 10817, 'local/unclipped_grad_norm': 0.8588764840364456, 'local/model_version': 72160, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:19,863] {'global/mean_episode_return': 46120.0, 'global/mean_episode_step': 4658.2, 'global/SPS': 3126.9655585214437, 'global/env_act_steps': 46182528, 'global/env_train_steps': 46177920, 'global/optimizer_steps': 72152, 'global/running_reward': 22310.263597328245, 'global/running_step': 2324.5428196564885, 'global/steps_done': 46182528, 'global/episodes_done': 10814, 'global/unclipped_grad_norm': 0.7811988002310196, 'global/model_version': 72152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:29,874] calculate_sps 32640 steps in 10.014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:29,875] calculate_sps 35200 steps in 10.014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:29,875] {'local/mean_episode_return': 43825.0, 'local/mean_episode_step': 4640.0, 'local/SPS': 3259.442085333134, 'local/env_act_steps': 46218624, 'local/env_train_steps': 46215040, 'local/optimizer_steps': 72210, 'local/running_reward': 22173.248291015625, 'local/running_step': 2313.7312622070312, 'local/steps_done': 46218624, 'local/episodes_done': 10822, 'local/unclipped_grad_norm': 0.8036006391048431, 'local/model_version': 72210, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:29,876] {'global/mean_episode_return': 45900.0, 'global/mean_episode_step': 4718.0, 'global/SPS': 3515.0846018298503, 'global/env_act_steps': 46215168, 'global/env_train_steps': 46213120, 'global/optimizer_steps': 72208, 'global/running_reward': 22151.28676470588, 'global/running_step': 2311.4605698529413, 'global/steps_done': 46215168, 'global/episodes_done': 10821, 'global/unclipped_grad_norm': 0.8684801124036312, 'global/model_version': 72208, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:39,887] calculate_sps 33920 steps in 10.0126
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:39,888] calculate_sps 30720 steps in 10.0126
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:39,888] {'local/mean_episode_return': 48971.42857142857, 'local/mean_episode_step': 4874.428571428572, 'local/SPS': 3387.7161500652514, 'local/env_act_steps': 46251136, 'local/env_train_steps': 46248960, 'local/optimizer_steps': 72264, 'local/running_reward': 22409.854822834644, 'local/running_step': 2338.4127399114172, 'local/steps_done': 46251136, 'local/episodes_done': 10829, 'local/unclipped_grad_norm': 0.8516272825223429, 'local/model_version': 72264, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:39,899] {'global/mean_episode_return': 49971.42857142857, 'global/mean_episode_step': 4951.142857142857, 'global/SPS': 3068.1202868515484, 'global/env_act_steps': 46248576, 'global/env_train_steps': 46243840, 'global/optimizer_steps': 72256, 'global/running_reward': 22426.095545977012, 'global/running_step': 2339.6373922413795, 'global/steps_done': 46248576, 'global/episodes_done': 10828, 'global/unclipped_grad_norm': 0.868191996589303, 'global/model_version': 72256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:49,906] calculate_sps 30720 steps in 10.0181
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:49,906] calculate_sps 35840 steps in 10.0181
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:49,906] {'local/mean_episode_return': 52428.57142857143, 'local/mean_episode_step': 5066.571428571428, 'local/SPS': 3066.460446642825, 'local/env_act_steps': 46284672, 'local/env_train_steps': 46279680, 'local/optimizer_steps': 72312, 'local/running_reward': 22345.956583969466, 'local/running_step': 2336.663108301527, 'local/steps_done': 46284672, 'local/episodes_done': 10836, 'local/unclipped_grad_norm': 0.7983188523600498, 'local/model_version': 72312, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:49,907] {'global/mean_episode_return': 50475.0, 'global/mean_episode_step': 4956.375, 'global/SPS': 3577.5371877499624, 'global/env_act_steps': 46281216, 'global/env_train_steps': 46279680, 'global/optimizer_steps': 72312, 'global/running_reward': 22362.665441176472, 'global/running_step': 2337.7448529411763, 'global/steps_done': 46281216, 'global/episodes_done': 10836, 'global/unclipped_grad_norm': 0.7823589598493916, 'global/model_version': 72312, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:59,936] calculate_sps 35840 steps in 10.0304
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:11:59,936] calculate_sps 30720 steps in 10.0304
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:59,936] {'local/mean_episode_return': 37575.0, 'local/mean_episode_step': 3975.625, 'local/SPS': 3573.121595971128, 'local/env_act_steps': 46316544, 'local/env_train_steps': 46315520, 'local/optimizer_steps': 72367, 'local/running_reward': 22044.051204819276, 'local/running_step': 2308.2671623995984, 'local/steps_done': 46316544, 'local/episodes_done': 10844, 'local/unclipped_grad_norm': 0.8014464367519726, 'local/model_version': 72367, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:11:59,937] {'global/mean_episode_return': 37714.28571428572, 'global/mean_episode_step': 3976.4285714285716, 'global/SPS': 3062.6756536895386, 'global/env_act_steps': 46314624, 'global/env_train_steps': 46310400, 'global/optimizer_steps': 72360, 'global/running_reward': 22051.083572796935, 'global/running_step': 2309.227191091954, 'global/steps_done': 46314624, 'global/episodes_done': 10843, 'global/unclipped_grad_norm': 0.7943364928166071, 'global/model_version': 72360, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:12:09,951] calculate_sps 30720 steps in 10.0149
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:12:09,951] calculate_sps 35200 steps in 10.0149
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:12:09,951] {'local/mean_episode_return': 46133.333333333336, 'local/mean_episode_step': 4804.666666666667, 'local/SPS': 3067.4231863534837, 'local/env_act_steps': 46349824, 'local/env_train_steps': 46346240, 'local/optimizer_steps': 72416, 'local/running_reward': 22254.58533653846, 'local/running_step': 2324.051171875, 'local/steps_done': 46349824, 'local/episodes_done': 10850, 'local/unclipped_grad_norm': 0.8343685196370495, 'local/model_version': 72416, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:12:09,953] {'global/mean_episode_return': 44771.42857142857, 'global/mean_episode_step': 4685.428571428572, 'global/SPS': 3514.755734363367, 'global/env_act_steps': 46347136, 'global/env_train_steps': 46345600, 'global/optimizer_steps': 72414, 'global/running_reward': 22242.236712598424, 'global/running_step': 2323.3331077755906, 'global/steps_done': 46347136, 'global/episodes_done': 10850, 'global/unclipped_grad_norm': 0.82343140023726, 'global/model_version': 72414, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:12:19,967] calculate_sps 32000 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:12:19,968] calculate_sps 31360 steps in 10.0164
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:12:19,968] {'local/mean_episode_return': 49300.0, 'local/mean_episode_step': 4915.25, 'local/SPS': 3194.761245514298, 'local/env_act_steps': 46382464, 'local/env_train_steps': 46378240, 'local/optimizer_steps': 72466, 'local/running_reward': 22511.053921568626, 'local/running_step': 2347.6288296568628, 'local/steps_done': 46382464, 'local/episodes_done': 10857, 'local/unclipped_grad_norm': 0.8940212035179138, 'local/model_version': 72466, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:12:19,969] {'global/mean_episode_return': 49300.0, 'global/mean_episode_step': 4915.25, 'global/SPS': 3130.8660206040117, 'global/env_act_steps': 46380416, 'global/env_train_steps': 46376960, 'global/optimizer_steps': 72464, 'global/running_reward': 22506.82091346154, 'global/running_step': 2347.1259014423076, 'global/steps_done': 46380416, 'global/episodes_done': 10857, 'global/unclipped_grad_norm': 0.8962658202648163, 'global/model_version': 72464, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:12:29,996] calculate_sps 34560 steps in 10.0286
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:12:29,996] calculate_sps 32640 steps in 10.0286
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:12:29,996] {'local/mean_episode_return': 43000.0, 'local/mean_episode_step': 4464.833333333333, 'local/SPS': 3446.1436261729486, 'local/env_act_steps': 46414592, 'local/env_train_steps': 46412800, 'local/optimizer_steps': 72520, 'local/running_reward': 22474.707420318726, 'local/running_step': 2345.2442417828684, 'local/steps_done': 46414592, 'local/episodes_done': 10863, 'local/unclipped_grad_norm': 0.8514979299571779, 'local/model_version': 72520, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:12:29,998] {'global/mean_episode_return': 43000.0, 'global/mean_episode_step': 4464.833333333333, 'global/SPS': 3254.691202496674, 'global/env_act_steps': 46413184, 'global/env_train_steps': 46409600, 'global/optimizer_steps': 72514, 'global/running_reward': 22466.668701171875, 'global/running_step': 2344.2969665527344, 'global/steps_done': 46413184, 'global/episodes_done': 10863, 'global/unclipped_grad_norm': 0.868471903204918, 'global/model_version': 72514, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:12:40,015] calculate_sps 30720 steps in 10.0192
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:12:40,015] calculate_sps 33920 steps in 10.0192
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:12:40,016] {'local/mean_episode_return': 52000.0, 'local/mean_episode_step': 5194.571428571428, 'local/SPS': 3066.101362584869, 'local/env_act_steps': 46448000, 'local/env_train_steps': 46443520, 'local/optimizer_steps': 72568, 'local/running_reward': 22303.957136015324, 'local/running_step': 2334.651999521073, 'local/steps_done': 46448000, 'local/episodes_done': 10870, 'local/unclipped_grad_norm': 0.8341730001072089, 'local/model_version': 72568, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:12:40,017] {'global/mean_episode_return': 53200.0, 'global/mean_episode_step': 5236.2, 'global/SPS': 3385.4869211874598, 'global/env_act_steps': 46446208, 'global/env_train_steps': 46443520, 'global/optimizer_steps': 72568, 'global/running_reward': 22300.19379844961, 'global/running_step': 2334.1842599321703, 'global/steps_done': 46446208, 'global/episodes_done': 10868, 'global/unclipped_grad_norm': 0.8306579711260619, 'global/model_version': 72568, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:12:50,063] calculate_sps 34560 steps in 10.048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:12:50,063] calculate_sps 31360 steps in 10.048
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:12:50,063] {'local/mean_episode_return': 45083.333333333336, 'local/mean_episode_step': 4693.25, 'local/SPS': 3439.4938402738685, 'local/env_act_steps': 46480128, 'local/env_train_steps': 46478080, 'local/optimizer_steps': 72621, 'local/running_reward': 22299.215637450197, 'local/running_step': 2333.7016621015937, 'local/steps_done': 46480128, 'local/episodes_done': 10877, 'local/unclipped_grad_norm': 0.8357496419042911, 'local/model_version': 72621, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:12:50,064] {'global/mean_episode_return': 46062.5, 'global/mean_episode_step': 4792.5625, 'global/SPS': 3121.0221883966583, 'global/env_act_steps': 46479616, 'global/env_train_steps': 46474880, 'global/optimizer_steps': 72616, 'global/running_reward': 22307.03424329502, 'global/running_step': 2334.463182471264, 'global/steps_done': 46479616, 'global/episodes_done': 10877, 'global/unclipped_grad_norm': 0.8012017222742239, 'global/model_version': 72616, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:00,077] calculate_sps 32000 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:00,077] calculate_sps 35200 steps in 10.0136
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:00,077] {'local/mean_episode_return': 50250.0, 'local/mean_episode_step': 5094.625, 'local/SPS': 3195.6603426504926, 'local/env_act_steps': 46512640, 'local/env_train_steps': 46510080, 'local/optimizer_steps': 72672, 'local/running_reward': 22607.4249507874, 'local/running_step': 2357.798535925197, 'local/steps_done': 46512640, 'local/episodes_done': 10882, 'local/unclipped_grad_norm': 0.833566333733353, 'local/model_version': 72672, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:00,079] {'global/mean_episode_return': 50250.0, 'global/mean_episode_step': 5094.625, 'global/SPS': 3515.2263769155416, 'global/env_act_steps': 46511616, 'global/env_train_steps': 46510080, 'global/optimizer_steps': 72672, 'global/running_reward': 22601.575, 'global/running_step': 2357.256875, 'global/steps_done': 46511616, 'global/episodes_done': 10882, 'global/unclipped_grad_norm': 0.8633737745029586, 'global/model_version': 72672, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:10,096] calculate_sps 30720 steps in 10.0192
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:10,096] calculate_sps 30720 steps in 10.0192
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:10,096] {'local/mean_episode_return': 47155.555555555555, 'local/mean_episode_step': 4872.555555555556, 'local/SPS': 3066.1231051732493, 'local/env_act_steps': 46545920, 'local/env_train_steps': 46540800, 'local/optimizer_steps': 72720, 'local/running_reward': 22247.13341346154, 'local/running_step': 2319.8204927884617, 'local/steps_done': 46545920, 'local/episodes_done': 10891, 'local/unclipped_grad_norm': 0.7767588580027223, 'local/model_version': 72720, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:10,098] {'global/mean_episode_return': 47155.555555555555, 'global/mean_episode_step': 4872.555555555556, 'global/SPS': 3066.1231051732493, 'global/env_act_steps': 46544896, 'global/env_train_steps': 46540800, 'global/optimizer_steps': 72720, 'global/running_reward': 22258.65985576923, 'global/running_step': 2321.0912860576923, 'global/steps_done': 46544896, 'global/episodes_done': 10891, 'global/unclipped_grad_norm': 0.7767588580027223, 'global/model_version': 72720, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:20,138] calculate_sps 35840 steps in 10.0423
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:20,138] calculate_sps 33920 steps in 10.0423
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:20,138] {'local/mean_episode_return': 41533.333333333336, 'local/mean_episode_step': 4324.666666666667, 'local/SPS': 3568.908033792457, 'local/env_act_steps': 46577664, 'local/env_train_steps': 46576640, 'local/optimizer_steps': 72775, 'local/running_reward': 22733.99697580645, 'local/running_step': 2368.5133568548385, 'local/steps_done': 46577664, 'local/episodes_done': 10894, 'local/unclipped_grad_norm': 0.8234582711349834, 'local/model_version': 72775, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:20,140] {'global/mean_episode_return': 41533.333333333336, 'global/mean_episode_step': 4324.666666666667, 'global/SPS': 3377.7165319821465, 'global/env_act_steps': 46577280, 'global/env_train_steps': 46574720, 'global/optimizer_steps': 72772, 'global/running_reward': 22712.512351778656, 'global/running_step': 2366.339550395257, 'global/steps_done': 46577280, 'global/episodes_done': 10894, 'global/unclipped_grad_norm': 0.8153785438491747, 'global/model_version': 72772, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:30,148] calculate_sps 30720 steps in 10.0103
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:30,149] calculate_sps 32640 steps in 10.0103
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:30,149] {'local/mean_episode_return': 42800.0, 'local/mean_episode_step': 4651.0, 'local/SPS': 3068.8436516216443, 'local/env_act_steps': 46611712, 'local/env_train_steps': 46607360, 'local/optimizer_steps': 72824, 'local/running_reward': 23510.46757518797, 'local/running_step': 2447.187265037594, 'local/steps_done': 46611712, 'local/episodes_done': 10895, 'local/unclipped_grad_norm': 0.9067105133922733, 'local/model_version': 72824, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:30,150] {'global/mean_episode_return': 42800.0, 'global/mean_episode_step': 4651.0, 'global/SPS': 3260.646379847997, 'global/env_act_steps': 46611072, 'global/env_train_steps': 46607360, 'global/optimizer_steps': 72824, 'global/running_reward': 23493.80918560606, 'global/running_step': 2445.464607007576, 'global/steps_done': 46611072, 'global/episodes_done': 10895, 'global/unclipped_grad_norm': 0.9099872267016997, 'global/model_version': 72824, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:40,152] calculate_sps 35200 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:40,153] calculate_sps 33920 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:40,153] {'local/mean_episode_return': 42900.0, 'local/mean_episode_step': 4351.166666666667, 'local/SPS': 3518.4341837769894, 'local/env_act_steps': 46644096, 'local/env_train_steps': 46642560, 'local/optimizer_steps': 72878, 'local/running_reward': 24184.862895256916, 'local/running_step': 2514.682188735178, 'local/steps_done': 46644096, 'local/episodes_done': 10901, 'local/unclipped_grad_norm': 0.8071054937662901, 'local/model_version': 72878, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:40,154] {'global/mean_episode_return': 42900.0, 'global/mean_episode_step': 4351.166666666667, 'global/SPS': 3390.4911225487353, 'global/env_act_steps': 46643968, 'global/env_train_steps': 46641280, 'global/optimizer_steps': 72877, 'global/running_reward': 24189.43944552529, 'global/running_step': 2515.174732490272, 'global/steps_done': 46643968, 'global/episodes_done': 10901, 'global/unclipped_grad_norm': 0.802150124648832, 'global/model_version': 72877, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:50,166] calculate_sps 31360 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:13:50,166] calculate_sps 32640 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:50,166] {'local/mean_episode_return': 40883.333333333336, 'local/mean_episode_step': 4216.416666666667, 'local/SPS': 3131.954963390307, 'local/env_act_steps': 46677248, 'local/env_train_steps': 46673920, 'local/optimizer_steps': 72928, 'local/running_reward': 24007.969353281853, 'local/running_step': 2497.091246380309, 'local/steps_done': 46677248, 'local/episodes_done': 10913, 'local/unclipped_grad_norm': 0.8013464957475662, 'local/model_version': 72928, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:13:50,179] {'global/mean_episode_return': 40883.333333333336, 'global/mean_episode_step': 4216.416666666667, 'global/SPS': 3259.7898598552174, 'global/env_act_steps': 46677120, 'global/env_train_steps': 46673920, 'global/optimizer_steps': 72928, 'global/running_reward': 24008.011583011583, 'global/running_step': 2497.093448359073, 'global/steps_done': 46677120, 'global/episodes_done': 10913, 'global/unclipped_grad_norm': 0.806609114595488, 'global/model_version': 72928, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:00,195] calculate_sps 32640 steps in 10.0299
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:00,195] calculate_sps 25600 steps in 10.0299
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:00,196] {'local/mean_episode_return': 42371.42857142857, 'local/mean_episode_step': 4299.0, 'local/SPS': 3254.2844072942403, 'local/env_act_steps': 46710144, 'local/env_train_steps': 46706560, 'local/optimizer_steps': 72978, 'local/running_reward': 23876.86040856031, 'local/running_step': 2485.4716986867707, 'local/steps_done': 46710144, 'local/episodes_done': 10920, 'local/unclipped_grad_norm': 0.7802580207586288, 'local/model_version': 72978, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:00,196] {'global/mean_episode_return': 39680.0, 'global/mean_episode_step': 4102.6, 'global/SPS': 2552.3799272896003, 'global/env_act_steps': 46704128, 'global/env_train_steps': 46699520, 'global/optimizer_steps': 72968, 'global/running_reward': 23852.5547985782, 'global/running_step': 2483.415099229858, 'global/steps_done': 46704128, 'global/episodes_done': 10918, 'global/unclipped_grad_norm': 0.777497510612011, 'global/model_version': 72968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:10,210] calculate_sps 33920 steps in 10.0146
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:10,211] calculate_sps 35200 steps in 10.0146
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:10,211] {'local/mean_episode_return': 41622.22222222222, 'local/mean_episode_step': 4383.333333333333, 'local/SPS': 3387.0616602490136, 'local/env_act_steps': 46742528, 'local/env_train_steps': 46740480, 'local/optimizer_steps': 73032, 'local/running_reward': 23898.505434782608, 'local/running_step': 2482.692224555336, 'local/steps_done': 46742528, 'local/episodes_done': 10929, 'local/unclipped_grad_norm': 0.8209869353859512, 'local/model_version': 73032, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:10,212] {'global/mean_episode_return': 41880.0, 'global/mean_episode_step': 4363.6, 'global/SPS': 3514.87530780558, 'global/env_act_steps': 46736256, 'global/env_train_steps': 46734720, 'global/optimizer_steps': 73022, 'global/running_reward': 23962.25722111554, 'global/running_step': 2490.5595430776893, 'global/steps_done': 46736256, 'global/episodes_done': 10928, 'global/unclipped_grad_norm': 0.8072134714435648, 'global/model_version': 73022, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:20,212] calculate_sps 30720 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:20,213] calculate_sps 31360 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:20,213] {'local/mean_episode_return': 37985.71428571428, 'local/mean_episode_step': 4079.5, 'local/SPS': 3071.36124124271, 'local/env_act_steps': 46776064, 'local/env_train_steps': 46771200, 'local/optimizer_steps': 73080, 'local/running_reward': 23352.182729007633, 'local/running_step': 2420.9608480438933, 'local/steps_done': 46776064, 'local/episodes_done': 10937, 'local/unclipped_grad_norm': 0.8420575999965271, 'local/model_version': 73080, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:20,223] {'global/mean_episode_return': 39987.5, 'global/mean_episode_step': 4243.8125, 'global/SPS': 3135.3479337686, 'global/env_act_steps': 46769920, 'global/env_train_steps': 46766080, 'global/optimizer_steps': 73072, 'global/running_reward': 23367.104325095057, 'global/running_step': 2423.1187024714827, 'global/steps_done': 46769920, 'global/episodes_done': 10937, 'global/unclipped_grad_norm': 0.8705113226175308, 'global/model_version': 73072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:30,222] calculate_sps 35200 steps in 10.0098
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:30,222] calculate_sps 33280 steps in 10.0098
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:30,222] {'local/mean_episode_return': 48450.0, 'local/mean_episode_step': 4768.8, 'local/SPS': 3516.542401108224, 'local/env_act_steps': 46807936, 'local/env_train_steps': 46806400, 'local/optimizer_steps': 73134, 'local/running_reward': 23103.658383534137, 'local/running_step': 2395.5257279116468, 'local/steps_done': 46807936, 'local/episodes_done': 10948, 'local/unclipped_grad_norm': 0.8292831502578877, 'local/model_version': 73134, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:30,223] {'global/mean_episode_return': 48450.0, 'global/mean_episode_step': 4768.8, 'global/SPS': 3324.730997411412, 'global/env_act_steps': 46802560, 'global/env_train_steps': 46799360, 'global/optimizer_steps': 73124, 'global/running_reward': 23253.412990196077, 'global/running_step': 2409.946629901961, 'global/steps_done': 46802560, 'global/episodes_done': 10948, 'global/unclipped_grad_norm': 0.7842547939373896, 'global/model_version': 73124, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:40,239] calculate_sps 31360 steps in 10.017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:40,239] calculate_sps 33280 steps in 10.017
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:40,240] {'local/mean_episode_return': 50400.0, 'local/mean_episode_step': 4970.166666666667, 'local/SPS': 3130.687249032869, 'local/env_act_steps': 46841216, 'local/env_train_steps': 46837760, 'local/optimizer_steps': 73184, 'local/running_reward': 22673.810096153848, 'local/running_step': 2358.6160456730768, 'local/steps_done': 46841216, 'local/episodes_done': 10954, 'local/unclipped_grad_norm': 0.7541846340894699, 'local/model_version': 73184, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:40,241] {'global/mean_episode_return': 50400.0, 'global/mean_episode_step': 4970.166666666667, 'global/SPS': 3322.3619785654937, 'global/env_act_steps': 46835456, 'global/env_train_steps': 46832640, 'global/optimizer_steps': 73176, 'global/running_reward': 22656.888375486382, 'global/running_step': 2356.2786357003893, 'global/steps_done': 46835456, 'global/episodes_done': 10954, 'global/unclipped_grad_norm': 0.7848874382101573, 'global/model_version': 73176, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:50,268] calculate_sps 32000 steps in 10.0297
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:14:50,269] calculate_sps 31360 steps in 10.0297
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:50,269] {'local/mean_episode_return': 48400.0, 'local/mean_episode_step': 4929.5, 'local/SPS': 3190.5084309340696, 'local/env_act_steps': 46873856, 'local/env_train_steps': 46869760, 'local/optimizer_steps': 73233, 'local/running_reward': 23417.279411764706, 'local/running_step': 2432.2420036764706, 'local/steps_done': 46873856, 'local/episodes_done': 10956, 'local/unclipped_grad_norm': 0.7401603052810747, 'local/model_version': 73233, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:14:50,270] {'global/mean_episode_return': 48400.0, 'global/mean_episode_step': 4929.5, 'global/SPS': 3126.698262315388, 'global/env_act_steps': 46868608, 'global/env_train_steps': 46864000, 'global/optimizer_steps': 73224, 'global/running_reward': 23261.293436293436, 'global/running_step': 2417.091578185328, 'global/steps_done': 46868608, 'global/episodes_done': 10956, 'global/unclipped_grad_norm': 0.7801900574316581, 'global/model_version': 73224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:00,288] calculate_sps 34560 steps in 10.0188
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:00,288] calculate_sps 35200 steps in 10.0188
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:00,298] {'local/mean_episode_return': 53666.666666666664, 'local/mean_episode_step': 5188.333333333333, 'local/SPS': 3449.500950012854, 'local/env_act_steps': 46905856, 'local/env_train_steps': 46904320, 'local/optimizer_steps': 73288, 'local/running_reward': 23997.83125, 'local/running_step': 2490.8400625, 'local/steps_done': 46905856, 'local/episodes_done': 10962, 'local/unclipped_grad_norm': 0.7834213679487055, 'local/model_version': 73288, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:00,300] {'global/mean_episode_return': 56100.0, 'global/mean_episode_step': 5297.0, 'global/SPS': 3513.3805972353143, 'global/env_act_steps': 46900608, 'global/env_train_steps': 46899200, 'global/optimizer_steps': 73280, 'global/running_reward': 23976.5, 'global/running_step': 2488.05284375, 'global/steps_done': 46900608, 'global/episodes_done': 10960, 'global/unclipped_grad_norm': 0.7517373833273139, 'global/model_version': 73280, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:10,306] calculate_sps 30720 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:10,306] calculate_sps 30720 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:10,306] {'local/mean_episode_return': 46600.0, 'local/mean_episode_step': 4985.4, 'local/SPS': 3066.5109484437166, 'local/env_act_steps': 46939648, 'local/env_train_steps': 46935040, 'local/optimizer_steps': 73336, 'local/running_reward': 24257.078598484848, 'local/running_step': 2518.8226503314395, 'local/steps_done': 46939648, 'local/episodes_done': 10967, 'local/unclipped_grad_norm': 0.7787412932763497, 'local/model_version': 73336, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:10,307] {'global/mean_episode_return': 47600.0, 'global/mean_episode_step': 4968.2, 'global/SPS': 3066.5109484437166, 'global/env_act_steps': 46934528, 'global/env_train_steps': 46929920, 'global/optimizer_steps': 73328, 'global/running_reward': 24194.66391509434, 'global/running_step': 2513.551857311321, 'global/steps_done': 46934528, 'global/episodes_done': 10965, 'global/unclipped_grad_norm': 0.8065142203122377, 'global/model_version': 73328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:20,312] calculate_sps 34560 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:20,312] calculate_sps 35840 steps in 10.0045
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:20,312] {'local/mean_episode_return': 46750.0, 'local/mean_episode_step': 4834.75, 'local/SPS': 3454.4517040828455, 'local/env_act_steps': 46971776, 'local/env_train_steps': 46969600, 'local/optimizer_steps': 73389, 'local/running_reward': 24588.458665338647, 'local/running_step': 2543.0192355577688, 'local/steps_done': 46971776, 'local/episodes_done': 10971, 'local/unclipped_grad_norm': 0.8086645755003083, 'local/model_version': 73389, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:20,313] {'global/mean_episode_return': 46600.0, 'global/mean_episode_step': 4894.5, 'global/SPS': 3582.3943597896173, 'global/env_act_steps': 46966784, 'global/env_train_steps': 46965760, 'global/optimizer_steps': 73383, 'global/running_reward': 24523.797123015873, 'global/running_step': 2537.1854538690477, 'global/steps_done': 46966784, 'global/episodes_done': 10971, 'global/unclipped_grad_norm': 0.7587004038420591, 'global/model_version': 73383, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:30,314] calculate_sps 32000 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:30,315] calculate_sps 30720 steps in 10.0042
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:30,315] {'local/mean_episode_return': 50755.555555555555, 'local/mean_episode_step': 5135.777777777777, 'local/SPS': 3198.65024302837, 'local/env_act_steps': 47004672, 'local/env_train_steps': 47001600, 'local/optimizer_steps': 73440, 'local/running_reward': 25009.97689688716, 'local/running_step': 2582.0366305933853, 'local/steps_done': 47004672, 'local/episodes_done': 10980, 'local/unclipped_grad_norm': 0.9146465425397835, 'local/model_version': 73440, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:30,316] {'global/mean_episode_return': 50425.0, 'global/mean_episode_step': 5103.0, 'global/SPS': 3070.704233307235, 'global/env_act_steps': 47000064, 'global/env_train_steps': 46996480, 'global/optimizer_steps': 73432, 'global/running_reward': 25058.76201923077, 'global/running_step': 2587.6610276442307, 'global/steps_done': 47000064, 'global/episodes_done': 10979, 'global/unclipped_grad_norm': 0.8825081434785104, 'global/model_version': 73432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:40,320] calculate_sps 31360 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:40,321] calculate_sps 33920 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:40,321] {'local/mean_episode_return': 47200.0, 'local/mean_episode_step': 4738.333333333333, 'local/SPS': 3134.5296280281195, 'local/env_act_steps': 47037696, 'local/env_train_steps': 47032960, 'local/optimizer_steps': 73488, 'local/running_reward': 23941.07921511628, 'local/running_step': 2475.600956879845, 'local/steps_done': 47037696, 'local/episodes_done': 10992, 'local/unclipped_grad_norm': 0.8131525733818611, 'local/model_version': 73488, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:40,322] {'global/mean_episode_return': 47166.666666666664, 'global/mean_episode_step': 4762.666666666667, 'global/SPS': 3390.4095976630683, 'global/env_act_steps': 47032960, 'global/env_train_steps': 47030400, 'global/optimizer_steps': 73484, 'global/running_reward': 24078.112840466925, 'global/running_step': 2488.6961028696496, 'global/steps_done': 47032960, 'global/episodes_done': 10991, 'global/unclipped_grad_norm': 0.8678138416547042, 'global/model_version': 73484, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:50,320] calculate_sps 35200 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:15:50,321] calculate_sps 32640 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:50,321] {'local/mean_episode_return': 51233.333333333336, 'local/mean_episode_step': 5148.5, 'local/SPS': 3519.517926442923, 'local/env_act_steps': 47069568, 'local/env_train_steps': 47068160, 'local/optimizer_steps': 73544, 'local/running_reward': 23234.312248995982, 'local/running_step': 2405.897213855422, 'local/steps_done': 47069568, 'local/episodes_done': 10998, 'local/unclipped_grad_norm': 0.8496612172041621, 'local/model_version': 73544, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:15:50,322] {'global/mean_episode_return': 51600.0, 'global/mean_episode_step': 5142.428571428572, 'global/SPS': 3263.5529863379834, 'global/env_act_steps': 47065984, 'global/env_train_steps': 47063040, 'global/optimizer_steps': 73536, 'global/running_reward': 23245.893895348836, 'global/running_step': 2406.6948582848836, 'global/steps_done': 47065984, 'global/episodes_done': 10998, 'global/unclipped_grad_norm': 0.844885864509986, 'global/model_version': 73536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 15:15:52,155] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 47069568, 'env_train_steps': 47068160, 'optimizer_steps': 73544, 'running_reward': 23290.234375, 'running_step': 2413.94140625, 'steps_done': 47069568, 'episodes_done': 10998, 'unclipped_grad_norm': 0.8760434314608574, 'model_version': 73544, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 15:15:52,260] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint_v73552.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 15:15:52,503] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 47069568, 'env_train_steps': 47068160, 'optimizer_steps': 73544, 'running_reward': 23290.234375, 'running_step': 2413.94140625, 'steps_done': 47069568, 'episodes_done': 10998, 'unclipped_grad_norm': 0.8760434314608574, 'model_version': 73544, 'virtual_batch_size': 32.0, 'num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 15:15:52,607] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:00,348] calculate_sps 30720 steps in 10.0281
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:00,349] calculate_sps 30720 steps in 10.0281
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:00,349] {'local/mean_episode_return': 45714.28571428572, 'local/mean_episode_step': 4647.428571428572, 'local/SPS': 3063.383416130509, 'local/env_act_steps': 47102208, 'local/env_train_steps': 47098880, 'local/optimizer_steps': 73592, 'local/running_reward': 23326.139705882353, 'local/running_step': 2419.9511029411765, 'local/steps_done': 47102208, 'local/episodes_done': 11005, 'local/unclipped_grad_norm': 0.7685135534654061, 'local/model_version': 73592, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:00,350] {'global/mean_episode_return': 48866.666666666664, 'global/mean_episode_step': 4894.0, 'global/SPS': 3063.383416130509, 'global/env_act_steps': 47099008, 'global/env_train_steps': 47093760, 'global/optimizer_steps': 73584, 'global/running_reward': 23325.411821705427, 'global/running_step': 2419.4268108042634, 'global/steps_done': 47099008, 'global/episodes_done': 11004, 'global/unclipped_grad_norm': 0.781989062204957, 'global/model_version': 73584, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:10,368] calculate_sps 32640 steps in 10.0204
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:10,369] calculate_sps 35840 steps in 10.0204
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:10,369] {'local/mean_episode_return': 44642.857142857145, 'local/mean_episode_step': 4581.0, 'local/SPS': 3257.3498652229537, 'local/env_act_steps': 47135104, 'local/env_train_steps': 47131520, 'local/optimizer_steps': 73642, 'local/running_reward': 23000.966682879378, 'local/running_step': 2386.4092290856033, 'local/steps_done': 47135104, 'local/episodes_done': 11013, 'local/unclipped_grad_norm': 0.7671123504638672, 'local/model_version': 73642, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:10,370] {'global/mean_episode_return': 42412.5, 'global/mean_episode_step': 4404.375, 'global/SPS': 3576.6978912252043, 'global/env_act_steps': 47131392, 'global/env_train_steps': 47129600, 'global/optimizer_steps': 73640, 'global/running_reward': 23015.174160079052, 'global/running_step': 2388.047307312253, 'global/steps_done': 47131392, 'global/episodes_done': 11013, 'global/unclipped_grad_norm': 0.7762150328074183, 'global/model_version': 73640, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:20,387] calculate_sps 33920 steps in 10.0181
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:20,387] calculate_sps 30720 steps in 10.0181
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:20,388] {'local/mean_episode_return': 38166.666666666664, 'local/mean_episode_step': 4168.833333333333, 'local/SPS': 3385.871886907796, 'local/env_act_steps': 47167744, 'local/env_train_steps': 47165440, 'local/optimizer_steps': 73696, 'local/running_reward': 23366.23774509804, 'local/running_step': 2418.8158088235296, 'local/steps_done': 47167744, 'local/episodes_done': 11019, 'local/unclipped_grad_norm': 0.8388135527019147, 'local/model_version': 73696, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:20,389] {'global/mean_episode_return': 38166.666666666664, 'global/mean_episode_step': 4168.833333333333, 'global/SPS': 3066.450010784419, 'global/env_act_steps': 47165056, 'global/env_train_steps': 47160320, 'global/optimizer_steps': 73688, 'global/running_reward': 23325.04752851711, 'global/running_step': 2415.6361097908743, 'global/steps_done': 47165056, 'global/episodes_done': 11019, 'global/unclipped_grad_norm': 0.8079878780990839, 'global/model_version': 73688, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:30,404] calculate_sps 30720 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:30,405] calculate_sps 35840 steps in 10.0171
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:30,405] {'local/mean_episode_return': 47911.11111111111, 'local/mean_episode_step': 4913.444444444444, 'local/SPS': 3066.7407088473465, 'local/env_act_steps': 47201152, 'local/env_train_steps': 47196160, 'local/optimizer_steps': 73744, 'local/running_reward': 23479.90301724138, 'local/running_step': 2423.2061781609195, 'local/steps_done': 47201152, 'local/episodes_done': 11028, 'local/unclipped_grad_norm': 0.7868774216622114, 'local/model_version': 73744, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:30,415] {'global/mean_episode_return': 48800.0, 'global/mean_episode_step': 5003.875, 'global/SPS': 3577.8641603219044, 'global/env_act_steps': 47197184, 'global/env_train_steps': 47196160, 'global/optimizer_steps': 73743, 'global/running_reward': 23508.540836653385, 'global/running_step': 2426.6654320219122, 'global/steps_done': 47197184, 'global/episodes_done': 11027, 'global/unclipped_grad_norm': 0.8173458104783838, 'global/model_version': 73743, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:40,428] calculate_sps 35200 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:40,429] calculate_sps 30720 steps in 10.0247
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:40,429] {'local/mean_episode_return': 40400.0, 'local/mean_episode_step': 4147.25, 'local/SPS': 3511.342748047867, 'local/env_act_steps': 47232896, 'local/env_train_steps': 47231360, 'local/optimizer_steps': 73798, 'local/running_reward': 23554.85131048387, 'local/running_step': 2427.9928490423385, 'local/steps_done': 47232896, 'local/episodes_done': 11032, 'local/unclipped_grad_norm': 0.7216991699404187, 'local/model_version': 73798, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:40,430] {'global/mean_episode_return': 40480.0, 'global/mean_episode_step': 4155.8, 'global/SPS': 3064.4445801145025, 'global/env_act_steps': 47230720, 'global/env_train_steps': 47226880, 'global/optimizer_steps': 73792, 'global/running_reward': 23511.170085877864, 'global/running_step': 2423.5534947519086, 'global/steps_done': 47230720, 'global/episodes_done': 11032, 'global/unclipped_grad_norm': 0.730904393658346, 'global/model_version': 73792, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:50,434] calculate_sps 31360 steps in 10.0056
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:16:50,435] calculate_sps 33280 steps in 10.0056
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:50,435] {'local/mean_episode_return': 47266.666666666664, 'local/mean_episode_step': 4673.833333333333, 'local/SPS': 3134.2539420697594, 'local/env_act_steps': 47265792, 'local/env_train_steps': 47262720, 'local/optimizer_steps': 73848, 'local/running_reward': 24016.622081712063, 'local/running_step': 2471.817515807393, 'local/steps_done': 47265792, 'local/episodes_done': 11038, 'local/unclipped_grad_norm': 0.7600899493694305, 'local/model_version': 73848, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:16:50,436] {'global/mean_episode_return': 45200.0, 'global/mean_episode_step': 4529.8, 'global/SPS': 3326.147040563826, 'global/env_act_steps': 47263232, 'global/env_train_steps': 47260160, 'global/optimizer_steps': 73843, 'global/running_reward': 23992.015255905513, 'global/running_step': 2469.625246062992, 'global/steps_done': 47263232, 'global/episodes_done': 11037, 'global/unclipped_grad_norm': 0.727566615039227, 'global/model_version': 73843, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:00,463] calculate_sps 32000 steps in 10.029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:00,463] calculate_sps 33280 steps in 10.029
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:00,463] {'local/mean_episode_return': 43350.0, 'local/mean_episode_step': 4601.75, 'local/SPS': 3190.73976587723, 'local/env_act_steps': 47298816, 'local/env_train_steps': 47294720, 'local/optimizer_steps': 73897, 'local/running_reward': 24276.38687015504, 'local/running_step': 2496.0793059593025, 'local/steps_done': 47298816, 'local/episodes_done': 11042, 'local/unclipped_grad_norm': 0.749919128661253, 'local/model_version': 73897, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:00,464] {'global/mean_episode_return': 46200.0, 'global/mean_episode_step': 4760.2, 'global/SPS': 3318.3693565123194, 'global/env_act_steps': 47296256, 'global/env_train_steps': 47293440, 'global/optimizer_steps': 73896, 'global/running_reward': 24238.668846899225, 'global/running_step': 2492.4698098352715, 'global/steps_done': 47296256, 'global/episodes_done': 11042, 'global/unclipped_grad_norm': 0.7628361335340536, 'global/model_version': 73896, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:10,489] calculate_sps 34560 steps in 10.0258
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:10,490] calculate_sps 32000 steps in 10.0258
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:10,490] {'local/mean_episode_return': 48053.333333333336, 'local/mean_episode_step': 4778.0, 'local/SPS': 3447.0952384689303, 'local/env_act_steps': 47331328, 'local/env_train_steps': 47329280, 'local/optimizer_steps': 73952, 'local/running_reward': 23971.745816929135, 'local/running_step': 2464.177965059055, 'local/steps_done': 47331328, 'local/episodes_done': 11057, 'local/unclipped_grad_norm': 0.8509334157813679, 'local/model_version': 73952, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:10,491] {'global/mean_episode_return': 49984.61538461538, 'global/mean_episode_step': 4925.846153846154, 'global/SPS': 3191.754850434195, 'global/env_act_steps': 47329536, 'global/env_train_steps': 47325440, 'global/optimizer_steps': 73945, 'global/running_reward': 24058.88221153846, 'global/running_step': 2472.7096754807694, 'global/steps_done': 47329536, 'global/episodes_done': 11055, 'global/unclipped_grad_norm': 0.8419966618625485, 'global/model_version': 73945, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:20,500] calculate_sps 30720 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:20,501] calculate_sps 34560 steps in 10.0111
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:20,501] {'local/mean_episode_return': 49475.0, 'local/mean_episode_step': 4917.875, 'local/SPS': 3068.589971100021, 'local/env_act_steps': 47364352, 'local/env_train_steps': 47360000, 'local/optimizer_steps': 74000, 'local/running_reward': 22969.785610465115, 'local/running_step': 2368.009871608527, 'local/steps_done': 47364352, 'local/episodes_done': 11065, 'local/unclipped_grad_norm': 0.8315653260797262, 'local/model_version': 74000, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:20,502] {'global/mean_episode_return': 46680.0, 'global/mean_episode_step': 4697.7, 'global/SPS': 3452.1637174875236, 'global/env_act_steps': 47362048, 'global/env_train_steps': 47360000, 'global/optimizer_steps': 74000, 'global/running_reward': 23000.805856299212, 'global/running_step': 2370.802995816929, 'global/steps_done': 47362048, 'global/episodes_done': 11065, 'global/unclipped_grad_norm': 0.8437837887894023, 'global/model_version': 74000, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:30,510] calculate_sps 35200 steps in 10.01
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:30,511] calculate_sps 31360 steps in 10.01
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:30,511] {'local/mean_episode_return': 49516.666666666664, 'local/mean_episode_step': 5072.666666666667, 'local/SPS': 3516.467187539374, 'local/env_act_steps': 47396864, 'local/env_train_steps': 47395200, 'local/optimizer_steps': 74055, 'local/running_reward': 22365.372785433072, 'local/running_step': 2310.3404281496064, 'local/steps_done': 47396864, 'local/episodes_done': 11072, 'local/unclipped_grad_norm': 0.81230278394439, 'local/model_version': 74055, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:30,512] {'global/mean_episode_return': 49980.0, 'global/mean_episode_step': 5109.2, 'global/SPS': 3132.8525852623516, 'global/env_act_steps': 47395968, 'global/env_train_steps': 47391360, 'global/optimizer_steps': 74048, 'global/running_reward': 22384.156839622643, 'global/running_step': 2312.2213738207547, 'global/steps_done': 47395968, 'global/episodes_done': 11071, 'global/unclipped_grad_norm': 0.8311387300491333, 'global/model_version': 74048, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:40,543] calculate_sps 31360 steps in 10.032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:40,543] calculate_sps 35200 steps in 10.032
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:40,543] {'local/mean_episode_return': 45000.0, 'local/mean_episode_step': 4708.0, 'local/SPS': 3125.986314886051, 'local/env_act_steps': 47430528, 'local/env_train_steps': 47426560, 'local/optimizer_steps': 74104, 'local/running_reward': 22981.921340304183, 'local/running_step': 2371.2009268060838, 'local/steps_done': 47430528, 'local/episodes_done': 11076, 'local/unclipped_grad_norm': 0.7917335799762181, 'local/model_version': 74104, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:40,545] {'global/mean_episode_return': 45440.0, 'global/mean_episode_step': 4744.4, 'global/SPS': 3508.7601493618936, 'global/env_act_steps': 47429120, 'global/env_train_steps': 47426560, 'global/optimizer_steps': 74104, 'global/running_reward': 22959.151785714286, 'global/running_step': 2369.0388211872587, 'global/steps_done': 47429120, 'global/episodes_done': 11076, 'global/unclipped_grad_norm': 0.778159633811031, 'global/model_version': 74104, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:50,563] calculate_sps 33920 steps in 10.0205
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:17:50,563] calculate_sps 31360 steps in 10.0205
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:50,563] {'local/mean_episode_return': 55650.0, 'local/mean_episode_step': 5333.5, 'local/SPS': 3385.0627384707755, 'local/env_act_steps': 47463040, 'local/env_train_steps': 47460480, 'local/optimizer_steps': 74156, 'local/running_reward': 23242.039862204725, 'local/running_step': 2394.50390625, 'local/steps_done': 47463040, 'local/episodes_done': 11084, 'local/unclipped_grad_norm': 0.7953162095867671, 'local/model_version': 74156, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:17:50,564] {'global/mean_episode_return': 55650.0, 'global/mean_episode_step': 5333.5, 'global/SPS': 3129.586305378641, 'global/env_act_steps': 47462656, 'global/env_train_steps': 47457920, 'global/optimizer_steps': 74152, 'global/running_reward': 23247.668177480915, 'global/running_step': 2395.004442986641, 'global/steps_done': 47462656, 'global/episodes_done': 11084, 'global/unclipped_grad_norm': 0.7923909270515045, 'global/model_version': 74152, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:00,579] calculate_sps 32640 steps in 10.0163
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:00,580] calculate_sps 35200 steps in 10.0163
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:00,580] {'local/mean_episode_return': 47309.09090909091, 'local/mean_episode_step': 4832.545454545455, 'local/SPS': 3258.693004059118, 'local/env_act_steps': 47495680, 'local/env_train_steps': 47493120, 'local/optimizer_steps': 74208, 'local/running_reward': 22492.84926470588, 'local/running_step': 2325.6098651960783, 'local/steps_done': 47495680, 'local/episodes_done': 11095, 'local/unclipped_grad_norm': 0.8548696688734568, 'local/model_version': 74208, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:00,581] {'global/mean_episode_return': 46560.0, 'global/mean_episode_step': 4776.2, 'global/SPS': 3514.276769083362, 'global/env_act_steps': 47494784, 'global/env_train_steps': 47493120, 'global/optimizer_steps': 74208, 'global/running_reward': 22506.95343625498, 'global/running_step': 2327.05515438247, 'global/steps_done': 47494784, 'global/episodes_done': 11094, 'global/unclipped_grad_norm': 0.853123235383204, 'global/model_version': 74208, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:10,601] calculate_sps 30720 steps in 10.0216
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:10,603] calculate_sps 30720 steps in 10.0216
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:10,603] {'local/mean_episode_return': 52950.0, 'local/mean_episode_step': 5161.25, 'local/SPS': 3065.364339941859, 'local/env_act_steps': 47528960, 'local/env_train_steps': 47523840, 'local/optimizer_steps': 74256, 'local/running_reward': 22262.62019230769, 'local/running_step': 2307.053064903846, 'local/steps_done': 47528960, 'local/episodes_done': 11099, 'local/unclipped_grad_norm': 0.8278073333203793, 'local/model_version': 74256, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:10,604] {'global/mean_episode_return': 53320.0, 'global/mean_episode_step': 5208.2, 'global/SPS': 3065.364339941859, 'global/env_act_steps': 47528448, 'global/env_train_steps': 47523840, 'global/optimizer_steps': 74256, 'global/running_reward': 22257.996673003803, 'global/running_step': 2306.418934173004, 'global/steps_done': 47528448, 'global/episodes_done': 11099, 'global/unclipped_grad_norm': 0.8278073333203793, 'global/model_version': 74256, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:20,634] calculate_sps 35200 steps in 10.034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:20,635] calculate_sps 34560 steps in 10.034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:20,635] {'local/mean_episode_return': 41822.22222222222, 'local/mean_episode_step': 4470.222222222223, 'local/SPS': 3508.089419230079, 'local/env_act_steps': 47560576, 'local/env_train_steps': 47559040, 'local/optimizer_steps': 74310, 'local/running_reward': 22523.905617408906, 'local/running_step': 2331.208122469636, 'local/steps_done': 47560576, 'local/episodes_done': 11108, 'local/unclipped_grad_norm': 0.713142000414707, 'local/model_version': 74310, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:20,636] {'global/mean_episode_return': 41822.22222222222, 'global/mean_episode_step': 4470.222222222223, 'global/SPS': 3444.305975244077, 'global/env_act_steps': 47560448, 'global/env_train_steps': 47558400, 'global/optimizer_steps': 74309, 'global/running_reward': 22525.7625, 'global/running_step': 2331.4669375, 'global/steps_done': 47560448, 'global/episodes_done': 11108, 'global/unclipped_grad_norm': 0.7111114437850017, 'global/model_version': 74309, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:30,636] calculate_sps 31360 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:30,636] calculate_sps 32000 steps in 10.0005
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:30,637] {'local/mean_episode_return': 51800.0, 'local/mean_episode_step': 5236.25, 'local/SPS': 3135.858545199215, 'local/env_act_steps': 47593984, 'local/env_train_steps': 47590400, 'local/optimizer_steps': 74360, 'local/running_reward': 22437.865181992336, 'local/running_step': 2319.0407387452105, 'local/steps_done': 47593984, 'local/episodes_done': 11112, 'local/unclipped_grad_norm': 0.7665384161472321, 'local/model_version': 74360, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:30,638] {'global/mean_episode_return': 51800.0, 'global/mean_episode_step': 5236.25, 'global/SPS': 3199.855658366546, 'global/env_act_steps': 47593984, 'global/env_train_steps': 47590400, 'global/optimizer_steps': 74360, 'global/running_reward': 22435.132395038167, 'global/running_step': 2318.7883170324426, 'global/steps_done': 47593984, 'global/episodes_done': 11112, 'global/unclipped_grad_norm': 0.7676016139049157, 'global/model_version': 74360, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:40,637] calculate_sps 32640 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:40,638] calculate_sps 25600 steps in 10.0006
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:40,638] {'local/mean_episode_return': 44885.71428571428, 'local/mean_episode_step': 4539.285714285715, 'local/SPS': 3263.803594582731, 'local/env_act_steps': 47626752, 'local/env_train_steps': 47623040, 'local/optimizer_steps': 74410, 'local/running_reward': 22666.71142578125, 'local/running_step': 2342.4330444335938, 'local/steps_done': 47626752, 'local/episodes_done': 11119, 'local/unclipped_grad_norm': 0.7456501799821854, 'local/model_version': 74410, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:40,639] {'global/mean_episode_return': 46833.333333333336, 'global/mean_episode_step': 4707.333333333333, 'global/SPS': 2559.8459565354756, 'global/env_act_steps': 47620736, 'global/env_train_steps': 47616000, 'global/optimizer_steps': 74400, 'global/running_reward': 22672.226375598086, 'global/running_step': 2343.415557715311, 'global/steps_done': 47620736, 'global/episodes_done': 11118, 'global/unclipped_grad_norm': 0.7522215880453587, 'global/model_version': 74400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:50,641] calculate_sps 33920 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:18:50,641] calculate_sps 35840 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:50,650] {'local/mean_episode_return': 48250.0, 'local/mean_episode_step': 4897.75, 'local/SPS': 3390.390449175263, 'local/env_act_steps': 47659136, 'local/env_train_steps': 47656960, 'local/optimizer_steps': 74464, 'local/running_reward': 23141.168478260868, 'local/running_step': 2385.813858695652, 'local/steps_done': 47659136, 'local/episodes_done': 11123, 'local/unclipped_grad_norm': 0.7543380122493815, 'local/model_version': 74464, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:18:50,652] {'global/mean_episode_return': 40400.0, 'global/mean_episode_step': 4198.333333333333, 'global/SPS': 3582.299342524806, 'global/env_act_steps': 47653376, 'global/env_train_steps': 47651840, 'global/optimizer_steps': 74456, 'global/running_reward': 23031.5625, 'global/running_step': 2375.321966911765, 'global/steps_done': 47653376, 'global/episodes_done': 11121, 'global/unclipped_grad_norm': 0.7432699512158122, 'global/model_version': 74456, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:00,652] calculate_sps 30720 steps in 10.0118
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:00,653] calculate_sps 30720 steps in 10.0118
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:00,662] {'local/mean_episode_return': 50100.0, 'local/mean_episode_step': 4719.0, 'local/SPS': 3068.383242627805, 'local/env_act_steps': 47692800, 'local/env_train_steps': 47687680, 'local/optimizer_steps': 74512, 'local/running_reward': 23869.451045627375, 'local/running_step': 2453.7336917775665, 'local/steps_done': 47692800, 'local/episodes_done': 11125, 'local/unclipped_grad_norm': 0.7933317689845959, 'local/model_version': 74512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:00,664] {'global/mean_episode_return': 51300.0, 'global/mean_episode_step': 4991.25, 'global/SPS': 3068.383242627805, 'global/env_act_steps': 47687168, 'global/env_train_steps': 47682560, 'global/optimizer_steps': 74504, 'global/running_reward': 23717.412405303032, 'global/running_step': 2439.1919685132575, 'global/steps_done': 47687168, 'global/episodes_done': 11125, 'global/unclipped_grad_norm': 0.8040653839707375, 'global/model_version': 74504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:10,669] calculate_sps 35840 steps in 10.0148
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:10,669] calculate_sps 35840 steps in 10.0148
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:10,671] {'local/mean_episode_return': 49200.0, 'local/mean_episode_step': 5002.666666666667, 'local/SPS': 3578.7117572783386, 'local/env_act_steps': 47724672, 'local/env_train_steps': 47723520, 'local/optimizer_steps': 74567, 'local/running_reward': 24096.109437751005, 'local/running_step': 2478.457109688755, 'local/steps_done': 47724672, 'local/episodes_done': 11131, 'local/unclipped_grad_norm': 0.8320242264054039, 'local/model_version': 74567, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:10,675] {'global/mean_episode_return': 49200.0, 'global/mean_episode_step': 4992.2, 'global/SPS': 3578.7117572783386, 'global/env_act_steps': 47719424, 'global/env_train_steps': 47718400, 'global/optimizer_steps': 74559, 'global/running_reward': 24090.08556547619, 'global/running_step': 2477.4215029761904, 'global/steps_done': 47719424, 'global/episodes_done': 11130, 'global/unclipped_grad_norm': 0.8049475745721297, 'global/model_version': 74559, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:20,671] calculate_sps 30720 steps in 10.0037
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:20,671] calculate_sps 30720 steps in 10.0037
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:20,672] {'local/mean_episode_return': 46866.666666666664, 'local/mean_episode_step': 4639.333333333333, 'local/SPS': 3070.8618720102213, 'local/env_act_steps': 47757312, 'local/env_train_steps': 47754240, 'local/optimizer_steps': 74616, 'local/running_reward': 24389.295343137255, 'local/running_step': 2510.873069852941, 'local/steps_done': 47757312, 'local/episodes_done': 11137, 'local/unclipped_grad_norm': 0.8507285975680059, 'local/model_version': 74616, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:20,673] {'global/mean_episode_return': 45300.0, 'global/mean_episode_step': 4582.5, 'global/SPS': 3070.8618720102213, 'global/env_act_steps': 47752704, 'global/env_train_steps': 47749120, 'global/optimizer_steps': 74608, 'global/running_reward': 24340.931490384617, 'global/running_step': 2505.67890625, 'global/steps_done': 47752704, 'global/episodes_done': 11136, 'global/unclipped_grad_norm': 0.8465344814621673, 'global/model_version': 74608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:30,677] calculate_sps 31360 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:30,690] calculate_sps 32640 steps in 10.0047
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:30,690] {'local/mean_episode_return': 46714.28571428572, 'local/mean_episode_step': 4726.285714285715, 'local/SPS': 3134.517452306298, 'local/env_act_steps': 47790336, 'local/env_train_steps': 47785600, 'local/optimizer_steps': 74664, 'local/running_reward': 24287.80886627907, 'local/running_step': 2497.441527374031, 'local/steps_done': 47790336, 'local/episodes_done': 11145, 'local/unclipped_grad_norm': 0.7261316453417143, 'local/model_version': 74664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:30,692] {'global/mean_episode_return': 48200.0, 'global/mean_episode_step': 4810.0, 'global/SPS': 3262.4569401555345, 'global/env_act_steps': 47785344, 'global/env_train_steps': 47781760, 'global/optimizer_steps': 74658, 'global/running_reward': 24321.88725490196, 'global/running_step': 2501.4795955882355, 'global/steps_done': 47785344, 'global/episodes_done': 11145, 'global/unclipped_grad_norm': 0.7538604259490966, 'global/model_version': 74658, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:40,695] calculate_sps 35200 steps in 10.019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:40,695] calculate_sps 33920 steps in 10.019
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:40,695] {'local/mean_episode_return': 45400.0, 'local/mean_episode_step': 4565.25, 'local/SPS': 3513.340883884738, 'local/env_act_steps': 47822848, 'local/env_train_steps': 47820800, 'local/optimizer_steps': 74720, 'local/running_reward': 24451.556348425198, 'local/running_step': 2513.9582923228345, 'local/steps_done': 47822848, 'local/episodes_done': 11149, 'local/unclipped_grad_norm': 0.8251606545278004, 'local/model_version': 74720, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:40,707] {'global/mean_episode_return': 45400.0, 'global/mean_episode_step': 4565.25, 'global/SPS': 3385.583033561657, 'global/env_act_steps': 47818496, 'global/env_train_steps': 47815680, 'global/optimizer_steps': 74712, 'global/running_reward': 24374.342422779922, 'global/running_step': 2506.3504162644786, 'global/steps_done': 47818496, 'global/episodes_done': 11149, 'global/unclipped_grad_norm': 0.8256511859319828, 'global/model_version': 74712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:50,696] calculate_sps 30720 steps in 10.0016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:19:50,696] calculate_sps 32000 steps in 10.0016
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:50,706] {'local/mean_episode_return': 50028.57142857143, 'local/mean_episode_step': 5033.714285714285, 'local/SPS': 3071.5224619394708, 'local/env_act_steps': 47856256, 'local/env_train_steps': 47851520, 'local/optimizer_steps': 74768, 'local/running_reward': 24980.154454022988, 'local/running_step': 2562.0799509099616, 'local/steps_done': 47856256, 'local/episodes_done': 11156, 'local/unclipped_grad_norm': 0.7466018348932266, 'local/model_version': 74768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:19:50,708] {'global/mean_episode_return': 47800.0, 'global/mean_episode_step': 4888.0, 'global/SPS': 3199.502564520282, 'global/env_act_steps': 47851776, 'global/env_train_steps': 47847680, 'global/optimizer_steps': 74761, 'global/running_reward': 24940.32451923077, 'global/running_step': 2559.003966346154, 'global/steps_done': 47851776, 'global/episodes_done': 11154, 'global/unclipped_grad_norm': 0.7853598923099284, 'global/model_version': 74761, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:00,716] calculate_sps 34560 steps in 10.0202
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:00,716] calculate_sps 34560 steps in 10.0202
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:00,716] {'local/mean_episode_return': 45433.333333333336, 'local/mean_episode_step': 4571.833333333333, 'local/SPS': 3449.019736067871, 'local/env_act_steps': 47888128, 'local/env_train_steps': 47886080, 'local/optimizer_steps': 74821, 'local/running_reward': 25039.539407630524, 'local/running_step': 2562.188002008032, 'local/steps_done': 47888128, 'local/episodes_done': 11164, 'local/unclipped_grad_norm': 0.7550860154178908, 'local/model_version': 74821, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:00,717] {'global/mean_episode_return': 46466.666666666664, 'global/mean_episode_step': 4697.333333333333, 'global/SPS': 3449.019736067871, 'global/env_act_steps': 47884032, 'global/env_train_steps': 47882240, 'global/optimizer_steps': 74816, 'global/running_reward': 25039.521329365078, 'global/running_step': 2562.7444506448414, 'global/steps_done': 47884032, 'global/episodes_done': 11160, 'global/unclipped_grad_norm': 0.7114530595866116, 'global/model_version': 74816, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:10,745] calculate_sps 32000 steps in 10.0289
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:10,746] calculate_sps 30720 steps in 10.0289
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:10,746] {'local/mean_episode_return': 51560.0, 'local/mean_episode_step': 4888.8, 'local/SPS': 3190.779665065639, 'local/env_act_steps': 47921408, 'local/env_train_steps': 47918080, 'local/optimizer_steps': 74872, 'local/running_reward': 24835.606971153848, 'local/running_step': 2545.6591947115385, 'local/steps_done': 47921408, 'local/episodes_done': 11169, 'local/unclipped_grad_norm': 0.8492946484509636, 'local/model_version': 74872, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:10,747] {'global/mean_episode_return': 51828.57142857143, 'global/mean_episode_step': 4926.714285714285, 'global/SPS': 3063.148478463014, 'global/env_act_steps': 47917696, 'global/env_train_steps': 47912960, 'global/optimizer_steps': 74864, 'global/running_reward': 24864.94177756654, 'global/running_step': 2547.4423122623575, 'global/steps_done': 47917696, 'global/episodes_done': 11169, 'global/unclipped_grad_norm': 0.8652882265547911, 'global/model_version': 74864, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:20,793] calculate_sps 32640 steps in 10.0483
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:20,793] calculate_sps 35840 steps in 10.0483
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:20,794] {'local/mean_episode_return': 51960.0, 'local/mean_episode_step': 5073.4, 'local/SPS': 3248.29708563375, 'local/env_act_steps': 47954304, 'local/env_train_steps': 47950720, 'local/optimizer_steps': 74922, 'local/running_reward': 25017.57052529183, 'local/running_step': 2568.2181420233464, 'local/steps_done': 47954304, 'local/episodes_done': 11174, 'local/unclipped_grad_norm': 0.8543510913848877, 'local/model_version': 74922, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:20,795] {'global/mean_episode_return': 51960.0, 'global/mean_episode_step': 5073.4, 'global/SPS': 3566.7575842252945, 'global/env_act_steps': 47949952, 'global/env_train_steps': 47948800, 'global/optimizer_steps': 74920, 'global/running_reward': 24980.784970238095, 'global/running_step': 2564.5813182043653, 'global/steps_done': 47949952, 'global/episodes_done': 11174, 'global/unclipped_grad_norm': 0.8507994104708944, 'global/model_version': 74920, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:30,795] calculate_sps 33920 steps in 10.0009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:30,795] calculate_sps 30720 steps in 10.0009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:30,795] {'local/mean_episode_return': 46600.0, 'local/mean_episode_step': 4852.75, 'local/SPS': 3391.7097767260393, 'local/env_act_steps': 47986560, 'local/env_train_steps': 47984640, 'local/optimizer_steps': 74976, 'local/running_reward': 25377.579365079364, 'local/running_step': 2604.5437437996034, 'local/steps_done': 47986560, 'local/episodes_done': 11178, 'local/unclipped_grad_norm': 0.7777065474677969, 'local/model_version': 74976, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:30,803] {'global/mean_episode_return': 46600.0, 'global/mean_episode_step': 4852.75, 'global/SPS': 3071.7371562801864, 'global/env_act_steps': 47983616, 'global/env_train_steps': 47979520, 'global/optimizer_steps': 74968, 'global/running_reward': 25318.346007604563, 'global/running_step': 2598.6151378326995, 'global/steps_done': 47983616, 'global/episodes_done': 11178, 'global/unclipped_grad_norm': 0.7400716816385587, 'global/model_version': 74968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:40,820] calculate_sps 30720 steps in 10.0257
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:40,820] calculate_sps 34560 steps in 10.0257
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:40,830] {'local/mean_episode_return': 47971.42857142857, 'local/mean_episode_step': 4895.142857142857, 'local/SPS': 3064.137921833758, 'local/env_act_steps': 48019840, 'local/env_train_steps': 48015360, 'local/optimizer_steps': 75024, 'local/running_reward': 26128.978365384617, 'local/running_step': 2674.207782451923, 'local/steps_done': 48019840, 'local/episodes_done': 11185, 'local/unclipped_grad_norm': 0.7715124736229578, 'local/model_version': 75024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:40,831] {'global/mean_episode_return': 51200.0, 'global/mean_episode_step': 5080.8, 'global/SPS': 3447.1551620629775, 'global/env_act_steps': 48016128, 'global/env_train_steps': 48014080, 'global/optimizer_steps': 75021, 'global/running_reward': 26112.83218503937, 'global/running_step': 2673.0418922244094, 'global/steps_done': 48016128, 'global/episodes_done': 11183, 'global/unclipped_grad_norm': 0.7848434667542296, 'global/model_version': 75021, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:50,854] calculate_sps 34560 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:20:50,855] calculate_sps 32000 steps in 10.0346
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:50,855] {'local/mean_episode_return': 51771.42857142857, 'local/mean_episode_step': 5143.428571428572, 'local/SPS': 3444.0831371915056, 'local/env_act_steps': 48051968, 'local/env_train_steps': 48049920, 'local/optimizer_steps': 75077, 'local/running_reward': 25690.730826693227, 'local/running_step': 2628.436815239044, 'local/steps_done': 48051968, 'local/episodes_done': 11192, 'local/unclipped_grad_norm': 0.7726936216624278, 'local/model_version': 75077, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:20:50,856] {'global/mean_episode_return': 48550.0, 'global/mean_episode_step': 4933.75, 'global/SPS': 3188.9658677699126, 'global/env_act_steps': 48049536, 'global/env_train_steps': 48046080, 'global/optimizer_steps': 75072, 'global/running_reward': 25725.826149425287, 'global/running_step': 2631.8285141283527, 'global/steps_done': 48049536, 'global/episodes_done': 11191, 'global/unclipped_grad_norm': 0.7941062765962937, 'global/model_version': 75072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:00,873] calculate_sps 32000 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:00,873] calculate_sps 32000 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:00,873] {'local/mean_episode_return': 48300.0, 'local/mean_episode_step': 4849.125, 'local/SPS': 3194.272507234119, 'local/env_act_steps': 48084736, 'local/env_train_steps': 48081920, 'local/optimizer_steps': 75128, 'local/running_reward': 25392.083740234375, 'local/running_step': 2602.304473876953, 'local/steps_done': 48084736, 'local/episodes_done': 11200, 'local/unclipped_grad_norm': 0.8168462076607872, 'local/model_version': 75128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:00,874] {'global/mean_episode_return': 48911.11111111111, 'global/mean_episode_step': 4909.888888888889, 'global/SPS': 3194.272507234119, 'global/env_act_steps': 48082176, 'global/env_train_steps': 48078080, 'global/optimizer_steps': 75121, 'global/running_reward': 25416.366421568626, 'global/running_step': 2604.789920343137, 'global/steps_done': 48082176, 'global/episodes_done': 11200, 'global/unclipped_grad_norm': 0.7987528753523924, 'global/model_version': 75121, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:10,894] calculate_sps 30720 steps in 10.0215
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:10,894] calculate_sps 34560 steps in 10.0215
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:10,895] {'local/mean_episode_return': 54457.142857142855, 'local/mean_episode_step': 5395.571428571428, 'local/SPS': 3065.423848808005, 'local/env_act_steps': 48117888, 'local/env_train_steps': 48112640, 'local/optimizer_steps': 75176, 'local/running_reward': 25416.56611969112, 'local/running_step': 2603.674227799228, 'local/steps_done': 48117888, 'local/episodes_done': 11207, 'local/unclipped_grad_norm': 0.8168095579991738, 'local/model_version': 75176, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:10,896] {'global/mean_episode_return': 55033.333333333336, 'global/mean_episode_step': 5395.333333333333, 'global/SPS': 3448.6018299090056, 'global/env_act_steps': 48114816, 'global/env_train_steps': 48112640, 'global/optimizer_steps': 75176, 'global/running_reward': 25428.051470588234, 'global/running_step': 2604.775643382353, 'global/steps_done': 48114816, 'global/episodes_done': 11206, 'global/unclipped_grad_norm': 0.8264613276178187, 'global/model_version': 75176, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:20,903] calculate_sps 35840 steps in 10.0091
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:20,903] calculate_sps 30720 steps in 10.0091
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:20,914] {'local/mean_episode_return': 48580.0, 'local/mean_episode_step': 5015.6, 'local/SPS': 3580.728830656903, 'local/env_act_steps': 48149888, 'local/env_train_steps': 48148480, 'local/optimizer_steps': 75232, 'local/running_reward': 24689.46875, 'local/running_step': 2527.6354375, 'local/steps_done': 48149888, 'local/episodes_done': 11217, 'local/unclipped_grad_norm': 0.8673678854746478, 'local/model_version': 75232, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:20,915] {'global/mean_episode_return': 50466.666666666664, 'global/mean_episode_step': 5197.666666666667, 'global/SPS': 3069.19614056306, 'global/env_act_steps': 48148352, 'global/env_train_steps': 48143360, 'global/optimizer_steps': 75224, 'global/running_reward': 24738.120229007633, 'global/running_step': 2532.866054389313, 'global/steps_done': 48148352, 'global/episodes_done': 11215, 'global/unclipped_grad_norm': 0.8499586017181476, 'global/model_version': 75224, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:30,918] calculate_sps 30720 steps in 10.0144
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:30,918] calculate_sps 35840 steps in 10.0144
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:30,918] {'local/mean_episode_return': 44300.0, 'local/mean_episode_step': 4623.6, 'local/SPS': 3067.5760334328097, 'local/env_act_steps': 48183040, 'local/env_train_steps': 48179200, 'local/optimizer_steps': 75280, 'local/running_reward': 24315.317326254826, 'local/running_step': 2485.710756515444, 'local/steps_done': 48183040, 'local/episodes_done': 11227, 'local/unclipped_grad_norm': 0.7866042573004961, 'local/model_version': 75280, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:30,920] {'global/mean_episode_return': 44745.454545454544, 'global/mean_episode_step': 4652.727272727273, 'global/SPS': 3578.8387056716115, 'global/env_act_steps': 48180352, 'global/env_train_steps': 48179200, 'global/optimizer_steps': 75279, 'global/running_reward': 24356.53125, 'global/running_step': 2490.20178125, 'global/steps_done': 48180352, 'global/episodes_done': 11226, 'global/unclipped_grad_norm': 0.8192589933221991, 'global/model_version': 75279, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:40,950] calculate_sps 33920 steps in 10.0326
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:40,950] calculate_sps 30720 steps in 10.0326
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:40,950] {'local/mean_episode_return': 46200.0, 'local/mean_episode_step': 4598.833333333333, 'local/SPS': 3380.9689574499093, 'local/env_act_steps': 48215680, 'local/env_train_steps': 48213120, 'local/optimizer_steps': 75332, 'local/running_reward': 24115.17156862745, 'local/running_step': 2465.146844362745, 'local/steps_done': 48215680, 'local/episodes_done': 11233, 'local/unclipped_grad_norm': 0.7703525974200323, 'local/model_version': 75332, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:40,951] {'global/mean_episode_return': 44371.42857142857, 'global/mean_episode_step': 4489.0, 'global/SPS': 3062.0096218414274, 'global/env_act_steps': 48214144, 'global/env_train_steps': 48209920, 'global/optimizer_steps': 75328, 'global/running_reward': 24103.610321969696, 'global/running_step': 2463.912168560606, 'global/steps_done': 48214144, 'global/episodes_done': 11233, 'global/unclipped_grad_norm': 0.7491129946951963, 'global/model_version': 75328, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:50,958] calculate_sps 32640 steps in 10.0075
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:21:50,958] calculate_sps 35840 steps in 10.0075
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:50,970] {'local/mean_episode_return': 46080.0, 'local/mean_episode_step': 4658.6, 'local/SPS': 3261.5699410281863, 'local/env_act_steps': 48248832, 'local/env_train_steps': 48245760, 'local/optimizer_steps': 75384, 'local/running_reward': 24588.000723938225, 'local/running_step': 2508.287976592664, 'local/steps_done': 48248832, 'local/episodes_done': 11238, 'local/unclipped_grad_norm': 0.7649307417181822, 'local/model_version': 75384, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:21:50,972] {'global/mean_episode_return': 46080.0, 'global/mean_episode_step': 4658.6, 'global/SPS': 3581.3316999525186, 'global/env_act_steps': 48246784, 'global/env_train_steps': 48245760, 'global/optimizer_steps': 75383, 'global/running_reward': 24567.751225490196, 'global/running_step': 2506.4311580882354, 'global/steps_done': 48246784, 'global/episodes_done': 11238, 'global/unclipped_grad_norm': 0.7832243588837711, 'global/model_version': 75383, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:00,964] calculate_sps 31360 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:00,965] calculate_sps 30720 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:00,965] {'local/mean_episode_return': 45600.0, 'local/mean_episode_step': 4657.5, 'local/SPS': 3133.9671785578767, 'local/env_act_steps': 48281856, 'local/env_train_steps': 48277120, 'local/optimizer_steps': 75433, 'local/running_reward': 24751.211240310076, 'local/running_step': 2521.5806383236436, 'local/steps_done': 48281856, 'local/episodes_done': 11248, 'local/unclipped_grad_norm': 0.8067821544043872, 'local/model_version': 75433, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:00,966] {'global/mean_episode_return': 45600.0, 'global/mean_episode_step': 4657.5, 'global/SPS': 3070.0086647097564, 'global/env_act_steps': 48280320, 'global/env_train_steps': 48276480, 'global/optimizer_steps': 75432, 'global/running_reward': 24772.346135496184, 'global/running_step': 2523.8454496660306, 'global/steps_done': 48280320, 'global/episodes_done': 11248, 'global/unclipped_grad_norm': 0.8094654472506776, 'global/model_version': 75432, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:10,987] calculate_sps 35200 steps in 10.0231
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:10,987] calculate_sps 33920 steps in 10.0231
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:10,988] {'local/mean_episode_return': 46942.857142857145, 'local/mean_episode_step': 4723.142857142857, 'local/SPS': 3511.8968476956024, 'local/env_act_steps': 48313984, 'local/env_train_steps': 48312320, 'local/optimizer_steps': 75488, 'local/running_reward': 23837.84860557769, 'local/running_step': 2432.2268737549803, 'local/steps_done': 48313984, 'local/episodes_done': 11255, 'local/unclipped_grad_norm': 0.8314954389225353, 'local/model_version': 75488, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:10,989] {'global/mean_episode_return': 46942.857142857145, 'global/mean_episode_step': 4723.142857142857, 'global/SPS': 3384.1915077793988, 'global/env_act_steps': 48312960, 'global/env_train_steps': 48310400, 'global/optimizer_steps': 75484, 'global/running_reward': 23844.166666666668, 'global/running_step': 2432.779993872549, 'global/steps_done': 48312960, 'global/episodes_done': 11255, 'global/unclipped_grad_norm': 0.8354900009357012, 'global/model_version': 75484, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:21,016] calculate_sps 30720 steps in 10.0286
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:21,016] calculate_sps 32640 steps in 10.0286
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:21,016] {'local/mean_episode_return': 46800.0, 'local/mean_episode_step': 4801.2, 'local/SPS': 3063.235210398789, 'local/env_act_steps': 48346880, 'local/env_train_steps': 48343040, 'local/optimizer_steps': 75536, 'local/running_reward': 24396.200145914398, 'local/running_step': 2486.619406614786, 'local/steps_done': 48346880, 'local/episodes_done': 11260, 'local/unclipped_grad_norm': 0.7665913744519154, 'local/model_version': 75536, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:21,018] {'global/mean_episode_return': 46800.0, 'global/mean_episode_step': 4801.2, 'global/SPS': 3254.6874110487133, 'global/env_act_steps': 48345984, 'global/env_train_steps': 48343040, 'global/optimizer_steps': 75536, 'global/running_reward': 24382.21293604651, 'global/running_step': 2485.3310925387595, 'global/steps_done': 48345984, 'global/episodes_done': 11260, 'global/unclipped_grad_norm': 0.7591322941275743, 'global/model_version': 75536, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:31,022] calculate_sps 33280 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:31,046] calculate_sps 32000 steps in 10.0049
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:31,046] {'local/mean_episode_return': 44025.0, 'local/mean_episode_step': 4535.625, 'local/SPS': 3326.384274796714, 'local/env_act_steps': 48379520, 'local/env_train_steps': 48376320, 'local/optimizer_steps': 75587, 'local/running_reward': 24810.75980392157, 'local/running_step': 2525.770649509804, 'local/steps_done': 48379520, 'local/episodes_done': 11268, 'local/unclipped_grad_norm': 0.7446525196234385, 'local/model_version': 75587, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:31,047] {'global/mean_episode_return': 44025.0, 'global/mean_episode_step': 4535.625, 'global/SPS': 3198.4464180737637, 'global/env_act_steps': 48379136, 'global/env_train_steps': 48375040, 'global/optimizer_steps': 75585, 'global/running_reward': 24814.225386100385, 'global/running_step': 2526.066451496139, 'global/steps_done': 48379136, 'global/episodes_done': 11268, 'global/unclipped_grad_norm': 0.7396005106215574, 'global/model_version': 75585, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:41,035] calculate_sps 33280 steps in 10.014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:41,035] calculate_sps 34560 steps in 10.014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:41,035] {'local/mean_episode_return': 52291.666666666664, 'local/mean_episode_step': 5047.291666666667, 'local/SPS': 3323.3534265757876, 'local/env_act_steps': 48411776, 'local/env_train_steps': 48409600, 'local/optimizer_steps': 75640, 'local/running_reward': 23883.30853174603, 'local/running_step': 2437.5027901785716, 'local/steps_done': 48411776, 'local/episodes_done': 11281, 'local/unclipped_grad_norm': 0.7748381146844828, 'local/model_version': 75640, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:41,037] {'global/mean_episode_return': 52291.666666666664, 'global/mean_episode_step': 5047.291666666667, 'global/SPS': 3451.174712213318, 'global/env_act_steps': 48411392, 'global/env_train_steps': 48409600, 'global/optimizer_steps': 75640, 'global/running_reward': 23896.70138888889, 'global/running_step': 2438.6929563492063, 'global/steps_done': 48411392, 'global/episodes_done': 11281, 'global/unclipped_grad_norm': 0.7782413374293934, 'global/model_version': 75640, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:51,048] calculate_sps 30720 steps in 10.0138
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:22:51,049] calculate_sps 25600 steps in 10.0138
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:51,049] {'local/mean_episode_return': 50044.444444444445, 'local/mean_episode_step': 4977.666666666667, 'local/SPS': 3067.776517695479, 'local/env_act_steps': 48444672, 'local/env_train_steps': 48440320, 'local/optimizer_steps': 75688, 'local/running_reward': 22551.04571984436, 'local/running_step': 2321.9601471303504, 'local/steps_done': 48444672, 'local/episodes_done': 11290, 'local/unclipped_grad_norm': 0.828913883616527, 'local/model_version': 75688, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:22:51,050] {'global/mean_episode_return': 49975.0, 'global/mean_episode_step': 4950.625, 'global/SPS': 2556.480431412899, 'global/env_act_steps': 48438016, 'global/env_train_steps': 48435200, 'global/optimizer_steps': 75680, 'global/running_reward': 22605.28846153846, 'global/running_step': 2327.1754056490386, 'global/steps_done': 48438016, 'global/episodes_done': 11289, 'global/unclipped_grad_norm': 0.8419949442148209, 'global/model_version': 75680, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:01,055] calculate_sps 34560 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:01,070] calculate_sps 31360 steps in 10.0046
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:01,070] {'local/mean_episode_return': 48928.57142857143, 'local/mean_episode_step': 4807.142857142857, 'local/SPS': 3454.4014873869733, 'local/env_act_steps': 48477056, 'local/env_train_steps': 48474880, 'local/optimizer_steps': 75741, 'local/running_reward': 22387.926136363636, 'local/running_step': 2309.185029644269, 'local/steps_done': 48477056, 'local/episodes_done': 11298, 'local/unclipped_grad_norm': 0.7695382040626598, 'local/model_version': 75741, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:01,072] {'global/mean_episode_return': 48180.0, 'global/mean_episode_step': 4795.4, 'global/SPS': 3134.549497814105, 'global/env_act_steps': 48471168, 'global/env_train_steps': 48466560, 'global/optimizer_steps': 75728, 'global/running_reward': 22451.568532818532, 'global/running_step': 2314.0109194015445, 'global/steps_done': 48471168, 'global/episodes_done': 11295, 'global/unclipped_grad_norm': 0.792754735176762, 'global/model_version': 75728, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:11,067] calculate_sps 32000 steps in 10.0137
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:11,067] calculate_sps 35200 steps in 10.0137
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:11,068] {'local/mean_episode_return': 46628.57142857143, 'local/mean_episode_step': 4693.142857142857, 'local/SPS': 3195.6127888864885, 'local/env_act_steps': 48509824, 'local/env_train_steps': 48506880, 'local/optimizer_steps': 75792, 'local/running_reward': 21809.70458984375, 'local/running_step': 2257.8506774902344, 'local/steps_done': 48509824, 'local/episodes_done': 11306, 'local/unclipped_grad_norm': 0.7969740635039759, 'local/model_version': 75792, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:11,069] {'global/mean_episode_return': 47860.0, 'global/mean_episode_step': 4771.9, 'global/SPS': 3515.1740677751377, 'global/env_act_steps': 48503680, 'global/env_train_steps': 48501760, 'global/optimizer_steps': 75784, 'global/running_reward': 21854.595226377955, 'global/running_step': 2261.9001906988187, 'global/steps_done': 48503680, 'global/episodes_done': 11306, 'global/unclipped_grad_norm': 0.7747981138527393, 'global/model_version': 75784, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:21,075] calculate_sps 30720 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:21,075] calculate_sps 30720 steps in 10.008
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:21,075] {'local/mean_episode_return': 49700.0, 'local/mean_episode_step': 5033.5, 'local/SPS': 3069.5536830195833, 'local/env_act_steps': 48542720, 'local/env_train_steps': 48537600, 'local/optimizer_steps': 75840, 'local/running_reward': 22026.92120622568, 'local/running_step': 2279.5065965466924, 'local/steps_done': 48542720, 'local/episodes_done': 11312, 'local/unclipped_grad_norm': 0.7936665869007508, 'local/model_version': 75840, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:21,077] {'global/mean_episode_return': 50250.0, 'global/mean_episode_step': 5096.75, 'global/SPS': 3069.5536830195833, 'global/env_act_steps': 48536832, 'global/env_train_steps': 48532480, 'global/optimizer_steps': 75832, 'global/running_reward': 21967.9597007722, 'global/running_step': 2274.0745053088804, 'global/steps_done': 48536832, 'global/episodes_done': 11310, 'global/unclipped_grad_norm': 0.7940796247373024, 'global/model_version': 75832, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:31,095] calculate_sps 35840 steps in 10.0197
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:31,095] calculate_sps 35200 steps in 10.0197
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:31,095] {'local/mean_episode_return': 44850.0, 'local/mean_episode_step': 4560.875, 'local/SPS': 3576.950660191264, 'local/env_act_steps': 48575104, 'local/env_train_steps': 48573440, 'local/optimizer_steps': 75896, 'local/running_reward': 21955.32979249012, 'local/running_step': 2266.997159090909, 'local/steps_done': 48575104, 'local/episodes_done': 11320, 'local/unclipped_grad_norm': 0.7431982415063041, 'local/model_version': 75896, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:31,096] {'global/mean_episode_return': 44377.77777777778, 'global/mean_episode_step': 4545.0, 'global/SPS': 3513.076541259277, 'global/env_act_steps': 48569344, 'global/env_train_steps': 48567680, 'global/optimizer_steps': 75887, 'global/running_reward': 21985.519192913387, 'global/running_step': 2270.8307086614172, 'global/steps_done': 48569344, 'global/episodes_done': 11319, 'global/unclipped_grad_norm': 0.718291641365398, 'global/model_version': 75887, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:41,126] calculate_sps 30720 steps in 10.0314
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:41,126] calculate_sps 31360 steps in 10.0314
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:41,126] {'local/mean_episode_return': 46866.666666666664, 'local/mean_episode_step': 4665.166666666667, 'local/SPS': 3062.3801941281, 'local/env_act_steps': 48608768, 'local/env_train_steps': 48604160, 'local/optimizer_steps': 75944, 'local/running_reward': 21812.87428707224, 'local/running_step': 2253.5883436311788, 'local/steps_done': 48608768, 'local/episodes_done': 11326, 'local/unclipped_grad_norm': 0.6941038028647503, 'local/model_version': 75944, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:41,128] {'global/mean_episode_return': 48257.142857142855, 'global/mean_episode_step': 4769.571428571428, 'global/SPS': 3126.1797815057685, 'global/env_act_steps': 48603264, 'global/env_train_steps': 48599040, 'global/optimizer_steps': 75936, 'global/running_reward': 21804.174528301886, 'global/running_step': 2252.153567216981, 'global/steps_done': 48603264, 'global/episodes_done': 11326, 'global/unclipped_grad_norm': 0.7200337678802257, 'global/model_version': 75936, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:51,152] calculate_sps 34560 steps in 10.0268
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:23:51,153] calculate_sps 34560 steps in 10.0268
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:51,153] {'local/mean_episode_return': 45171.42857142857, 'local/mean_episode_step': 4691.714285714285, 'local/SPS': 3446.7699167661367, 'local/env_act_steps': 48640768, 'local/env_train_steps': 48638720, 'local/optimizer_steps': 75997, 'local/running_reward': 22003.95625, 'local/running_step': 2274.1550625, 'local/steps_done': 48640768, 'local/episodes_done': 11333, 'local/unclipped_grad_norm': 0.8246353173030997, 'local/model_version': 75997, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:23:51,154] {'global/mean_episode_return': 45171.42857142857, 'global/mean_episode_step': 4691.714285714285, 'global/SPS': 3446.7699167661367, 'global/env_act_steps': 48635648, 'global/env_train_steps': 48633600, 'global/optimizer_steps': 75989, 'global/running_reward': 22001.27223320158, 'global/running_step': 2274.401000494071, 'global/steps_done': 48635648, 'global/episodes_done': 11333, 'global/unclipped_grad_norm': 0.8195974832435824, 'global/model_version': 75989, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:01,181] calculate_sps 32000 steps in 10.0287
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:01,182] calculate_sps 32000 steps in 10.0287
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:01,182] {'local/mean_episode_return': 47300.0, 'local/mean_episode_step': 4572.0, 'local/SPS': 3190.8430051802507, 'local/env_act_steps': 48673664, 'local/env_train_steps': 48670720, 'local/optimizer_steps': 76048, 'local/running_reward': 22371.248784046693, 'local/running_step': 2309.564354328794, 'local/steps_done': 48673664, 'local/episodes_done': 11335, 'local/unclipped_grad_norm': 0.7876396085701737, 'local/model_version': 76048, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:01,183] {'global/mean_episode_return': 47300.0, 'global/mean_episode_step': 4572.0, 'global/SPS': 3190.8430051802507, 'global/env_act_steps': 48668672, 'global/env_train_steps': 48665600, 'global/optimizer_steps': 76040, 'global/running_reward': 22228.094718992248, 'global/running_step': 2295.0224382267443, 'global/steps_done': 48668672, 'global/episodes_done': 11335, 'global/unclipped_grad_norm': 0.7848098652035582, 'global/model_version': 76040, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:11,203] calculate_sps 31360 steps in 10.0216
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:11,203] calculate_sps 32640 steps in 10.0216
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:11,203] {'local/mean_episode_return': 47400.0, 'local/mean_episode_step': 4678.0, 'local/SPS': 3129.2377849970685, 'local/env_act_steps': 48706688, 'local/env_train_steps': 48702080, 'local/optimizer_steps': 76096, 'local/running_reward': 23330.729166666668, 'local/running_step': 2403.7490915697676, 'local/steps_done': 48706688, 'local/episodes_done': 11341, 'local/unclipped_grad_norm': 0.7875114350269238, 'local/model_version': 76096, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:11,204] {'global/mean_episode_return': 44300.0, 'global/mean_episode_step': 4458.25, 'global/SPS': 3256.9617762214384, 'global/env_act_steps': 48701952, 'global/env_train_steps': 48698240, 'global/optimizer_steps': 76090, 'global/running_reward': 23251.905048076922, 'global/running_step': 2396.156610576923, 'global/steps_done': 48701952, 'global/episodes_done': 11339, 'global/unclipped_grad_norm': 0.7877311736345292, 'global/model_version': 76090, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:21,227] calculate_sps 35200 steps in 10.0241
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:21,227] calculate_sps 33920 steps in 10.0241
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:21,228] {'local/mean_episode_return': 51311.11111111111, 'local/mean_episode_step': 5096.888888888889, 'local/SPS': 3511.5339152199062, 'local/env_act_steps': 48738816, 'local/env_train_steps': 48737280, 'local/optimizer_steps': 76152, 'local/running_reward': 22973.144920318726, 'local/running_step': 2367.444036354582, 'local/steps_done': 48738816, 'local/episodes_done': 11350, 'local/unclipped_grad_norm': 0.8731899719153132, 'local/model_version': 76152, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:21,235] {'global/mean_episode_return': 51340.0, 'global/mean_episode_step': 5074.9, 'global/SPS': 3383.841772848273, 'global/env_act_steps': 48734592, 'global/env_train_steps': 48732160, 'global/optimizer_steps': 76144, 'global/running_reward': 23072.267156862745, 'global/running_step': 2377.6245404411766, 'global/steps_done': 48734592, 'global/episodes_done': 11349, 'global/unclipped_grad_norm': 0.8609651078780493, 'global/model_version': 76144, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:31,248] calculate_sps 30720 steps in 10.0208
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:31,248] calculate_sps 31360 steps in 10.0208
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:31,248] {'local/mean_episode_return': 46066.666666666664, 'local/mean_episode_step': 4727.333333333333, 'local/SPS': 3065.6353573493334, 'local/env_act_steps': 48772352, 'local/env_train_steps': 48768000, 'local/optimizer_steps': 76200, 'local/running_reward': 23066.835639312976, 'local/running_step': 2377.5152969942746, 'local/steps_done': 48772352, 'local/episodes_done': 11353, 'local/unclipped_grad_norm': 0.7610185947269201, 'local/model_version': 76200, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:31,250] {'global/mean_episode_return': 48450.0, 'global/mean_episode_step': 4885.0, 'global/SPS': 3129.5027606274443, 'global/env_act_steps': 48768128, 'global/env_train_steps': 48763520, 'global/optimizer_steps': 76192, 'global/running_reward': 22988.984971374044, 'global/running_step': 2369.379204437023, 'global/steps_done': 48768128, 'global/episodes_done': 11353, 'global/unclipped_grad_norm': 0.7848142093668381, 'global/model_version': 76192, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:41,279] calculate_sps 35840 steps in 10.0314
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:41,279] calculate_sps 35200 steps in 10.0314
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:41,280] {'local/mean_episode_return': 46750.0, 'local/mean_episode_step': 4646.125, 'local/SPS': 3572.776978064349, 'local/env_act_steps': 48804864, 'local/env_train_steps': 48803840, 'local/optimizer_steps': 76255, 'local/running_reward': 23237.721456692914, 'local/running_step': 2397.2816806102364, 'local/steps_done': 48804864, 'local/episodes_done': 11361, 'local/unclipped_grad_norm': 0.8191821889443831, 'local/model_version': 76255, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:41,281] {'global/mean_episode_return': 45628.57142857143, 'global/mean_episode_step': 4539.285714285715, 'global/SPS': 3508.9773891703426, 'global/env_act_steps': 48801024, 'global/env_train_steps': 48798720, 'global/optimizer_steps': 76248, 'global/running_reward': 23259.229085603114, 'global/running_step': 2399.1623601653696, 'global/steps_done': 48801024, 'global/episodes_done': 11360, 'global/unclipped_grad_norm': 0.8192985212164265, 'global/model_version': 76248, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:51,304] calculate_sps 30720 steps in 10.0243
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:24:51,304] calculate_sps 30720 steps in 10.0243
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:51,304] {'local/mean_episode_return': 49125.0, 'local/mean_episode_step': 4927.5, 'local/SPS': 3064.548368110217, 'local/env_act_steps': 48838272, 'local/env_train_steps': 48834560, 'local/optimizer_steps': 76304, 'local/running_reward': 23439.24209770115, 'local/running_step': 2415.0701927681994, 'local/steps_done': 48838272, 'local/episodes_done': 11369, 'local/unclipped_grad_norm': 0.7838306335770354, 'local/model_version': 76304, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:24:51,315] {'global/mean_episode_return': 47500.0, 'global/mean_episode_step': 4900.5, 'global/SPS': 3064.548368110217, 'global/env_act_steps': 48834688, 'global/env_train_steps': 48829440, 'global/optimizer_steps': 76296, 'global/running_reward': 23424.435598859316, 'global/running_step': 2414.0245960076045, 'global/steps_done': 48834688, 'global/episodes_done': 11366, 'global/unclipped_grad_norm': 0.7491635574648777, 'global/model_version': 76296, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:01,352] calculate_sps 33920 steps in 10.0492
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:01,353] calculate_sps 35840 steps in 10.0492
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:01,353] {'local/mean_episode_return': 49371.42857142857, 'local/mean_episode_step': 4852.285714285715, 'local/SPS': 3375.3835169506915, 'local/env_act_steps': 48871040, 'local/env_train_steps': 48868480, 'local/optimizer_steps': 76356, 'local/running_reward': 23002.57568359375, 'local/running_step': 2372.1452026367188, 'local/steps_done': 48871040, 'local/episodes_done': 11376, 'local/unclipped_grad_norm': 0.7391718729184225, 'local/model_version': 76356, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:01,354] {'global/mean_episode_return': 49977.77777777778, 'global/mean_episode_step': 4888.666666666667, 'global/SPS': 3566.442961306391, 'global/env_act_steps': 48867200, 'global/env_train_steps': 48865280, 'global/optimizer_steps': 76352, 'global/running_reward': 23040.15748031496, 'global/running_step': 2375.5559178149606, 'global/steps_done': 48867200, 'global/episodes_done': 11375, 'global/unclipped_grad_norm': 0.7773556975381715, 'global/model_version': 76352, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:11,362] calculate_sps 32640 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:11,362] calculate_sps 30720 steps in 10.009
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:11,362] {'local/mean_episode_return': 39525.0, 'local/mean_episode_step': 4203.625, 'local/SPS': 3261.0756631412014, 'local/env_act_steps': 48903680, 'local/env_train_steps': 48901120, 'local/optimizer_steps': 76408, 'local/running_reward': 22657.077205882353, 'local/running_step': 2335.6633272058825, 'local/steps_done': 48903680, 'local/episodes_done': 11385, 'local/unclipped_grad_norm': 0.7862271821269622, 'local/model_version': 76408, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:11,375] {'global/mean_episode_return': 42325.0, 'global/mean_episode_step': 4380.375, 'global/SPS': 3069.247682956425, 'global/env_act_steps': 48900608, 'global/env_train_steps': 48896000, 'global/optimizer_steps': 76400, 'global/running_reward': 22679.346264367818, 'global/running_step': 2338.3478807471265, 'global/steps_done': 48900608, 'global/episodes_done': 11384, 'global/unclipped_grad_norm': 0.8043013208856186, 'global/model_version': 76400, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:21,366] calculate_sps 30720 steps in 10.0037
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:21,366] calculate_sps 35840 steps in 10.0037
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:21,366] {'local/mean_episode_return': 46766.666666666664, 'local/mean_episode_step': 4533.166666666667, 'local/SPS': 3070.8568220515367, 'local/env_act_steps': 48936960, 'local/env_train_steps': 48931840, 'local/optimizer_steps': 76456, 'local/running_reward': 22883.984375, 'local/running_step': 2357.170012019231, 'local/steps_done': 48936960, 'local/episodes_done': 11389, 'local/unclipped_grad_norm': 0.8845832869410515, 'local/model_version': 76456, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:21,379] {'global/mean_episode_return': 44075.0, 'global/mean_episode_step': 4391.125, 'global/SPS': 3582.6662923934596, 'global/env_act_steps': 48933120, 'global/env_train_steps': 48931840, 'global/optimizer_steps': 76456, 'global/running_reward': 22833.778297244095, 'global/running_step': 2351.90640378937, 'global/steps_done': 48933120, 'global/episodes_done': 11389, 'global/unclipped_grad_norm': 0.8496620974370411, 'global/model_version': 76456, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:31,383] calculate_sps 35840 steps in 10.0176
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:31,383] calculate_sps 30720 steps in 10.0176
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:31,384] {'local/mean_episode_return': 42300.0, 'local/mean_episode_step': 4362.75, 'local/SPS': 3577.7009220126183, 'local/env_act_steps': 48969088, 'local/env_train_steps': 48967680, 'local/optimizer_steps': 76512, 'local/running_reward': 23473.823456175298, 'local/running_step': 2415.6030253984063, 'local/steps_done': 48969088, 'local/episodes_done': 11393, 'local/unclipped_grad_norm': 0.8598053221191678, 'local/model_version': 76512, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:31,385] {'global/mean_episode_return': 42300.0, 'global/mean_episode_step': 4362.75, 'global/SPS': 3066.6007902965302, 'global/env_act_steps': 48966656, 'global/env_train_steps': 48962560, 'global/optimizer_steps': 76504, 'global/running_reward': 23416.960877862595, 'global/running_step': 2410.2972328244273, 'global/steps_done': 48966656, 'global/episodes_done': 11393, 'global/unclipped_grad_norm': 0.8516990145047506, 'global/model_version': 76504, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:41,405] calculate_sps 30720 steps in 10.0223
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:41,406] calculate_sps 35200 steps in 10.0223
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:41,406] {'local/mean_episode_return': 54488.88888888889, 'local/mean_episode_step': 5248.0, 'local/SPS': 3065.1734312597687, 'local/env_act_steps': 49002496, 'local/env_train_steps': 48998400, 'local/optimizer_steps': 76560, 'local/running_reward': 23646.018917624522, 'local/running_step': 2433.9888948754788, 'local/steps_done': 49002496, 'local/episodes_done': 11402, 'local/unclipped_grad_norm': 0.8852808543791374, 'local/model_version': 76560, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:41,407] {'global/mean_episode_return': 53800.0, 'global/mean_episode_step': 5229.625, 'global/SPS': 3512.1778899851515, 'global/env_act_steps': 48999296, 'global/env_train_steps': 48997760, 'global/optimizer_steps': 76558, 'global/running_reward': 23677.916666666668, 'global/running_step': 2436.6011642156864, 'global/steps_done': 48999296, 'global/episodes_done': 11401, 'global/unclipped_grad_norm': 0.8977595109630514, 'global/model_version': 76558, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:51,448] calculate_sps 34560 steps in 10.0427
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:25:51,448] calculate_sps 31360 steps in 10.0427
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:51,448] {'local/mean_episode_return': 48800.0, 'local/mean_episode_step': 4946.0, 'local/SPS': 3441.3062606593317, 'local/env_act_steps': 49035008, 'local/env_train_steps': 49032960, 'local/optimizer_steps': 76613, 'local/running_reward': 23741.117125984252, 'local/running_step': 2448.768885334646, 'local/steps_done': 49035008, 'local/episodes_done': 11403, 'local/unclipped_grad_norm': 0.7637417603213832, 'local/model_version': 76613, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:25:51,449] {'global/mean_episode_return': 54400.0, 'global/mean_episode_step': 5170.5, 'global/SPS': 3122.666792079764, 'global/env_act_steps': 49033088, 'global/env_train_steps': 49029120, 'global/optimizer_steps': 76608, 'global/running_reward': 23679.385653409092, 'global/running_step': 2442.5834812973485, 'global/steps_done': 49033088, 'global/episodes_done': 11403, 'global/unclipped_grad_norm': 0.7437351411581039, 'global/model_version': 76608, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 15:25:52,525] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 49033088, 'env_train_steps': 49029120, 'optimizer_steps': 76608, 'running_reward': None, 'running_step': None, 'steps_done': 49033088, 'episodes_done': 11403, 'unclipped_grad_norm': None, 'model_version': 76608, 'virtual_batch_size': None, 'num_gradients': None}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 15:25:52,630] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:01,475] calculate_sps 32000 steps in 10.0272
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:01,476] calculate_sps 33280 steps in 10.0272
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:01,476] {'local/mean_episode_return': 44350.0, 'local/mean_episode_step': 4439.75, 'local/SPS': 3191.331680939609, 'local/env_act_steps': 49068032, 'local/env_train_steps': 49064960, 'local/optimizer_steps': 76664, 'local/running_reward': 24527.325581395347, 'local/running_step': 2524.564801356589, 'local/steps_done': 49068032, 'local/episodes_done': 11407, 'local/unclipped_grad_norm': 0.6938929534425923, 'local/model_version': 76664, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:01,478] {'global/mean_episode_return': 44350.0, 'global/mean_episode_step': 4439.75, 'global/SPS': 3318.984948177194, 'global/env_act_steps': 49065600, 'global/env_train_steps': 49062400, 'global/optimizer_steps': 76660, 'global/running_reward': 24482.941683070865, 'global/running_step': 2520.278635580709, 'global/steps_done': 49065600, 'global/episodes_done': 11407, 'global/unclipped_grad_norm': 0.732568923670512, 'global/model_version': 76660, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:11,476] calculate_sps 31360 steps in 10.0001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:11,490] calculate_sps 33280 steps in 10.0001
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:11,490] {'local/mean_episode_return': 44342.857142857145, 'local/mean_episode_step': 4541.285714285715, 'local/SPS': 3135.977195905572, 'local/env_act_steps': 49101056, 'local/env_train_steps': 49096320, 'local/optimizer_steps': 76713, 'local/running_reward': 24818.362403100775, 'local/running_step': 2548.8258539244184, 'local/steps_done': 49101056, 'local/episodes_done': 11414, 'local/unclipped_grad_norm': 0.884038184978524, 'local/model_version': 76713, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:11,492] {'global/mean_episode_return': 44342.857142857145, 'global/mean_episode_step': 4541.285714285715, 'global/SPS': 3327.9757997365255, 'global/env_act_steps': 49098496, 'global/env_train_steps': 49095680, 'global/optimizer_steps': 76712, 'global/running_reward': 24816.032344357976, 'global/running_step': 2548.8687682392997, 'global/steps_done': 49098496, 'global/episodes_done': 11414, 'global/unclipped_grad_norm': 0.8583703969533627, 'global/model_version': 76712, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:21,504] calculate_sps 35200 steps in 10.0282
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:21,504] calculate_sps 32640 steps in 10.0282
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:21,504] {'local/mean_episode_return': 47960.0, 'local/mean_episode_step': 4716.6, 'local/SPS': 3510.095119049306, 'local/env_act_steps': 49133568, 'local/env_train_steps': 49131520, 'local/optimizer_steps': 76768, 'local/running_reward': 25180.50565944882, 'local/running_step': 2584.552688238189, 'local/steps_done': 49133568, 'local/episodes_done': 11419, 'local/unclipped_grad_norm': 0.8144376158714295, 'local/model_version': 76768, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:21,506] {'global/mean_episode_return': 47960.0, 'global/mean_episode_step': 4716.6, 'global/SPS': 3254.815474027538, 'global/env_act_steps': 49131904, 'global/env_train_steps': 49128320, 'global/optimizer_steps': 76762, 'global/running_reward': 25155.699233716474, 'global/running_step': 2582.1781010536397, 'global/steps_done': 49131904, 'global/episodes_done': 11419, 'global/unclipped_grad_norm': 0.8337623077630997, 'global/model_version': 76762, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:31,515] calculate_sps 30720 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:31,515] calculate_sps 33920 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:31,516] {'local/mean_episode_return': 48292.307692307695, 'local/mean_episode_step': 4797.384615384615, 'local/SPS': 3068.4201433350095, 'local/env_act_steps': 49166976, 'local/env_train_steps': 49162240, 'local/optimizer_steps': 76816, 'local/running_reward': 24631.42361111111, 'local/running_step': 2533.8444085249043, 'local/steps_done': 49166976, 'local/episodes_done': 11432, 'local/unclipped_grad_norm': 0.8454184960573912, 'local/model_version': 76816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:31,517] {'global/mean_episode_return': 48292.307692307695, 'global/mean_episode_step': 4797.384615384615, 'global/SPS': 3388.047241599073, 'global/env_act_steps': 49165056, 'global/env_train_steps': 49162240, 'global/optimizer_steps': 76816, 'global/running_reward': 24699.089044401546, 'global/running_step': 2540.054144546332, 'global/steps_done': 49165056, 'global/episodes_done': 11432, 'global/unclipped_grad_norm': 0.8192069872661873, 'global/model_version': 76816, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:41,517] calculate_sps 35840 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:41,518] calculate_sps 32640 steps in 10.0021
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:41,519] {'local/mean_episode_return': 50375.0, 'local/mean_episode_step': 5078.5, 'local/SPS': 3583.234623932938, 'local/env_act_steps': 49199232, 'local/env_train_steps': 49198080, 'local/optimizer_steps': 76872, 'local/running_reward': 24039.130704365078, 'local/running_step': 2479.946831597222, 'local/steps_done': 49199232, 'local/episodes_done': 11440, 'local/unclipped_grad_norm': 0.7745756171643734, 'local/model_version': 76872, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:41,519] {'global/mean_episode_return': 50375.0, 'global/mean_episode_step': 5078.5, 'global/SPS': 3263.302961081783, 'global/env_act_steps': 49198464, 'global/env_train_steps': 49194880, 'global/optimizer_steps': 76866, 'global/running_reward': 24052.286877394636, 'global/running_step': 2481.134997605364, 'global/steps_done': 49198464, 'global/episodes_done': 11440, 'global/unclipped_grad_norm': 0.7820017671585083, 'global/model_version': 76866, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:51,519] calculate_sps 30720 steps in 10.002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:26:51,520] calculate_sps 33920 steps in 10.002
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:51,520] {'local/mean_episode_return': 49400.0, 'local/mean_episode_step': 4977.6, 'local/SPS': 3071.3922833309325, 'local/env_act_steps': 49233408, 'local/env_train_steps': 49228800, 'local/optimizer_steps': 76920, 'local/running_reward': 23781.513342696628, 'local/running_step': 2458.2325901217228, 'local/steps_done': 49233408, 'local/episodes_done': 11445, 'local/unclipped_grad_norm': 0.7610682596762975, 'local/model_version': 76920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:26:51,521] {'global/mean_episode_return': 49400.0, 'global/mean_episode_step': 4977.6, 'global/SPS': 3391.3289795112382, 'global/env_act_steps': 49232000, 'global/env_train_steps': 49228800, 'global/optimizer_steps': 76920, 'global/running_reward': 23767.944895038167, 'global/running_step': 2456.74361879771, 'global/steps_done': 49232000, 'global/episodes_done': 11445, 'global/unclipped_grad_norm': 0.7556930123655884, 'global/model_version': 76920, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:01,532] calculate_sps 35840 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:01,532] calculate_sps 34560 steps in 10.0129
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:01,533] {'local/mean_episode_return': 44625.0, 'local/mean_episode_step': 4444.125, 'local/SPS': 3579.38809558245, 'local/env_act_steps': 49266688, 'local/env_train_steps': 49264640, 'local/optimizer_steps': 76976, 'local/running_reward': 23822.37980769231, 'local/running_step': 2463.6938701923077, 'local/steps_done': 49266688, 'local/episodes_done': 11453, 'local/unclipped_grad_norm': 0.8666411851133619, 'local/model_version': 76976, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:01,546] {'global/mean_episode_return': 44625.0, 'global/mean_episode_step': 4444.125, 'global/SPS': 3451.5528064545056, 'global/env_act_steps': 49265536, 'global/env_train_steps': 49263360, 'global/optimizer_steps': 76973, 'global/running_reward': 23828.99570610687, 'global/running_step': 2464.38528745229, 'global/steps_done': 49265536, 'global/episodes_done': 11453, 'global/unclipped_grad_norm': 0.8499401200492427, 'global/model_version': 76973, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:11,543] calculate_sps 32000 steps in 10.0108
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:11,544] calculate_sps 32000 steps in 10.0108
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:11,544] {'local/mean_episode_return': 50033.333333333336, 'local/mean_episode_step': 4977.0, 'local/SPS': 3196.5355084495877, 'local/env_act_steps': 49300864, 'local/env_train_steps': 49296640, 'local/optimizer_steps': 77026, 'local/running_reward': 24272.261235955055, 'local/running_step': 2508.1370552434455, 'local/steps_done': 49300864, 'local/episodes_done': 11459, 'local/unclipped_grad_norm': 0.7789232170581818, 'local/model_version': 77026, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:11,546] {'global/mean_episode_return': 50033.333333333336, 'global/mean_episode_step': 4977.0, 'global/SPS': 3196.5355084495877, 'global/env_act_steps': 49300096, 'global/env_train_steps': 49295360, 'global/optimizer_steps': 77024, 'global/running_reward': 24264.29398148148, 'global/running_step': 2507.332609953704, 'global/steps_done': 49300096, 'global/episodes_done': 11459, 'global/unclipped_grad_norm': 0.7996963250870798, 'global/model_version': 77024, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:21,552] calculate_sps 34560 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:21,552] calculate_sps 35840 steps in 10.0087
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:21,552] {'local/mean_episode_return': 41700.0, 'local/mean_episode_step': 4309.0, 'local/SPS': 3452.990912655628, 'local/env_act_steps': 49334272, 'local/env_train_steps': 49331200, 'local/optimizer_steps': 77080, 'local/running_reward': 24220.92013888889, 'local/running_step': 2498.786039272031, 'local/steps_done': 49334272, 'local/episodes_done': 11469, 'local/unclipped_grad_norm': 1.1833844940971445, 'local/model_version': 77080, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:21,554] {'global/mean_episode_return': 41700.0, 'global/mean_episode_step': 4309.0, 'global/SPS': 3580.879464976207, 'global/env_act_steps': 49333504, 'global/env_train_steps': 49331200, 'global/optimizer_steps': 77080, 'global/running_reward': 24227.185105363984, 'global/running_step': 2499.618295019157, 'global/steps_done': 49333504, 'global/episodes_done': 11469, 'global/unclipped_grad_norm': 1.1705266242580754, 'global/model_version': 77080, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:31,562] calculate_sps 34560 steps in 10.01
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:31,562] calculate_sps 33920 steps in 10.01
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:31,571] {'local/mean_episode_return': 50133.333333333336, 'local/mean_episode_step': 4877.0, 'local/SPS': 3452.5612710214396, 'local/env_act_steps': 49367936, 'local/env_train_steps': 49365760, 'local/optimizer_steps': 77134, 'local/running_reward': 24389.233602661596, 'local/running_step': 2509.066361692015, 'local/steps_done': 49367936, 'local/episodes_done': 11472, 'local/unclipped_grad_norm': 0.9579769102511583, 'local/model_version': 77134, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:31,572] {'global/mean_episode_return': 50133.333333333336, 'global/mean_episode_step': 4877.0, 'global/SPS': 3388.624951187709, 'global/env_act_steps': 49367680, 'global/env_train_steps': 49365120, 'global/optimizer_steps': 77132, 'global/running_reward': 24377.349602059927, 'global/running_step': 2507.944785814607, 'global/steps_done': 49367680, 'global/episodes_done': 11472, 'global/unclipped_grad_norm': 0.9580367964047652, 'global/model_version': 77132, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:41,563] calculate_sps 32000 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:41,564] calculate_sps 27520 steps in 10.0014
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:41,564] {'local/mean_episode_return': 47733.333333333336, 'local/mean_episode_step': 4874.666666666667, 'local/SPS': 3199.5539714796246, 'local/env_act_steps': 49402112, 'local/env_train_steps': 49397760, 'local/optimizer_steps': 77184, 'local/running_reward': 24831.053370786518, 'local/running_step': 2551.6806530898875, 'local/steps_done': 49402112, 'local/episodes_done': 11481, 'local/unclipped_grad_norm': 0.7896937572956085, 'local/model_version': 77184, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:41,565] {'global/mean_episode_return': 45200.0, 'global/mean_episode_step': 4557.2, 'global/SPS': 2751.6164154724775, 'global/env_act_steps': 49394944, 'global/env_train_steps': 49392640, 'global/optimizer_steps': 77176, 'global/running_reward': 24879.011150234743, 'global/running_step': 2557.52314407277, 'global/steps_done': 49394944, 'global/episodes_done': 11477, 'global/unclipped_grad_norm': 0.8021072413433682, 'global/model_version': 77176, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:51,595] calculate_sps 35840 steps in 10.0314
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:27:51,595] calculate_sps 33280 steps in 10.0314
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:51,595] {'local/mean_episode_return': 47400.0, 'local/mean_episode_step': 4941.4, 'local/SPS': 3572.790479584671, 'local/env_act_steps': 49435008, 'local/env_train_steps': 49433600, 'local/optimizer_steps': 77240, 'local/running_reward': 24680.971546692606, 'local/running_step': 2531.38235651751, 'local/steps_done': 49435008, 'local/episodes_done': 11486, 'local/unclipped_grad_norm': 0.8743882785950389, 'local/model_version': 77240, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:27:51,597] {'global/mean_episode_return': 49800.0, 'global/mean_episode_step': 5147.0, 'global/SPS': 3317.591159614338, 'global/env_act_steps': 49429120, 'global/env_train_steps': 49425920, 'global/optimizer_steps': 77228, 'global/running_reward': 24648.93024344569, 'global/running_step': 2528.693995786517, 'global/steps_done': 49429120, 'global/episodes_done': 11485, 'global/unclipped_grad_norm': 0.8871778433139508, 'global/model_version': 77228, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:01,628] calculate_sps 30720 steps in 10.034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:01,629] calculate_sps 33280 steps in 10.034
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:01,638] {'local/mean_episode_return': 50565.71428571428, 'local/mean_episode_step': 4901.0, 'local/SPS': 3061.5941082742843, 'local/env_act_steps': 49469184, 'local/env_train_steps': 49464320, 'local/optimizer_steps': 77288, 'local/running_reward': 24829.047284644195, 'local/running_step': 2549.2655664794006, 'local/steps_done': 49469184, 'local/episodes_done': 11493, 'local/unclipped_grad_norm': 0.820163290326794, 'local/model_version': 77288, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:01,639] {'global/mean_episode_return': 49893.333333333336, 'global/mean_episode_step': 4830.5, 'global/SPS': 3316.7269506304747, 'global/env_act_steps': 49462784, 'global/env_train_steps': 49459200, 'global/optimizer_steps': 77280, 'global/running_reward': 24833.578897338404, 'global/running_step': 2548.833204610266, 'global/steps_done': 49462784, 'global/episodes_done': 11491, 'global/unclipped_grad_norm': 0.8073507088881272, 'global/model_version': 77280, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:11,632] calculate_sps 35840 steps in 10.0039
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:11,633] calculate_sps 35840 steps in 10.0039
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:11,633] {'local/mean_episode_return': 46575.0, 'local/mean_episode_step': 4799.0, 'local/SPS': 3582.5922645780443, 'local/env_act_steps': 49502080, 'local/env_train_steps': 49500160, 'local/optimizer_steps': 77344, 'local/running_reward': 24956.955252918287, 'local/running_step': 2557.9417862354085, 'local/steps_done': 49502080, 'local/episodes_done': 11501, 'local/unclipped_grad_norm': 0.8933932280966214, 'local/model_version': 77344, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:11,634] {'global/mean_episode_return': 48275.0, 'global/mean_episode_step': 4932.125, 'global/SPS': 3582.5922645780443, 'global/env_act_steps': 49496064, 'global/env_train_steps': 49495040, 'global/optimizer_steps': 77335, 'global/running_reward': 24992.896634615383, 'global/running_step': 2562.6025540865385, 'global/steps_done': 49496064, 'global/episodes_done': 11499, 'global/unclipped_grad_norm': 0.878305625373667, 'global/model_version': 77335, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:21,655] calculate_sps 30720 steps in 10.0224
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:21,655] calculate_sps 30720 steps in 10.0224
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:21,655] {'local/mean_episode_return': 49250.0, 'local/mean_episode_step': 4948.75, 'local/SPS': 3065.131139964136, 'local/env_act_steps': 49536000, 'local/env_train_steps': 49530880, 'local/optimizer_steps': 77392, 'local/running_reward': 24219.251179245282, 'local/running_step': 2483.3372641509436, 'local/steps_done': 49536000, 'local/episodes_done': 11509, 'local/unclipped_grad_norm': 0.8149294201284647, 'local/model_version': 77392, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:21,657] {'global/mean_episode_return': 47720.0, 'global/mean_episode_step': 4846.6, 'global/SPS': 3065.131139964136, 'global/env_act_steps': 49530368, 'global/env_train_steps': 49525760, 'global/optimizer_steps': 77384, 'global/running_reward': 24277.973414179105, 'global/running_step': 2489.3251224347014, 'global/steps_done': 49530368, 'global/episodes_done': 11509, 'global/unclipped_grad_norm': 0.8444076831243477, 'global/model_version': 77384, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:31,661] calculate_sps 35840 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:31,662] calculate_sps 35840 steps in 10.0065
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:31,662] {'local/mean_episode_return': 48828.57142857143, 'local/mean_episode_step': 4932.857142857143, 'local/SPS': 3581.685053345891, 'local/env_act_steps': 49568768, 'local/env_train_steps': 49566720, 'local/optimizer_steps': 77448, 'local/running_reward': 24315.753173828125, 'local/running_step': 2489.909149169922, 'local/steps_done': 49568768, 'local/episodes_done': 11516, 'local/unclipped_grad_norm': 0.8137217552534172, 'local/model_version': 77448, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:31,663] {'global/mean_episode_return': 52160.0, 'global/mean_episode_step': 5255.4, 'global/SPS': 3581.685053345891, 'global/env_act_steps': 49563392, 'global/env_train_steps': 49561600, 'global/optimizer_steps': 77440, 'global/running_reward': 24303.9425872093, 'global/running_step': 2489.078367248062, 'global/steps_done': 49563392, 'global/episodes_done': 11514, 'global/unclipped_grad_norm': 0.8066671900451183, 'global/model_version': 77440, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:41,706] calculate_sps 32000 steps in 10.0454
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:41,706] calculate_sps 32000 steps in 10.0454
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:41,707] {'local/mean_episode_return': 42900.0, 'local/mean_episode_step': 4389.125, 'local/SPS': 3185.537084544356, 'local/env_act_steps': 49602816, 'local/env_train_steps': 49598720, 'local/optimizer_steps': 77497, 'local/running_reward': 24236.924342105263, 'local/running_step': 2481.5913122650377, 'local/steps_done': 49602816, 'local/episodes_done': 11524, 'local/unclipped_grad_norm': 0.7642572364028619, 'local/model_version': 77497, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:41,707] {'global/mean_episode_return': 42420.0, 'global/mean_episode_step': 4336.6, 'global/SPS': 3185.537084544356, 'global/env_act_steps': 49597696, 'global/env_train_steps': 49593600, 'global/optimizer_steps': 77489, 'global/running_reward': 24259.36916977612, 'global/running_step': 2483.904326026119, 'global/steps_done': 49597696, 'global/episodes_done': 11524, 'global/unclipped_grad_norm': 0.7716413182871682, 'global/model_version': 77489, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:51,716] calculate_sps 34560 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:28:51,716] calculate_sps 34560 steps in 10.0096
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:51,717] {'local/mean_episode_return': 49800.0, 'local/mean_episode_step': 4919.0, 'local/SPS': 3452.6986887880526, 'local/env_act_steps': 49636224, 'local/env_train_steps': 49633280, 'local/optimizer_steps': 77552, 'local/running_reward': 24439.56537356322, 'local/running_step': 2502.9505507662834, 'local/steps_done': 49636224, 'local/episodes_done': 11530, 'local/unclipped_grad_norm': 0.825658459555019, 'local/model_version': 77552, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:28:51,727] {'global/mean_episode_return': 52320.0, 'global/mean_episode_step': 5107.8, 'global/SPS': 3452.6986887880526, 'global/env_act_steps': 49631232, 'global/env_train_steps': 49628160, 'global/optimizer_steps': 77544, 'global/running_reward': 24395.467557251908, 'global/running_step': 2498.4762344942746, 'global/steps_done': 49631232, 'global/episodes_done': 11529, 'global/unclipped_grad_norm': 0.8084635935046456, 'global/model_version': 77544, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:01,717] calculate_sps 33920 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:01,717] calculate_sps 34560 steps in 10.0011
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:01,717] {'local/mean_episode_return': 48453.333333333336, 'local/mean_episode_step': 4754.066666666667, 'local/SPS': 3391.6106480295593, 'local/env_act_steps': 49669760, 'local/env_train_steps': 49667200, 'local/optimizer_steps': 77604, 'local/running_reward': 23954.08516221374, 'local/running_step': 2456.301496898855, 'local/steps_done': 49669760, 'local/episodes_done': 11545, 'local/unclipped_grad_norm': 0.8142428547143936, 'local/model_version': 77604, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:01,718] {'global/mean_episode_return': 49106.666666666664, 'global/mean_episode_step': 4812.6, 'global/SPS': 3455.6033017659665, 'global/env_act_steps': 49664768, 'global/env_train_steps': 49662720, 'global/optimizer_steps': 77597, 'global/running_reward': 24200.316078244276, 'global/running_step': 2480.246630486641, 'global/steps_done': 49664768, 'global/episodes_done': 11544, 'global/unclipped_grad_norm': 0.8213852267220335, 'global/model_version': 77597, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:11,744] calculate_sps 32640 steps in 10.0262
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:11,744] calculate_sps 32000 steps in 10.0262
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:11,744] {'local/mean_episode_return': 53800.0, 'local/mean_episode_step': 5151.5, 'local/SPS': 3255.474287090512, 'local/env_act_steps': 49703808, 'local/env_train_steps': 49699840, 'local/optimizer_steps': 77656, 'local/running_reward': 23297.850093984962, 'local/running_step': 2393.8862781954886, 'local/steps_done': 49703808, 'local/episodes_done': 11547, 'local/unclipped_grad_norm': 0.8397516528001199, 'local/model_version': 77656, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:11,745] {'global/mean_episode_return': 45000.0, 'global/mean_episode_step': 4466.666666666667, 'global/SPS': 3191.6414579318744, 'global/env_act_steps': 49699328, 'global/env_train_steps': 49694720, 'global/optimizer_steps': 77648, 'global/running_reward': 23174.20138888889, 'global/running_step': 2381.278298611111, 'global/steps_done': 49699328, 'global/episodes_done': 11547, 'global/unclipped_grad_norm': 0.8546204713045382, 'global/model_version': 77648, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:21,775] calculate_sps 35840 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:21,775] calculate_sps 35840 steps in 10.0317
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:21,775] {'local/mean_episode_return': 47680.0, 'local/mean_episode_step': 4789.0, 'local/SPS': 3572.660138981281, 'local/env_act_steps': 49736704, 'local/env_train_steps': 49735680, 'local/optimizer_steps': 77711, 'local/running_reward': 23927.02456225681, 'local/running_step': 2457.6893847276265, 'local/steps_done': 49736704, 'local/episodes_done': 11552, 'local/unclipped_grad_norm': 0.8437933157790791, 'local/model_version': 77711, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:21,776] {'global/mean_episode_return': 47680.0, 'global/mean_episode_step': 4789.0, 'global/SPS': 3572.660138981281, 'global/env_act_steps': 49732864, 'global/env_train_steps': 49730560, 'global/optimizer_steps': 77704, 'global/running_reward': 23882.36521946565, 'global/running_step': 2452.9808563931297, 'global/steps_done': 49732864, 'global/episodes_done': 11552, 'global/unclipped_grad_norm': 0.8382724401141916, 'global/model_version': 77704, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:31,779] calculate_sps 30720 steps in 10.0036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:31,779] calculate_sps 33280 steps in 10.0036
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:31,779] {'local/mean_episode_return': 50000.0, 'local/mean_episode_step': 4956.384615384615, 'local/SPS': 3070.89092789231, 'local/env_act_steps': 49771264, 'local/env_train_steps': 49766400, 'local/optimizer_steps': 77760, 'local/running_reward': 23977.69675925926, 'local/running_step': 2465.8719618055557, 'local/steps_done': 49771264, 'local/episodes_done': 11565, 'local/unclipped_grad_norm': 0.8880104294845036, 'local/model_version': 77760, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:31,781] {'global/mean_episode_return': 50422.22222222222, 'global/mean_episode_step': 5071.555555555556, 'global/SPS': 3326.7985052166696, 'global/env_act_steps': 49766912, 'global/env_train_steps': 49763840, 'global/optimizer_steps': 77755, 'global/running_reward': 24066.24177631579, 'global/running_step': 2474.5167410714284, 'global/steps_done': 49766912, 'global/episodes_done': 11561, 'global/unclipped_grad_norm': 0.8710213852863685, 'global/model_version': 77755, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:41,813] calculate_sps 35840 steps in 10.0334
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:41,813] calculate_sps 33280 steps in 10.0334
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:41,813] {'local/mean_episode_return': 50373.333333333336, 'local/mean_episode_step': 5032.966666666666, 'local/SPS': 3572.0554320689685, 'local/env_act_steps': 49804416, 'local/env_train_steps': 49802240, 'local/optimizer_steps': 77816, 'local/running_reward': 21905.4777992278, 'local/running_step': 2266.3740649131273, 'local/steps_done': 49804416, 'local/episodes_done': 11581, 'local/unclipped_grad_norm': 0.7821163982152939, 'local/model_version': 77816, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:41,815] {'global/mean_episode_return': 50787.5, 'global/mean_episode_step': 4966.46875, 'global/SPS': 3316.9086154926135, 'global/env_act_steps': 49800960, 'global/env_train_steps': 49797120, 'global/optimizer_steps': 77808, 'global/running_reward': 22169.155310150374, 'global/running_step': 2291.67695606203, 'global/steps_done': 49800960, 'global/episodes_done': 11578, 'global/unclipped_grad_norm': 0.8054872217043391, 'global/model_version': 77808, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:51,826] calculate_sps 31360 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:29:51,831] calculate_sps 35840 steps in 10.0117
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:51,831] {'local/mean_episode_return': 46355.555555555555, 'local/mean_episode_step': 4764.222222222223, 'local/SPS': 3132.335418248809, 'local/env_act_steps': 49838336, 'local/env_train_steps': 49833600, 'local/optimizer_steps': 77864, 'local/running_reward': 20682.82429245283, 'local/running_step': 2144.0137382075472, 'local/steps_done': 49838336, 'local/episodes_done': 11590, 'local/unclipped_grad_norm': 0.8849818880359331, 'local/model_version': 77864, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:29:51,833] {'global/mean_episode_return': 45509.09090909091, 'global/mean_episode_step': 4754.909090909091, 'global/SPS': 3579.8119065700675, 'global/env_act_steps': 49833984, 'global/env_train_steps': 49832960, 'global/optimizer_steps': 77863, 'global/running_reward': 20743.495639534885, 'global/running_step': 2150.0929929748063, 'global/steps_done': 49833984, 'global/episodes_done': 11589, 'global/unclipped_grad_norm': 0.8398855594071475, 'global/model_version': 77863, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:30:01,840] calculate_sps 35200 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:30:01,841] calculate_sps 30720 steps in 10.0162
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:30:01,841] {'local/mean_episode_return': 47733.333333333336, 'local/mean_episode_step': 4738.666666666667, 'local/SPS': 3514.3030355859137, 'local/env_act_steps': 49871616, 'local/env_train_steps': 49868800, 'local/optimizer_steps': 77920, 'local/running_reward': 20964.356971153848, 'local/running_step': 2176.090234375, 'local/steps_done': 49871616, 'local/episodes_done': 11593, 'local/unclipped_grad_norm': 0.7997677640191146, 'local/model_version': 77920, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:30:01,842] {'global/mean_episode_return': 49750.0, 'global/mean_episode_step': 4902.5, 'global/SPS': 3067.02810378407, 'global/env_act_steps': 49868672, 'global/env_train_steps': 49863680, 'global/optimizer_steps': 77912, 'global/running_reward': 20890.181042435423, 'global/running_step': 2168.189633302583, 'global/steps_done': 49868672, 'global/episodes_done': 11593, 'global/unclipped_grad_norm': 0.8068506200702823, 'global/model_version': 77912, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:30:11,860] calculate_sps 33920 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:30:11,860] calculate_sps 35840 steps in 10.0199
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:30:11,860] {'local/mean_episode_return': 45800.0, 'local/mean_episode_step': 4588.416666666667, 'local/SPS': 3385.256612063934, 'local/env_act_steps': 49905280, 'local/env_train_steps': 49902720, 'local/optimizer_steps': 77972, 'local/running_reward': 21339.638783269962, 'local/running_step': 2218.353225998099, 'local/steps_done': 49905280, 'local/episodes_done': 11600, 'local/unclipped_grad_norm': 0.8032342155392354, 'local/model_version': 77972, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:30:11,861] {'global/mean_episode_return': 45800.0, 'global/mean_episode_step': 4588.416666666667, 'global/SPS': 3576.8749108600055, 'global/env_act_steps': 49902080, 'global/env_train_steps': 49899520, 'global/optimizer_steps': 77968, 'global/running_reward': 21332.136015325672, 'global/running_step': 2217.4311242816093, 'global/steps_done': 49902080, 'global/episodes_done': 11600, 'global/unclipped_grad_norm': 0.8168854324945382, 'global/model_version': 77968, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:30:21,867] calculate_sps 32640 steps in 10.0068
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:30:21,867] calculate_sps 33280 steps in 10.0068
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:30:21,868] {'local/mean_episode_return': 46066.666666666664, 'local/mean_episode_step': 4716.166666666667, 'local/SPS': 3261.7851175800847, 'local/env_act_steps': 49938816, 'local/env_train_steps': 49935360, 'local/optimizer_steps': 78024, 'local/running_reward': 21667.211354961833, 'local/running_step': 2249.571624522901, 'local/steps_done': 49938816, 'local/episodes_done': 11606, 'local/unclipped_grad_norm': 0.8364686920092657, 'local/model_version': 78024, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:30:21,869] {'global/mean_episode_return': 45920.0, 'global/mean_episode_step': 4734.8, 'global/SPS': 3325.741688513028, 'global/env_act_steps': 49935872, 'global/env_train_steps': 49932800, 'global/optimizer_steps': 78019, 'global/running_reward': 21632.267992424244, 'global/running_step': 2246.2699455492425, 'global/steps_done': 49935872, 'global/episodes_done': 11605, 'global/unclipped_grad_norm': 0.8296105557797002, 'global/model_version': 78019, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:30:31,893] calculate_sps 35200 steps in 10.0268
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:30:31,894] calculate_sps 33280 steps in 10.0268
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:30:31,894] {'local/mean_episode_return': 40733.333333333336, 'local/mean_episode_step': 4204.666666666667, 'local/SPS': 3510.5789552539723, 'local/env_act_steps': 49972096, 'local/env_train_steps': 49970560, 'local/optimizer_steps': 78078, 'local/running_reward': 21946.802884615383, 'local/running_step': 2276.0887620192307, 'local/steps_done': 49972096, 'local/episodes_done': 11609, 'local/unclipped_grad_norm': 0.8097900770328663, 'local/model_version': 78078, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:30:31,895] {'global/mean_episode_return': 42250.0, 'global/mean_episode_step': 4309.25, 'global/SPS': 3319.0928304219374, 'global/env_act_steps': 49970048, 'global/env_train_steps': 49966080, 'global/optimizer_steps': 78072, 'global/running_reward': 21901.12944756554, 'global/running_step': 2271.601884363296, 'global/steps_done': 49970048, 'global/episodes_done': 11609, 'global/unclipped_grad_norm': 0.8115543858060297, 'global/model_version': 78072, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:30:41,912] calculate_sps 31360 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:208 2021-12-02 15:30:41,912] calculate_sps 35840 steps in 10.0179
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:30:41,912] {'local/mean_episode_return': 49650.0, 'local/mean_episode_step': 4978.25, 'local/SPS': 3130.3892176100667, 'local/env_act_steps': 50006656, 'local/env_train_steps': 50001920, 'local/optimizer_steps': 78128, 'local/running_reward': 22803.275462962964, 'local/running_step': 2361.511400462963, 'local/steps_done': 50006656, 'local/episodes_done': 11613, 'local/unclipped_grad_norm': 0.8028159701824188, 'local/model_version': 78128, 'local/virtual_batch_size': 32.0, 'local/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:177 2021-12-02 15:30:41,914] {'global/mean_episode_return': 50066.666666666664, 'global/mean_episode_step': 4988.0, 'global/SPS': 3577.5876772686474, 'global/env_act_steps': 50003840, 'global/env_train_steps': 50001920, 'global/optimizer_steps': 78128, 'global/running_reward': 22764.968039772728, 'global/running_step': 2357.6032492897725, 'global/steps_done': 50003840, 'global/episodes_done': 11612, 'global/unclipped_grad_norm': 0.802151772592749, 'global/model_version': 78128, 'global/virtual_batch_size': 32.0, 'global/num_gradients': 1.0}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:369 2021-12-02 15:30:41,944] Stopping training after 50001920 steps
[INFO:learnfair2269:215010:adventurous-cheetah experiment:188 2021-12-02 15:30:41,944] saving global stats {'mean_episode_return': None, 'mean_episode_step': None, 'SPS': None, 'env_act_steps': 50003840, 'env_train_steps': 50001920, 'optimizer_steps': 78128, 'running_reward': None, 'running_step': None, 'steps_done': 50003840, 'episodes_done': 11612, 'unclipped_grad_norm': None, 'model_version': 78128, 'virtual_batch_size': None, 'num_gradients': None}
[INFO:learnfair2269:215010:adventurous-cheetah experiment:198 2021-12-02 15:30:42,035] Checkpoint saved to /checkpoint/hnr/moolib-atari/KungFuMaster-2-just-nightingale-20211202/checkpoint.tar
[INFO:learnfair2269:215010:adventurous-cheetah experiment:531 2021-12-02 15:30:42,036] Graceful exit. Bye bye!
